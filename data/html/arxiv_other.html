<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<!-- new favicon config and versions by realfavicongenerator.net -->
<link rel="apple-touch-icon" sizes="180x180" href="https://static.arxiv.org/static/base/0.17.2.1/images/icons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://static.arxiv.org/static/base/0.17.2.1/images/icons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://static.arxiv.org/static/base/0.17.2.1/images/icons/favicon-16x16.png">
<link rel="manifest" href="https://static.arxiv.org/static/base/0.17.2.1/images/icons/site.webmanifest">
<link rel="mask-icon" href="https://static.arxiv.org/static/base/0.17.2.1/images/icons/safari-pinned-tab.svg" color="#b31b1b">
<link rel="shortcut icon" href="https://static.arxiv.org/static/base/0.17.2.1/images/icons/favicon.ico">
<meta name="msapplication-TileColor" content="#b31b1b">
<meta name="msapplication-config" content="images/icons/browserconfig.xml">
<meta name="theme-color" content="#b31b1b">
<!-- end favicon config -->
<title>Advanced Search | arXiv e-print repository</title>
<script defer src="https://static.arxiv.org/static/base/0.17.2.1/fontawesome-free-5.11.2-web/js/all.js"></script>
<link rel="stylesheet" href="https://static.arxiv.org/static/base/0.17.2.1/css/arxivstyle.css" />
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    messageStyle: "none",
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true,
      ignoreClass: '.*',
      processClass: 'mathjax.*'
    },
    TeX: {
        extensions: ["AMSmath.js", "AMSsymbols.js", "noErrors.js"],
        noErrors: {
          inlineDelimiters: ["$","$"],
          multiLine: false,
          style: {
            "font-size": "normal",
            "border": ""
          }
        }
    },
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>
<script src='//static.arxiv.org/MathJax-2.7.3/MathJax.js'></script>
<script src="https://static.arxiv.org/static/base/0.17.2.1/js/notification.js"></script>

    
  <link rel="stylesheet" href="https://static.arxiv.org/static/search/0.5.6/css/bulma-tooltip.min.css" />
  <link rel="stylesheet" href="https://static.arxiv.org/static/search/0.5.6/css/search.css" />
  <script
    src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
    integrity="sha256-k2WSCIexGzOj3Euiig+TlR8gA0EmPjuc79OEeY5L45g="
    crossorigin="anonymous"></script>

  <script src="https://static.arxiv.org/static/search/0.5.6/js/fieldset.js"></script>
  <style>
  radio#cf-customfield_11400 {
    display: none;
  }
  </style>
  <script type="text/javascript" src="https://arxiv-org.atlassian.net/s/d41d8cd98f00b204e9800998ecf8427e-T/-tqqyqk/b/20/a44af77267a987a660377e5c46e0fb64/_/download/batch/com.atlassian.jira.collector.plugin.jira-issue-collector-plugin:issuecollector/com.atlassian.jira.collector.plugin.jira-issue-collector-plugin:issuecollector.js?locale=en-US&collectorId=3b3dcb4c"></script>

    <script type="text/javascript">
    window.ATL_JQ_PAGE_PROPS =  {
    	"triggerFunction": function(showCollectorDialog) {
    		//Requires that jQuery is available!
    		$("#feedback-button").click(function(e) {
    			e.preventDefault();
    			showCollectorDialog();
    		});
    	},
      fieldValues: {
        "components": ["16000"],  // Search component.
        "versions": ["14260"],  // Release search-0.5.6
        "customfield_11401": window.location.href
      }
    };
    </script>

    <!-- Pendo -->
    <script>
     (function(apiKey){
         (function(p,e,n,d,o){var v,w,x,y,z;o=p[d]=p[d]||{};o._q=[];
             v=['initialize','identify','updateOptions','pageLoad'];for(w=0,x=v.length;w<x;++w)(function(m){
                 o[m]=o[m]||function(){o._q[m===v[0]?'unshift':'push']([m].concat([].slice.call(arguments,0)));};})(v[w]);
             y=e.createElement(n);y.async=!0;y.src='https://content.analytics.arxiv.org/agent/static/'+apiKey+'/pendo.js';
             z=e.getElementsByTagName(n)[0];z.parentNode.insertBefore(y,z);})(window,document,'script','pendo');

         // Call this whenever information about your visitors becomes available
         // Please use Strings, Numbers, or Bools for value types.
         pendo.initialize({
             visitor: {
                 id:              'VISITOR-UNIQUE-ID'   // Required if user is logged in
                 // email:        // Recommended if using Pendo Feedback, or NPS Email
                 // full_name:    // Recommended if using Pendo Feedback
                 // role:         // Optional

                 // You can add any additional visitor level key-values here,
                 // as long as it's not one of the above reserved names.
             },

             account: {
                 id:           'ACCOUNT-UNIQUE-ID' // Highly recommended
                 // name:         // Optional
                 // is_paying:    // Recommended if using Pendo Feedback
                 // monthly_value:// Recommended if using Pendo Feedback
                 // planLevel:    // Optional
                 // planPrice:    // Optional
                 // creationDate: // Optional

                 // You can add any additional account level key-values here,
                 // as long as it's not one of the above reserved names.
             }
         });
     })('d6494389-b427-4103-7c76-03182ecc8e60');
    </script>
    <!-- End Pendo -->


  </head>
  <body>
  
  
  <header><a href="#main-container" class="is-sr-only">Skip to main content</a>
    
    <!-- contains Cornell logo and sponsor statement -->
<div class="attribution level is-marginless" role="banner">
  <div class="level-left">
    <a class="level-item" href="https://cornell.edu/"><img src="https://static.arxiv.org/static/base/0.17.2.1/images/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" aria-label="logo" /></a>
  </div>
  <div class="level-right is-marginless"><p class="sponsors level-item is-marginless"><a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a></p></div>
</div>
<!-- contains arXiv identity and search bar -->
<div class="identity level is-marginless">
  <div class="level-left">
    <div class="level-item">
      <a class="arxiv" href="https://arxiv.org/" aria-label="arxiv-logo"><img src="https://static.arxiv.org/static/base/0.17.2.1/images/arxiv-logo-web.svg" alt="arXiv" aria-label="logo" width="85" /></a>
    </div>
  </div>
  
  <div class="search-block level-right">
    <form class="level-item mini-search" method="GET" action="https://arxiv.org/search">
      <div class="field has-addons">
        <div class="control">
          <input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" />
          <p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
        </div>
        <div class="control">
          <div class="select is-small">
            <select name="searchtype" aria-label="Field to search">
              <option value="all" selected="selected">All fields</option>
              <option value="title">Title</option>
              <option value="author">Author</option>
              <option value="abstract">Abstract</option>
              <option value="comments">Comments</option>
              <option value="journal_ref">Journal reference</option>
              <option value="acm_class">ACM classification</option>
              <option value="msc_class">MSC classification</option>
              <option value="report_num">Report number</option>
              <option value="paper_id">arXiv identifier</option>
              <option value="doi">DOI</option>
              <option value="orcid">ORCID</option>
              <option value="author_id">arXiv author ID</option>
              <option value="help">Help pages</option>
              <option value="full_text">Full text</option>
            </select>
          </div>
        </div>
        <input type="hidden" name="source" value="header">
        <button class="button is-small is-cul-darker">Search</button>
      </div>
    </form>
  </div>
</div> <!-- closes identity -->

<div class="container">
    <div class="user-tools is-size-7 has-text-right has-text-weight-bold" role="navigation" aria-label="User menu">
      <a href="https://arxiv.org/login">Login</a>
    </div>
</div>
    
  </header>
  <main class="container" id="main-container">
    


    
  <div class="level is-marginless">
    <div class="level-left">
      <h1 class="title is-clearfix">
    
        Showing 1&ndash;200 of 826 results
    
</h1>
    </div>
    <div class="level-right is-hidden-mobile">
      <!-- feedback for mobile is moved to footer -->
      <span class="help" style="display: inline-block;"><a href="https://github.com/arXiv/arxiv-search/releases">Search v0.5.6 released 2020-02-24</a>&nbsp;&nbsp;</span>
      <button class="button is-small" id="feedback-button">Feedback?</button>
    </div>
  </div>
    <div class="content">
      
  
    

    <div class="columns">
      <div class="column is-two-thirds-tablet">
        <p style="margin-bottom: .5em">Query: <a href="/search/advanced?terms-0-operator=AND&amp;terms-0-term=%28code+OR+program+OR+software+OR+application%29+AND+%28optimize+OR+optimizing+OR+optimization+OR+improve+OR+improving+OR+improvement+OR+automated+OR+automatically+OR+reduce+OR+reducing%29+AND+%28functional+OR+functionality+OR+size+OR+slimming+OR+bloat+OR+debloating%29&amp;terms-0-field=all&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=200&amp;order=-announced_date_first">order: -announced_date_first; size: 200; classification: Computer Science (cs); include_cross_list: True; terms: AND all=(code OR program OR software OR application) AND (optimize OR optimizing OR optimization OR improve OR improving OR improvement OR automated OR automatically OR reduce OR reducing) AND (functional OR functionality OR size OR slimming OR bloat OR debloating)</a></p>
        <div class="buttons">
          <a class="button is-link" href="/search/advanced?terms-0-operator=AND&amp;terms-0-term=%28code+OR+program+OR+software+OR+application%29+AND+%28optimize+OR+optimizing+OR+optimization+OR+improve+OR+improving+OR+improvement+OR+automated+OR+automatically+OR+reduce+OR+reducing%29+AND+%28functional+OR+functionality+OR+size+OR+slimming+OR+bloat+OR+debloating%29&amp;terms-0-field=all&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=200&amp;order=-announced_date_first">Refine query</a><a class="button" href="/search/advanced">New search</a>
        </div>
      </div>
      <div class="column is-one-third-tablet is-hidden-mobile">
        <p class="has-text-right" style="margin-top: 1em">
          
          <a href="/search/?order=-announced_date_first&amp;size=200">Simple Search</a>
          
        </p>
      </div>
    </div>

    
        
<div class="level breathe-horizontal">
  <div class="level-left">
    <form method="GET" action="/search/advanced">
      <div style="display: none;">
        
          
            <input id="advanced" name="advanced" type="hidden" value="">
          
        
          
            <ul id="terms"><li><label for="terms-0">Terms-0</label> <table id="terms-0"><tr><th><label for="terms-0-term">Search term...</label></th><td><input id="terms-0-term" name="terms-0-term" type="text" value="(code OR program OR software OR application) AND (optimize OR optimizing OR optimization OR improve OR improving OR improvement OR automated OR automatically OR reduce OR reducing) AND (functional OR functionality OR size OR slimming OR bloat OR debloating)"></td></tr><tr><th><label for="terms-0-operator">Operator</label></th><td><select id="terms-0-operator" name="terms-0-operator"><option selected value="AND">AND</option><option value="OR">OR</option><option value="NOT">NOT</option></select></td></tr><tr><th><label for="terms-0-field">Field</label></th><td><select id="terms-0-field" name="terms-0-field"><option value="title">Title</option><option value="author">Author(s)</option><option value="abstract">Abstract</option><option value="comments">Comments</option><option value="journal_ref">Journal reference</option><option value="acm_class">ACM classification</option><option value="msc_class">MSC classification</option><option value="report_num">Report number</option><option value="paper_id">arXiv identifier</option><option value="cross_list_category">Cross-list category</option><option value="doi">DOI</option><option value="orcid">ORCID</option><option value="author_id">arXiv author ID</option><option selected value="all">All fields</option></select></td></tr></table></li></ul>
          
        
          
            <table id="classification"><tr><th><label for="classification-computer_science">Computer Science (cs)</label></th><td><input checked id="classification-computer_science" name="classification-computer_science" type="checkbox" value="y"></td></tr><tr><th><label for="classification-economics">Economics (econ)</label></th><td><input id="classification-economics" name="classification-economics" type="checkbox" value="y"></td></tr><tr><th><label for="classification-eess">Electrical Engineering and Systems Science (eess)</label></th><td><input id="classification-eess" name="classification-eess" type="checkbox" value="y"></td></tr><tr><th><label for="classification-mathematics">Mathematics (math)</label></th><td><input id="classification-mathematics" name="classification-mathematics" type="checkbox" value="y"></td></tr><tr><th><label for="classification-physics">Physics</label></th><td><input id="classification-physics" name="classification-physics" type="checkbox" value="y"></td></tr><tr><th><label for="classification-physics_archives">Physics Archives</label></th><td><select id="classification-physics_archives" name="classification-physics_archives"><option selected value="all">all</option><option value="astro-ph">astro-ph</option><option value="cond-mat">cond-mat</option><option value="gr-qc">gr-qc</option><option value="hep-ex">hep-ex</option><option value="hep-lat">hep-lat</option><option value="hep-ph">hep-ph</option><option value="hep-th">hep-th</option><option value="math-ph">math-ph</option><option value="nlin">nlin</option><option value="nucl-ex">nucl-ex</option><option value="nucl-th">nucl-th</option><option value="physics">physics</option><option value="quant-ph">quant-ph</option></select></td></tr><tr><th><label for="classification-q_biology">Quantitative Biology (q-bio)</label></th><td><input id="classification-q_biology" name="classification-q_biology" type="checkbox" value="y"></td></tr><tr><th><label for="classification-q_finance">Quantitative Finance (q-fin)</label></th><td><input id="classification-q_finance" name="classification-q_finance" type="checkbox" value="y"></td></tr><tr><th><label for="classification-statistics">Statistics (stat)</label></th><td><input id="classification-statistics" name="classification-statistics" type="checkbox" value="y"></td></tr><tr><th><label for="classification-include_cross_list">Include cross-list</label></th><td><ul id="classification-include_cross_list"><li><input checked id="classification-include_cross_list-0" name="classification-include_cross_list" type="radio" value="include"> <label for="classification-include_cross_list-0">Include cross-listed papers</label></li><li><input id="classification-include_cross_list-1" name="classification-include_cross_list" type="radio" value="exclude"> <label for="classification-include_cross_list-1">Exclude cross-listed papers</label></li></ul></td></tr></table>
          
        
          
            <table id="date"><tr><th><label for="date-filter_by">Filter by</label></th><td><ul id="date-filter_by"><li><input checked id="date-filter_by-0" name="date-filter_by" type="radio" value="all_dates"> <label for="date-filter_by-0">All dates</label></li><li><input id="date-filter_by-1" name="date-filter_by" type="radio" value="past_12"> <label for="date-filter_by-1">Past 12 months</label></li><li><input id="date-filter_by-2" name="date-filter_by" type="radio" value="specific_year"> <label for="date-filter_by-2">Specific year</label></li><li><input id="date-filter_by-3" name="date-filter_by" type="radio" value="date_range"> <label for="date-filter_by-3">Date range</label></li></ul></td></tr><tr><th><label for="date-year">Year</label></th><td><input id="date-year" name="date-year" type="text" value=""></td></tr><tr><th><label for="date-from_date">From</label></th><td><input id="date-from_date" name="date-from_date" type="text" value=""></td></tr><tr><th><label for="date-to_date">to</label></th><td><input id="date-to_date" name="date-to_date" type="text" value=""></td></tr><tr><th><label for="date-date_type">Apply to</label></th><td><ul id="date-date_type"><li><input checked id="date-date_type-0" name="date-date_type" type="radio" value="submitted_date"> <label for="date-date_type-0">Submission date (most recent)</label></li><li><input id="date-date_type-1" name="date-date_type" type="radio" value="submitted_date_first"> <label for="date-date_type-1">Submission date (original)</label></li><li><input id="date-date_type-2" name="date-date_type" type="radio" value="announced_date_first"> <label for="date-date_type-2">Announcement date</label></li></ul></td></tr></table>
          
        
          
        
          
        
          
            <input id="include_older_versions" name="include_older_versions" type="checkbox" value="y">
          
        
          
            <ul id="abstracts"><li><input checked id="abstracts-0" name="abstracts" type="radio" value="show"> <label for="abstracts-0">Show abstracts</label></li><li><input id="abstracts-1" name="abstracts" type="radio" value="hide"> <label for="abstracts-1">Hide abstracts</label></li></ul>
          
        
      </div>
      <div class="box field is-grouped is-grouped-multiline level-item">
        <div class="control">
          <span class="select is-small">
            <select id="size" name="size"><option value="25">25</option><option value="50">50</option><option value="100">100</option><option selected value="200">200</option></select>
          </span>
          <label for="size">results per page</label>.
        </div>
        <div class="control">
          <label for="order">Sort results by</label>
          <span class="select is-small">
            <select id="order" name="order"><option selected value="-announced_date_first">Announcement date (newest first)</option><option value="announced_date_first">Announcement date (oldest first)</option><option value="-submitted_date">Submission date (newest first)</option><option value="submitted_date">Submission date (oldest first)</option><option value="">Relevance</option></select>
          </span>
        </div>
        <div class="control">
          <button class="button is-small is-link">Go</button>
        </div>
      </div>
    </form>
  </div>
</div>
        


  <nav class="pagination is-small is-centered breathe-horizontal" role="navigation" aria-label="pagination">
    
    <a href=""
      class="pagination-previous is-invisible">Previous
    </a>
    
    
      <a href="/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=%28code+OR+program+OR+software+OR+application%29+AND+%28optimize+OR+optimizing+OR+optimization+OR+improve+OR+improving+OR+improvement+OR+automated+OR+automatically+OR+reduce+OR+reducing%29+AND+%28functional+OR+functionality+OR+size+OR+slimming+OR+bloat+OR+debloating%29&amp;terms-0-field=all&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=200&amp;order=-announced_date_first&amp;start=200"
        class="pagination-next" >Next
      </a>
    
    <ul class="pagination-list">

      <li>
        <a href="/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=%28code+OR+program+OR+software+OR+application%29+AND+%28optimize+OR+optimizing+OR+optimization+OR+improve+OR+improving+OR+improvement+OR+automated+OR+automatically+OR+reduce+OR+reducing%29+AND+%28functional+OR+functionality+OR+size+OR+slimming+OR+bloat+OR+debloating%29&amp;terms-0-field=all&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=200&amp;order=-announced_date_first&amp;start=0"
          class="pagination-link is-current"
          aria-label="Goto page 1">1
        </a>
      </li>

      
        
        <li>
          <a href="/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=%28code+OR+program+OR+software+OR+application%29+AND+%28optimize+OR+optimizing+OR+optimization+OR+improve+OR+improving+OR+improvement+OR+automated+OR+automatically+OR+reduce+OR+reducing%29+AND+%28functional+OR+functionality+OR+size+OR+slimming+OR+bloat+OR+debloating%29&amp;terms-0-field=all&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=200&amp;order=-announced_date_first&amp;start=200"
            class="pagination-link "
            aria-label="Page 2"
            aria-current="page">2
          </a>
        </li>
        
        <li>
          <a href="/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=%28code+OR+program+OR+software+OR+application%29+AND+%28optimize+OR+optimizing+OR+optimization+OR+improve+OR+improving+OR+improvement+OR+automated+OR+automatically+OR+reduce+OR+reducing%29+AND+%28functional+OR+functionality+OR+size+OR+slimming+OR+bloat+OR+debloating%29&amp;terms-0-field=all&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=200&amp;order=-announced_date_first&amp;start=400"
            class="pagination-link "
            aria-label="Page 3"
            aria-current="page">3
          </a>
        </li>
        
        <li>
          <a href="/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=%28code+OR+program+OR+software+OR+application%29+AND+%28optimize+OR+optimizing+OR+optimization+OR+improve+OR+improving+OR+improvement+OR+automated+OR+automatically+OR+reduce+OR+reducing%29+AND+%28functional+OR+functionality+OR+size+OR+slimming+OR+bloat+OR+debloating%29&amp;terms-0-field=all&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=200&amp;order=-announced_date_first&amp;start=600"
            class="pagination-link "
            aria-label="Page 4"
            aria-current="page">4
          </a>
        </li>
        
        <li>
          <a href="/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=%28code+OR+program+OR+software+OR+application%29+AND+%28optimize+OR+optimizing+OR+optimization+OR+improve+OR+improving+OR+improvement+OR+automated+OR+automatically+OR+reduce+OR+reducing%29+AND+%28functional+OR+functionality+OR+size+OR+slimming+OR+bloat+OR+debloating%29&amp;terms-0-field=all&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=200&amp;order=-announced_date_first&amp;start=800"
            class="pagination-link "
            aria-label="Page 5"
            aria-current="page">5
          </a>
        </li>
        
      
    </ul>
  </nav>
  



<ol class="breathe-horizontal" start="1"> 


  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2107.02244">arXiv:2107.02244</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2107.02244">pdf</a>, <a href="https://arxiv.org/format/2107.02244">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Networking and Internet Architecture">cs.NI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Programming Languages">cs.PL</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1145/3452296.3472903">10.1145/3452296.3472903 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Lucid: A Language for Control in the Data Plane
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Sonchack%2C+J">John Sonchack</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Loehr%2C+D">Devon Loehr</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rexford%2C+J">Jennifer Rexford</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Walker%2C+D">David Walker</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2107.02244v1-abstract-short" style="display: inline;">
        Programmable switch hardware makes it possible to move fine-grained control logic inside the network data plane, <span class="search-hit mathjax">improving</span> performance for a wide range of&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2107.02244v1-abstract-full').style.display = 'inline'; document.getElementById('2107.02244v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2107.02244v1-abstract-full" style="display: none;">
        Programmable switch hardware makes it possible to move fine-grained control logic inside the network data plane, <span class="search-hit mathjax">improving</span> performance for a wide range of <span class="search-hit mathjax">applications</span>. However, <span class="search-hit mathjax">applications</span> with integrated control are inherently hard to write in existing data-plane <span class="search-hit mathjax">programming</span> languages such as P4. This paper presents Lucid, a language that raises the level of abstraction for putting control <span class="search-hit mathjax">functionality</span> in the data plane. Lucid introduces abstractions that make it easy to write sophisticated data-plane <span class="search-hit mathjax">applications</span> with interleaved packet-handling and control logic, specialized type and syntax systems that prevent programmer bugs related to data-plane state, and an open-sourced compiler that translates Lucid <span class="search-hit mathjax">programs</span> into P4 <span class="search-hit mathjax">optimized</span> for the Intel Tofino. These features make Lucid general and easy to use, as we demonstrate by writing a suite of ten different data-plane <span class="search-hit mathjax">applications</span> in Lucid. Working prototypes take well under an hour to write, even for a programmer without prior Tofino experience, have around 10x fewer lines of <span class="search-hit mathjax">code</span> compared to P4, and compile efficiently to real hardware. In a stateful firewall written in Lucid, we find that moving control from a switch&#39;s CPU to its data-plane processor using Lucid <span class="search-hit mathjax">reduces</span> the latency of performance-sensitive operations by over 300X.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2107.02244v1-abstract-full').style.display = 'none'; document.getElementById('2107.02244v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 5 July, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">12 pages plus 5 pages references/appendix. 17 figures. To appear in SIGCOMM 2021</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          C.2.1
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2107.01093">arXiv:2107.01093</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2107.01093">pdf</a>, <a href="https://arxiv.org/format/2107.01093">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Model Checking C++ <span class="search-hit mathjax">Programs</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Monteiro%2C+F+R">Felipe R. Monteiro</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gadelha%2C+M+R">Mikhail R. Gadelha</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cordeiro%2C+L+C">Lucas C. Cordeiro</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2107.01093v1-abstract-short" style="display: inline;">
        In the last three decades, memory safety issues in system <span class="search-hit mathjax">programming</span> languages such as C or C++ have been one of the significant sources of security vulnerabilities. However, there exist only a few attempts with limited success to cope with the complexity of C++&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2107.01093v1-abstract-full').style.display = 'inline'; document.getElementById('2107.01093v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2107.01093v1-abstract-full" style="display: none;">
        In the last three decades, memory safety issues in system <span class="search-hit mathjax">programming</span> languages such as C or C++ have been one of the significant sources of security vulnerabilities. However, there exist only a few attempts with limited success to cope with the complexity of C++ <span class="search-hit mathjax">program</span> verification. Here we describe and evaluate a novel verification approach based on bounded model checking (BMC) and satisfiability modulo theories (SMT) to verify C++ <span class="search-hit mathjax">programs</span> formally. Our verification approach analyzes bounded C++ <span class="search-hit mathjax">programs</span> by encoding into SMT various sophisticated features that the C++ <span class="search-hit mathjax">programming</span> language offers, such as templates, inheritance, polymorphism, exception handling, and the Standard C++ Libraries. We formalize these features within our formal verification framework using a decidable fragment of first-order logic and then show how state-of-the-art SMT solvers can efficiently handle that. We implemented our verification approach on top of ESBMC. We compare ESBMC to LLBMC and DIVINE, which are state-of-the-art verifiers to check C++ <span class="search-hit mathjax">programs</span> directly from the LLVM bitcode. Experimental results show that ESBMC can handle a wide range of C++ <span class="search-hit mathjax">programs</span>, presenting a higher number of correct verification results. At the same time, it <span class="search-hit mathjax">reduces</span> the verification time if compared to LLBMC and DIVINE tools. Additionally, ESBMC has been applied to a commercial C++ <span class="search-hit mathjax">application</span> in the telecommunication domain and successfully detected arithmetic overflow errors, potentially leading to security vulnerabilities.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2107.01093v1-abstract-full').style.display = 'none'; document.getElementById('2107.01093v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 2 July, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">30 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2107.00615">arXiv:2107.00615</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2107.00615">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Medical Physics">physics.med-ph</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computational Engineering, Finance, and Science">cs.CE</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Signal Processing">eess.SP</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A linear phase evolution model for reduction of temporal unwrapping and field estimation errors in multi-echo GRE
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Paul%2C+J+S">Joseph Suresh Paul</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Madhusoodhanan%2C+S">Sreekanth Madhusoodhanan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2107.00615v1-abstract-short" style="display: inline;">
        This article aims at developing a model based <span class="search-hit mathjax">optimization</span> for reduction of temporal unwrapping and field estimation errors in multi-echo acquisition of Gradient Echo sequence. Using the assumption that the phase is linear along the temporal dimension, the field estimation is performed by&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2107.00615v1-abstract-full').style.display = 'inline'; document.getElementById('2107.00615v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2107.00615v1-abstract-full" style="display: none;">
        This article aims at developing a model based <span class="search-hit mathjax">optimization</span> for reduction of temporal unwrapping and field estimation errors in multi-echo acquisition of Gradient Echo sequence. Using the assumption that the phase is linear along the temporal dimension, the field estimation is performed by <span class="search-hit mathjax">application</span> of unity rank approximation to the Hankel matrix formed using the complex exponential of the channel combined phase at each echo time. For the purpose of maintaining consistency with the observed complex data, the linear phase evolution model is formulated as an <span class="search-hit mathjax">optimization</span> problem with a cost <span class="search-hit mathjax">function</span> that involves a fidelity term and a unity rank prior, implemented using alternating minimization. Itoh s algorithm applied to the multi-echo phase estimated from this linear phase evolution model is able to <span class="search-hit mathjax">reduce</span> the unwrapping errors as compared to the unwrapping when directly applied to the measured phase. Secondly, the <span class="search-hit mathjax">improved</span> accuracy of the frequency fit in comparison to estimation using weighted least-square regression and penalized maximum likelihood is demonstrated using numerical simulation of field perturbation due to magnetic susceptibility effect. It is shown that the field can be estimated with 80 percent reduction in mean absolute error in comparison to wLSR and 66 percent reduction with respect to penalized maximum likelihood. The <span class="search-hit mathjax">improvement</span> in performance becomes more pronounced with increasing strengths of field gradient magnitudes and echo spacing.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2107.00615v1-abstract-full').style.display = 'none'; document.getElementById('2107.00615v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 26 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">29pages, 8 figures</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          J.2
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.15878">arXiv:2106.15878</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.15878">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Formal Languages and Automata Theory">cs.FL</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Programming Languages">cs.PL</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Towards establishing formal verification and inductive <span class="search-hit mathjax">code</span> synthesis in the PLC domain
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Wei%C3%9F%2C+M">Matthias Wei√ü</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Marks%2C+P">Philipp Marks</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Maschler%2C+B">Benjamin Maschler</a>, 
      
      <a href="/search/?searchtype=author&amp;query=White%2C+D">Dustin White</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kesseli%2C+P">Pascal Kesseli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Weyrich%2C+M">Michael Weyrich</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.15878v1-abstract-short" style="display: inline;">
        Nowadays, formal methods are used in various areas for the verification of <span class="search-hit mathjax">programs</span> or for&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.15878v1-abstract-full').style.display = 'inline'; document.getElementById('2106.15878v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.15878v1-abstract-full" style="display: none;">
        Nowadays, formal methods are used in various areas for the verification of <span class="search-hit mathjax">programs</span> or for <span class="search-hit mathjax">code</span> generation from models in order to increase the quality of <span class="search-hit mathjax">software</span> and to <span class="search-hit mathjax">reduce</span> costs. However, there are still fields in which formal methods have not been widely adopted, despite the large set of possible benefits offered. This is the case for the area of programmable logic controllers (PLC). This article aims to evaluate the potential of formal methods in the context of PLC development. For this purpose, the general concepts of formal methods are first introduced and then transferred to the PLC area, resulting in an engineering-oriented description of the technology that is based on common concepts from PLC development. Based on this description, PLC professionals with varying degrees of experience were interviewed for their perspective on the topic and to identify possible use cases within the PLC domain. The survey results indicate the technology&#39;s high potential in the PLC area, either as a tool to directly support the developer or as a key element within a model-based systems engineering toolchain. The evaluation of the survey results is performed with the aid of a demo <span class="search-hit mathjax">application</span> that communicates with the Totally Integrated <span class="search-hit mathjax">Automation</span> Portal from Siemens and generates <span class="search-hit mathjax">programs</span> via Fastsynth, a model-based open source <span class="search-hit mathjax">code</span> generator. Benchmarks based on an industry-related PLC project show satisfactory synthesis times and a successful integration into the workflow of a PLC developer.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.15878v1-abstract-full').style.display = 'none'; document.getElementById('2106.15878v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">8 pages, 6 figures, 1 table. Accepted for publication at IEEE INDIN 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.14156">arXiv:2106.14156</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.14156">pdf</a>, <a href="https://arxiv.org/format/2106.14156">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Post-Training Quantization for Vision Transformer
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+Z">Zhenhua Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+Y">Yunhe Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Han%2C+K">Kai Han</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+S">Siwei Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gao%2C+W">Wen Gao</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.14156v1-abstract-short" style="display: inline;">
        Recently, transformer has achieved remarkable performance on a variety of computer vision <span class="search-hit mathjax">applications</span>. Compared with mainstream convolutional neural networks, vision transformers are often of sophisticated architectures for extracting powerful feature representations, which are more difficult to be developed on mobile devices. In this paper, we present an e&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.14156v1-abstract-full').style.display = 'inline'; document.getElementById('2106.14156v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.14156v1-abstract-full" style="display: none;">
        Recently, transformer has achieved remarkable performance on a variety of computer vision <span class="search-hit mathjax">applications</span>. Compared with mainstream convolutional neural networks, vision transformers are often of sophisticated architectures for extracting powerful feature representations, which are more difficult to be developed on mobile devices. In this paper, we present an effective post-training quantization algorithm for <span class="search-hit mathjax">reducing</span> the memory storage and computational costs of vision transformers. Basically, the quantization task can be regarded as finding the <span class="search-hit mathjax">optimal</span> low-bit quantization intervals for weights and inputs, respectively. To preserve the <span class="search-hit mathjax">functionality</span> of the attention mechanism, we introduce a ranking loss into the conventional quantization objective that aims to keep the relative order of the self-attention results after quantization. Moreover, we thoroughly analyze the relationship between quantization loss of different layers and the feature diversity, and explore a mixed-precision quantization scheme by exploiting the nuclear norm of each attention map and output feature. The effectiveness of the proposed method is verified on several benchmark models and datasets, which outperforms the state-of-the-art post-training quantization algorithms. For instance, we can obtain an 81.29\% top-1 accuracy using DeiT-B model on ImageNet dataset with about 8-bit quantization.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.14156v1-abstract-full').style.display = 'none'; document.getElementById('2106.14156v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 27 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.11851">arXiv:2106.11851</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.11851">pdf</a>, <a href="https://arxiv.org/format/2106.11851">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Stochastic Polyak Stepsize with a Moving Target
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Gower%2C+R+M">Robert M. Gower</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Defazio%2C+A">Aaron Defazio</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rabbat%2C+M">Michael Rabbat</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.11851v1-abstract-short" style="display: inline;">
        We propose a new stochastic gradient method that uses recorded past loss values to <span class="search-hit mathjax">reduce</span> the variance. Our method can be interpreted as a new stochastic variant of the Polyak Stepsize that converges globally without assuming interpolation. Our method introduces auxiliary variables, one for each data point, that track the loss value for each data point. We p&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.11851v1-abstract-full').style.display = 'inline'; document.getElementById('2106.11851v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.11851v1-abstract-full" style="display: none;">
        We propose a new stochastic gradient method that uses recorded past loss values to <span class="search-hit mathjax">reduce</span> the variance. Our method can be interpreted as a new stochastic variant of the Polyak Stepsize that converges globally without assuming interpolation. Our method introduces auxiliary variables, one for each data point, that track the loss value for each data point. We provide a global convergence theory for our method by showing that it can be interpreted as a special variant of online SGD. The new method only stores a single scalar per data point, opening up new <span class="search-hit mathjax">applications</span> for variance reduction where memory is the bottleneck.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.11851v1-abstract-full').style.display = 'none'; document.getElementById('2106.11851v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">41 pages, 13 figures, 1 table</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        
          <span class="has-text-black-bis has-text-weight-semibold">MSC Class:</span>
          90C53; 74S60; 90C06; 62L20; 68W20; 15B52; 65Y20; 68W40
        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          G.1.6
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.11756">arXiv:2106.11756</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.11756">pdf</a>, <a href="https://arxiv.org/format/2106.11756">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Trinity: A No-<span class="search-hit mathjax">Code</span> AI platform for complex spatial datasets
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Iyer%2C+C+V+K">C. V. Krishnakumar Iyer</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hou%2C+F">Feili Hou</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+H">Henry Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+Y">Yonghong Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Oh%2C+K">Kay Oh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ganguli%2C+S">Swetava Ganguli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pandey%2C+V">Vipul Pandey</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.11756v5-abstract-short" style="display: inline;">
        We present a no-<span class="search-hit mathjax">code</span> Artificial Intelligence (AI) platform called Trinity with the main design goal of enabling both machine learning researchers and non-technical geospatial domain experts to experiment with domain-specific signals and datasets for solving a variety of complex problems on their own. This versatility to solve diverse problems is achieved by&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.11756v5-abstract-full').style.display = 'inline'; document.getElementById('2106.11756v5-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.11756v5-abstract-full" style="display: none;">
        We present a no-<span class="search-hit mathjax">code</span> Artificial Intelligence (AI) platform called Trinity with the main design goal of enabling both machine learning researchers and non-technical geospatial domain experts to experiment with domain-specific signals and datasets for solving a variety of complex problems on their own. This versatility to solve diverse problems is achieved by transforming complex Spatio-temporal datasets to make them consumable by standard deep learning models, in this case, Convolutional Neural Networks (CNNs), and giving the ability to formulate disparate problems in a standard way, eg. semantic segmentation. With an intuitive user interface, a feature store that hosts derivatives of complex feature engineering, a deep learning kernel, and a scalable data processing mechanism, Trinity provides a powerful platform for domain experts to share the stage with scientists and engineers in solving business-critical problems. It enables quick prototyping, rapid experimentation and <span class="search-hit mathjax">reduces</span> the time to production by standardizing model building and deployment. In this paper, we present our motivation behind Trinity and its design along with showcasing sample <span class="search-hit mathjax">applications</span> to motivate the idea of lowering the bar to using AI.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.11756v5-abstract-full').style.display = 'none'; document.getElementById('2106.11756v5-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 1 July, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 21 June, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">12 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.11396">arXiv:2106.11396</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.11396">pdf</a>, <a href="https://arxiv.org/ps/2106.11396">ps</a>, <a href="https://arxiv.org/format/2106.11396">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        BiAdam: Fast Adaptive Bilevel <span class="search-hit mathjax">Optimization</span> Methods
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Huang%2C+F">Feihu Huang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Huang%2C+H">Heng Huang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.11396v2-abstract-short" style="display: inline;">
        Bilevel <span class="search-hit mathjax">optimization</span> recently has attracted increased interest in machine learning due to its many&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.11396v2-abstract-full').style.display = 'inline'; document.getElementById('2106.11396v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.11396v2-abstract-full" style="display: none;">
        Bilevel <span class="search-hit mathjax">optimization</span> recently has attracted increased interest in machine learning due to its many <span class="search-hit mathjax">applications</span> such as hyper-parameter <span class="search-hit mathjax">optimization</span> and policy <span class="search-hit mathjax">optimization</span>. Although some methods recently have been proposed to solve the bilevel problems, these methods do not consider using adaptive learning rates. To fill this gap, in the paper, we propose a class of fast and effective adaptive methods for solving bilevel <span class="search-hit mathjax">optimization</span> problems that the outer problem is possibly nonconvex and the inner problem is strongly-convex. Specifically, we propose a fast single-loop BiAdam algorithm based on the basic momentum technique, which achieves a sample complexity of $\tilde{O}(Œµ^{-4})$ for finding an $Œµ$-stationary point. At the same time, we propose an accelerated version of BiAdam algorithm (VR-BiAdam) by using variance <span class="search-hit mathjax">reduced</span> technique, which reaches the best known sample complexity of $\tilde{O}(Œµ^{-3})$. To further <span class="search-hit mathjax">reduce</span> computation in estimating derivatives, we propose a fast single-loop stochastic approximated BiAdam algorithm (saBiAdam) by avoiding the Hessian inverse, which still achieves a sample complexity of $\tilde{O}(Œµ^{-4})$ without large batches. We further present an accelerated version of saBiAdam algorithm (VR-saBiAdam), which also reaches the best known sample complexity of $\tilde{O}(Œµ^{-3})$. We apply the unified adaptive matrices to our methods as the SUPER-ADAM \citep{huang2021super}, which including many types of adaptive learning rates. Moreover, our framework can flexibly use the momentum and variance <span class="search-hit mathjax">reduced</span> techniques. In particular, we provide a useful convergence analysis framework for both the constrained and unconstrained bilevel <span class="search-hit mathjax">optimization</span>. To the best of our knowledge, we first study the adaptive bilevel <span class="search-hit mathjax">optimization</span> methods with adaptive learning rates.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.11396v2-abstract-full').style.display = 'none'; document.getElementById('2106.11396v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 June, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 21 June, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">66 pages, 2 tables. We add the detailed proofs</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.11246">arXiv:2106.11246</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.11246">pdf</a>, <a href="https://arxiv.org/format/2106.11246">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Quantum Physics">quant-ph</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Emerging Technologies">cs.ET</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        LEAP: Scaling Numerical <span class="search-hit mathjax">Optimization</span> Based Synthesis Using an Incremental Approach
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Smith%2C+E">Ethan Smith</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Davis%2C+M+G">Marc G. Davis</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Larson%2C+J+M">Jeffrey M. Larson</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Younis%2C+E">Ed Younis</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Iancu%2C+C">Costin Iancu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lavrijsen%2C+W">Wim Lavrijsen</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.11246v1-abstract-short" style="display: inline;">
        While showing great promise, circuit synthesis techniques that combine numerical <span class="search-hit mathjax">optimization</span> with search over circuit structures face scalability challenges due to large number of parameters, exponential search spaces, and complex objective&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.11246v1-abstract-full').style.display = 'inline'; document.getElementById('2106.11246v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.11246v1-abstract-full" style="display: none;">
        While showing great promise, circuit synthesis techniques that combine numerical <span class="search-hit mathjax">optimization</span> with search over circuit structures face scalability challenges due to large number of parameters, exponential search spaces, and complex objective <span class="search-hit mathjax">functions</span>. The LEAP algorithm <span class="search-hit mathjax">improves</span> scaling across these dimensions using iterative circuit synthesis, incremental reoptimization, dimensionality reduction, and <span class="search-hit mathjax">improved</span> numerical <span class="search-hit mathjax">optimization</span>. LEAP draws on the design of the <span class="search-hit mathjax">optimal</span> synthesis algorithm QSearch by extending it with an incremental approach to determine constant prefix solutions for a circuit. By narrowing the search space, LEAP <span class="search-hit mathjax">improves</span> scalability from four to six qubit circuits. LEAP was evaluated with known quantum circuits such as QFT and physical simulation circuits like the VQE, TFIM and QITE. LEAP is able to compile four qubit unitaries up to $59\times$ faster than QSearch and five and six qubit unitaries with up to $1.2\times$ fewer CNOTs compared to the advanced QFAST package. LEAP is able to <span class="search-hit mathjax">reduce</span> the CNOT count by up to $48\times$, or $11\times$ on average, compared to the IBM Qiskit compiler. Although employing heuristics, LEAP has generated <span class="search-hit mathjax">optimal</span> depth circuits for all test cases where a solution is known a priori. The techniques introduced by LEAP are <span class="search-hit mathjax">applicable</span> to other numerical <span class="search-hit mathjax">optimization</span> based synthesis approaches.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.11246v1-abstract-full').style.display = 'none'; document.getElementById('2106.11246v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 21 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">20 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.10022">arXiv:2106.10022</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.10022">pdf</a>, <a href="https://arxiv.org/format/2106.10022">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Local AdaGrad-Type Algorithm for Stochastic Convex-Concave Minimax Problems
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Liao%2C+L">Luofeng Liao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shen%2C+L">Li Shen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Duan%2C+J">Jia Duan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kolar%2C+M">Mladen Kolar</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tao%2C+D">Dacheng Tao</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.10022v1-abstract-short" style="display: inline;">
        Large scale convex-concave minimax problems arise in numerous <span class="search-hit mathjax">applications</span>, including game theory, robust training, and training of generative adversarial networks. Despite their wide&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.10022v1-abstract-full').style.display = 'inline'; document.getElementById('2106.10022v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.10022v1-abstract-full" style="display: none;">
        Large scale convex-concave minimax problems arise in numerous <span class="search-hit mathjax">applications</span>, including game theory, robust training, and training of generative adversarial networks. Despite their wide <span class="search-hit mathjax">applicability</span>, solving such problems efficiently and effectively is challenging in the presence of large amounts of data using existing stochastic minimax methods. We study a class of stochastic minimax methods and develop a communication-efficient distributed stochastic extragradient algorithm, LocalAdaSEG, with an adaptive learning rate suitable for solving convex-concave minimax problem in the Parameter-Server model. LocalAdaSEG has three main features: (i) periodic communication strategy <span class="search-hit mathjax">reduces</span> the communication cost between workers and the server; (ii) an adaptive learning rate that is computed locally and allows for tuning-free implementation; and (iii) theoretically, a nearly linear speed-up with respect to the dominant variance term, arising from estimation of the stochastic gradient, is proven in both the smooth and nonsmooth convex-concave settings. LocalAdaSEG is used to solve a stochastic bilinear game, and train generative adversarial network. We compare LocalAdaSEG against several existing <span class="search-hit mathjax">optimizers</span> for minimax problems and demonstrate its efficacy through several experiments in both the homogeneous and heterogeneous settings.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.10022v1-abstract-full').style.display = 'none'; document.getElementById('2106.10022v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 18 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">24 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.09884">arXiv:2106.09884</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.09884">pdf</a>, <a href="https://arxiv.org/ps/2106.09884">ps</a>, <a href="https://arxiv.org/format/2106.09884">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Batch Multi-Fidelity Bayesian <span class="search-hit mathjax">Optimization</span> with Deep Auto-Regressive Networks
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+S">Shibo Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kirby%2C+R+M">Robert M. Kirby</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhe%2C+S">Shandian Zhe</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.09884v1-abstract-short" style="display: inline;">
        Bayesian <span class="search-hit mathjax">optimization</span> (BO) is a powerful approach for&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.09884v1-abstract-full').style.display = 'inline'; document.getElementById('2106.09884v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.09884v1-abstract-full" style="display: none;">
        Bayesian <span class="search-hit mathjax">optimization</span> (BO) is a powerful approach for <span class="search-hit mathjax">optimizing</span> black-box, expensive-to-evaluate <span class="search-hit mathjax">functions</span>. To enable a flexible trade-off between the cost and accuracy, many <span class="search-hit mathjax">applications</span> allow the <span class="search-hit mathjax">function</span> to be evaluated at different fidelities. In order to <span class="search-hit mathjax">reduce</span> the <span class="search-hit mathjax">optimization</span> cost while maximizing the benefit-cost ratio, in this paper, we propose Batch Multi-fidelity Bayesian <span class="search-hit mathjax">Optimization</span> with Deep Auto-Regressive Networks (BMBO-DARN). We use a set of Bayesian neural networks to construct a fully auto-regressive model, which is expressive enough to capture strong yet complex relationships across all the fidelities, so as to <span class="search-hit mathjax">improve</span> the surrogate learning and <span class="search-hit mathjax">optimization</span> performance. Furthermore, to enhance the quality and diversity of queries, we develop a simple yet efficient batch querying method, without any combinatorial search over the fidelities. We propose a batch acquisition <span class="search-hit mathjax">function</span> based on Max-value Entropy Search (MES) principle, which penalizes highly correlated queries and encourages diversity. We use posterior samples and moment matching to fulfill efficient computation of the acquisition <span class="search-hit mathjax">function</span> and conduct alternating <span class="search-hit mathjax">optimization</span> over every fidelity-input pair, which guarantees an <span class="search-hit mathjax">improvement</span> at each step. We demonstrate the advantage of our approach on four real-world hyperparameter <span class="search-hit mathjax">optimization</span> <span class="search-hit mathjax">applications</span>.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.09884v1-abstract-full').style.display = 'none'; document.getElementById('2106.09884v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.09877">arXiv:2106.09877</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.09877">pdf</a>, <a href="https://arxiv.org/format/2106.09877">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Numerical Analysis">math.NA</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Mathematical Software">cs.MS</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        HIFIR: Hybrid Incomplete Factorization with Iterative Refinement for Preconditioning Ill-conditioned and Singular Systems
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+Q">Qiao Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jiao%2C+X">Xiangmin Jiao</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.09877v1-abstract-short" style="display: inline;">
        We introduce a <span class="search-hit mathjax">software</span> package called HIFIR for preconditioning sparse, unsymmetric, ill-conditioned, and potentially singular systems. HIFIR computes a hybrid incomplete factorization, which combines multilevel incomplete LU factorization with a truncated, rank-revealing QR factorization on the final Schur complement. This novel hybridization is based on t&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.09877v1-abstract-full').style.display = 'inline'; document.getElementById('2106.09877v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.09877v1-abstract-full" style="display: none;">
        We introduce a <span class="search-hit mathjax">software</span> package called HIFIR for preconditioning sparse, unsymmetric, ill-conditioned, and potentially singular systems. HIFIR computes a hybrid incomplete factorization, which combines multilevel incomplete LU factorization with a truncated, rank-revealing QR factorization on the final Schur complement. This novel hybridization is based on the new theory of approximate generalized inverse and $Œµ$-accuracy. It enables near-<span class="search-hit mathjax">optimal</span> preconditioners for consistent systems and enables flexible GMRES to solve inconsistent systems when coupled with iterative refinement. In this paper, we focus on some practical algorithmic and <span class="search-hit mathjax">software</span> issues of HIFIR. In particular, we introduce a new inverse-based rook pivoting into ILU, which <span class="search-hit mathjax">improves</span> the robustness and the overall efficiency for some ill-conditioned systems by significantly <span class="search-hit mathjax">reducing</span> the <span class="search-hit mathjax">size</span> of the final Schur complement for some systems. We also describe the <span class="search-hit mathjax">software</span> design of HIFIR in terms of its efficient data structures for supporting rook pivoting in a multilevel setting, its template-based generic <span class="search-hit mathjax">programming</span> interfaces for mixed-precision real and complex values in C++, and its user-friendly high-level interfaces in MATLAB and Python. We demonstrate the effectiveness of HIFIR for ill-conditioned or singular systems arising from several <span class="search-hit mathjax">applications</span>, including the Helmholtz equation, linear elasticity, stationary incompressible Navier--Stokes equations, and time-dependent advection-diffusion equation.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.09877v1-abstract-full').style.display = 'none'; document.getElementById('2106.09877v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Submitted to ACM Transactions on Mathematical <span class="search-hit mathjax">Software</span> (TOMS)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.08253">arXiv:2106.08253</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.08253">pdf</a>, <a href="https://arxiv.org/ps/2106.08253">ps</a>, <a href="https://arxiv.org/format/2106.08253">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        <span class="search-hit mathjax">Code</span> Generation Based on Deep Learning: a Brief Review
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zhu%2C+Q">Qihao Zhu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+W">Wenjie Zhang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.08253v4-abstract-short" style="display: inline;">
        <span class="search-hit mathjax">Automatic</span>&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.08253v4-abstract-full').style.display = 'inline'; document.getElementById('2106.08253v4-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.08253v4-abstract-full" style="display: none;">
        <span class="search-hit mathjax">Automatic</span> <span class="search-hit mathjax">software</span> development has been a research hot spot in the field of <span class="search-hit mathjax">software</span> engineering (SE) in the past decade. In particular, deep learning (DL) has been applied and achieved a lot of progress in various SE tasks. Among all <span class="search-hit mathjax">applications</span>, <span class="search-hit mathjax">automatic</span> <span class="search-hit mathjax">code</span> generation by machines as a general concept, including <span class="search-hit mathjax">code</span> completion and <span class="search-hit mathjax">code</span> synthesis, is a common expectation in the field of SE, which may greatly <span class="search-hit mathjax">reduce</span> the development burden of the <span class="search-hit mathjax">software</span> developers and <span class="search-hit mathjax">improves</span> the efficiency and quality of the <span class="search-hit mathjax">software</span> development process to a certain extent. <span class="search-hit mathjax">Code</span> completion is an important part of modern integrated development environments (IDEs). <span class="search-hit mathjax">Code</span> completion technology effectively helps programmers complete <span class="search-hit mathjax">code</span> class names, method names, and key-words, etc., which <span class="search-hit mathjax">improves</span> the efficiency of <span class="search-hit mathjax">program</span> development and <span class="search-hit mathjax">reduces</span> spelling errors in the <span class="search-hit mathjax">coding</span> process. Such tools use static analysis on the <span class="search-hit mathjax">code</span> and provide candidates for completion arranged in alphabetical order. <span class="search-hit mathjax">Code</span> synthesis is implemented from two aspects, one based on input-output samples and the other based on <span class="search-hit mathjax">functionality</span> description. In this study, we introduce existing techniques of these two aspects and the corresponding DL techniques, and present some possible future research directions.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.08253v4-abstract-full').style.display = 'none'; document.getElementById('2106.08253v4-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 4 July, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 15 June, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">10 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.07537">arXiv:2106.07537</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.07537">pdf</a>, <a href="https://arxiv.org/format/2106.07537">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A Wasserstein Minimax Framework for Mixed Linear Regression
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Diamandis%2C+T">Theo Diamandis</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Eldar%2C+Y+C">Yonina C. Eldar</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fallah%2C+A">Alireza Fallah</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farnia%2C+F">Farzan Farnia</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ozdaglar%2C+A">Asuman Ozdaglar</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.07537v2-abstract-short" style="display: inline;">
        &hellip;distributions are commonly used to model clustered data in statistical learning tasks. In this paper, we consider the Mixed Linear Regression (MLR) problem. We propose an <span class="search-hit mathjax">optimal</span> transport-based framework for MLR problems, Wasserstein Mixed Linear Regression (WMLR), which minimizes the Wasserstein distance between the learned and target mixture regression mo&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.07537v2-abstract-full').style.display = 'inline'; document.getElementById('2106.07537v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.07537v2-abstract-full" style="display: none;">
        Multi-modal distributions are commonly used to model clustered data in statistical learning tasks. In this paper, we consider the Mixed Linear Regression (MLR) problem. We propose an <span class="search-hit mathjax">optimal</span> transport-based framework for MLR problems, Wasserstein Mixed Linear Regression (WMLR), which minimizes the Wasserstein distance between the learned and target mixture regression models. Through a model-based duality analysis, WMLR <span class="search-hit mathjax">reduces</span> the underlying MLR task to a nonconvex-concave minimax <span class="search-hit mathjax">optimization</span> problem, which can be provably solved to find a minimax stationary point by the Gradient Descent Ascent (GDA) algorithm. In the special case of mixtures of two linear regression models, we show that WMLR enjoys global convergence and generalization guarantees. We prove that WMLR&#39;s sample complexity grows linearly with the dimension of data. Finally, we discuss the <span class="search-hit mathjax">application</span> of WMLR to the federated learning task where the training samples are collected by multiple agents in a network. Unlike the Expectation Maximization algorithm, WMLR directly extends to the distributed, federated learning setting. We support our theoretical results through several numerical experiments, which highlight our framework&#39;s ability to handle the federated learning setting with mixture models.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.07537v2-abstract-full').style.display = 'none'; document.getElementById('2106.07537v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 June, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 14 June, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">To appear in 38th International Conference on Machine Learning (ICML 2021)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.07520">arXiv:2106.07520</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.07520">pdf</a>, <a href="https://arxiv.org/format/2106.07520">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        JUGE: An Infrastructure for Benchmarking Java Unit Test Generators
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Devroey%2C+X">Xavier Devroey</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gambi%2C+A">Alessio Gambi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Galeotti%2C+J+P">Juan Pablo Galeotti</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Just%2C+R">Ren√© Just</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kifetew%2C+F">Fitsum Kifetew</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Panichella%2C+A">Annibale Panichella</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Panichella%2C+S">Sebastiano Panichella</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.07520v1-abstract-short" style="display: inline;">
        Researchers and practitioners have designed and implemented various <span class="search-hit mathjax">automated</span> test case generators to support effective&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.07520v1-abstract-full').style.display = 'inline'; document.getElementById('2106.07520v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.07520v1-abstract-full" style="display: none;">
        Researchers and practitioners have designed and implemented various <span class="search-hit mathjax">automated</span> test case generators to support effective <span class="search-hit mathjax">software</span> testing. Such generators exist for various languages (e.g., Java, C#, or Python) and for various platforms (e.g., desktop, web, or mobile <span class="search-hit mathjax">applications</span>). Such generators exhibit varying effectiveness and efficiency, depending on the testing goals they aim to satisfy (e.g., unit-testing of libraries vs. system-testing of entire <span class="search-hit mathjax">applications</span>) and the underlying techniques they implement. In this context, practitioners need to be able to compare different generators to identify the most suited one for their requirements, while researchers seek to identify future research directions. This can be achieved through the systematic execution of large-scale evaluations of different generators. However, the execution of such empirical evaluations is not trivial and requires a substantial effort to collect benchmarks, setup the evaluation infrastructure, and collect and analyse the results. In this paper, we present our JUnit Generation benchmarking infrastructure (JUGE) supporting generators (e.g., search-based, random-based, symbolic execution, etc.) seeking to <span class="search-hit mathjax">automate</span> the production of unit tests for various purposes (e.g., validation, regression testing, fault localization, etc.). The primary goal is to <span class="search-hit mathjax">reduce</span> the overall effort, ease the comparison of several generators, and enhance the knowledge transfer between academia and industry by standardizing the evaluation and comparison process. Since 2013, eight editions of a unit testing tool competition, co-located with the Search-Based <span class="search-hit mathjax">Software</span> Testing Workshop, have taken place and used and updated JUGE. As a result, an increasing amount of tools (over ten) from both academia and industry have been evaluated on JUGE, matured over the years, and allowed the identification of future research directions.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.07520v1-abstract-full').style.display = 'none'; document.getElementById('2106.07520v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.07243">arXiv:2106.07243</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.07243">pdf</a>, <a href="https://arxiv.org/ps/2106.07243">ps</a>, <a href="https://arxiv.org/format/2106.07243">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Multiagent Systems">cs.MA</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Signal Processing">eess.SP</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Compressed Gradient Tracking for Decentralized <span class="search-hit mathjax">Optimization</span> Over General Directed Networks
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Song%2C+Z">Zhuoqing Song</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shi%2C+L">Lei Shi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pu%2C+S">Shi Pu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yan%2C+M">Ming Yan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.07243v1-abstract-short" style="display: inline;">
        In this paper, we propose two communication-efficient algorithms for decentralized <span class="search-hit mathjax">optimization</span> over a multi-agent network with general directed network topology. In the first part, we consider a novel communication-efficient gradient tracking based method, termed Compressed Push-Pull (CPP), which combines the Push-Pull method with communication compression.&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.07243v1-abstract-full').style.display = 'inline'; document.getElementById('2106.07243v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.07243v1-abstract-full" style="display: none;">
        In this paper, we propose two communication-efficient algorithms for decentralized <span class="search-hit mathjax">optimization</span> over a multi-agent network with general directed network topology. In the first part, we consider a novel communication-efficient gradient tracking based method, termed Compressed Push-Pull (CPP), which combines the Push-Pull method with communication compression. We show that CPP is <span class="search-hit mathjax">applicable</span> to a general class of unbiased compression operators and achieves linear convergence for strongly convex and smooth objective <span class="search-hit mathjax">functions</span>. In the second part, we propose a broadcast-like version of CPP (B-CPP), which also achieves linear convergence rate under the same conditions for the objective <span class="search-hit mathjax">functions</span>. B-CPP can be applied in an asynchronous broadcast setting and further <span class="search-hit mathjax">reduce</span> communication costs compared to CPP. Numerical experiments complement the theoretical analysis and confirm the effectiveness of the proposed methods.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.07243v1-abstract-full').style.display = 'none'; document.getElementById('2106.07243v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">working paper</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.06143">arXiv:2106.06143</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.06143">pdf</a>, <a href="https://arxiv.org/format/2106.06143">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Signal Processing">eess.SP</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Monotonic Neural Network: combining Deep Learning with Domain Knowledge for Chiller Plants Energy <span class="search-hit mathjax">Optimization</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+F">Fanhe Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+F">Faen Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ben%2C+S">Shenglan Ben</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Qin%2C+S">Shuxin Qin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhou%2C+P">Pengcheng Zhou</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhou%2C+C">Changsheng Zhou</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xu%2C+F">Fengyi Xu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.06143v1-abstract-short" style="display: inline;">
        In this paper, we are interested in building a domain knowledge based deep learning framework to solve the chiller plants energy <span class="search-hit mathjax">optimization</span> problems. Compared to the hotspot&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.06143v1-abstract-full').style.display = 'inline'; document.getElementById('2106.06143v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.06143v1-abstract-full" style="display: none;">
        In this paper, we are interested in building a domain knowledge based deep learning framework to solve the chiller plants energy <span class="search-hit mathjax">optimization</span> problems. Compared to the hotspot <span class="search-hit mathjax">applications</span> of deep learning (e.g. image classification and NLP), it is difficult to collect enormous data for deep network training in real-world physical systems. Most existing methods <span class="search-hit mathjax">reduce</span> the complex systems into linear model to facilitate the training on small samples. To tackle the small sample <span class="search-hit mathjax">size</span> problem, this paper considers domain knowledge in the structure and loss design of deep network to build a nonlinear model with lower redundancy <span class="search-hit mathjax">function</span> space. Specifically, the energy consumption estimation of most chillers can be physically viewed as an input-output monotonic problem. Thus, we can design a Neural Network with monotonic constraints to mimic the physical behavior of the system. We verify the proposed method in a cooling system of a data center, experimental results show the superiority of our framework in energy <span class="search-hit mathjax">optimization</span> compared to the existing ones.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.06143v1-abstract-full').style.display = 'none'; document.getElementById('2106.06143v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 10 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.04916">arXiv:2106.04916</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.04916">pdf</a>, <a href="https://arxiv.org/format/2106.04916">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Erratum: Leveraging Flexible Tree Matching to Repair Broken Locators in Web <span class="search-hit mathjax">Automation</span> Scripts
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Brisset%2C+S">Sacha Brisset</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rouvoy%2C+R">Romain Rouvoy</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Seinturier%2C+L">Lionel Seinturier</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pawlak%2C+R">Renaud Pawlak</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.04916v1-abstract-short" style="display: inline;">
        Web <span class="search-hit mathjax">applications</span> are constantly evolving to integrate new features and fix reported bugs. Even an imperceptible change can sometimes entail significant modifications of the Document Object Model (DOM), which is the underlying model used by browsers to render all the elements included in a web&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.04916v1-abstract-full').style.display = 'inline'; document.getElementById('2106.04916v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.04916v1-abstract-full" style="display: none;">
        Web <span class="search-hit mathjax">applications</span> are constantly evolving to integrate new features and fix reported bugs. Even an imperceptible change can sometimes entail significant modifications of the Document Object Model (DOM), which is the underlying model used by browsers to render all the elements included in a web <span class="search-hit mathjax">application</span>. Scripts that interact with web <span class="search-hit mathjax">applications</span> (e.g. web test scripts, crawlers, or robotic process <span class="search-hit mathjax">automation</span>) rely on this continuously evolving DOM which means they are often particularly fragile. More precisely, the major cause of breakages observed in <span class="search-hit mathjax">automation</span> scripts are element locators, which are identifiers used by <span class="search-hit mathjax">automation</span> scripts to navigate across the DOM. When the DOM evolves, these identifiers tend to break, thus causing the related scripts to no longer locate the intended target elements. For this reason, several contributions explored the idea of <span class="search-hit mathjax">automatically</span> repairing broken locators on a page. These works attempt to repair a given broken locator by scanning all elements in the new DOM to find the most similar one. Unfortunately, this approach fails to scale when the complexity of web pages grows, leading either to long computation times or incorrect element repairs. This article, therefore, adopts a different perspective on this problem by introducing a new locator repair solution that leverages tree matching algorithms to relocate broken locators. This solution, named Erratum, implements a holistic approach to <span class="search-hit mathjax">reduce</span> the element search space, which greatly eases the locator repair task and drastically <span class="search-hit mathjax">improves</span> repair accuracy. We compare the robustness of Erratum on a large-scale benchmark composed of realistic and synthetic mutations applied to popular web <span class="search-hit mathjax">applications</span> currently deployed in production. Our empirical results demonstrate that Erratum outperforms the accuracy of WATER, a state-of-the-art solution, by 67%.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.04916v1-abstract-full').style.display = 'none'; document.getElementById('2106.04916v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 9 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.04729">arXiv:2106.04729</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.04729">pdf</a>, <a href="https://arxiv.org/format/2106.04729">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Drones for Medical Delivery Considering Different Demands Classes: A Markov Decision Process Approach for Managing Health Centers Dispatching Medical Products
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Asadi%2C+A">Amin Asadi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pinkley%2C+S+N">Sarah Nurre Pinkley</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.04729v1-abstract-short" style="display: inline;">
        We consider the problem of <span class="search-hit mathjax">optimizing</span> the distribution operations of a hub using drones to deliver medical supplies to different geographic regions. Drones are an innovative method with many benefits including low-contact delivery thereby&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.04729v1-abstract-full').style.display = 'inline'; document.getElementById('2106.04729v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.04729v1-abstract-full" style="display: none;">
        We consider the problem of <span class="search-hit mathjax">optimizing</span> the distribution operations of a hub using drones to deliver medical supplies to different geographic regions. Drones are an innovative method with many benefits including low-contact delivery thereby <span class="search-hit mathjax">reducing</span> the spread of pandemic and vaccine-preventable diseases. While we focus on medical supply delivery for this work, it is <span class="search-hit mathjax">applicable</span> to drone delivery for many other <span class="search-hit mathjax">applications</span>, including food, postal items, and e-commerce delivery. In this paper, our goal is to address drone delivery challenges by <span class="search-hit mathjax">optimizing</span> the distribution operations at a drone hub that dispatch drones to different geographic locations generating stochastic demands for medical supplies. By considering different geographic locations, we consider different classes of demand that require different flight ranges, which is directly related to the amount of charge held in a drone battery. We classify the stochastic demands based on their distance from the drone hub, use a Markov decision process to model the problem, and perform computational tests using realistic data representing a prominent drone delivery company. We solve the problem using a reinforcement learning method and show its high performance compared with the exact solution found using dynamic <span class="search-hit mathjax">programming</span>. Finally, we analyze the results and provide insights for managing the drone hub operations.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.04729v1-abstract-full').style.display = 'none'; document.getElementById('2106.04729v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.04618">arXiv:2106.04618</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.04618">pdf</a>, <a href="https://arxiv.org/format/2106.04618">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Neural and Evolutionary Computing">cs.NE</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        EXPObench: Benchmarking Surrogate-based Optimisation Algorithms on Expensive Black-box <span class="search-hit mathjax">Functions</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Bliek%2C+L">Laurens Bliek</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Guijt%2C+A">Arthur Guijt</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Karlsson%2C+R">Rickard Karlsson</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Verwer%2C+S">Sicco Verwer</a>, 
      
      <a href="/search/?searchtype=author&amp;query=de+Weerdt%2C+M">Mathijs de Weerdt</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.04618v1-abstract-short" style="display: inline;">
        &hellip;the literature, these algorithms are usually evaluated with synthetic benchmarks which are well established but have no expensive objective, and only on one or two real-life <span class="search-hit mathjax">applications</span> which vary wildly between papers. There is a clear lack of standardisation when it comes to benchmarking surrogate algorithms on real-life, expensive, black-box objective&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.04618v1-abstract-full').style.display = 'inline'; document.getElementById('2106.04618v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.04618v1-abstract-full" style="display: none;">
        Surrogate algorithms such as Bayesian optimisation are especially designed for black-box optimisation problems with expensive objectives, such as hyperparameter tuning or simulation-based optimisation. In the literature, these algorithms are usually evaluated with synthetic benchmarks which are well established but have no expensive objective, and only on one or two real-life <span class="search-hit mathjax">applications</span> which vary wildly between papers. There is a clear lack of standardisation when it comes to benchmarking surrogate algorithms on real-life, expensive, black-box objective <span class="search-hit mathjax">functions</span>. This makes it very difficult to draw conclusions on the effect of algorithmic contributions. A new benchmark library, EXPObench, provides first steps towards such a standardisation. The library is used to provide an extensive comparison of six different surrogate algorithms on four expensive optimisation problems from different real-life <span class="search-hit mathjax">applications</span>. This has led to new insights regarding the relative importance of exploration, the evaluation time of the objective, and the used model. A further contribution is that we make the algorithms and benchmark problem instances publicly available, contributing to more uniform analysis of surrogate algorithms. Most importantly, we include the performance of the six algorithms on all evaluated problem instances. This results in a unique new dataset that lowers the bar for researching new methods as the number of expensive evaluations required for comparison is significantly <span class="search-hit mathjax">reduced</span>.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.04618v1-abstract-full').style.display = 'none'; document.getElementById('2106.04618v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">13 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.04508">arXiv:2106.04508</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.04508">pdf</a>, <a href="https://arxiv.org/format/2106.04508">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Energy-Efficient Adaptive System Reconfiguration for Dynamic Deadlines in Autonomous Driving
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Yi%2C+S">Saehanseul Yi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kim%2C+T">Tae-Wook Kim</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kim%2C+J">Jong-Chan Kim</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dutt%2C+N">Nikil Dutt</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.04508v1-abstract-short" style="display: inline;">
        The increasing computing demands of autonomous driving <span class="search-hit mathjax">applications</span> make energy&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.04508v1-abstract-full').style.display = 'inline'; document.getElementById('2106.04508v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.04508v1-abstract-full" style="display: none;">
        The increasing computing demands of autonomous driving <span class="search-hit mathjax">applications</span> make energy <span class="search-hit mathjax">optimizations</span> critical for <span class="search-hit mathjax">reducing</span> battery capacity and vehicle weight. Current energy <span class="search-hit mathjax">optimization</span> methods typically target traditional real-time systems with static deadlines, resulting in conservative energy savings that are unable to exploit additional energy <span class="search-hit mathjax">optimizations</span> due to dynamic deadlines arising from the vehicle&#39;s change in velocity and driving context. We present an adaptive system <span class="search-hit mathjax">optimization</span> and reconfiguration approach that dynamically adapts the scheduling parameters and processor speeds to satisfy dynamic deadlines while consuming as little energy as possible. Our experimental results with an autonomous driving task set from Bosch and real-world driving data show energy reductions up to 46.4% on average in typical dynamic driving scenarios compared with traditional static energy <span class="search-hit mathjax">optimization</span> methods, demonstrating great potential for dynamic energy <span class="search-hit mathjax">optimization</span> gains by exploiting dynamic deadlines.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.04508v1-abstract-full').style.display = 'none'; document.getElementById('2106.04508v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 3 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">IEEE ISORC 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.03799">arXiv:2106.03799</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.03799">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Data Structures and Algorithms">cs.DS</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Deterministic Iteratively Built KD-Tree with KNN Search for Exact <span class="search-hit mathjax">Applications</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Naim%2C+A">Aryan Naim</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bowkett%2C+J">Joseph Bowkett</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Karumanchi%2C+S">Sisir Karumanchi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tavallali%2C+P">Peyman Tavallali</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kennedy%2C+B">Brett Kennedy</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.03799v1-abstract-short" style="display: inline;">
        K-Nearest Neighbors (KNN) search is a fundamental algorithm in artificial intelligence <span class="search-hit mathjax">software</span> with&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.03799v1-abstract-full').style.display = 'inline'; document.getElementById('2106.03799v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.03799v1-abstract-full" style="display: none;">
        K-Nearest Neighbors (KNN) search is a fundamental algorithm in artificial intelligence <span class="search-hit mathjax">software</span> with <span class="search-hit mathjax">applications</span> in robotics, and autonomous vehicles. These wide-ranging <span class="search-hit mathjax">applications</span> utilize KNN either directly for simple classification or combine KNN results as input to other algorithms such as Locally Weighted Learning (LWL). Similar to binary trees, kd-trees become unbalanced as new data is added in online <span class="search-hit mathjax">applications</span> which can lead to rapid degradation in search performance unless the tree is rebuilt. Although approximate methods are suitable for graphics <span class="search-hit mathjax">applications</span>, which prioritize query speed over query accuracy, they are unsuitable for certain <span class="search-hit mathjax">applications</span> in autonomous systems, aeronautics, and robotic manipulation where exact solutions are desired. In this paper, we will attempt to assess the performance of non-recursive deterministic kd-tree <span class="search-hit mathjax">functions</span> and KNN <span class="search-hit mathjax">functions</span>. We will also present a &#34;forest of interval kd-trees&#34; which <span class="search-hit mathjax">reduces</span> the number of tree rebuilds, without compromising the exactness of query results.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.03799v1-abstract-full').style.display = 'none'; document.getElementById('2106.03799v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.03368">arXiv:2106.03368</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.03368">pdf</a>, <a href="https://arxiv.org/format/2106.03368">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1007/978-3-319-64119-5_14">10.1007/978-3-319-64119-5_14 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Verification of Component Fault Trees Using Error Effect Simulations
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Reiter%2C+S">Sebastian Reiter</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zeller%2C+M">Marc Zeller</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hoefig%2C+K">Kai Hoefig</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Viehl%2C+A">Alexander Viehl</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bringmann%2C+O">Oliver Bringmann</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rosenstiel%2C+W">Wolfgang Rosenstiel</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.03368v1-abstract-short" style="display: inline;">
        &hellip;an approach, which combines deductive safety analyses, in form of Component Fault Trees (CFTs), with an Error Effect Simulation (EES) for sanity checks. The combination <span class="search-hit mathjax">reduces</span> the drawbacks of both analyses, such as the subjective failure propagation assumptions in the CFTs or the determination of relevant fault scenarios for the EES. Both CFTs and the EES&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.03368v1-abstract-full').style.display = 'inline'; document.getElementById('2106.03368v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.03368v1-abstract-full" style="display: none;">
        The growing complexity of safety-relevant systems causes an increasing effort for safety assurance. The reduction of development costs and time-to-market, while guaranteeing safe operation, is therefore a major challenge. In order to enable efficient safety assessment of complex architectures, we present an approach, which combines deductive safety analyses, in form of Component Fault Trees (CFTs), with an Error Effect Simulation (EES) for sanity checks. The combination <span class="search-hit mathjax">reduces</span> the drawbacks of both analyses, such as the subjective failure propagation assumptions in the CFTs or the determination of relevant fault scenarios for the EES. Both CFTs and the EES provide a modular, reusable and compositional safety analysis and are <span class="search-hit mathjax">applicable</span> throughout the whole design process. They support continuous model refinement and the reuse of conducted safety analysis and simulation models. Hence, safety goal violations can be identified in early design stages and the reuse of conducted safety analyses <span class="search-hit mathjax">reduces</span> the overhead for safety assessment.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.03368v1-abstract-full').style.display = 'none'; document.getElementById('2106.03368v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.03353">arXiv:2106.03353</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.03353">pdf</a>, <a href="https://arxiv.org/format/2106.03353">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Programming Languages">cs.PL</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Understanding Neural <span class="search-hit mathjax">Code</span> Intelligence Through <span class="search-hit mathjax">Program</span> Simplification
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Rabin%2C+M+R+I">Md Rafiqul Islam Rabin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hellendoorn%2C+V+J">Vincent J. Hellendoorn</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Alipour%2C+M+A">Mohammad Amin Alipour</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.03353v1-abstract-short" style="display: inline;">
        A wide range of <span class="search-hit mathjax">code</span> intelligence (CI) tools, powered by deep neural networks, have been developed recently to&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.03353v1-abstract-full').style.display = 'inline'; document.getElementById('2106.03353v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.03353v1-abstract-full" style="display: none;">
        A wide range of <span class="search-hit mathjax">code</span> intelligence (CI) tools, powered by deep neural networks, have been developed recently to <span class="search-hit mathjax">improve</span> <span class="search-hit mathjax">programming</span> productivity and perform <span class="search-hit mathjax">program</span> analysis. To reliably use such tools, developers often need to reason about the behavior of the underlying models and the factors that affect them. This is especially challenging for tools backed by deep neural networks. Various methods have tried to <span class="search-hit mathjax">reduce</span> this opacity in the vein of &#34;transparent/interpretable-AI&#34;. However, these approaches are often specific to a particular set of network architectures, even requiring access to the network&#39;s parameters. This makes them difficult to use for the average programmer, which hinders the reliable adoption of neural CI systems. In this paper, we propose a simple, model-agnostic approach to identify critical input features for models in CI systems, by drawing on <span class="search-hit mathjax">software</span> debugging research, specifically delta debugging. Our approach, SIVAND, uses simplification techniques that <span class="search-hit mathjax">reduce</span> the <span class="search-hit mathjax">size</span> of input <span class="search-hit mathjax">programs</span> of a CI model while preserving the predictions of the model. We show that this approach yields remarkably small outputs and is broadly <span class="search-hit mathjax">applicable</span> across many model architectures and problem domains. We find that the models in our experiments often rely heavily on just a few syntactic features in input <span class="search-hit mathjax">programs</span>. We believe that SIVAND&#39;s extracted features may help understand neural CI systems&#39; predictions and learned behavior.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.03353v1-abstract-full').style.display = 'none'; document.getElementById('2106.03353v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">The 29th ACM Joint European <span class="search-hit mathjax">Software</span> Engineering Conference and Symposium on the Foundations of <span class="search-hit mathjax">Software</span> Engineering (ESEC/FSE'21)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.03272">arXiv:2106.03272</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.03272">pdf</a>, <a href="https://arxiv.org/format/2106.03272">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computational Finance">q-fin.CP</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Signatured Deep Fictitious Play for Mean Field Games with Common Noise
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Min%2C+M">Ming Min</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hu%2C+R">Ruimeng Hu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.03272v1-abstract-short" style="display: inline;">
        &hellip;structure with millions of simulations of common noise paths in order to produce accurate solutions, which results in prohibitive computational cost and limits the <span class="search-hit mathjax">applications</span> to a large extent. In this paper, based on the rough path theory, we propose a novel single-loop algorithm, named signatured deep fictitious play, by which we can work with the unfixe&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.03272v1-abstract-full').style.display = 'inline'; document.getElementById('2106.03272v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.03272v1-abstract-full" style="display: none;">
        Existing deep learning methods for solving mean-field games (MFGs) with common noise fix the sampling common noise paths and then solve the corresponding MFGs. This leads to a nested-loop structure with millions of simulations of common noise paths in order to produce accurate solutions, which results in prohibitive computational cost and limits the <span class="search-hit mathjax">applications</span> to a large extent. In this paper, based on the rough path theory, we propose a novel single-loop algorithm, named signatured deep fictitious play, by which we can work with the unfixed common noise setup to avoid the nested-loop structure and <span class="search-hit mathjax">reduce</span> the computational complexity significantly. The proposed algorithm can accurately capture the effect of common uncertainty changes on mean-field equilibria without further training of neural networks, as previously needed in the existing machine learning algorithms. The efficiency is supported by three <span class="search-hit mathjax">applications</span>, including linear-quadratic MFGs, mean-field portfolio game, and mean-field game of <span class="search-hit mathjax">optimal</span> consumption and investment. Overall, we provide a new point of view from the rough path theory to solve MFGs with common noise with significantly <span class="search-hit mathjax">improved</span> efficiency and an extensive range of <span class="search-hit mathjax">applications</span>. In addition, we report the first deep learning work to deal with extended MFGs (a mean-field interaction via both the states and controls) with common noise.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.03272v1-abstract-full').style.display = 'none'; document.getElementById('2106.03272v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 6 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Published at ICML 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.03088">arXiv:2106.03088</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.03088">pdf</a>, <a href="https://arxiv.org/format/2106.03088">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        <span class="search-hit mathjax">Reducing</span> the feature divergence of RGB and near-infrared images using Switchable Normalization
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Yang%2C+S">Siwei Yang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yu%2C+S">Shaozuo Yu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhao%2C+B">Bingchen Zhao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+Y">Yin Wang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.03088v1-abstract-short" style="display: inline;">
        Visual pattern recognition over agricultural areas is an important <span class="search-hit mathjax">application</span> of aerial image processing. In this paper, we consider the multi-modality nature of agricultural aerial images and show that naively combining different modalities together without taking the feature divergence into account can lead to sub-&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.03088v1-abstract-full').style.display = 'inline'; document.getElementById('2106.03088v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.03088v1-abstract-full" style="display: none;">
        Visual pattern recognition over agricultural areas is an important <span class="search-hit mathjax">application</span> of aerial image processing. In this paper, we consider the multi-modality nature of agricultural aerial images and show that naively combining different modalities together without taking the feature divergence into account can lead to sub-<span class="search-hit mathjax">optimal</span> results. Thus, we apply a Switchable Normalization block to our DeepLabV3 segmentation model to alleviate the feature divergence. Using the popular symmetric Kullback Leibler divergence measure, we show that our model can greatly <span class="search-hit mathjax">reduce</span> the divergence between RGB and near-infrared channels. Together with a hybrid loss <span class="search-hit mathjax">function</span>, our model achieves nearly 10\% <span class="search-hit mathjax">improvements</span> in mean IoU over previously published baseline.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.03088v1-abstract-full').style.display = 'none'; document.getElementById('2106.03088v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 6 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">CVPR2020 AgriVision workshop</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.02140">arXiv:2106.02140</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.02140">pdf</a>, <a href="https://arxiv.org/format/2106.02140">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1007/978-3-319-10557-4_43">10.1007/978-3-319-10557-4_43 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Towards a Cross-Domain <span class="search-hit mathjax">Software</span> Safety Assurance Process for Embedded Systems
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zeller%2C+M">Marc Zeller</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hoefig%2C+K">Kai Hoefig</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rothfelder%2C+M">Martin Rothfelder</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.02140v1-abstract-short" style="display: inline;">
        In this work, we outline a cross-domain assurance process for safety-relevant <span class="search-hit mathjax">software</span> in embedded systems. This process aims to be applied in various different <span class="search-hit mathjax">application</span> domains and in conjunction with any development methodology. With this approach we plan to <span class="search-hit mathjax">reduce</span> the growi&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.02140v1-abstract-full').style.display = 'inline'; document.getElementById('2106.02140v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.02140v1-abstract-full" style="display: none;">
        In this work, we outline a cross-domain assurance process for safety-relevant <span class="search-hit mathjax">software</span> in embedded systems. This process aims to be applied in various different <span class="search-hit mathjax">application</span> domains and in conjunction with any development methodology. With this approach we plan to <span class="search-hit mathjax">reduce</span> the growing effort for safety assessment in embedded systems by reusing safety analysis techniques and tools for the product development in different domains.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.02140v1-abstract-full').style.display = 'none'; document.getElementById('2106.02140v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 3 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.02018">arXiv:2106.02018</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.02018">pdf</a>, <a href="https://arxiv.org/format/2106.02018">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Nonlinear Matrix Approximation with Radial Basis <span class="search-hit mathjax">Function</span> Components
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Rebrova%2C+E">Elizaveta Rebrova</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tang%2C+Y">Yu-Hang Tang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.02018v2-abstract-short" style="display: inline;">
        We introduce and investigate matrix approximation by decomposition into a sum of radial basis <span class="search-hit mathjax">function</span> (RBF) components. An RBF component is a generalization of the outer product between a pair of vectors, where an RBF&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.02018v2-abstract-full').style.display = 'inline'; document.getElementById('2106.02018v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.02018v2-abstract-full" style="display: none;">
        We introduce and investigate matrix approximation by decomposition into a sum of radial basis <span class="search-hit mathjax">function</span> (RBF) components. An RBF component is a generalization of the outer product between a pair of vectors, where an RBF <span class="search-hit mathjax">function</span> replaces the scalar multiplication between individual vector elements. Even though the RBF <span class="search-hit mathjax">functions</span> are positive definite, the summation across components is not restricted to convex combinations and allows us to compute the decomposition for any real matrix that is not necessarily symmetric or positive definite. We formulate the problem of seeking such a decomposition as an <span class="search-hit mathjax">optimization</span> problem with a nonlinear and non-convex loss <span class="search-hit mathjax">function</span>. Several modern versions of the gradient descent method, including their scalable stochastic counterparts, are used to solve this problem. We provide extensive empirical evidence of the effectiveness of the RBF decomposition and that of the gradient-based fitting algorithm. While being conceptually motivated by singular value decomposition (SVD), our proposed nonlinear counterpart outperforms SVD by drastically <span class="search-hit mathjax">reducing</span> the memory required to approximate a data matrix with the same L2 error for a wide range of matrix types. For example, it leads to 2 to 6 times memory save for Gaussian noise, graph adjacency matrices, and kernel matrices. Moreover, this proximity-based decomposition can offer additional interpretability in <span class="search-hit mathjax">applications</span> that involve, e.g., capturing the inner low-dimensional structure of the data, retaining graph connectivity structure, and preserving the acutance of images.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.02018v2-abstract-full').style.display = 'none'; document.getElementById('2106.02018v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 23 June, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 3 June, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.01975">arXiv:2106.01975</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.01975">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="High Energy Physics - Lattice">hep-lat</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Machine Learning and Variational Algorithms for Lattice Field Theory
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Kanwar%2C+G">Gurtej Kanwar</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.01975v1-abstract-short" style="display: inline;">
        &hellip;(MCMC) methods suffer from critical slowing down in this limit, restricting the precision of continuum extrapolations. Further difficulties arise when measuring correlation <span class="search-hit mathjax">functions</span> of operators widely separated in spacetime: for most correlation&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.01975v1-abstract-full').style.display = 'inline'; document.getElementById('2106.01975v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.01975v1-abstract-full" style="display: none;">
        In lattice quantum field theory studies, parameters defining the lattice theory must be tuned toward criticality to access continuum physics. Commonly used Markov chain Monte Carlo (MCMC) methods suffer from critical slowing down in this limit, restricting the precision of continuum extrapolations. Further difficulties arise when measuring correlation <span class="search-hit mathjax">functions</span> of operators widely separated in spacetime: for most correlation <span class="search-hit mathjax">functions</span>, an exponentially severe signal-to-noise problem is encountered as the operators are taken to be widely separated. This dissertation details two new techniques to address these issues. First, we define a novel MCMC algorithm based on generative flow-based models. Such models utilize machine learning methods to describe efficient approximate samplers for distributions of interest. Independently drawn flow-based samples are then used as proposals in an asymptotically exact Metropolis-Hastings Markov chain. We address incorporating symmetries of interest, including translational and gauge symmetries. We secondly introduce an approach to &#34;deform&#34; Monte Carlo estimators based on contour deformations applied to the domain of the path integral. The deformed estimators associated with an observable give equivalent unbiased measurements of that observable, but generically have different variances. We define families of deformed manifolds for lattice gauge theories and introduce methods to efficiently <span class="search-hit mathjax">optimize</span> the choice of manifold (the &#34;observifold&#34;), minimizing the deformed observable variance. Finally, we demonstrate that flow-based MCMC can mitigate critical slowing down and observifolds can exponentially <span class="search-hit mathjax">reduce</span> variance in proof-of-principle <span class="search-hit mathjax">applications</span> to scalar $œÜ^4$ theory and $\mathrm{U}(1)$ and $\mathrm{SU}(N)$ lattice gauge theories.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.01975v1-abstract-full').style.display = 'none'; document.getElementById('2106.01975v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 3 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">PhD Thesis, MIT (June 2021). Based on work appearing in arXiv:2101.12668, arXiv:2008.05456, arXiv:2003.06413, arXiv:2003.05914, arXiv:1904.12072, arXiv:1806.01832, arXiv:2101.08176, arXiv:2002.02428, and arXiv:1811.03944</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.01766">arXiv:2106.01766</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.01766">pdf</a>, <a href="https://arxiv.org/ps/2106.01766">ps</a>, <a href="https://arxiv.org/format/2106.01766">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1109/ISPRAS.2018.00009">10.1109/ISPRAS.2018.00009 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Dynamic Analysis of ARINC 653 RTOS with LLVM
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Cheptsov%2C+V">Vitaly Cheptsov</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Khoroshilov%2C+A">Alexey Khoroshilov</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.01766v1-abstract-short" style="display: inline;">
        Existing standards for airborne-embedded <span class="search-hit mathjax">software</span> systems impose a number of requirements&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.01766v1-abstract-full').style.display = 'inline'; document.getElementById('2106.01766v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.01766v1-abstract-full" style="display: none;">
        Existing standards for airborne-embedded <span class="search-hit mathjax">software</span> systems impose a number of requirements <span class="search-hit mathjax">applicable</span> to the <span class="search-hit mathjax">software</span> development cycle of hard real-time operating systems found in modern aircraft. The measures taken are meant to <span class="search-hit mathjax">reduce</span> the risks of undesired consequences, but have strongly varying costs. Dynamic instrumentation and static analysis are common practices used to <span class="search-hit mathjax">automatically</span> find <span class="search-hit mathjax">software</span> defects, from strictly non-conforming <span class="search-hit mathjax">code</span> constructions to memory corruptions or invalid control flow. LLVM analyser and sanitizer infrastructure, while regularly applied to general-purpose <span class="search-hit mathjax">software</span>, originally was not thought to be introduced to heavily restricted environments. In this paper we discuss the specifics of airborne systems with regards to dynamic instrumentation and provide practical considerations to be taken into account for the effective use of general-purpose instrumentation tools. We bring a complete LLVM stack support to JetOS, a prospective onboard real-time operating system currently being developed at ISP RAS in collaboration with GosNIIAS. As an example, we port AddressSanitizer, MemorySanitizer, and UndefinedBehaviorSanitizer and provide the details against the caveats on all relevant sides: a sanitizer, a compiler, and an operating system. In addition we suggest uninvolved optimisations and enhancements to the runtimes to maximise the effects of the tools.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.01766v1-abstract-full').style.display = 'none'; document.getElementById('2106.01766v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 3 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">7 pages</span>
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        2018 Ivannikov Ispras Open Conference (ISPRAS), 2018, pp. 9-15
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2105.15015">arXiv:2105.15015</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2105.15015">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1109/RAM.2018.8463058">10.1109/RAM.2018.8463058 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Model-Based Reliability and Safety: <span class="search-hit mathjax">Reducing</span> the Complexity of Safety Analyses Using Component Fault Trees
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Hoefig%2C+K">Kai Hoefig</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Joanni%2C+A">Andreas Joanni</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zeller%2C+M">Marc Zeller</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Montrone%2C+F">Francesco Montrone</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rothfelder%2C+M">Martin Rothfelder</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Amarnath%2C+R">Rakshith Amarnath</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Munk%2C+P">Peter Munk</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Nordmann%2C+A">Arne Nordmann</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2105.15015v1-abstract-short" style="display: inline;">
        The importance of mission or safety critical <span class="search-hit mathjax">software</span> systems in many&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.15015v1-abstract-full').style.display = 'inline'; document.getElementById('2105.15015v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2105.15015v1-abstract-full" style="display: none;">
        The importance of mission or safety critical <span class="search-hit mathjax">software</span> systems in many <span class="search-hit mathjax">application</span> domains of embedded systems is continuously growing, and so is the effort and complexity for reliability and safety analysis. Model driven development is currently one of the key approaches to cope with increasing development complexity, in general. Applying similar concepts to reliability, availability, maintainability and safety (RAMS) analysis activities is a promising approach to extend the advantages of model driven development to safety engineering activities aiming at a reduction of development costs, a higher product quality and a shorter time-to-market. Nevertheless, many model-based safety or reliability engineering approaches aim at <span class="search-hit mathjax">reducing</span> the analysis complexity but <span class="search-hit mathjax">applications</span> or case studies are rare. Therefore we present here a large scale industrial case study which shows the benefits of the <span class="search-hit mathjax">application</span> of component fault trees when it comes to complex safety mechanisms. We compare the methodology of component fault trees against classic fault trees and summarize benefits and drawbacks of both modeling methodologies.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.15015v1-abstract-full').style.display = 'none'; document.getElementById('2105.15015v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 31 May, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2021.
      
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        2018 Annual Reliability and Maintainability Symposium (RAMS)
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2105.13512">arXiv:2105.13512</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2105.13512">pdf</a>, <a href="https://arxiv.org/ps/2105.13512">ps</a>, <a href="https://arxiv.org/format/2105.13512">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Numerical Analysis">math.NA</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Information Theory">cs.IT</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Lower Bounds on the Low-Distortion Embedding Dimension of Submanifolds of $\mathbb{R}^n$
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Iwen%2C+M">Mark Iwen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tavakoli%2C+A">Arman Tavakoli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Schmidt%2C+B">Benjamin Schmidt</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2105.13512v1-abstract-short" style="display: inline;">
        &hellip;for which there exists a bi-Lipschitz <span class="search-hit mathjax">function</span> $f: \mathcal{M} \mapsto \mathbb{R}^m$ with bi-Lipschitz constants close to one. The main result bounds the embedding dimension $m$ below in terms of the bi-Lipschitz constants of $f$ and the reach, volume, diameter, and dimension of $\mathcal{M}$. This new lower bound is applied to show that prior upper bounds&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.13512v1-abstract-full').style.display = 'inline'; document.getElementById('2105.13512v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2105.13512v1-abstract-full" style="display: none;">
        Let $\mathcal{M}$ be a smooth submanifold of $\mathbb{R}^n$ equipped with the Euclidean (chordal) metric. This note considers the smallest dimension $m$ for which there exists a bi-Lipschitz <span class="search-hit mathjax">function</span> $f: \mathcal{M} \mapsto \mathbb{R}^m$ with bi-Lipschitz constants close to one. The main result bounds the embedding dimension $m$ below in terms of the bi-Lipschitz constants of $f$ and the reach, volume, diameter, and dimension of $\mathcal{M}$. This new lower bound is applied to show that prior upper bounds by Eftekhari and Wakin (arXiv:1306.4748) on the minimal low-distortion embedding dimension of such manifolds using random matrices achieve near-<span class="search-hit mathjax">optimal</span> dependence on both reach and volume. This supports random linear maps as being nearly as efficient as the best possible nonlinear maps at <span class="search-hit mathjax">reducing</span> the ambient dimension for manifold data. In the process of proving our main result, we also prove similar results concerning the impossibility of achieving better nonlinear measurement maps with the Restricted Isometry Property (RIP) in compressive sensing <span class="search-hit mathjax">applications</span>.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.13512v1-abstract-full').style.display = 'none'; document.getElementById('2105.13512v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 27 May, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2105.12841">arXiv:2105.12841</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2105.12841">pdf</a>, <a href="https://arxiv.org/format/2105.12841">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        DNNV: A Framework for Deep Neural Network Verification
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Shriver%2C+D">David Shriver</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Elbaum%2C+S">Sebastian Elbaum</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dwyer%2C+M+B">Matthew B. Dwyer</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2105.12841v1-abstract-short" style="display: inline;">
        &hellip;Existing benchmarks are rarely in formats supported by verifiers other than the one for which the benchmark was introduced. In this work we present DNNV, a framework for <span class="search-hit mathjax">reducing</span> the burden on DNN verifier researchers, developers, and users. DNNV standardizes input and output formats, includes a simple yet expressive DSL for specifying DNN properties, and p&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.12841v1-abstract-full').style.display = 'inline'; document.getElementById('2105.12841v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2105.12841v1-abstract-full" style="display: none;">
        Despite the large number of sophisticated deep neural network (DNN) verification algorithms, DNN verifier developers, users, and researchers still face several challenges. First, verifier developers must contend with the rapidly changing DNN field to support new DNN operations and property types. Second, verifier users have the burden of selecting a verifier input format to specify their problem. Due to the many input formats, this decision can greatly restrict the verifiers that a user may run. Finally, researchers face difficulties in re-using benchmarks to evaluate and compare verifiers, due to the large number of input formats required to run different verifiers. Existing benchmarks are rarely in formats supported by verifiers other than the one for which the benchmark was introduced. In this work we present DNNV, a framework for <span class="search-hit mathjax">reducing</span> the burden on DNN verifier researchers, developers, and users. DNNV standardizes input and output formats, includes a simple yet expressive DSL for specifying DNN properties, and provides powerful simplification and reduction operations to facilitate the <span class="search-hit mathjax">application</span>, development, and comparison of DNN verifiers. We show how DNNV increases the support of verifiers for existing benchmarks from 30% to 74%.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.12841v1-abstract-full').style.display = 'none'; document.getElementById('2105.12841v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 26 May, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2105.12026">arXiv:2105.12026</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2105.12026">pdf</a>, <a href="https://arxiv.org/ps/2105.12026">ps</a>, <a href="https://arxiv.org/format/2105.12026">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Providing Meaningful Data Summarizations Using Exemplar-based Clustering in Industry 4.0
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Honysz%2C+P">Philipp-Jan Honysz</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Schulze-Struchtrup%2C+A">Alexander Schulze-Struchtrup</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Buschj%C3%A4ger%2C+S">Sebastian Buschj√§ger</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Morik%2C+K">Katharina Morik</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2105.12026v2-abstract-short" style="display: inline;">
        Data summarizations are a valuable tool to derive knowledge from large data streams and have proven their usefulness in a great number of <span class="search-hit mathjax">applications</span>. Summaries can be found by&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.12026v2-abstract-full').style.display = 'inline'; document.getElementById('2105.12026v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2105.12026v2-abstract-full" style="display: none;">
        Data summarizations are a valuable tool to derive knowledge from large data streams and have proven their usefulness in a great number of <span class="search-hit mathjax">applications</span>. Summaries can be found by <span class="search-hit mathjax">optimizing</span> submodular <span class="search-hit mathjax">functions</span>. These <span class="search-hit mathjax">functions</span> map subsets of data to real values, which indicate their &#34;representativeness&#34; and which should be maximized to find a diverse summary of the underlying data. In this paper, we studied Exemplar-based clustering as a submodular <span class="search-hit mathjax">function</span> and provide a GPU algorithm to cope with its high computational complexity. We show, that our GPU implementation provides speedups of up to 72x using single-precision and up to 452x using half-precision computation compared to conventional CPU algorithms. We also show, that the GPU algorithm not only provides remarkable runtime benefits with workstation-grade GPUs but also with low-power embedded computation units for which speedups of up to 35x are possible. Furthermore, we apply our algorithm to real-world data from injection molding manufacturing processes and discuss how found summaries help with steering this specific process to cut costs and <span class="search-hit mathjax">reduce</span> the manufacturing of bad parts. Beyond pure speedup considerations, we show, that our approach can provide summaries within reasonable time frames for this kind of industrial, real-world data.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.12026v2-abstract-full').style.display = 'none'; document.getElementById('2105.12026v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 18 June, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 25 May, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">arXiv admin note: substantial text overlap with arXiv:2101.08763</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2105.11654">arXiv:2105.11654</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2105.11654">pdf</a>, <a href="https://arxiv.org/format/2105.11654">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Neural and Evolutionary Computing">cs.NE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        <span class="search-hit mathjax">Optimal</span> ANN-SNN Conversion for Fast and Accurate Inference in Deep Spiking Neural Networks
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ding%2C+J">Jianhao Ding</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yu%2C+Z">Zhaofei Yu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tian%2C+Y">Yonghong Tian</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Huang%2C+T">Tiejun Huang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2105.11654v1-abstract-short" style="display: inline;">
        &hellip;way to train deep SNNs is through ANN-SNN conversion. However, the conversion usually suffers from accuracy loss and long inference time, which impede the practical <span class="search-hit mathjax">application</span> of SNN. In this paper, we theoretically analyze ANN-SNN conversion and derive sufficient conditions of the&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.11654v1-abstract-full').style.display = 'inline'; document.getElementById('2105.11654v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2105.11654v1-abstract-full" style="display: none;">
        Spiking Neural Networks (SNNs), as bio-inspired energy-efficient neural networks, have attracted great attentions from researchers and industry. The most efficient way to train deep SNNs is through ANN-SNN conversion. However, the conversion usually suffers from accuracy loss and long inference time, which impede the practical <span class="search-hit mathjax">application</span> of SNN. In this paper, we theoretically analyze ANN-SNN conversion and derive sufficient conditions of the <span class="search-hit mathjax">optimal</span> conversion. To better correlate ANN-SNN and get greater accuracy, we propose Rate Norm Layer to replace the ReLU activation <span class="search-hit mathjax">function</span> in source ANN training, enabling direct conversion from a trained ANN to an SNN. Moreover, we propose an <span class="search-hit mathjax">optimal</span> fit curve to quantify the fit between the activation value of source ANN and the actual firing rate of target SNN. We show that the inference time can be <span class="search-hit mathjax">reduced</span> by <span class="search-hit mathjax">optimizing</span> the upper bound of the fit curve in the revised ANN to achieve fast inference. Our theory can explain the existing work on fast reasoning and get better results. The experimental results show that the proposed method achieves near loss less conversion with VGG-16, PreActResNet-18, and deeper structures. Moreover, it can reach 8.6x faster reasoning performance under 0.265x energy consumption of the typical method. The <span class="search-hit mathjax">code</span> is available at https://github.com/DingJianhao/OptSNNConvertion-RNL-RIL.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.11654v1-abstract-full').style.display = 'none'; document.getElementById('2105.11654v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 25 May, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">9 pages, 7 figures, 2 tables. To appear in the 30th International Joint Conference on Artificial Intelligence (IJCAI 2021)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2105.11229">arXiv:2105.11229</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2105.11229">pdf</a>, <a href="https://arxiv.org/format/2105.11229">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        FaaSNet: Scalable and Fast Provisioning of Custom Serverless Container Runtimes at Alibaba Cloud <span class="search-hit mathjax">Function</span> Compute
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+A">Ao Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chang%2C+S">Shuai Chang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tian%2C+H">Huangshi Tian</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+H">Hongqi Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yang%2C+H">Haoran Yang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+H">Huiba Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Du%2C+R">Rui Du</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cheng%2C+Y">Yue Cheng</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2105.11229v2-abstract-short" style="display: inline;">
        Serverless computing, or <span class="search-hit mathjax">Function</span>-as-a-Service (FaaS), enables a new way of building and scaling&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.11229v2-abstract-full').style.display = 'inline'; document.getElementById('2105.11229v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2105.11229v2-abstract-full" style="display: none;">
        Serverless computing, or <span class="search-hit mathjax">Function</span>-as-a-Service (FaaS), enables a new way of building and scaling <span class="search-hit mathjax">applications</span> by allowing users to deploy fine-grained <span class="search-hit mathjax">functions</span> while providing fully-managed resource provisioning and auto-scaling. Custom FaaS container support is gaining traction as it enables better control over OSes, versioning, and tooling for modernizing FaaS <span class="search-hit mathjax">applications</span>. However, providing rapid container provisioning introduces non-trivial challenges for FaaS providers, since container provisioning is costly, and real-world FaaS workloads exhibit highly dynamic patterns. In this paper, we design FaaSNet, a highly-scalable middleware system for accelerating FaaS container provisioning. FaaSNet is driven by the workload and infrastructure requirements of the FaaS platform at one of the world&#39;s largest cloud providers, Alibaba Cloud <span class="search-hit mathjax">Function</span> Compute. FaaSNet enables scalable container provisioning via a lightweight, adaptive <span class="search-hit mathjax">function</span> tree (FT) structure. FaaSNet uses an I/O efficient, on-demand fetching mechanism to further <span class="search-hit mathjax">reduce</span> provisioning costs at scale. We implement and integrate FaaSNet in Alibaba Cloud <span class="search-hit mathjax">Function</span> Compute. Evaluation results show that FaaSNet: (1) finishes provisioning 2500 <span class="search-hit mathjax">function</span> containers on 1000 virtual machines in 8.3 seconds, (2) scales 13.4x and 16.3x faster than Alibaba Cloud&#39;s current FaaS platform and a state-of-the-art P2P container registry (Kraken), respectively, and (3) sustains a bursty workload using 75.2% less time than an <span class="search-hit mathjax">optimized</span> baseline.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.11229v2-abstract-full').style.display = 'none'; document.getElementById('2105.11229v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 27 May, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 24 May, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">This is the preprint version of a paper published in USENIX ATC 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2105.07544">arXiv:2105.07544</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2105.07544">pdf</a>, <a href="https://arxiv.org/format/2105.07544">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Numerical Analysis">math.NA</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Mathematical Software">cs.MS</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Experimental Evaluation of Multiprecision Strategies for GMRES on GPUs
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Loe%2C+J+A">Jennifer A. Loe</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Glusa%2C+C+A">Christian A. Glusa</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yamazaki%2C+I">Ichitaro Yamazaki</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Boman%2C+E+G">Erik G. Boman</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rajamanickam%2C+S">Sivasankaran Rajamanickam</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2105.07544v1-abstract-short" style="display: inline;">
        Support for lower precision computation is becoming more common in accelerator hardware due to lower power usage, <span class="search-hit mathjax">reduced</span> data movement and increased computational performance. However, computational science and engineering (CSE) problems require double precision accuracy in several domains. This conflict between hardware trends and&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.07544v1-abstract-full').style.display = 'inline'; document.getElementById('2105.07544v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2105.07544v1-abstract-full" style="display: none;">
        Support for lower precision computation is becoming more common in accelerator hardware due to lower power usage, <span class="search-hit mathjax">reduced</span> data movement and increased computational performance. However, computational science and engineering (CSE) problems require double precision accuracy in several domains. This conflict between hardware trends and <span class="search-hit mathjax">application</span> needs has resulted in a need for multiprecision strategies at the linear algebra algorithms level if we want to exploit the hardware to its full potential while meeting the accuracy requirements. In this paper, we focus on preconditioned sparse iterative linear solvers, a key kernel in several CSE <span class="search-hit mathjax">applications</span>. We present a study of multiprecision strategies for accelerating this kernel on GPUs. We seek the best methods for incorporating multiple precisions into the GMRES linear solver; these include iterative refinement and parallelizable preconditioners. Our work presents strategies to determine when multiprecision GMRES will be effective and to choose parameters for a multiprecision iterative refinement solver to achieve better performance. We use an implementation that is based on the Trilinos library and employs Kokkos Kernels for performance portability of linear algebra kernels. Performance results demonstrate the promise of multiprecision approaches and demonstrate even further <span class="search-hit mathjax">improvements</span> are possible by <span class="search-hit mathjax">optimizing</span> low-level kernels.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.07544v1-abstract-full').style.display = 'none'; document.getElementById('2105.07544v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 May, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted for publication in the IEEE IPDPS Accelerators and Hybrid Emerging Systems (AsHES) 11th Workshop, 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2105.07420">arXiv:2105.07420</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2105.07420">pdf</a>, <a href="https://arxiv.org/format/2105.07420">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Resource Planning for Hospitals Under Special Consideration of the COVID-19 Pandemic: <span class="search-hit mathjax">Optimization</span> and Sensitivity Analysis
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Bartz-Beielstein%2C+T">Thomas Bartz-Beielstein</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dr%C3%B6scher%2C+M">Marcel Dr√∂scher</a>, 
      
      <a href="/search/?searchtype=author&amp;query=G%C3%BCr%2C+A">Alpar G√ºr</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hinterleitner%2C+A">Alexander Hinterleitner</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mersmann%2C+O">Olaf Mersmann</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Peeva%2C+D">Dessislava Peeva</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Reese%2C+L">Lennard Reese</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rehbach%2C+N">Nicolas Rehbach</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rehbach%2C+F">Frederik Rehbach</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sen%2C+A">Amrita Sen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Subbotin%2C+A">Aleksandr Subbotin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zaefferer%2C+M">Martin Zaefferer</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2105.07420v1-abstract-short" style="display: inline;">
        &hellip;is determined by 29 parameters. Reasonable default values of these parameters were obtained in detailed discussions with medical professionals. We aim to investigate and <span class="search-hit mathjax">optimize</span> these parameters to&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.07420v1-abstract-full').style.display = 'inline'; document.getElementById('2105.07420v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2105.07420v1-abstract-full" style="display: none;">
        Crises like the COVID-19 pandemic pose a serious challenge to health-care institutions. They need to plan the resources required for handling the increased load, for instance, hospital beds and ventilators. To support the resource planning of local health authorities from the Cologne region, BaBSim.Hospital, a tool for capacity planning based on discrete event simulation, was created. The predictive quality of the simulation is determined by 29 parameters. Reasonable default values of these parameters were obtained in detailed discussions with medical professionals. We aim to investigate and <span class="search-hit mathjax">optimize</span> these parameters to <span class="search-hit mathjax">improve</span> BaBSim.Hospital. First approaches with &#34;out-of-the-box&#34; <span class="search-hit mathjax">optimization</span> algorithms failed. Implementing a surrogate-based <span class="search-hit mathjax">optimization</span> approach generated useful results in a reasonable time. To understand the behavior of the algorithm and to get valuable insights into the fitness landscape, an in-depth sensitivity analysis was performed. The sensitivity analysis is crucial for the <span class="search-hit mathjax">optimization</span> process because it allows focusing the <span class="search-hit mathjax">optimization</span> on the most important parameters. We illustrate how this <span class="search-hit mathjax">reduces</span> the problem dimension without compromising the resulting accuracy. The presented approach is <span class="search-hit mathjax">applicable</span> to many other real-world problems, e.g., the development of new elevator systems to cover the last mile or simulation of student flow in academic study periods.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.07420v1-abstract-full').style.display = 'none'; document.getElementById('2105.07420v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 May, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2105.07026">arXiv:2105.07026</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2105.07026">pdf</a>, <a href="https://arxiv.org/format/2105.07026">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Probability">math.PR</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A Monotone Approximate Dynamic <span class="search-hit mathjax">Programming</span> Approach for the Stochastic Scheduling, Allocation, and Inventory Replenishment Problem: <span class="search-hit mathjax">Applications</span> to Drone and Electric Vehicle Battery Swap Stations
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Asadi%2C+A">Amin Asadi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pinkley%2C+S+N">Sarah Nurre Pinkley</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2105.07026v1-abstract-short" style="display: inline;">
        There is a growing interest in using electric vehicles (EVs) and drones for many <span class="search-hit mathjax">applications</span>. However, battery-oriented issues, including range anxiety and battery degradation, impede adoption. Battery swap stations are one alternative to&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.07026v1-abstract-full').style.display = 'inline'; document.getElementById('2105.07026v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2105.07026v1-abstract-full" style="display: none;">
        There is a growing interest in using electric vehicles (EVs) and drones for many <span class="search-hit mathjax">applications</span>. However, battery-oriented issues, including range anxiety and battery degradation, impede adoption. Battery swap stations are one alternative to <span class="search-hit mathjax">reduce</span> these concerns that allow the swap of depleted for full batteries in minutes. We consider the problem of deriving actions at a battery swap station when explicitly considering the uncertain arrival of swap demand, battery degradation, and replacement. We model the operations at a battery swap station using a finite horizon Markov Decision Process model for the stochastic scheduling, allocation, and inventory replenishment problem (SAIRP), which determines when and how many batteries are charged, discharged, and replaced over time. We present theoretical proofs for the monotonicity of the value <span class="search-hit mathjax">function</span> and monotone structure of an <span class="search-hit mathjax">optimal</span> policy for special SAIRP cases. Due to the curses of dimensionality, we develop a new monotone approximate dynamic <span class="search-hit mathjax">programming</span> (ADP) method, which intelligently initializes a value <span class="search-hit mathjax">function</span> approximation using regression. In computational tests, we demonstrate the superior performance of the new regression-based monotone ADP method as compared to exact methods and other monotone ADP methods. Further, with the tests, we deduce policy insights for drone swap stations.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.07026v1-abstract-full').style.display = 'none'; document.getElementById('2105.07026v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 May, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2105.02600">arXiv:2105.02600</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2105.02600">pdf</a>, <a href="https://arxiv.org/format/2105.02600">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Discrete Mathematics">cs.DM</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        <span class="search-hit mathjax">Optimal</span> Subgraph on Disturbed Network
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Guillot%2C+M">Matthieu Guillot</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Aghezzaf%2C+E">El-Houssaine Aghezzaf</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Faouzi%2C+N+E">Nour-Eddin El Faouzi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Furno%2C+A">Angelo Furno</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2105.02600v1-abstract-short" style="display: inline;">
        &hellip;transportation systems are drastically changed both qualitatively and quantitatively and the network has become obsolete. In this article, we study the problem of finding an <span class="search-hit mathjax">optimal</span> subnetwork that guarantee that (i) the minimal access time from any node of the urban network to the new network is not {\em too large} compared to the original transportation ne&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.02600v1-abstract-full').style.display = 'inline'; document.getElementById('2105.02600v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2105.02600v1-abstract-full" style="display: none;">
        During the pandemic of COVID-19, the demand of the transportation systems are drastically changed both qualitatively and quantitatively and the network has become obsolete. In this article, we study the problem of finding an <span class="search-hit mathjax">optimal</span> subnetwork that guarantee that (i) the minimal access time from any node of the urban network to the new network is not {\em too large} compared to the original transportation network; (ii) for any itinerary, the delay caused by the deletion of nodes of the transportation network is not {\em too big}; and (iii) the number of nodes of the transportation network has been <span class="search-hit mathjax">reduced</span> at least by a known factor. A solution is <span class="search-hit mathjax">optimal</span> if it induces a minimal global delay. We model this problem as a Mixed Integer Linear <span class="search-hit mathjax">Program</span> before applying the model on a real-case <span class="search-hit mathjax">application</span> on the Lyon&#39;s buses transportation network.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.02600v1-abstract-full').style.display = 'none'; document.getElementById('2105.02600v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 6 May, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2105.02540">arXiv:2105.02540</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2105.02540">pdf</a>, <a href="https://arxiv.org/format/2105.02540">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Distribution Awareness for AI System Testing
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Berend%2C+D">David Berend</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2105.02540v1-abstract-short" style="display: inline;">
        As Deep Learning (DL) is continuously adopted in many safety critical <span class="search-hit mathjax">applications</span>, its quality and reliability start to raise concerns. Similar to the traditional&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.02540v1-abstract-full').style.display = 'inline'; document.getElementById('2105.02540v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2105.02540v1-abstract-full" style="display: none;">
        As Deep Learning (DL) is continuously adopted in many safety critical <span class="search-hit mathjax">applications</span>, its quality and reliability start to raise concerns. Similar to the traditional <span class="search-hit mathjax">software</span> development process, testing the DL <span class="search-hit mathjax">software</span> to uncover its defects at an early stage is an effective way to <span class="search-hit mathjax">reduce</span> risks after deployment. Although recent progress has been made in designing novel testing techniques for DL <span class="search-hit mathjax">software</span>, the distribution of generated test data is not taken into consideration. It is therefore hard to judge whether the identified errors are indeed meaningful errors to the DL <span class="search-hit mathjax">application</span>. Therefore, we propose a new OOD-guided testing technique which aims to generate new unseen test cases relevant to the underlying DL system task. Our results show that this technique is able to filter up to 55.44% of error test case on CIFAR-10 and is 10.05% more effective in enhancing robustness.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.02540v1-abstract-full').style.display = 'none'; document.getElementById('2105.02540v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 6 May, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">2 pages, 1 figure, pre-print</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2105.00115">arXiv:2105.00115</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2105.00115">pdf</a>, <a href="https://arxiv.org/format/2105.00115">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Numerical Analysis">math.NA</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Mathematical Software">cs.MS</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        QDOT: Quantized Dot Product Kernel for Approximate High-Performance Computing
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Diffenderfer%2C+J">James Diffenderfer</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Osei-Kuffuor%2C+D">Daniel Osei-Kuffuor</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Menon%2C+H">Harshitha Menon</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2105.00115v1-abstract-short" style="display: inline;">
        Approximate computing techniques have been successful in <span class="search-hit mathjax">reducing</span> computation and power costs in several domains. However, error sensitive&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.00115v1-abstract-full').style.display = 'inline'; document.getElementById('2105.00115v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2105.00115v1-abstract-full" style="display: none;">
        Approximate computing techniques have been successful in <span class="search-hit mathjax">reducing</span> computation and power costs in several domains. However, error sensitive <span class="search-hit mathjax">applications</span> in high-performance computing are unable to benefit from existing approximate computing strategies that are not developed with guaranteed error bounds. While approximate computing techniques can be developed for individual high-performance computing <span class="search-hit mathjax">applications</span> by domain specialists, this often requires additional theoretical analysis and potentially extensive <span class="search-hit mathjax">software</span> modification. Hence, the development of low-level error-bounded approximate computing strategies that can be introduced into any high-performance computing <span class="search-hit mathjax">application</span> without requiring additional analysis or significant <span class="search-hit mathjax">software</span> alterations is desirable. In this paper, we provide a contribution in this direction by proposing a general framework for designing error-bounded approximate computing strategies and apply it to the dot product kernel to develop qdot -- an error-bounded approximate dot product kernel. Following the introduction of qdot, we perform a theoretical analysis that yields a deterministic bound on the relative approximation error introduced by qdot. Empirical tests are performed to illustrate the tightness of the derived error bound and to demonstrate the effectiveness of qdot on a synthetic dataset, as well as two scientific benchmarks -- Conjugate Gradient (CG) and the Power method. In particular, using qdot for the dot products in CG can result in a majority of components being perforated or quantized to half precision without increasing the iteration count required for convergence to the same solution as CG using a double precision dot product.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.00115v1-abstract-full').style.display = 'none'; document.getElementById('2105.00115v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 April, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2104.14056">arXiv:2104.14056</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2104.14056">pdf</a>, <a href="https://arxiv.org/format/2104.14056">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Machine Learning Techniques for <span class="search-hit mathjax">Software</span> Quality Assurance: A Survey
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Omri%2C+S">Safa Omri</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sinz%2C+C">Carsten Sinz</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2104.14056v1-abstract-short" style="display: inline;">
        Over the last years, machine learning techniques have been applied to more and more <span class="search-hit mathjax">application</span> domains, including&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.14056v1-abstract-full').style.display = 'inline'; document.getElementById('2104.14056v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2104.14056v1-abstract-full" style="display: none;">
        Over the last years, machine learning techniques have been applied to more and more <span class="search-hit mathjax">application</span> domains, including <span class="search-hit mathjax">software</span> engineering and, especially, <span class="search-hit mathjax">software</span> quality assurance. Important <span class="search-hit mathjax">application</span> domains have been, e.g., <span class="search-hit mathjax">software</span> defect prediction or test case selection and prioritization. The ability to predict which components in a large <span class="search-hit mathjax">software</span> system are most likely to contain the largest numbers of faults in the next release helps to better manage projects, including early estimation of possible release delays, and affordably guide corrective actions to <span class="search-hit mathjax">improve</span> the quality of the <span class="search-hit mathjax">software</span>. However, developing robust fault prediction models is a challenging task and many techniques have been proposed in the literature. Closely related to estimating defect-prone parts of a <span class="search-hit mathjax">software</span> system is the question of how to select and prioritize test cases, and indeed test case prioritization has been extensively researched as a means for <span class="search-hit mathjax">reducing</span> the time taken to discover regressions in <span class="search-hit mathjax">software</span>. In this survey, we discuss various approaches in both fault prediction and test case prioritization, also explaining how in recent studies deep learning algorithms for fault prediction help to bridge the gap between <span class="search-hit mathjax">programs</span>&#39; semantics and fault prediction features. We also review recently proposed machine learning methods for test case prioritization (TCP), and their ability to <span class="search-hit mathjax">reduce</span> the cost of regression testing without negatively affecting fault detection capabilities.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.14056v1-abstract-full').style.display = 'none'; document.getElementById('2104.14056v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 28 April, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2104.12586">arXiv:2104.12586</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2104.12586">pdf</a>, <a href="https://arxiv.org/ps/2104.12586">ps</a>, <a href="https://arxiv.org/format/2104.12586">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Information Theory">cs.IT</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Consistency issues in Gaussian Mixture Models reduction algorithms
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=D%27Ortenzio%2C+A">A. D&#39;Ortenzio</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Manes%2C+C">C. Manes</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2104.12586v1-abstract-short" style="display: inline;">
        In many contexts Gaussian Mixtures (GM) are used to approximate probability distributions, possibly time-varying. In some <span class="search-hit mathjax">applications</span> the number of GM components exponentially increases over time, and reduction procedures are required to keep them reasonably limited. The GM reduction (GMR) problem can be formulated by choosing different measures of the diss&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.12586v1-abstract-full').style.display = 'inline'; document.getElementById('2104.12586v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2104.12586v1-abstract-full" style="display: none;">
        In many contexts Gaussian Mixtures (GM) are used to approximate probability distributions, possibly time-varying. In some <span class="search-hit mathjax">applications</span> the number of GM components exponentially increases over time, and reduction procedures are required to keep them reasonably limited. The GM reduction (GMR) problem can be formulated by choosing different measures of the dissimilarity of GMs before and after reduction, like the Kullback-Leibler Divergence (KLD) and the Integral Squared Error (ISE). Since in no case the solution is obtained in closed form, many approximate GMR algorithms have been proposed in the past three decades, although none of them provides <span class="search-hit mathjax">optimality</span> guarantees. In this work we discuss the importance of the choice of the dissimilarity measure and the issue of consistency of all steps of a reduction algorithm with the chosen measure. Indeed, most of the existing GMR algorithms are composed by several steps which are not consistent with a unique measure, and for this reason may produce <span class="search-hit mathjax">reduced</span> GMs far from <span class="search-hit mathjax">optimality</span>. In particular, the use of the KLD, of the ISE and normalized ISE is discussed and compared in this perspective.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.12586v1-abstract-full').style.display = 'none'; document.getElementById('2104.12586v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 26 April, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2104.10301">arXiv:2104.10301</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2104.10301">pdf</a>, <a href="https://arxiv.org/format/2104.10301">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Neural and Evolutionary Computing">cs.NE</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1145/3449639.3459300">10.1145/3449639.3459300 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Towards Exploratory Landscape Analysis for Large-scale <span class="search-hit mathjax">Optimization</span>: A Dimensionality Reduction Framework
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Tanabe%2C+R">Ryoji Tanabe</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2104.10301v1-abstract-short" style="display: inline;">
        Although exploratory landscape analysis (ELA) has shown its effectiveness in various <span class="search-hit mathjax">applications</span>, most previous studies focused only on low- and moderate-dimensional problems. Thus, little is known about the scalability of the ELA approach for large-scale&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.10301v1-abstract-full').style.display = 'inline'; document.getElementById('2104.10301v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2104.10301v1-abstract-full" style="display: none;">
        Although exploratory landscape analysis (ELA) has shown its effectiveness in various <span class="search-hit mathjax">applications</span>, most previous studies focused only on low- and moderate-dimensional problems. Thus, little is known about the scalability of the ELA approach for large-scale <span class="search-hit mathjax">optimization</span>. In this context, first, this paper analyzes the computational cost of features in the flacco package. Our results reveal that two important feature classes (ela_level and ela_meta) cannot be applied to large-scale <span class="search-hit mathjax">optimization</span> due to their high computational cost. To <span class="search-hit mathjax">improve</span> the scalability of the ELA approach, this paper proposes a dimensionality reduction framework that computes features in a <span class="search-hit mathjax">reduced</span> lower-dimensional space than the original solution space. We demonstrate that the proposed framework can drastically <span class="search-hit mathjax">reduce</span> the computation time of ela_level and ela_meta for large dimensions. In addition, the proposed framework can make the cell-mapping feature classes scalable for large-scale <span class="search-hit mathjax">optimization</span>. Our results also show that features computed by the proposed framework are beneficial for predicting the high-level properties of the 24 large-scale BBOB <span class="search-hit mathjax">functions</span>.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.10301v1-abstract-full').style.display = 'none'; document.getElementById('2104.10301v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 20 April, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">This is an accepted version of a paper published in the proceedings of GECCO 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2104.05050">arXiv:2104.05050</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2104.05050">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Research on <span class="search-hit mathjax">Optimization</span> Method of Multi-scale Fish Target Fast Detection Network
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+Y">Yang Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+S">Shengmao Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+F">Fei Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fan%2C+W">Wei Fan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zou%2C+G">Guohua Zou</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bo%2C+J">Jing Bo</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2104.05050v1-abstract-short" style="display: inline;">
        &hellip;Fish&#34; of 84 fishes containing 10042 images, and based on this data set, proposed a multi-scale input fast fish target detection network (BTP-yoloV3) and its <span class="search-hit mathjax">optimization</span> method. The experiment uses Depthwise convolution to redesign the backbone of the yoloV4 network, which&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.05050v1-abstract-full').style.display = 'inline'; document.getElementById('2104.05050v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2104.05050v1-abstract-full" style="display: none;">
        The fish target detection algorithm lacks a good quality data set, and the algorithm achieves real-time detection with lower power consumption on embedded devices, and it is difficult to balance the calculation speed and identification ability. To this end, this paper collected and annotated a data set named &#34;Aquarium Fish&#34; of 84 fishes containing 10042 images, and based on this data set, proposed a multi-scale input fast fish target detection network (BTP-yoloV3) and its <span class="search-hit mathjax">optimization</span> method. The experiment uses Depthwise convolution to redesign the backbone of the yoloV4 network, which <span class="search-hit mathjax">reduces</span> the amount of calculation by 94.1%, and the test accuracy is 92.34%. Then, the training model is enhanced with MixUp, CutMix, and mosaic to increase the test accuracy by 1.27%; Finally, use the mish, swish, and ELU activation <span class="search-hit mathjax">functions</span> to increase the test accuracy by 0.76%. As a result, the accuracy of testing the network with 2000 fish images reached 94.37%, and the computational complexity of the network BFLOPS was only 5.47. Comparing the YoloV3~4, MobileNetV2-yoloV3, and YoloV3-tiny networks of migration learning on this data set. The results show that BTP-Yolov3 has smaller model parameters, faster calculation speed, and lower energy consumption during operation while ensuring the calculation accuracy. It provides a certain reference value for the practical <span class="search-hit mathjax">application</span> of neural network.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.05050v1-abstract-full').style.display = 'none'; document.getElementById('2104.05050v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 11 April, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2104.04611">arXiv:2104.04611</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2104.04611">pdf</a>, <a href="https://arxiv.org/format/2104.04611">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Self-Boosted <span class="search-hit mathjax">Automated</span> <span class="search-hit mathjax">Program</span> Repair
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Benton%2C+S">Samuel Benton</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+M">Mengshi Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+X">Xia Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+L">Lingming Zhang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2104.04611v1-abstract-short" style="display: inline;">
        <span class="search-hit mathjax">Program</span> repair is an integral part of every&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.04611v1-abstract-full').style.display = 'inline'; document.getElementById('2104.04611v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2104.04611v1-abstract-full" style="display: none;">
        <span class="search-hit mathjax">Program</span> repair is an integral part of every <span class="search-hit mathjax">software</span> system&#39;s life-cycle but can be extremely challenging. To date, researchers have proposed various <span class="search-hit mathjax">automated</span> <span class="search-hit mathjax">program</span> repair (APR) techniques to <span class="search-hit mathjax">reduce</span> efforts of manual debugging. However, given a real-world buggy <span class="search-hit mathjax">program</span>, a typical APR technique usually generates a large number of patches, each of which needs to be validated against the original test suite which incurs extremely high computation costs. Although existing APR techniques have already leveraged various static and/or dynamic information to find the desired patches faster, they are still rather costly. In a recent work, researchers proposed unified debugging to leverage the patch execution information during APR to help boost fault localization; in this way,the <span class="search-hit mathjax">application</span> scope of APR techniques can be extended to all possible bugs, e.g., the patch execution information during APR can help with manual repair of the bugs that cannot be <span class="search-hit mathjax">automatically</span> fixed. Inspired by unified debugging, this work proposes SeAPR (Self-Boosted <span class="search-hit mathjax">Automated</span> <span class="search-hit mathjax">Program</span> Repair), the first technique to leverage the earlier patch execution information during APR to help boost <span class="search-hit mathjax">automated</span> repair itself on-the-fly. Our basic intuition is that patches similar to earlier high-quality/low-quality patches should be promoted/degraded to speed up the detection of the desired patches. This experimental study on 12 state-of-the-art APR systems demonstrates that, overall, SeAPR can substantially <span class="search-hit mathjax">reduce</span> the number of patch executions with negligible overhead. Our study also investigates the impact of various configurations on SeAPR. Lastly, our study demonstrates that SeAPR can even leverage the patch execution information from other APR tools from the same buggy <span class="search-hit mathjax">program</span> to further boost APR.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.04611v1-abstract-full').style.display = 'none'; document.getElementById('2104.04611v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 9 April, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">13 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2104.04405">arXiv:2104.04405</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2104.04405">pdf</a>, <a href="https://arxiv.org/format/2104.04405">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Learning Sampling Policy for Faster Derivative Free <span class="search-hit mathjax">Optimization</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zhai%2C+Z">Zhou Zhai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gu%2C+B">Bin Gu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Huang%2C+H">Heng Huang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2104.04405v1-abstract-short" style="display: inline;">
        Zeroth-order (ZO, also known as derivative-free) methods, which estimate the gradient only by two <span class="search-hit mathjax">function</span> evaluations, have attracted much attention recently because of its broad&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.04405v1-abstract-full').style.display = 'inline'; document.getElementById('2104.04405v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2104.04405v1-abstract-full" style="display: none;">
        Zeroth-order (ZO, also known as derivative-free) methods, which estimate the gradient only by two <span class="search-hit mathjax">function</span> evaluations, have attracted much attention recently because of its broad <span class="search-hit mathjax">applications</span> in machine learning community. The two <span class="search-hit mathjax">function</span> evaluations are normally generated with random perturbations from standard Gaussian distribution. To speed up ZO methods, many methods, such as variance <span class="search-hit mathjax">reduced</span> stochastic ZO gradients and learning an adaptive Gaussian distribution, have recently been proposed to <span class="search-hit mathjax">reduce</span> the variances of ZO gradients. However, it is still an open problem whether there is a space to further <span class="search-hit mathjax">improve</span> the convergence of ZO methods. To explore this problem, in this paper, we propose a new reinforcement learning based ZO algorithm (ZO-RL) with learning the sampling policy for generating the perturbations in ZO <span class="search-hit mathjax">optimization</span> instead of using random sampling. To find the <span class="search-hit mathjax">optimal</span> policy, an actor-critic RL algorithm called deep deterministic policy gradient (DDPG) with two neural network <span class="search-hit mathjax">function</span> approximators is adopted. The learned sampling policy guides the perturbed points in the parameter space to estimate a more accurate ZO gradient. To the best of our knowledge, our ZO-RL is the first algorithm to learn the sampling policy using reinforcement learning for ZO <span class="search-hit mathjax">optimization</span> which is parallel to the existing methods. Especially, our ZO-RL can be combined with existing ZO algorithms that could further accelerate the algorithms. Experimental results for different ZO <span class="search-hit mathjax">optimization</span> problems show that our ZO-RL algorithm can effectively <span class="search-hit mathjax">reduce</span> the variances of ZO gradient by learning a sampling policy, and converge faster than existing ZO algorithms in different scenarios.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.04405v1-abstract-full').style.display = 'none'; document.getElementById('2104.04405v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 9 April, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">arXiv admin note: text overlap with arXiv:1910.09464 by other authors</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2104.02588">arXiv:2104.02588</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2104.02588">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computational Engineering, Finance, and Science">cs.CE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Sound">cs.SD</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Audio and Speech Processing">eess.AS</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Principal Component Analysis Applied to Gradient Fields in Band Gap <span class="search-hit mathjax">Optimization</span> Problems for Metamaterials
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Gnecco%2C+G">Giorgio Gnecco</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bacigalupo%2C+A">Andrea Bacigalupo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fantoni%2C+F">Francesca Fantoni</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Selvi%2C+D">Daniela Selvi</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2104.02588v5-abstract-short" style="display: inline;">
        A promising technique for the spectral design of acoustic metamaterials is based on the formulation of suitable constrained nonlinear <span class="search-hit mathjax">optimization</span> problems. Unfortunately, the straightforward&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.02588v5-abstract-full').style.display = 'inline'; document.getElementById('2104.02588v5-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2104.02588v5-abstract-full" style="display: none;">
        A promising technique for the spectral design of acoustic metamaterials is based on the formulation of suitable constrained nonlinear <span class="search-hit mathjax">optimization</span> problems. Unfortunately, the straightforward <span class="search-hit mathjax">application</span> of classical gradient-based iterative <span class="search-hit mathjax">optimization</span> algorithms to the numerical solution of such problems is typically highly demanding, due to the complexity of the underlying physical models. Nevertheless, supervised machine learning techniques can <span class="search-hit mathjax">reduce</span> such a computational effort, e.g., by replacing the original objective <span class="search-hit mathjax">functions</span> of such <span class="search-hit mathjax">optimization</span> problems with more-easily computable approximations. In this framework, the present article describes the <span class="search-hit mathjax">application</span> of a related unsupervised machine learning technique, namely, principal component analysis, to approximate the gradient of the objective <span class="search-hit mathjax">function</span> of a band gap <span class="search-hit mathjax">optimization</span> problem for an acoustic metamaterial, with the aim of making the successive <span class="search-hit mathjax">application</span> of a gradient-based iterative <span class="search-hit mathjax">optimization</span> algorithm faster. Numerical results show the effectiveness of the proposed method.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.02588v5-abstract-full').style.display = 'none'; document.getElementById('2104.02588v5-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 10 May, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 4 April, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2104.02214">arXiv:2104.02214</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2104.02214">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Intelligent Building Control Systems for Thermal Comfort and Energy-Efficiency: A Systematic Review of Artificial Intelligence-Assisted Techniques
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Merabet%2C+G+H">Ghezlane Halhoul Merabet</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Essaaidi%2C+M">Mohamed Essaaidi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Haddou%2C+M+B">Mohamed Ben Haddou</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Qolomany%2C+B">Basheer Qolomany</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Qadir%2C+J">Junaid Qadir</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Anan%2C+M">Muhammad Anan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Al-Fuqaha%2C+A">Ala Al-Fuqaha</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Abid%2C+M+R">Mohamed Riduan Abid</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Benhaddou%2C+D">Driss Benhaddou</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2104.02214v1-abstract-short" style="display: inline;">
        &hellip;primary energy consumed in most countries due to the proliferation of Heating, Ventilation and Air-Conditioning (HVAC) installations in response to the growing demand for <span class="search-hit mathjax">improved</span> thermal comfort.&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.02214v1-abstract-full').style.display = 'inline'; document.getElementById('2104.02214v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2104.02214v1-abstract-full" style="display: none;">
        Building operations represent a significant percentage of the total primary energy consumed in most countries due to the proliferation of Heating, Ventilation and Air-Conditioning (HVAC) installations in response to the growing demand for <span class="search-hit mathjax">improved</span> thermal comfort. <span class="search-hit mathjax">Reducing</span> the associated energy consumption while maintaining comfortable conditions in buildings are conflicting objectives and represent a typical <span class="search-hit mathjax">optimization</span> problem that requires intelligent system design. Over the last decade, different methodologies based on the Artificial Intelligence (AI) techniques have been deployed to find the sweet spot between energy use in HVAC systems and suitable indoor comfort levels to the occupants. This paper performs a comprehensive and an in-depth systematic review of AI-based techniques used for building control systems by assessing the outputs of these techniques, and their implementations in the reviewed works, as well as investigating their abilities to <span class="search-hit mathjax">improve</span> the energy-efficiency, while maintaining thermal comfort conditions. This enables a holistic view of (1) the complexities of delivering thermal comfort to users inside buildings in an energy-efficient way, and (2) the associated bibliographic material to assist researchers and experts in the field in tackling such a challenge. Among the 20 AI tools developed for both energy consumption and comfort control, <span class="search-hit mathjax">functions</span> such as identification and recognition patterns, <span class="search-hit mathjax">optimization</span>, predictive control. Based on the findings of this work, the <span class="search-hit mathjax">application</span> of AI technology in building control is a promising area of research and still an ongoing, i.e., the performance of AI-based control is not yet completely satisfactory. This is mainly due in part to the fact that these algorithms usually need a large amount of high-quality real-world data, which is lacking in the building or, more precisely, the energy sector.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.02214v1-abstract-full').style.display = 'none'; document.getElementById('2104.02214v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 5 April, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">arXiv admin note: text overlap with arXiv:2006.12559</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2104.01750">arXiv:2104.01750</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2104.01750">pdf</a>, <a href="https://arxiv.org/format/2104.01750">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        <span class="search-hit mathjax">Optimal</span> Sampling Gaps for Adaptive Submodular Maximization
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Tang%2C+S">Shaojie Tang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yuan%2C+J">Jing Yuan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2104.01750v2-abstract-short" style="display: inline;">
        Running machine learning algorithms on large and rapidly growing volumes of data are often computationally expensive, one common trick to <span class="search-hit mathjax">reduce</span> the&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.01750v2-abstract-full').style.display = 'inline'; document.getElementById('2104.01750v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2104.01750v2-abstract-full" style="display: none;">
        Running machine learning algorithms on large and rapidly growing volumes of data are often computationally expensive, one common trick to <span class="search-hit mathjax">reduce</span> the <span class="search-hit mathjax">size</span> of a data set, and thus <span class="search-hit mathjax">reduce</span> the computational cost of machine learning algorithms, is \emph{probability sampling}. It creates a sampled data set by including each data point from the original data set with a known probability. Although the benefit of running machine learning algorithms on the <span class="search-hit mathjax">reduced</span> data set is obvious, one major concern is that the performance of the solution obtained from samples might be much worse than that of the <span class="search-hit mathjax">optimal</span> solution when using the full data set. In this paper, we examine the performance loss caused by probability sampling in the context of adaptive submodular maximization. We consider a easiest probability sampling method which selects each data point independently with probability $r\in[0,1]$. We define sampling gap as the largest ratio of the <span class="search-hit mathjax">optimal</span> solution obtained from the full data set and the <span class="search-hit mathjax">optimal</span> solution obtained from the samples, over independence systems. Our main contribution is to show that if the utility <span class="search-hit mathjax">function</span> is policywise submodular, then for a given sampling rate $r$, the sampling gap is both upper bounded and lower bounded by $1/r$. One immediate implication of our result is that if we can find an $Œ±$-approximation solution based on a sampled data set (which is sampled at sampling rate $r$), then this solution achieves an $Œ±r$ approximation ratio for the original problem when using the full data set. We also show that the property of policywise submodular can be found in a wide range of real-world <span class="search-hit mathjax">applications</span>, including pool-based active learning and adaptive viral marketing.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.01750v2-abstract-full').style.display = 'none'; document.getElementById('2104.01750v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 12 April, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 4 April, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2104.01194">arXiv:2104.01194</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2104.01194">pdf</a>, <a href="https://arxiv.org/format/2104.01194">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Physics Informed Convex Artificial Neural Networks (PICANNs) for <span class="search-hit mathjax">Optimal</span> Transport based Density Estimation
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Singh%2C+A">Amanpreet Singh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bauer%2C+M">Martin Bauer</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Joshi%2C+S">Sarang Joshi</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2104.01194v1-abstract-short" style="display: inline;">
        <span class="search-hit mathjax">Optimal</span> Mass Transport (OMT) is a well studied problem with a variety of&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.01194v1-abstract-full').style.display = 'inline'; document.getElementById('2104.01194v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2104.01194v1-abstract-full" style="display: none;">
        <span class="search-hit mathjax">Optimal</span> Mass Transport (OMT) is a well studied problem with a variety of <span class="search-hit mathjax">applications</span> in a diverse set of fields ranging from Physics to Computer Vision and in particular Statistics and Data Science. Since the original formulation of Monge in 1781 significant theoretical progress been made on the existence, uniqueness and properties of the <span class="search-hit mathjax">optimal</span> transport maps. The actual numerical computation of the transport maps, particularly in high dimensions, remains a challenging problem. By Brenier&#39;s theorem, the continuous OMT problem can be <span class="search-hit mathjax">reduced</span> to that of solving a non-linear PDE of Monge-Ampere type whose solution is a convex <span class="search-hit mathjax">function</span>. In this paper, building on recent developments of input convex neural networks and physics informed neural networks for solving PDE&#39;s, we propose a Deep Learning approach to solve the continuous OMT problem.
  To demonstrate the versatility of our framework we focus on the ubiquitous density estimation and generative modeling tasks in statistics and machine learning. Finally as an example we show how our framework can be incorporated with an autoencoder to estimate an effective probabilistic generative model.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.01194v1-abstract-full').style.display = 'none'; document.getElementById('2104.01194v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 2 April, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">15 page, 6 figures, 1 table</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2104.00428">arXiv:2104.00428</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2104.00428">pdf</a>, <a href="https://arxiv.org/format/2104.00428">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Storchastic: A Framework for General Stochastic <span class="search-hit mathjax">Automatic</span> Differentiation
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=van+Krieken%2C+E">Emile van Krieken</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tomczak%2C+J+M">Jakub M. Tomczak</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Teije%2C+A+t">Annette ten Teije</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2104.00428v2-abstract-short" style="display: inline;">
        Modelers use <span class="search-hit mathjax">automatic</span> differentiation (AD) of computation graphs to implement complex Deep Learning models without defining gradient computations. Stochastic AD extends AD to stochastic computation graphs with sampling steps, which arise when modelers handle the intractable expectations common in Reinforcement Learning and Variational Inference. However, cu&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.00428v2-abstract-full').style.display = 'inline'; document.getElementById('2104.00428v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2104.00428v2-abstract-full" style="display: none;">
        Modelers use <span class="search-hit mathjax">automatic</span> differentiation (AD) of computation graphs to implement complex Deep Learning models without defining gradient computations. Stochastic AD extends AD to stochastic computation graphs with sampling steps, which arise when modelers handle the intractable expectations common in Reinforcement Learning and Variational Inference. However, current methods for stochastic AD are limited: They are either only <span class="search-hit mathjax">applicable</span> to continuous random variables and differentiable <span class="search-hit mathjax">functions</span>, or can only use simple but high variance score-<span class="search-hit mathjax">function</span> estimators. To overcome these limitations, we introduce Storchastic, a new framework for AD of stochastic computation graphs. Storchastic allows the modeler to choose from a wide variety of gradient estimation methods at each sampling step, to <span class="search-hit mathjax">optimally</span> <span class="search-hit mathjax">reduce</span> the variance of the gradient estimates. Furthermore, Storchastic is provably unbiased for estimation of any-order gradients, and generalizes variance reduction techniques to higher-order gradient estimates. Finally, we implement Storchastic as a PyTorch library.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.00428v2-abstract-full').style.display = 'none'; document.getElementById('2104.00428v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 28 May, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 1 April, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">28 pages, 1 figure</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2104.00142">arXiv:2104.00142</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2104.00142">pdf</a>, <a href="https://arxiv.org/format/2104.00142">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        NodeSRT: A Selective Regression Testing Tool for Node.js <span class="search-hit mathjax">Application</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+Y">Yufeng Chen</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2104.00142v1-abstract-short" style="display: inline;">
        Node.js is one of the most popular frameworks for building web <span class="search-hit mathjax">applications</span>. As&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.00142v1-abstract-full').style.display = 'inline'; document.getElementById('2104.00142v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2104.00142v1-abstract-full" style="display: none;">
        Node.js is one of the most popular frameworks for building web <span class="search-hit mathjax">applications</span>. As <span class="search-hit mathjax">software</span> systems mature, the cost of running their entire regression test suite can become significant. Selective Regression Testing (SRT) is a technique that executes only a subset of tests the regression test suite can detect <span class="search-hit mathjax">software</span> failures more efficiently. Previous SRT studies mainly focused on standard desktop <span class="search-hit mathjax">applications</span>. Node.js <span class="search-hit mathjax">applications</span> are considered hard to perform test reduction because of Node&#39;s asynchronous, event-driven <span class="search-hit mathjax">programming</span> model and because JavaScript is a dynamic <span class="search-hit mathjax">programming</span> language. In this paper, we present NodeSRT, a Selective Regression Testing framework for Node.js <span class="search-hit mathjax">applications</span>. By performing static and dynamic analysis, NodeSRT identifies the relationship between changed methods and tests, then <span class="search-hit mathjax">reduces</span> the regression test suite to only tests that are affected by the change to <span class="search-hit mathjax">improve</span> the execution time of the regression test suite. To evaluate our selection technique, we applied NodeSRT to two open-source projects: Uppy and Simorgh, then compared our approach with the retest-all strategy and current industry-standard SRT technique: Jest OnlyChange. The results demonstrate that NodeSRT correctly selects affected tests based on changes and is 250% faster, 450% more precise than the Jest OnlyChange.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.00142v1-abstract-full').style.display = 'none'; document.getElementById('2104.00142v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 31 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.17231">arXiv:2103.17231</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.17231">pdf</a>, <a href="https://arxiv.org/format/2103.17231">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        CDiNN -Convex Difference Neural Networks
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Sankaranarayanan%2C+P">Parameswaran Sankaranarayanan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rengaswamy%2C+R">Raghunathan Rengaswamy</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.17231v2-abstract-short" style="display: inline;">
        Neural networks with ReLU activation <span class="search-hit mathjax">function</span> have been shown to be universal&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.17231v2-abstract-full').style.display = 'inline'; document.getElementById('2103.17231v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.17231v2-abstract-full" style="display: none;">
        Neural networks with ReLU activation <span class="search-hit mathjax">function</span> have been shown to be universal <span class="search-hit mathjax">function</span> approximators and learn <span class="search-hit mathjax">function</span> mapping as non-smooth <span class="search-hit mathjax">functions</span>. Recently, there is considerable interest in the use of neural networks in <span class="search-hit mathjax">applications</span> such as <span class="search-hit mathjax">optimal</span> control. It is well-known that <span class="search-hit mathjax">optimization</span> involving non-convex, non-smooth <span class="search-hit mathjax">functions</span> are computationally intensive and have limited convergence guarantees. Moreover, the choice of <span class="search-hit mathjax">optimization</span> hyper-parameters used in gradient descent/ascent significantly affect the quality of the obtained solutions. A new neural network architecture called the Input Convex Neural Networks (ICNNs) learn the output as a convex <span class="search-hit mathjax">function</span> of inputs thereby allowing the use of efficient convex <span class="search-hit mathjax">optimization</span> methods. Use of ICNNs for determining the input for minimizing output has two major problems: learning of a non-convex <span class="search-hit mathjax">function</span> as a convex mapping could result in significant <span class="search-hit mathjax">function</span> approximation error, and we also note that the existing representations cannot capture simple dynamic structures like linear time delay systems. We attempt to address the above problems by introduction of a new neural network architecture, which we call the CDiNN, which learns the <span class="search-hit mathjax">function</span> as a difference of polyhedral convex <span class="search-hit mathjax">functions</span> from data. We also discuss that, in some cases, the <span class="search-hit mathjax">optimal</span> input can be obtained from CDiNN through difference of convex <span class="search-hit mathjax">optimization</span> with convergence guarantees and that at each iteration, the problem is <span class="search-hit mathjax">reduced</span> to a linear <span class="search-hit mathjax">programming</span> problem.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.17231v2-abstract-full').style.display = 'none'; document.getElementById('2103.17231v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 5 April, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 31 March, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.15608">arXiv:2103.15608</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.15608">pdf</a>, <a href="https://arxiv.org/format/2103.15608">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Neural and Evolutionary Computing">cs.NE</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Hybrid Evolutionary <span class="search-hit mathjax">Optimization</span> Approach for Oilfield Well Control <span class="search-hit mathjax">Optimization</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Kumar%2C+A">Ajitabh Kumar</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.15608v1-abstract-short" style="display: inline;">
        Oilfield production <span class="search-hit mathjax">optimization</span> is challenging due to subsurface model complexity and associated non-linearity, large number of control parameters, large number of production scenarios, and subsurface uncertainties.&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.15608v1-abstract-full').style.display = 'inline'; document.getElementById('2103.15608v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.15608v1-abstract-full" style="display: none;">
        Oilfield production <span class="search-hit mathjax">optimization</span> is challenging due to subsurface model complexity and associated non-linearity, large number of control parameters, large number of production scenarios, and subsurface uncertainties. <span class="search-hit mathjax">Optimization</span> involves time-consuming reservoir simulation studies to compare different production scenarios and settings. This paper presents efficacy of two hybrid evolutionary <span class="search-hit mathjax">optimization</span> approaches for well control <span class="search-hit mathjax">optimization</span> of a waterflooding operation, and demonstrates their <span class="search-hit mathjax">application</span> using Olympus benchmark. A simpler, weighted sum of cumulative fluid (WCF) is used as objective <span class="search-hit mathjax">function</span> first, which is then replaced by net present value (NPV) of discounted cash-flow for comparison. Two popular evolutionary <span class="search-hit mathjax">optimization</span> algorithms, genetic algorithm (GA) and particle swarm <span class="search-hit mathjax">optimization</span> (PSO), are first used in standalone mode to solve well control <span class="search-hit mathjax">optimization</span> problem. Next, both GA and PSO methods are used with another popular <span class="search-hit mathjax">optimization</span> algorithm, covariance matrix adaptation-evolution strategy (CMA-ES), in hybrid mode. Hybrid <span class="search-hit mathjax">optimization</span> run is made by transferring the resulting population from one algorithm to the next as its starting population for further <span class="search-hit mathjax">improvement</span>. Approximately four thousand simulation runs are needed for standalone GA and PSO methods to converge, while six thousand runs are needed in case of two hybrid <span class="search-hit mathjax">optimization</span> modes (GA-CMA-ES and PSO-CMA-ES). To <span class="search-hit mathjax">reduce</span> turn-around time, commercial cloud computing is used and simulation workload is distributed using parallel <span class="search-hit mathjax">programming</span>. GA and PSO algorithms have a good balance between exploratory and exploitative properties, thus are able identify regions of interest. CMA-ES algorithm is able to further refine the solution using its excellent exploitative properties. Thus, GA or PSO with CMA-ES in hybrid mode yields better <span class="search-hit mathjax">optimization</span> result as compared to standalone GA or PSO algorithms.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.15608v1-abstract-full').style.display = 'none'; document.getElementById('2103.15608v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 29 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.14024">arXiv:2103.14024</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.14024">pdf</a>, <a href="https://arxiv.org/format/2103.14024">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Graphics">cs.GR</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        PlenOctrees for Real-time Rendering of Neural Radiance Fields
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Yu%2C+A">Alex Yu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+R">Ruilong Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tancik%2C+M">Matthew Tancik</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+H">Hao Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ng%2C+R">Ren Ng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kanazawa%2C+A">Angjoo Kanazawa</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.14024v1-abstract-short" style="display: inline;">
        &hellip;by pre-tabulating the NeRF into a PlenOctree. In order to preserve view-dependent effects such as specularities, we factorize the appearance via closed-form spherical basis <span class="search-hit mathjax">functions</span>. Specifically, we show that it is possible to train NeRFs to predict a spherical harmonic representation of radiance, removing the viewing direction as an input to the neural ne&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.14024v1-abstract-full').style.display = 'inline'; document.getElementById('2103.14024v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.14024v1-abstract-full" style="display: none;">
        We introduce a method to render Neural Radiance Fields (NeRFs) in real time using PlenOctrees, an octree-based 3D representation which supports view-dependent effects. Our method can render 800x800 images at more than 150 FPS, which is over 3000 times faster than conventional NeRFs. We do so without sacrificing quality while preserving the ability of NeRFs to perform free-viewpoint rendering of scenes with arbitrary geometry and view-dependent effects. Real-time performance is achieved by pre-tabulating the NeRF into a PlenOctree. In order to preserve view-dependent effects such as specularities, we factorize the appearance via closed-form spherical basis <span class="search-hit mathjax">functions</span>. Specifically, we show that it is possible to train NeRFs to predict a spherical harmonic representation of radiance, removing the viewing direction as an input to the neural network. Furthermore, we show that PlenOctrees can be directly <span class="search-hit mathjax">optimized</span> to further minimize the reconstruction loss, which leads to equal or better quality compared to competing methods. Moreover, this octree <span class="search-hit mathjax">optimization</span> step can be used to <span class="search-hit mathjax">reduce</span> the training time, as we no longer need to wait for the NeRF training to converge fully. Our real-time neural rendering approach may potentially enable new <span class="search-hit mathjax">applications</span> such as 6-DOF industrial and product visualizations, as well as next generation AR/VR systems. PlenOctrees are amenable to in-browser rendering as well; please visit the project page for the interactive online demo, as well as video and <span class="search-hit mathjax">code</span>: https://alexyu.net/plenoctrees
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.14024v1-abstract-full').style.display = 'none'; document.getElementById('2103.14024v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 25 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.13909">arXiv:2103.13909</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.13909">pdf</a>, <a href="https://arxiv.org/ps/2103.13909">ps</a>, <a href="https://arxiv.org/format/2103.13909">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Numerical Analysis">math.NA</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1098/rsta.2020.0191">10.1098/rsta.2020.0191 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Regularization by Denoising Sub-sampled Newton Method for Spectral CT Multi-Material Decomposition
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Perelli%2C+A">Alessandro Perelli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Andersen%2C+M+S">Martin S. Andersen</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.13909v1-abstract-short" style="display: inline;">
        &hellip;exploiting different photon energy spectra. In this work, we aim at efficiently solving a model-based maximum-a-posterior problem to reconstruct multi-materials images with <span class="search-hit mathjax">application</span> to spectral CT. In particular, we propose to solve a regularized&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.13909v1-abstract-full').style.display = 'inline'; document.getElementById('2103.13909v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.13909v1-abstract-full" style="display: none;">
        Spectral Computed Tomography (CT) is an emerging technology that enables to estimate the concentration of basis materials within a scanned object by exploiting different photon energy spectra. In this work, we aim at efficiently solving a model-based maximum-a-posterior problem to reconstruct multi-materials images with <span class="search-hit mathjax">application</span> to spectral CT. In particular, we propose to solve a regularized <span class="search-hit mathjax">optimization</span> problem based on a plug-in image-denoising <span class="search-hit mathjax">function</span> using a randomized second order method. By approximating the Newton step using a sketching of the Hessian of the likelihood <span class="search-hit mathjax">function</span>, it is possible to <span class="search-hit mathjax">reduce</span> the complexity while retaining the complex prior structure given by the data-driven regularizer. We exploit a non-uniform block sub-sampling of the Hessian with inexact but efficient Conjugate gradient updates that require only Jacobian-vector products for denoising term. Finally, we show numerical and experimental results for spectral CT materials decomposition.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.13909v1-abstract-full').style.display = 'none'; document.getElementById('2103.13909v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 25 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted in Philosophical Transactions A, issue &#34;Synergistic tomographic image reconstruction (Part 1)&#34;</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.13509">arXiv:2103.13509</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.13509">pdf</a>, <a href="https://arxiv.org/ps/2103.13509">ps</a>, <a href="https://arxiv.org/format/2103.13509">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Science and Game Theory">cs.GT</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A Variational Inequality Approach to Bayesian Regression Games
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Guo%2C+W">Wenshuo Guo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jordan%2C+M+I">Michael I. Jordan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lin%2C+T">Tianyi Lin</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.13509v1-abstract-short" style="display: inline;">
        &hellip;conflicting, but not necessarily perfectly antagonistic objectives. Although the Bayesian approach is a more general alternative to the standard minimax formulation, the <span class="search-hit mathjax">applications</span> of Bayesian regression games have been limited due to computational difficulties, and the existence and uniqueness of a Bayesian equilibrium are only known for quadratic cost&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.13509v1-abstract-full').style.display = 'inline'; document.getElementById('2103.13509v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.13509v1-abstract-full" style="display: none;">
        Bayesian regression games are a special class of two-player general-sum Bayesian games in which the learner is partially informed about the adversary&#39;s objective through a Bayesian prior. This formulation captures the uncertainty in regard to the adversary, and is useful in problems where the learner and adversary may have conflicting, but not necessarily perfectly antagonistic objectives. Although the Bayesian approach is a more general alternative to the standard minimax formulation, the <span class="search-hit mathjax">applications</span> of Bayesian regression games have been limited due to computational difficulties, and the existence and uniqueness of a Bayesian equilibrium are only known for quadratic cost <span class="search-hit mathjax">functions</span>. First, we prove the existence and uniqueness of a Bayesian equilibrium for a class of convex and smooth Bayesian games by regarding it as a solution of an infinite-dimensional variational inequality (VI) in Hilbert space. We consider two special cases in which the infinite-dimensional VI <span class="search-hit mathjax">reduces</span> to a high-dimensional VI or a nonconvex stochastic <span class="search-hit mathjax">optimization</span>, and provide two simple algorithms of solving them with strong convergence guarantees. Numerical results on real datasets demonstrate the promise of this approach.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.13509v1-abstract-full').style.display = 'none'; document.getElementById('2103.13509v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 24 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.13147">arXiv:2103.13147</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.13147">pdf</a>, <a href="https://arxiv.org/format/2103.13147">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Multiagent Systems">cs.MA</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Multi-Agent Off-Policy TD Learning: Finite-Time Analysis with Near-<span class="search-hit mathjax">Optimal</span> Sample Complexity and Communication Complexity
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+Z">Ziyi Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhou%2C+Y">Yi Zhou</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+R">Rongrong Chen</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.13147v1-abstract-short" style="display: inline;">
        &hellip;studied recently. However, such a type of convergence has not been well established for off-policy TD learning in the multi-agent setting, which covers broader <span class="search-hit mathjax">applications</span> and is fundamentally more challenging. This work develops two decentralized TD with correction (TDC) algorithms for multi-agent off-policy TD learning under Markovian sampling. In particu&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.13147v1-abstract-full').style.display = 'inline'; document.getElementById('2103.13147v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.13147v1-abstract-full" style="display: none;">
        The finite-time convergence of off-policy TD learning has been comprehensively studied recently. However, such a type of convergence has not been well established for off-policy TD learning in the multi-agent setting, which covers broader <span class="search-hit mathjax">applications</span> and is fundamentally more challenging. This work develops two decentralized TD with correction (TDC) algorithms for multi-agent off-policy TD learning under Markovian sampling. In particular, our algorithms preserve full privacy of the actions, policies and rewards of the agents, and adopt mini-batch sampling to <span class="search-hit mathjax">reduce</span> the sampling variance and communication frequency. Under Markovian sampling and linear <span class="search-hit mathjax">function</span> approximation, we proved that the finite-time sample complexity of both algorithms for achieving an $Œµ$-accurate solution is in the order of $\mathcal{O}(Œµ^{-1}\ln Œµ^{-1})$, matching the near-<span class="search-hit mathjax">optimal</span> sample complexity of centralized TD(0) and TDC. Importantly, the communication complexity of our algorithms is in the order of $\mathcal{O}(\ln Œµ^{-1})$, which is significantly lower than the communication complexity $\mathcal{O}(Œµ^{-1}\ln Œµ^{-1})$ of the existing decentralized TD(0). Experiments corroborate our theoretical findings.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.13147v1-abstract-full').style.display = 'none'; document.getElementById('2103.13147v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 24 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">34 pages, 3 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.12874">arXiv:2103.12874</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.12874">pdf</a>, <a href="https://arxiv.org/format/2103.12874">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Information Retrieval">cs.IR</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Using Meta-learning to Recommend Process Discovery Methods
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Barbon%2C+S">Sylvio Barbon Jr</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ceravolo%2C+P">Paolo Ceravolo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Damiani%2C+E">Ernesto Damiani</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tavares%2C+G+M">Gabriel Marques Tavares</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.12874v1-abstract-short" style="display: inline;">
        &hellip;process models to enhance management capabilities. However, selecting the suitable method for a specific event log highly relies on human expertise, hindering its broad <span class="search-hit mathjax">application</span>. Solutions based on Meta-learning (MtL) have been promising for creating systems with <span class="search-hit mathjax">reduced</span> human assistance. This paper presents a MtL s&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.12874v1-abstract-full').style.display = 'inline'; document.getElementById('2103.12874v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.12874v1-abstract-full" style="display: none;">
        Process discovery methods have obtained remarkable achievements in Process Mining, delivering comprehensible process models to enhance management capabilities. However, selecting the suitable method for a specific event log highly relies on human expertise, hindering its broad <span class="search-hit mathjax">application</span>. Solutions based on Meta-learning (MtL) have been promising for creating systems with <span class="search-hit mathjax">reduced</span> human assistance. This paper presents a MtL solution for recommending process discovery methods that maximize model quality according to complementary dimensions. Thanks to our MtL pipeline, it was possible to recommend a discovery method with 92% of accuracy using light-weight features that describe the event log. Our experimental analysis also provided significant insights on the importance of log features in generating recommendations, paving the way to a deeper understanding of the discovery algorithms.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.12874v1-abstract-full').style.display = 'none'; document.getElementById('2103.12874v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 23 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">16 pages, 6 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.12293">arXiv:2103.12293</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.12293">pdf</a>, <a href="https://arxiv.org/format/2103.12293">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Stochastic Reweighted Gradient Descent
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Hanchi%2C+A+E">Ayoub El Hanchi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Stephens%2C+D+A">David A. Stephens</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.12293v1-abstract-short" style="display: inline;">
        Despite the strong theoretical guarantees that variance-<span class="search-hit mathjax">reduced</span> finite-sum&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.12293v1-abstract-full').style.display = 'inline'; document.getElementById('2103.12293v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.12293v1-abstract-full" style="display: none;">
        Despite the strong theoretical guarantees that variance-<span class="search-hit mathjax">reduced</span> finite-sum <span class="search-hit mathjax">optimization</span> algorithms enjoy, their <span class="search-hit mathjax">applicability</span> remains limited to cases where the memory overhead they introduce (SAG/SAGA), or the periodic full gradient computation they require (SVRG/SARAH) are manageable. A promising approach to achieving variance reduction while avoiding these drawbacks is the use of importance sampling instead of control variates. While many such methods have been proposed in the literature, directly proving that they <span class="search-hit mathjax">improve</span> the convergence of the resulting <span class="search-hit mathjax">optimization</span> algorithm has remained elusive. In this work, we propose an importance-sampling-based algorithm we call SRG (stochastic reweighted gradient). We analyze the convergence of SRG in the strongly-convex case and show that, while it does not recover the linear rate of control variates methods, it provably outperforms SGD. We pay particular attention to the time and memory overhead of our proposed method, and design a specialized red-black tree allowing its efficient implementation. Finally, we present empirical results to support our findings.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.12293v1-abstract-full').style.display = 'none'; document.getElementById('2103.12293v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 23 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.11154">arXiv:2103.11154</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.11154">pdf</a>, <a href="https://arxiv.org/format/2103.11154">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Neural and Evolutionary Computing">cs.NE</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Train Deep Neural Networks in 40-D Subspaces
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+T">Tao Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tan%2C+L">Lei Tan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tao%2C+Q">Qinghua Tao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+Y">Yipeng Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Huang%2C+X">Xiaolin Huang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.11154v1-abstract-short" style="display: inline;">
        &hellip;space. By investigating such low-dimensional properties of the training trajectory, we propose a Dynamic Linear Dimensionality Reduction (DLDR), which dramatically <span class="search-hit mathjax">reduces</span> the parameter space to a variable subspace of significantly lower dimension. Since there are only a few variables to&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.11154v1-abstract-full').style.display = 'inline'; document.getElementById('2103.11154v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.11154v1-abstract-full" style="display: none;">
        Although there are massive parameters in deep neural networks, the training can actually proceed in a rather low-dimensional space. By investigating such low-dimensional properties of the training trajectory, we propose a Dynamic Linear Dimensionality Reduction (DLDR), which dramatically <span class="search-hit mathjax">reduces</span> the parameter space to a variable subspace of significantly lower dimension. Since there are only a few variables to <span class="search-hit mathjax">optimize</span>, second-order methods become <span class="search-hit mathjax">applicable</span>. Following this idea, we develop a quasi-Newton-based algorithm to train these variables obtained by DLDR, rather than the original parameters of neural networks. The experimental results strongly support the dimensionality reduction performance: for many standard neural networks, <span class="search-hit mathjax">optimizing</span> over only 40 variables, one can achieve comparable performance against the regular training over thousands or even millions of parameters.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.11154v1-abstract-full').style.display = 'none'; document.getElementById('2103.11154v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 20 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.10872">arXiv:2103.10872</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.10872">pdf</a>, <a href="https://arxiv.org/format/2103.10872">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computational Engineering, Finance, and Science">cs.CE</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Mathematical Finance">q-fin.MF</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Risk Management">q-fin.RM</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        <span class="search-hit mathjax">Optimal</span> Clearing Payments in a Financial Contagion Model
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Calafiore%2C+G">Giuseppe Calafiore</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fracastoro%2C+G">Giulia Fracastoro</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Proskurnikov%2C+A+V">Anton V. Proskurnikov</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.10872v1-abstract-short" style="display: inline;">
        &hellip;of clearing vector (the vector of the entities&#39; total payments). In this paper, we propose a necessary and sufficient condition for the uniqueness of clearing vector <span class="search-hit mathjax">applicable</span> to an arbitrary topology of the financial network. Further, we show that the overall system loss can be <span class="search-hit mathjax">reduced</span> if one relaxes the pro-rata&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.10872v1-abstract-full').style.display = 'inline'; document.getElementById('2103.10872v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.10872v1-abstract-full" style="display: none;">
        Modern financial networks are characterized by complex structures of mutual obligations. Such interconnections may propagate and amplificate individual defaults, leading in some cases to financial disaster. For this reason, mathematical models for the study and control of systemic risk (the risk of severe instabilities on the system as a whole, due to default of single entities) have attracted considerable research attention in recent years. One important line of research is concerned with mechanisms of clearing, that is, the mechanism by which mutual debts are repaid, in the regular regime, or in a default regime. One of the first models of a clearing mechanism was proposed by Eisenberg and Noe and is based on the three rules: limited liability, the priority of debt claims over the shareholders&#39; interests, and the equal priority of debts (pro-rata rule). These three principles naturally lead to the concept of clearing vector (the vector of the entities&#39; total payments). In this paper, we propose a necessary and sufficient condition for the uniqueness of clearing vector <span class="search-hit mathjax">applicable</span> to an arbitrary topology of the financial network. Further, we show that the overall system loss can be <span class="search-hit mathjax">reduced</span> if one relaxes the pro-rata rule and replaces the clearing vector by a matrix of clearing payments. This approach shifts the focus from the individual interest to the system, or social, interest, in order to control and contain the adverse effects of cascaded failures.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.10872v1-abstract-full').style.display = 'none'; document.getElementById('2103.10872v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 19 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.10381">arXiv:2103.10381</a>
        <span>&nbsp;&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computational Engineering, Finance, and Science">cs.CE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computational Physics">physics.comp-ph</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Data-driven Coarse-grained Modeling of Non-equilibrium Systems
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+S">Shu Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+Z">Zhan Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pan%2C+W">Wenxiao Pan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.10381v2-abstract-short" style="display: inline;">
        Modeling a high-dimensional Hamiltonian system in <span class="search-hit mathjax">reduced</span> dimensions with respect to coarse-grained (CG) variables can greatly&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.10381v2-abstract-full').style.display = 'inline'; document.getElementById('2103.10381v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.10381v2-abstract-full" style="display: none;">
        Modeling a high-dimensional Hamiltonian system in <span class="search-hit mathjax">reduced</span> dimensions with respect to coarse-grained (CG) variables can greatly <span class="search-hit mathjax">reduce</span> computational cost and enable efficient bottom-up prediction of main features of the system for many <span class="search-hit mathjax">applications</span>. However, it usually experiences significantly altered dynamics due to loss of degrees of freedom upon coarse-graining. To establish CG models that can faithfully preserve dynamics, previous efforts mainly focused on equilibrium systems. In contrast, various soft matter systems are known out of equilibrium. Therefore, the present work concerns non-equilibrium systems and enables accurate and efficient CG modeling that preserves non-equilibrium dynamics and is generally <span class="search-hit mathjax">applicable</span> to any non-equilibrium process and any observable of interest. To this end, the dynamic equation of a CG variable is built in the form of the non-stationary generalized Langevin equation (nsGLE) to account for the dependence of non-equilibrium processes on the initial conditions, where the two-time memory kernel is determined from the data of the two-time auto-correlation <span class="search-hit mathjax">function</span> of the non-equilibrium trajectory-averaged observable of interest. By embedding the non-stationary non-Markovian process in an extended stochastic framework, an explicit form of the non-stationary random noise in the nsGLE is introduced, and the cost is significantly <span class="search-hit mathjax">reduced</span> for solving the nsGLE to predict the non-equilibrium dynamics of the CG variable. To prove and exploit the equivalence of the nsGLE and extended dynamics, the memory kernel is parameterized in a two-time exponential expansion. A data-driven hybrid <span class="search-hit mathjax">optimization</span> process is proposed for the parameterization, a non-convex and high-dimensional <span class="search-hit mathjax">optimization</span> problem.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.10381v2-abstract-full').style.display = 'none'; document.getElementById('2103.10381v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 18 March, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Large part of this paper needs to be revised</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.10294">arXiv:2103.10294</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.10294">pdf</a>, <a href="https://arxiv.org/format/2103.10294">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Discrete Mathematics">cs.DM</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Learning to Schedule Heuristics in Branch-and-Bound
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Chmiela%2C+A">Antonia Chmiela</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Khalil%2C+E+B">Elias B. Khalil</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gleixner%2C+A">Ambros Gleixner</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lodi%2C+A">Andrea Lodi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pokutta%2C+S">Sebastian Pokutta</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.10294v1-abstract-short" style="display: inline;">
        Primal heuristics play a crucial role in exact solvers for Mixed Integer <span class="search-hit mathjax">Programming</span> (MIP). While solvers are guaranteed to find&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.10294v1-abstract-full').style.display = 'inline'; document.getElementById('2103.10294v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.10294v1-abstract-full" style="display: none;">
        Primal heuristics play a crucial role in exact solvers for Mixed Integer <span class="search-hit mathjax">Programming</span> (MIP). While solvers are guaranteed to find <span class="search-hit mathjax">optimal</span> solutions given sufficient time, real-world <span class="search-hit mathjax">applications</span> typically require finding good solutions early on in the search to enable fast decision-making. While much of MIP research focuses on designing effective heuristics, the question of how to manage multiple MIP heuristics in a solver has not received equal attention. Generally, solvers follow hard-<span class="search-hit mathjax">coded</span> rules derived from empirical testing on broad sets of instances. Since the performance of heuristics is instance-dependent, using these general rules for a particular problem might not yield the best performance. In this work, we propose the first data-driven framework for scheduling heuristics in an exact MIP solver. By learning from data describing the performance of primal heuristics, we obtain a problem-specific schedule of heuristics that collectively find many solutions at minimal cost. We provide a formal description of the problem and propose an efficient algorithm for computing such a schedule. Compared to the default settings of a state-of-the-art academic MIP solver, we are able to <span class="search-hit mathjax">reduce</span> the average primal integral by up to 49% on a class of challenging instances.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.10294v1-abstract-full').style.display = 'none'; document.getElementById('2103.10294v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 18 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.09782">arXiv:2103.09782</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.09782">pdf</a>, <a href="https://arxiv.org/format/2103.09782">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Towards <span class="search-hit mathjax">Automated</span> Metamorphic Test Identification for Ocean System Models
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Hiremath%2C+D+J">Dilip Jagadeeshwarswamy Hiremath</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Claus%2C+M">Martin Claus</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hasselbring%2C+W">Wilhelm Hasselbring</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rath%2C+W">Willi Rath</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.09782v1-abstract-short" style="display: inline;">
        Metamorphic testing seeks to verify <span class="search-hit mathjax">software</span> in the absence of test oracles. Our&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.09782v1-abstract-full').style.display = 'inline'; document.getElementById('2103.09782v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.09782v1-abstract-full" style="display: none;">
        Metamorphic testing seeks to verify <span class="search-hit mathjax">software</span> in the absence of test oracles. Our <span class="search-hit mathjax">application</span> domain is ocean system modeling, where test oracles rarely exist, but where symmetries of the simulated physical systems are known. The input data set is large owing to the requirements of the <span class="search-hit mathjax">application</span> domain. This paper presents work in progress for the <span class="search-hit mathjax">automated</span> generation of metamorphic test scenarios using machine learning. We extended our previously proposed method [1] to identify metamorphic relations with <span class="search-hit mathjax">reduced</span> computational complexity. Initially, we represent metamorphic relations as identity maps. We construct a cost <span class="search-hit mathjax">function</span> that minimizes for identifying a metamorphic relation orthogonal to previously found metamorphic relations and penalize for the identity map. A machine learning algorithm is used to identify all possible metamorphic relations minimizing the defined cost <span class="search-hit mathjax">function</span>. We propose applying dimensionality reduction techniques to identify attributes in the input which have high variance among the identified metamorphic relations. We apply mutation on these selected attributes to identify distinct metamorphic relations with <span class="search-hit mathjax">reduced</span> computational complexity. For experimental evaluation, we subject the two implementations of an ocean-modeling <span class="search-hit mathjax">application</span> to the proposed method to present the use of metamorphic relations to test the two implementations of this <span class="search-hit mathjax">application</span>.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.09782v1-abstract-full').style.display = 'none'; document.getElementById('2103.09782v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">5 Pages, 1 Figure</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        
          <span class="has-text-black-bis has-text-weight-semibold">MSC Class:</span>
          J.2
        

        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.09595">arXiv:2103.09595</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.09595">pdf</a>, <a href="https://arxiv.org/format/2103.09595">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Cryptography and Security">cs.CR</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Assessing Smart Contracts Security Technical Debts
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ahmadjee%2C+S">Sabreen Ahmadjee</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mera-G%C3%B3mez%2C+C">Carlos Mera-G√≥mez</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bahsoon%2C+R">Rami Bahsoon</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.09595v1-abstract-short" style="display: inline;">
        &hellip;of the identified vulnerabilities leveraging the technical debt metaphor, its principal and interest. We use examples of vulnerable contracts to demonstrate the <span class="search-hit mathjax">applicability</span> of our approach. The results show that our assessment approach increases the visibility of security design issues. It also allows developers to concentrate on resolving smart contract v&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.09595v1-abstract-full').style.display = 'inline'; document.getElementById('2103.09595v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.09595v1-abstract-full" style="display: none;">
        Smart contracts are self-enforcing agreements that are employed to exchange assets without the approval of trusted third parties. This feature has encouraged various sectors to make use of smart contracts when transacting. Experience shows that many deployed contracts are vulnerable to exploitation due to their poor design, which allows attackers to steal valuable assets from the involved parties. Therefore, an assessment approach that allows developers to recognise the consequences of deploying vulnerable contracts is needed. In this paper, we propose a debt-aware approach for assessing security design vulnerabilities in smart contracts. Our assessment approach involves two main steps: (i) identification of design vulnerabilities using security analysis techniques and (ii) an estimation of the ramifications of the identified vulnerabilities leveraging the technical debt metaphor, its principal and interest. We use examples of vulnerable contracts to demonstrate the <span class="search-hit mathjax">applicability</span> of our approach. The results show that our assessment approach increases the visibility of security design issues. It also allows developers to concentrate on resolving smart contract vulnerabilities through technical debt impact analysis and prioritisation. Developers can use our approach to inform the design of more secure contracts and for <span class="search-hit mathjax">reducing</span> unintentional debts caused by a lack of awareness of security issues.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.09595v1-abstract-full').style.display = 'none'; document.getElementById('2103.09595v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.08457">arXiv:2103.08457</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.08457">pdf</a>, <a href="https://arxiv.org/format/2103.08457">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        RANP: Resource Aware Neuron Pruning at Initialization for 3D CNNs
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Xu%2C+Z">Zhiwei Xu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ajanthan%2C+T">Thalaiyasingam Ajanthan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Vineet%2C+V">Vibhav Vineet</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hartley%2C+R">Richard Hartley</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.08457v1-abstract-short" style="display: inline;">
        Although 3D Convolutional Neural Networks are essential for most learning based <span class="search-hit mathjax">applications</span> involving dense 3D data, their&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.08457v1-abstract-full').style.display = 'inline'; document.getElementById('2103.08457v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.08457v1-abstract-full" style="display: none;">
        Although 3D Convolutional Neural Networks are essential for most learning based <span class="search-hit mathjax">applications</span> involving dense 3D data, their <span class="search-hit mathjax">applicability</span> is limited due to excessive memory and computational requirements. Compressing such networks by pruning therefore becomes highly desirable. However, pruning 3D CNNs is largely unexplored possibly because of the complex nature of typical pruning algorithms that embeds pruning into an iterative <span class="search-hit mathjax">optimization</span> paradigm. In this work, we introduce a Resource Aware Neuron Pruning (RANP) algorithm that prunes 3D CNNs at initialization to high sparsity levels. Specifically, the core idea is to obtain an importance score for each neuron based on their sensitivity to the loss <span class="search-hit mathjax">function</span>. This neuron importance is then reweighted according to the neuron resource consumption related to FLOPs or memory. We demonstrate the effectiveness of our pruning method on 3D semantic segmentation with widely used 3D-UNets on ShapeNet and BraTS&#39;18 datasets, video classification with MobileNetV2 and I3D on UCF101 dataset, and two-view stereo matching with Pyramid Stereo Matching (PSM) network on SceneFlow dataset. In these experiments, our RANP leads to roughly 50%-95% reduction in FLOPs and 35%-80% reduction in memory with negligible loss in accuracy compared to the unpruned networks. This significantly <span class="search-hit mathjax">reduces</span> the computational resources required to train 3D CNNs. The pruned network obtained by our algorithm can also be easily scaled up and transferred to another dataset for training.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.08457v1-abstract-full').style.display = 'none'; document.getElementById('2103.08457v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 February, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">this is an extension of our 3DV2020 conference paper RANP. arXiv admin note: substantial text overlap with arXiv:2010.02488</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.07286">arXiv:2103.07286</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.07286">pdf</a>, <a href="https://arxiv.org/format/2103.07286">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Integration of Convolutional Neural Networks in Mobile <span class="search-hit mathjax">Applications</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Castanyer%2C+R+C">Roger Creus Castanyer</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mart%C3%ADnez-Fern%C3%A1ndez%2C+S">Silverio Mart√≠nez-Fern√°ndez</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Franch%2C+X">Xavier Franch</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.07286v1-abstract-short" style="display: inline;">
        When building Deep Learning (DL) models, data scientists and <span class="search-hit mathjax">software</span> engineers manage the trade-off between their accuracy, or any other suitable success criteria, and their complexity. In an environment with high computational power, a common practice is making the models go deeper by designing more sophisticated architectures. However, in the context of m&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.07286v1-abstract-full').style.display = 'inline'; document.getElementById('2103.07286v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.07286v1-abstract-full" style="display: none;">
        When building Deep Learning (DL) models, data scientists and <span class="search-hit mathjax">software</span> engineers manage the trade-off between their accuracy, or any other suitable success criteria, and their complexity. In an environment with high computational power, a common practice is making the models go deeper by designing more sophisticated architectures. However, in the context of mobile devices, which possess less computational power, keeping complexity under control is a must. In this paper, we study the performance of a system that integrates a DL model as a trade-off between the accuracy and the complexity. At the same time, we relate the complexity to the efficiency of the system. With this, we present a practical study that aims to explore the challenges met when <span class="search-hit mathjax">optimizing</span> the performance of DL models becomes a requirement. Concretely, we aim to identify: (i) the most concerning challenges when deploying DL-based <span class="search-hit mathjax">software</span> in mobile <span class="search-hit mathjax">applications</span>; and (ii) the path for <span class="search-hit mathjax">optimizing</span> the performance trade-off. We obtain results that verify many of the identified challenges in the related work such as the availability of frameworks and the <span class="search-hit mathjax">software</span>-data dependency. We provide a documentation of our experience when facing the identified challenges together with the discussion of possible solutions to them. Additionally, we implement a solution to the sustainability of the DL models when deployed in order to <span class="search-hit mathjax">reduce</span> the severity of other identified challenges. Moreover, we relate the performance trade-off to a new defined challenge featuring the impact of the complexity in the obtained accuracy. Finally, we discuss and motivate future work that aims to provide solutions to the more open challenges found.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.07286v1-abstract-full').style.display = 'none'; document.getElementById('2103.07286v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 11 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Pre-print. Accepted and to be published in WAIN@ICSE 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.06757">arXiv:2103.06757</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.06757">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Programming Languages">cs.PL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Auto-COP: Adaptation Generation in Context-Oriented <span class="search-hit mathjax">Programming</span> using Reinforcement Learning Options
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Cardozo%2C+N">Nicol√°s Cardozo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dusparic%2C+I">Ivana Dusparic</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.06757v1-abstract-short" style="display: inline;">
        Self-adaptive <span class="search-hit mathjax">software</span> systems continuously adapt in response to internal and external changes in their execution environment, captured as contexts. The COP paradigm posits a technique for the development of self-adaptive systems, capturing their main characteristics with specialized&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.06757v1-abstract-full').style.display = 'inline'; document.getElementById('2103.06757v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.06757v1-abstract-full" style="display: none;">
        Self-adaptive <span class="search-hit mathjax">software</span> systems continuously adapt in response to internal and external changes in their execution environment, captured as contexts. The COP paradigm posits a technique for the development of self-adaptive systems, capturing their main characteristics with specialized <span class="search-hit mathjax">programming</span> language constructs. COP adaptations are specified as independent modules composed in and out of the base system as contexts are activated and deactivated in response to sensed circumstances from the surrounding environment. However, the definition of adaptations, their contexts and associated specialized behavior, need to be specified at design time. In complex CPS this is intractable due to new unpredicted operating conditions. We propose Auto-COP, a new technique to enable generation of adaptations at run time. Auto-COP uses RL options to build action sequences, based on the previous instances of the system execution. Options are explored in interaction with the environment, and the most suitable options for each context are used to generate adaptations exploiting COP. To validate Auto-COP, we present two case studies exhibiting different system characteristics and <span class="search-hit mathjax">application</span> domains: a driving assistant and a robot delivery system. We present examples of Auto-COP <span class="search-hit mathjax">code</span> generated at run time, to illustrate the types of circumstances (contexts) requiring adaptation, and the corresponding generated adaptations for each context. We confirm that the generated adaptations exhibit correct system behavior measured by domain-specific performance metrics, while <span class="search-hit mathjax">reducing</span> the number of required execution/actuation steps by a factor of two showing that the adaptations are regularly selected by the running system as adaptive behavior is more appropriate than the execution of primitive actions.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.06757v1-abstract-full').style.display = 'none'; document.getElementById('2103.06757v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 11 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Submitted to The Art, Science, and Engineering of Programming Journal. 22 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.05244">arXiv:2103.05244</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.05244">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Mathematical Software">cs.MS</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Symbolic Computation">cs.SC</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        ModelingToolkit: A Composable Graph Transformation System For Equation-Based Modeling
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+Y">Yingbo Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gowda%2C+S">Shashi Gowda</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Anantharaman%2C+R">Ranjan Anantharaman</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Laughman%2C+C">Chris Laughman</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shah%2C+V">Viral Shah</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rackauckas%2C+C">Chris Rackauckas</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.05244v2-abstract-short" style="display: inline;">
        Getting good performance out of numerical equation solvers requires that the user has provided stable and efficient <span class="search-hit mathjax">functions</span> representing their model. However, users should not be trusted to write good&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.05244v2-abstract-full').style.display = 'inline'; document.getElementById('2103.05244v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.05244v2-abstract-full" style="display: none;">
        Getting good performance out of numerical equation solvers requires that the user has provided stable and efficient <span class="search-hit mathjax">functions</span> representing their model. However, users should not be trusted to write good <span class="search-hit mathjax">code</span>. In this manuscript we describe ModelingToolkit (MTK), a symbolic equation-based modeling system which allows for composable transformations to generate stable, efficient, and parallelized model implementations. MTK blurs the lines of traditional symbolic computing by acting directly on a user&#39;s numerical <span class="search-hit mathjax">code</span>. We show the ability to apply graph algorithms for <span class="search-hit mathjax">automatically</span> parallelizing and performing index reduction on <span class="search-hit mathjax">code</span> written for differential-algebraic equation (DAE) solvers, &#34;fixing&#34; the performance and stability of the model without requiring any changes to on the user&#39;s part. We demonstrate how composable model transformations can be combined with <span class="search-hit mathjax">automated</span> data-driven surrogate generation techniques, allowing machine learning methods to generate accelerated approximate models within an acausal modeling framework. These <span class="search-hit mathjax">reduced</span> models are shown to outperform the Dymola Modelica compiler on an HVAC model by 590x at 3\% error. Together, this demonstrates MTK as a system for bringing the latest research in graph transformations directly to modeling <span class="search-hit mathjax">applications</span>.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.05244v2-abstract-full').style.display = 'none'; document.getElementById('2103.05244v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 24 March, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 9 March, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">10 pages, 3 figures, 1 table</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.04674">arXiv:2103.04674</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.04674">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Structural Coupling for Microservices
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Panichella%2C+S">Sebastiano Panichella</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rahman%2C+M+I">Mohammad Imranur Rahman</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Taibi%2C+D">Davide Taibi</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.04674v1-abstract-short" style="display: inline;">
        Cloud-native <span class="search-hit mathjax">Applications</span> are &#39;distributed, elastic and horizontal-scalable systems composed of (micro)services which isolate states in a minimum of stateful components&#39;. Hence, an important property is to ensure a low coupling and a high cohesion among the (micro)services composing the cloud-native&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.04674v1-abstract-full').style.display = 'inline'; document.getElementById('2103.04674v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.04674v1-abstract-full" style="display: none;">
        Cloud-native <span class="search-hit mathjax">Applications</span> are &#39;distributed, elastic and horizontal-scalable systems composed of (micro)services which isolate states in a minimum of stateful components&#39;. Hence, an important property is to ensure a low coupling and a high cohesion among the (micro)services composing the cloud-native <span class="search-hit mathjax">application</span>. Loosely coupled and highly cohesive services allow development teams to work in parallel, <span class="search-hit mathjax">reducing</span> the communication overhead between teams. However, despite both practitioners and researchers agree on the importance of this general property, there are no validated metrics to effectively measure or test the actual coupling level between services. In this work, we propose ways to compute and visualize the coupling between microservices, by extending and adapting the concepts behind the computation of the traditional structural coupling. We validate these measures with a case study involving 17 open-source projects and we provide an <span class="search-hit mathjax">automatic</span> approach to measure them. The results of this study highlight how these metrics provide to practitioners a quantitative and visual view of services compositions, which can be useful to conceive advanced systems to monitor the evolution of the service.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.04674v1-abstract-full').style.display = 'none'; document.getElementById('2103.04674v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">11th International Conference on Cloud Computing and Services Science, CLOSER 2021</span>
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        11th International Conference on Cloud Computing and Services Science, CLOSER 2021
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.04651">arXiv:2103.04651</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.04651">pdf</a>, <a href="https://arxiv.org/format/2103.04651">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Information Theory">cs.IT</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Secure and Energy Efficient Transmission for IRS-Assisted Cognitive Radio Networks
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Wu%2C+X">Xuewen Wu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+J">Jingxiao Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xing%2C+Z">Zhe Xing</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gu%2C+C">Chenwei Gu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xue%2C+X">Xiaoping Xue</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zeng%2C+X">Xin Zeng</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.04651v2-abstract-short" style="display: inline;">
        This paper investigates the <span class="search-hit mathjax">application</span> of intelligent reflecting surface (IRS) in an underlay cognitive radio network (CRN), where a multi-antenna cognitive base station (CBS) utilizes spectrum assigned to the primary user (PU) to communicate with a secondary user (SU) via IRS in the presence of multiple coordinated eavesdroppers. To achieve the trade-off b&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.04651v2-abstract-full').style.display = 'inline'; document.getElementById('2103.04651v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.04651v2-abstract-full" style="display: none;">
        This paper investigates the <span class="search-hit mathjax">application</span> of intelligent reflecting surface (IRS) in an underlay cognitive radio network (CRN), where a multi-antenna cognitive base station (CBS) utilizes spectrum assigned to the primary user (PU) to communicate with a secondary user (SU) via IRS in the presence of multiple coordinated eavesdroppers. To achieve the trade-off between the secrecy rate (SR) and energy consumption, we propose a secrecy energy efficiency (SEE) maximization scheme by jointly design the transmit beamforming at CBS and the reflect beamforming at IRS under the SR constraint of SU, the transmit power constraint of CBS, the limited interference temperature of PU and the unit modulus constraint of IRS. The problem is challenging to solve due to the coupled <span class="search-hit mathjax">optimization</span> variables and unit modulus constraint, for which an iterative alternating <span class="search-hit mathjax">optimization</span> algorithm is proposed. As for <span class="search-hit mathjax">optimizing</span> the reflect beamforming, we introduce an auxiliary variable and convert the original non-convex problem into a semi-definite <span class="search-hit mathjax">programming</span> with rank-1 constraint, and then propose an iterative penalty <span class="search-hit mathjax">function</span> based algorithm to implement the <span class="search-hit mathjax">optimal</span> reflect beamforming. As for <span class="search-hit mathjax">optimizing</span> the transmit beamforming, we convert the original problem into an equivalent subtractive form, which is further transformed into a convex <span class="search-hit mathjax">function</span> by employing the difference of two-convex <span class="search-hit mathjax">functions</span> method. Furthermore, we provide a second-order-cone-<span class="search-hit mathjax">programming</span> approximation approach to <span class="search-hit mathjax">reduce</span> the computational complexity. The effectiveness and superiority of our proposed algorithm are verified in the simulation results.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.04651v2-abstract-full').style.display = 'none'; document.getElementById('2103.04651v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 March, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 8 March, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.03239">arXiv:2103.03239</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.03239">pdf</a>, <a href="https://arxiv.org/format/2103.03239">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Moshpit SGD: Communication-Efficient Decentralized Training on Heterogeneous Unreliable Devices
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ryabinin%2C+M">Max Ryabinin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gorbunov%2C+E">Eduard Gorbunov</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Plokhotnyuk%2C+V">Vsevolod Plokhotnyuk</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pekhimenko%2C+G">Gennady Pekhimenko</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.03239v1-abstract-short" style="display: inline;">
        &hellip;by using multiple compute nodes. This approach, known as distributed training, can utilize hundreds of computers via specialized message-passing protocols such as Ring All-<span class="search-hit mathjax">Reduce</span>. However, running these protocols at scale requires reliable high-speed networking that is only available in dedicated clusters. In contrast, many real-world&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.03239v1-abstract-full').style.display = 'inline'; document.getElementById('2103.03239v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.03239v1-abstract-full" style="display: none;">
        Training deep neural networks on large datasets can often be accelerated by using multiple compute nodes. This approach, known as distributed training, can utilize hundreds of computers via specialized message-passing protocols such as Ring All-<span class="search-hit mathjax">Reduce</span>. However, running these protocols at scale requires reliable high-speed networking that is only available in dedicated clusters. In contrast, many real-world <span class="search-hit mathjax">applications</span>, such as federated learning and cloud-based distributed training, operate on unreliable devices with unstable network bandwidth. As a result, these <span class="search-hit mathjax">applications</span> are restricted to using parameter servers or gossip-based averaging protocols. In this work, we lift that restriction by proposing Moshpit All-<span class="search-hit mathjax">Reduce</span> -- an iterative averaging protocol that exponentially converges to the global average. We demonstrate the efficiency of our protocol for distributed <span class="search-hit mathjax">optimization</span> with strong theoretical guarantees. The experiments show 1.3x speedup for ResNet-50 training on ImageNet compared to competitive gossip-based strategies and 1.5x speedup when training ALBERT-large from scratch using preemptible compute nodes.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.03239v1-abstract-full').style.display = 'none'; document.getElementById('2103.03239v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 4 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">41 pages, 6 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.02904">arXiv:2103.02904</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.02904">pdf</a>, <a href="https://arxiv.org/format/2103.02904">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Hardware Architecture">cs.AR</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Effective and Fast: A Novel Sequential Single Path Search for Mixed-Precision Quantization
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Sun%2C+Q">Qigong Sun</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jiao%2C+L">Licheng Jiao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ren%2C+Y">Yan Ren</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+X">Xiufang Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shang%2C+F">Fanhua Shang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+F">Fang Liu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.02904v1-abstract-short" style="display: inline;">
        Since model quantization helps to <span class="search-hit mathjax">reduce</span> the model&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.02904v1-abstract-full').style.display = 'inline'; document.getElementById('2103.02904v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.02904v1-abstract-full" style="display: none;">
        Since model quantization helps to <span class="search-hit mathjax">reduce</span> the model <span class="search-hit mathjax">size</span> and computation latency, it has been successfully applied in many <span class="search-hit mathjax">applications</span> of mobile phones, embedded devices and smart chips. The mixed-precision quantization model can match different quantization bit-precisions according to the sensitivity of different layers to achieve great performance. However, it is a difficult problem to quickly determine the quantization bit-precision of each layer in deep neural networks according to some constraints (e.g., hardware resources, energy consumption, model <span class="search-hit mathjax">size</span> and computation latency). To address this issue, we propose a novel sequential single path search (SSPS) method for mixed-precision quantization,in which the given constraints are introduced into its loss <span class="search-hit mathjax">function</span> to guide searching process. A single path search cell is used to combine a fully differentiable supernet, which can be <span class="search-hit mathjax">optimized</span> by gradient-based algorithms. Moreover, we sequentially determine the candidate precisions according to the selection certainties to exponentially <span class="search-hit mathjax">reduce</span> the search space and speed up the convergence of searching process. Experiments show that our method can efficiently search the mixed-precision models for different architectures (e.g., ResNet-20, 18, 34, 50 and MobileNet-V2) and datasets (e.g., CIFAR-10, ImageNet and COCO) under given constraints, and our experimental results verify that SSPS significantly outperforms their uniform counterparts.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.02904v1-abstract-full').style.display = 'none'; document.getElementById('2103.02904v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 4 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.01516">arXiv:2103.01516</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.01516">pdf</a>, <a href="https://arxiv.org/ps/2103.01516">ps</a>, <a href="https://arxiv.org/format/2103.01516">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Cryptography and Security">cs.CR</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Private Stochastic Convex <span class="search-hit mathjax">Optimization</span>: <span class="search-hit mathjax">Optimal</span> Rates in $\ell_1$ Geometry
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Asi%2C+H">Hilal Asi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Feldman%2C+V">Vitaly Feldman</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Koren%2C+T">Tomer Koren</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Talwar%2C+K">Kunal Talwar</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.01516v1-abstract-short" style="display: inline;">
        Stochastic convex <span class="search-hit mathjax">optimization</span> over an $\ell_1$-bounded domain is ubiquitous in machine learning <span class="search-hit mathjax">applications</span> such as LASSO but remains poorly understood when learning with differential privacy. We show that, up to logarithmic factors the <span class="search-hit mathjax">optimal</span> excess population loss of any&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.01516v1-abstract-full').style.display = 'inline'; document.getElementById('2103.01516v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.01516v1-abstract-full" style="display: none;">
        Stochastic convex <span class="search-hit mathjax">optimization</span> over an $\ell_1$-bounded domain is ubiquitous in machine learning <span class="search-hit mathjax">applications</span> such as LASSO but remains poorly understood when learning with differential privacy. We show that, up to logarithmic factors the <span class="search-hit mathjax">optimal</span> excess population loss of any $(\varepsilon,Œ¥)$-differentially private <span class="search-hit mathjax">optimizer</span> is $\sqrt{\log(d)/n} + \sqrt{d}/\varepsilon n.$ The upper bound is based on a new algorithm that combines the iterative localization approach of~\citet{FeldmanKoTa20} with a new analysis of private regularized mirror descent. It applies to $\ell_p$ bounded domains for $p\in [1,2]$ and queries at most $n^{3/2}$ gradients <span class="search-hit mathjax">improving</span> over the best previously known algorithm for the $\ell_2$ case which needs $n^2$ gradients. Further, we show that when the loss <span class="search-hit mathjax">functions</span> satisfy additional smoothness assumptions, the excess loss is upper bounded (up to logarithmic factors) by $\sqrt{\log(d)/n} + (\log(d)/\varepsilon n)^{2/3}.$ This bound is achieved by a new variance-<span class="search-hit mathjax">reduced</span> version of the Frank-Wolfe algorithm that requires just a single pass over the data. We also show that the lower bound in this case is the minimum of the two rates mentioned above.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.01516v1-abstract-full').style.display = 'none'; document.getElementById('2103.01516v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 2 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.01447">arXiv:2103.01447</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.01447">pdf</a>, <a href="https://arxiv.org/format/2103.01447">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        ZeroSARAH: Efficient Nonconvex Finite-Sum <span class="search-hit mathjax">Optimization</span> with Zero Full Gradient Computation
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+Z">Zhize Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Richt%C3%A1rik%2C+P">Peter Richt√°rik</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.01447v1-abstract-short" style="display: inline;">
        We propose ZeroSARAH -- a novel variant of the variance-<span class="search-hit mathjax">reduced</span> method SARAH (Nguyen et al., 2017) -- for minimizing the average of a large number of nonconvex <span class="search-hit mathjax">functions</span> $\frac{1}{n}\sum_{i=1}^{n}f_i(x)$. To the best of our knowledge, in this nonconvex finite-sum regime, all existing variance-&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.01447v1-abstract-full').style.display = 'inline'; document.getElementById('2103.01447v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.01447v1-abstract-full" style="display: none;">
        We propose ZeroSARAH -- a novel variant of the variance-<span class="search-hit mathjax">reduced</span> method SARAH (Nguyen et al., 2017) -- for minimizing the average of a large number of nonconvex <span class="search-hit mathjax">functions</span> $\frac{1}{n}\sum_{i=1}^{n}f_i(x)$. To the best of our knowledge, in this nonconvex finite-sum regime, all existing variance-<span class="search-hit mathjax">reduced</span> methods, including SARAH, SVRG, SAGA and their variants, need to compute the full gradient over all $n$ data samples at the initial point $x^0$, and then periodically compute the full gradient once every few iterations (for SVRG, SARAH and their variants). Moreover, SVRG, SAGA and their variants typically achieve weaker convergence results than variants of SARAH: $n^{2/3}/Œµ^2$ vs. $n^{1/2}/Œµ^2$. ZeroSARAH is the first variance-<span class="search-hit mathjax">reduced</span> method which does not require any full gradient computations, not even for the initial point. Moreover, ZeroSARAH obtains new state-of-the-art convergence results, which can <span class="search-hit mathjax">improve</span> the previous best-known result (given by e.g., SPIDER, SpiderBoost, SARAH, SSRGD and PAGE) in certain regimes. Avoiding any full gradient computations (which is a time-consuming step) is important in many <span class="search-hit mathjax">applications</span> as the number of data samples $n$ usually is very large. Especially in the distributed setting, periodic computation of full gradient over all data samples needs to periodically synchronize all machines/devices, which may be impossible or very hard to achieve. Thus, we expect that ZeroSARAH will have a practical impact in distributed and federated learning where full device participation is impractical.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.01447v1-abstract-full').style.display = 'none'; document.getElementById('2103.01447v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 1 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.12894">arXiv:2102.12894</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.12894">pdf</a>, <a href="https://arxiv.org/format/2102.12894">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Constrained <span class="search-hit mathjax">Optimization</span> to Train Neural Networks on Critical and Under-Represented Classes
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Sangalli%2C+S">Sara Sangalli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Erdil%2C+E">Ertunc Erdil</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hoetker%2C+A">Andreas Hoetker</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Donati%2C+O">Olivio Donati</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Konukoglu%2C+E">Ender Konukoglu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.12894v2-abstract-short" style="display: inline;">
        &hellip;are notorious for making more mistakes for the classes that have substantially fewer samples than the others during training. Such class imbalance is ubiquitous in clinical <span class="search-hit mathjax">applications</span> and very crucial to handle because the classes with fewer samples most often correspond to critical cases (e.g., cancer) where misclassifications can have severe consequences&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.12894v2-abstract-full').style.display = 'inline'; document.getElementById('2102.12894v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.12894v2-abstract-full" style="display: none;">
        Deep neural networks (DNNs) are notorious for making more mistakes for the classes that have substantially fewer samples than the others during training. Such class imbalance is ubiquitous in clinical <span class="search-hit mathjax">applications</span> and very crucial to handle because the classes with fewer samples most often correspond to critical cases (e.g., cancer) where misclassifications can have severe consequences. Not to miss such cases, binary classifiers need to be operated at high True Positive Rates (TPR) by setting a higher threshold but this comes at the cost of very high False Positive Rates (FPR) for problems with class imbalance. Existing methods for learning under class imbalance most often do not take this into account. We argue that prediction accuracy should be <span class="search-hit mathjax">improved</span> by emphasizing <span class="search-hit mathjax">reducing</span> FPRs at high TPRs for problems where misclassification of the positive, i.e., critical, class samples are associated with higher cost. To this end, we pose the training of a DNN for binary classification as a constrained <span class="search-hit mathjax">optimization</span> problem and introduce a novel constraint that can be used with existing loss <span class="search-hit mathjax">functions</span> to enforce maximal area under the ROC curve (AUC) through prioritizing FPR reduction at high TPR. We solve the resulting constrained <span class="search-hit mathjax">optimization</span> problem using an Augmented Lagrangian method (ALM). Going beyond binary, we also propose two possible extensions of the proposed constraint for multi-class classification problems. We present experimental results for image-based binary and multi-class classification <span class="search-hit mathjax">applications</span> using an in-house medical imaging dataset, CIFAR10, and CIFAR100. Our results demonstrate that the proposed method <span class="search-hit mathjax">improves</span> the baselines in majority of the cases by attaining higher accuracy on critical classes while <span class="search-hit mathjax">reducing</span> the misclassification rate for the non-critical class samples.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.12894v2-abstract-full').style.display = 'none'; document.getElementById('2102.12894v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 June, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 21 February, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.12466">arXiv:2102.12466</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.12466">pdf</a>, <a href="https://arxiv.org/format/2102.12466">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Information Directed Reward Learning for Reinforcement Learning
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Lindner%2C+D">David Lindner</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Turchetta%2C+M">Matteo Turchetta</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tschiatschek%2C+S">Sebastian Tschiatschek</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ciosek%2C+K">Kamil Ciosek</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Krause%2C+A">Andreas Krause</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.12466v1-abstract-short" style="display: inline;">
        For many reinforcement learning (RL) <span class="search-hit mathjax">applications</span>, specifying a reward is difficult. In this paper, we consider an RL setting where the agent can obtain information about the reward only by querying an expert that can, for example, evaluate individual states or provide binary preferences over trajectories. From such expensive feedback, we aim to learn a mode&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.12466v1-abstract-full').style.display = 'inline'; document.getElementById('2102.12466v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.12466v1-abstract-full" style="display: none;">
        For many reinforcement learning (RL) <span class="search-hit mathjax">applications</span>, specifying a reward is difficult. In this paper, we consider an RL setting where the agent can obtain information about the reward only by querying an expert that can, for example, evaluate individual states or provide binary preferences over trajectories. From such expensive feedback, we aim to learn a model of the reward <span class="search-hit mathjax">function</span> that allows standard RL algorithms to achieve high expected return with as few expert queries as possible. For this purpose, we propose Information Directed Reward Learning (IDRL), which uses a Bayesian model of the reward <span class="search-hit mathjax">function</span> and selects queries that maximize the information gain about the difference in return between potentially <span class="search-hit mathjax">optimal</span> policies. In contrast to prior active reward learning methods designed for specific types of queries, IDRL naturally accommodates different query types. Moreover, by shifting the focus from <span class="search-hit mathjax">reducing</span> the reward approximation error to <span class="search-hit mathjax">improving</span> the policy induced by the reward model, it achieves similar or better performance with significantly fewer queries. We support our findings with extensive evaluations in multiple environments and with different types of queries.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.12466v1-abstract-full').style.display = 'none'; document.getElementById('2102.12466v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 24 February, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.12086">arXiv:2102.12086</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.12086">pdf</a>, <a href="https://arxiv.org/format/2102.12086">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Dynamical Systems">math.DS</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Modern Koopman Theory for Dynamical Systems
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Brunton%2C+S+L">Steven L. Brunton</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Budi%C5%A1i%C4%87%2C+M">Marko Budi≈°iƒá</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kaiser%2C+E">Eurika Kaiser</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kutz%2C+J+N">J. Nathan Kutz</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.12086v1-abstract-short" style="display: inline;">
        &hellip;over the past decade, in which nonlinear dynamics are represented in terms of an infinite-dimensional linear operator acting on the space of all possible measurement <span class="search-hit mathjax">functions</span> of the system. This linear representation of nonlinear dynamics has tremendous potential to enable the prediction, estimation, and control of nonlinear systems with standard textbook m&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.12086v1-abstract-full').style.display = 'inline'; document.getElementById('2102.12086v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.12086v1-abstract-full" style="display: none;">
        The field of dynamical systems is being transformed by the mathematical tools and algorithms emerging from modern computing and data science. First-principles derivations and asymptotic reductions are giving way to data-driven approaches that formulate models in operator theoretic or probabilistic frameworks. Koopman spectral theory has emerged as a dominant perspective over the past decade, in which nonlinear dynamics are represented in terms of an infinite-dimensional linear operator acting on the space of all possible measurement <span class="search-hit mathjax">functions</span> of the system. This linear representation of nonlinear dynamics has tremendous potential to enable the prediction, estimation, and control of nonlinear systems with standard textbook methods developed for linear systems. However, obtaining finite-dimensional coordinate systems and embeddings in which the dynamics appear approximately linear remains a central open challenge. The success of Koopman analysis is due primarily to three key factors: 1) there exists rigorous theory connecting it to classical geometric approaches for dynamical systems, 2) the approach is formulated in terms of measurements, making it ideal for leveraging big-data and machine learning techniques, and 3) simple, yet powerful numerical algorithms, such as the dynamic mode decomposition (DMD), have been developed and extended to <span class="search-hit mathjax">reduce</span> Koopman theory to practice in real-world <span class="search-hit mathjax">applications</span>. In this review, we provide an overview of modern Koopman operator theory, describing recent theoretical and algorithmic developments and highlighting these methods with a diverse range of <span class="search-hit mathjax">applications</span>. We also discuss key advances and challenges in the rapidly growing field of machine learning that are likely to drive future developments and significantly transform the theoretical landscape of dynamical systems.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.12086v1-abstract-full').style.display = 'none'; document.getElementById('2102.12086v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 24 February, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">96 pages, 27 figures</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        
          <span class="has-text-black-bis has-text-weight-semibold">MSC Class:</span>
          34A34; 37A30; 37C10; 37M10; 37M99; 37N35; 47A35; 47B33
        

        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.12071">arXiv:2102.12071</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.12071">pdf</a>, <a href="https://arxiv.org/format/2102.12071">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Numerical Analysis">math.NA</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Learning <span class="search-hit mathjax">optimal</span> multigrid smoothers via neural networks
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Huang%2C+R">Ru Huang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+R">Ruipeng Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xi%2C+Y">Yuanzhe Xi</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.12071v2-abstract-short" style="display: inline;">
        &hellip;methods are one of the most efficient techniques for solving linear systems arising from Partial Differential Equations (PDEs) and graph Laplacians from machine learning <span class="search-hit mathjax">applications</span>. One of the key components of multigrid is smoothing, which aims at&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.12071v2-abstract-full').style.display = 'inline'; document.getElementById('2102.12071v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.12071v2-abstract-full" style="display: none;">
        Multigrid methods are one of the most efficient techniques for solving linear systems arising from Partial Differential Equations (PDEs) and graph Laplacians from machine learning <span class="search-hit mathjax">applications</span>. One of the key components of multigrid is smoothing, which aims at <span class="search-hit mathjax">reducing</span> high-frequency errors on each grid level. However, finding <span class="search-hit mathjax">optimal</span> smoothing algorithms is problem-dependent and can impose challenges for many problems. In this paper, we propose an efficient adaptive framework for learning <span class="search-hit mathjax">optimized</span> smoothers from operator stencils in the form of convolutional neural networks (CNNs). The CNNs are trained on small-scale problems from a given type of PDEs based on a supervised loss <span class="search-hit mathjax">function</span> derived from multigrid convergence theories, and can be applied to large-scale problems of the same class of PDEs. Numerical results on anisotropic rotated Laplacian problems demonstrate <span class="search-hit mathjax">improved</span> convergence rates and solution time compared with classical hand-crafted relaxation methods.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.12071v2-abstract-full').style.display = 'none'; document.getElementById('2102.12071v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 5 July, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 24 February, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.11559">arXiv:2102.11559</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.11559">pdf</a>, <a href="https://arxiv.org/format/2102.11559">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Toward Speeding up Mutation Analysis by Memoizing Expensive Methods
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ghanbari%2C+A">Ali Ghanbari</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Marcus%2C+A">Andrian Marcus</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.11559v1-abstract-short" style="display: inline;">
        Mutation analysis has many <span class="search-hit mathjax">applications</span>, such as assessing the quality of test cases, fault localization, test input generation, security analysis, etc. Such&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.11559v1-abstract-full').style.display = 'inline'; document.getElementById('2102.11559v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.11559v1-abstract-full" style="display: none;">
        Mutation analysis has many <span class="search-hit mathjax">applications</span>, such as assessing the quality of test cases, fault localization, test input generation, security analysis, etc. Such <span class="search-hit mathjax">applications</span> involve running test suite against a large number of <span class="search-hit mathjax">program</span> mutants leading to poor scalability. Much research has been aimed at speeding up this process, focusing on <span class="search-hit mathjax">reducing</span> the number of mutants, the number of executed tests, or the execution time of the mutants. This paper presents a novel approach, named MeMu, for <span class="search-hit mathjax">reducing</span> the execution time of the mutants, by memoizing the most expensive methods in the system. Memoization is an <span class="search-hit mathjax">optimization</span> technique that allows bypassing the execution of expensive methods, when repeated inputs are detected. MeMu can be used in conjunction with existing acceleration techniques. We implemented MeMu on top of PITest, a well-known JVM bytecode-level mutation analysis system, and obtained, on average, an 18.15% speed-up over PITest, in the execution time of the mutants for 12 real-world <span class="search-hit mathjax">programs</span>. These promising results and the fact that MeMu could also be used for other <span class="search-hit mathjax">applications</span> that involve repeated execution of tests (e.g., <span class="search-hit mathjax">automatic</span> <span class="search-hit mathjax">program</span> repair and regression testing), strongly support future research for <span class="search-hit mathjax">improving</span> its efficiency.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.11559v1-abstract-full').style.display = 'none'; document.getElementById('2102.11559v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 23 February, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">In proceedings of the 43rd ACM/IEEE International Conference on <span class="search-hit mathjax">Software</span> Engineering (ICSE'21) NIER</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.11210">arXiv:2102.11210</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.11210">pdf</a>, <a href="https://arxiv.org/format/2102.11210">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Non-Convex <span class="search-hit mathjax">Optimization</span> with Spectral Radius Regularization
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Sandler%2C+A">Adam Sandler</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Klabjan%2C+D">Diego Klabjan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Luo%2C+Y">Yuan Luo</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.11210v1-abstract-short" style="display: inline;">
        &hellip;allowing models to better generalize to real word test data, which may be distributed differently from the training data. Specifically, we propose a method of regularized <span class="search-hit mathjax">optimization</span> to&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.11210v1-abstract-full').style.display = 'inline'; document.getElementById('2102.11210v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.11210v1-abstract-full" style="display: none;">
        We develop a regularization method which finds flat minima during the training of deep neural networks and other machine learning models. These minima generalize better than sharp minima, allowing models to better generalize to real word test data, which may be distributed differently from the training data. Specifically, we propose a method of regularized <span class="search-hit mathjax">optimization</span> to <span class="search-hit mathjax">reduce</span> the spectral radius of the Hessian of the loss <span class="search-hit mathjax">function</span>. Additionally, we derive algorithms to efficiently perform this <span class="search-hit mathjax">optimization</span> on neural networks and prove convergence results for these algorithms. Furthermore, we demonstrate that our algorithm works effectively on multiple real world <span class="search-hit mathjax">applications</span> in multiple domains including healthcare. In order to show our models generalize well, we introduce different methods of testing generalizability.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.11210v1-abstract-full').style.display = 'none'; document.getElementById('2102.11210v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 February, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">12 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.10846">arXiv:2102.10846</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.10846">pdf</a>, <a href="https://arxiv.org/ps/2102.10846">ps</a>, <a href="https://arxiv.org/format/2102.10846">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Signal Processing">eess.SP</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Expanding boundaries of Gap Safe screening
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Dantas%2C+C">Cassio Dantas</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Soubies%2C+E">Emmanuel Soubies</a>, 
      
      <a href="/search/?searchtype=author&amp;query=F%C3%A9votte%2C+C">C√©dric F√©votte</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.10846v1-abstract-short" style="display: inline;">
        Sparse <span class="search-hit mathjax">optimization</span> problems are ubiquitous in many fields such as statistics, signal/image processing and machine learning. This has led to the birth of many iterative algorithms to solve them. A powerful strategy to boost the performance of these algorithms is known as safe screening: it allows the early identification of zero coordinates in the solution,&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.10846v1-abstract-full').style.display = 'inline'; document.getElementById('2102.10846v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.10846v1-abstract-full" style="display: none;">
        Sparse <span class="search-hit mathjax">optimization</span> problems are ubiquitous in many fields such as statistics, signal/image processing and machine learning. This has led to the birth of many iterative algorithms to solve them. A powerful strategy to boost the performance of these algorithms is known as safe screening: it allows the early identification of zero coordinates in the solution, which can then be eliminated to <span class="search-hit mathjax">reduce</span> the problem&#39;s <span class="search-hit mathjax">size</span> and accelerate convergence. In this work, we extend the existing Gap Safe screening framework by relaxing the global strong-concavity assumption on the dual cost <span class="search-hit mathjax">function</span>. Instead, we exploit local regularity properties, that is, strong concavity on well-chosen subsets of the domain. The non-negativity constraint is also integrated to the existing framework. Besides making safe screening possible to a broader class of <span class="search-hit mathjax">functions</span> that includes beta-divergences (e.g., the Kullback-Leibler divergence), the proposed approach also <span class="search-hit mathjax">improves</span> upon the existing Gap Safe screening rules on previously <span class="search-hit mathjax">applicable</span> cases (e.g., logistic regression). The proposed general framework is exemplified by some notable particular cases: logistic <span class="search-hit mathjax">function</span>, beta = 1.5 and Kullback-Leibler divergences. Finally, we showcase the effectiveness of the proposed screening rules with different solvers (coordinate descent, multiplicative-update and proximal gradient algorithms) and different data sets (binary classification, hyperspectral and count data).
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.10846v1-abstract-full').style.display = 'none'; document.getElementById('2102.10846v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 February, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.10707">arXiv:2102.10707</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.10707">pdf</a>, <a href="https://arxiv.org/format/2102.10707">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A Zeroth-Order Block Coordinate Descent Algorithm for Huge-Scale Black-Box <span class="search-hit mathjax">Optimization</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Cai%2C+H">HanQin Cai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lou%2C+Y">Yuchen Lou</a>, 
      
      <a href="/search/?searchtype=author&amp;query=McKenzie%2C+D">Daniel McKenzie</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yin%2C+W">Wotao Yin</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.10707v2-abstract-short" style="display: inline;">
        We consider the zeroth-order <span class="search-hit mathjax">optimization</span> problem in the huge-scale setting, where the dimension of the problem is so large that performing even basic vector operations on the decision variables is infeasible. In this paper, we propose a novel algorithm, coined ZO-BCD, that exhibits favorable overall query complexity and has a much smaller per-iteration comp&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.10707v2-abstract-full').style.display = 'inline'; document.getElementById('2102.10707v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.10707v2-abstract-full" style="display: none;">
        We consider the zeroth-order <span class="search-hit mathjax">optimization</span> problem in the huge-scale setting, where the dimension of the problem is so large that performing even basic vector operations on the decision variables is infeasible. In this paper, we propose a novel algorithm, coined ZO-BCD, that exhibits favorable overall query complexity and has a much smaller per-iteration computational complexity. In addition, we discuss how the memory footprint of ZO-BCD can be <span class="search-hit mathjax">reduced</span> even further by the clever use of circulant measurement matrices. As an <span class="search-hit mathjax">application</span> of our new method, we propose the idea of crafting adversarial attacks on neural network based classifiers in a wavelet domain, which can result in problem dimensions of over 1.7 million. In particular, we show that crafting adversarial examples to audio classifiers in a wavelet domain can achieve the state-of-the-art attack success rate of 97.9%.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.10707v2-abstract-full').style.display = 'none'; document.getElementById('2102.10707v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 11 June, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 21 February, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted to ICML 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.09336">arXiv:2102.09336</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.09336">pdf</a>, <a href="https://arxiv.org/format/2102.09336">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        FIXME: Enhance <span class="search-hit mathjax">Software</span> Reliability with Hybrid Approaches in Cloud
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Hwang%2C+J">Jinho Hwang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shwartz%2C+L">Larisa Shwartz</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+Q">Qing Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Batta%2C+R">Raghav Batta</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kumar%2C+H">Harshit Kumar</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Nidd%2C+M">Michael Nidd</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.09336v1-abstract-short" style="display: inline;">
        &hellip;integration/deployment (CICD) in cloud connects developers who need to deliver value faster and more transparently with site reliability engineers (SREs) who need to manage <span class="search-hit mathjax">applications</span> reliably. SREs feed back development issues to developers, and developers commit fixes and trigger CICD to redeploy. The release cycle is more continuous than ever, thus the&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.09336v1-abstract-full').style.display = 'inline'; document.getElementById('2102.09336v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.09336v1-abstract-full" style="display: none;">
        With the promise of reliability in cloud, more enterprises are migrating to cloud. The process of continuous integration/deployment (CICD) in cloud connects developers who need to deliver value faster and more transparently with site reliability engineers (SREs) who need to manage <span class="search-hit mathjax">applications</span> reliably. SREs feed back development issues to developers, and developers commit fixes and trigger CICD to redeploy. The release cycle is more continuous than ever, thus the <span class="search-hit mathjax">code</span> to production is faster and more <span class="search-hit mathjax">automated</span>. To provide this higher level agility, the cloud platforms become more complex in the face of flexibility with deeper layers of virtualization. However, reliability does not come for free with all these complexities. <span class="search-hit mathjax">Software</span> engineers and SREs need to deal with wider information spectrum from virtualized layers. Therefore, providing correlated information with true positive evidences is critical to identify the root cause of issues quickly in order to <span class="search-hit mathjax">reduce</span> mean time to recover (MTTR), performance metrics for SREs. Similarity, knowledge, or statistics driven approaches have been effective, but with increasing data volume and types, an individual approach is limited to correlate semantic relations of different data sources. In this paper, we introduce FIXME to enhance <span class="search-hit mathjax">software</span> reliability with hybrid diagnosis approaches for enterprises. Our evaluation results show using hybrid diagnosis approach is about 17% better in precision. The results are helpful for both practitioners and researchers to develop hybrid diagnosis in the highly dynamic cloud environment.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.09336v1-abstract-full').style.display = 'none'; document.getElementById('2102.09336v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 February, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">ICSE SEIP, 2021</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          I.2.1
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.08571">arXiv:2102.08571</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.08571">pdf</a>, <a href="https://arxiv.org/ps/2102.08571">ps</a>, <a href="https://arxiv.org/format/2102.08571">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Self-Triggered Markov Decision Processes
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Huang%2C+Y">Yunhan Huang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhu%2C+Q">Quanyan Zhu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.08571v1-abstract-short" style="display: inline;">
        &hellip;Markov Decision Processes (MDPs) with self-triggered strategies, where the idea of self-triggered control is extended to more generic MDP models. This extension broadens the <span class="search-hit mathjax">application</span> of self-triggering policies to a broader range of systems. We study the co-design problems of the control policy and the triggering policy to&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.08571v1-abstract-full').style.display = 'inline'; document.getElementById('2102.08571v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.08571v1-abstract-full" style="display: none;">
        In this paper, we study Markov Decision Processes (MDPs) with self-triggered strategies, where the idea of self-triggered control is extended to more generic MDP models. This extension broadens the <span class="search-hit mathjax">application</span> of self-triggering policies to a broader range of systems. We study the co-design problems of the control policy and the triggering policy to <span class="search-hit mathjax">optimize</span> two pre-specified cost criteria. The first cost criterion is introduced by incorporating a pre-specified update penalty into the traditional MDP cost criteria to <span class="search-hit mathjax">reduce</span> the use of communication resources. Under this criteria, a novel dynamic <span class="search-hit mathjax">programming</span> (DP) equation called DP equation with <span class="search-hit mathjax">optimized</span> lookahead to proposed to solve for the self-triggering policy under this criteria. The second self-triggering policy is to maximize the triggering time while still guaranteeing a pre-specified level of sub-<span class="search-hit mathjax">optimality</span>. Theoretical underpinnings are established for the computation and implementation of both policies. Through a gridworld numerical example, we illustrate the two policies&#39; effectiveness in <span class="search-hit mathjax">reducing</span> sources consumption and demonstrate the trade-offs between resource consumption and system performance.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.08571v1-abstract-full').style.display = 'none'; document.getElementById('2102.08571v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 February, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.08547">arXiv:2102.08547</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.08547">pdf</a>, <a href="https://arxiv.org/format/2102.08547">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        NEAT: A Framework for <span class="search-hit mathjax">Automated</span> Exploration of Floating Point Approximations
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Barati%2C+S">Saeid Barati</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ehudin%2C+L">Lee Ehudin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hoffmann%2C+H">Hank Hoffmann</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.08547v1-abstract-short" style="display: inline;">
        &hellip;between computational accuracy and energy efficiency at different levels of the system stack. Approximation at the floating point unit (FPU) allows saving energy by simply <span class="search-hit mathjax">reducing</span> the number of computed floating point bits in return for accuracy loss. Although, finding the most energy efficient approximation for various&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.08547v1-abstract-full').style.display = 'inline'; document.getElementById('2102.08547v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.08547v1-abstract-full" style="display: none;">
        Much recent research is devoted to exploring tradeoffs between computational accuracy and energy efficiency at different levels of the system stack. Approximation at the floating point unit (FPU) allows saving energy by simply <span class="search-hit mathjax">reducing</span> the number of computed floating point bits in return for accuracy loss. Although, finding the most energy efficient approximation for various <span class="search-hit mathjax">applications</span> with minimal effort is the main challenge. To address this issue, we propose NEAT: a pin tool that helps users <span class="search-hit mathjax">automatically</span> explore the accuracy-energy tradeoff space induced by various floating point implementations. NEAT helps programmers explore the effects of simultaneously using multiple floating point implementations to achieve the lowest energy consumption for an accuracy constraint or vice versa. NEAT accepts one or more user-defined floating point implementations and programmable placement rules for where/when to apply them. NEAT then <span class="search-hit mathjax">automatically</span> replaces floating point operations with different implementations based on the user-specified rules during the runtime and explores the resulting tradeoff space to find the best use of approximate floating point implementations for the precision tuning throughout the <span class="search-hit mathjax">program</span>. We evaluate NEAT by enforcing combinations of 24/53 different floating point implementations with three sets of placement rules on a wide range of benchmarks. We find that heuristic precision tuning at the <span class="search-hit mathjax">function</span> level provides up to 22% and 48% energy savings at 1% and 10% accuracy loss comparing to applying a single implementation for the whole <span class="search-hit mathjax">application</span>. Also, NEAT is <span class="search-hit mathjax">applicable</span> to neural networks where it finds the <span class="search-hit mathjax">optimal</span> precision level for each layer considering an accuracy target for the model.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.08547v1-abstract-full').style.display = 'none'; document.getElementById('2102.08547v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 February, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.06311">arXiv:2102.06311</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.06311">pdf</a>, <a href="https://arxiv.org/ps/2102.06311">ps</a>, <a href="https://arxiv.org/format/2102.06311">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Does Culture Matter? Impact of Individualism and Uncertainty Avoidance on App Reviews
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Fischer%2C+R+A">Ricarda Anna-Lena Fischer</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Walczuch%2C+R">Rita Walczuch</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Guzman%2C+E">Emitza Guzman</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.06311v2-abstract-short" style="display: inline;">
        Mobile <span class="search-hit mathjax">applications</span> are often used by an international audience and therefore receive a high daily amount of user reviews from various countries. Previous work found evidence that app store reviews contain helpful information for&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.06311v2-abstract-full').style.display = 'inline'; document.getElementById('2102.06311v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.06311v2-abstract-full" style="display: none;">
        Mobile <span class="search-hit mathjax">applications</span> are often used by an international audience and therefore receive a high daily amount of user reviews from various countries. Previous work found evidence that app store reviews contain helpful information for <span class="search-hit mathjax">software</span> evolution processes. However, the cultural diversity of the reviews and its consequences on specific user feedback characteristics has only been researched to a limited extent so far. In this paper, we examine the influence of two cultural dimensions, Individualism and Uncertainty Avoidance on user feedback in Apple app store reviews written in different languages. For this purpose, we collected 647,141 reviews from eight countries and written in five languages over a period of six months. We then used manual content analysis and <span class="search-hit mathjax">automated</span> processing to examine a sample of 3,120 reviews. The results show that there is a statistically significant influence of Individualism and Uncertainty Avoidance on user feedback characteristics. The results of this study will help researchers and practitioners to <span class="search-hit mathjax">reduce</span> algorithm bias caused by less diversified training and test data and to raise awareness of the importance of analyzing diversified user feedback.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.06311v2-abstract-full').style.display = 'none'; document.getElementById('2102.06311v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 March, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 11 February, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.04259">arXiv:2102.04259</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.04259">pdf</a>, <a href="https://arxiv.org/ps/2102.04259">ps</a>, <a href="https://arxiv.org/format/2102.04259">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Probability">math.PR</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Statistics Theory">math.ST</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Concentration of Non-Isotropic Random Tensors with <span class="search-hit mathjax">Applications</span> to Learning and Empirical Risk Minimization
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Even%2C+M">Mathieu Even</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Massouli%C3%A9%2C+L">Laurent Massouli√©</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.04259v2-abstract-short" style="display: inline;">
        Dimension is an inherent bottleneck to some modern learning tasks, where <span class="search-hit mathjax">optimization</span> methods suffer from the&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.04259v2-abstract-full').style.display = 'inline'; document.getElementById('2102.04259v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.04259v2-abstract-full" style="display: none;">
        Dimension is an inherent bottleneck to some modern learning tasks, where <span class="search-hit mathjax">optimization</span> methods suffer from the <span class="search-hit mathjax">size</span> of the data. In this paper, we study non-isotropic distributions of data and develop tools that aim at <span class="search-hit mathjax">reducing</span> these dimensional costs by a dependency on an effective dimension rather than the ambient one. Based on non-asymptotic estimates of the metric entropy of ellipsoids -- that prove to generalize to infinite dimensions -- and on a chaining argument, our uniform concentration bounds involve an effective dimension instead of the global dimension, <span class="search-hit mathjax">improving</span> over existing results. We show the importance of taking advantage of non-isotropic properties in learning problems with the following <span class="search-hit mathjax">applications</span>: i) we <span class="search-hit mathjax">improve</span> state-of-the-art results in statistical preconditioning for communication-efficient distributed <span class="search-hit mathjax">optimization</span>, ii) we introduce a non-isotropic randomized smoothing for non-smooth <span class="search-hit mathjax">optimization</span>. Both <span class="search-hit mathjax">applications</span> cover a class of <span class="search-hit mathjax">functions</span> that encompasses empirical risk minization (ERM) for linear models.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.04259v2-abstract-full').style.display = 'none'; document.getElementById('2102.04259v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 June, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 4 February, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    

    
      <p class="comments is-size-7">
        

        
          <span class="has-text-black-bis has-text-weight-semibold">MSC Class:</span>
          60E15; 60B20; 60E15; 60F10
        

        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.03877">arXiv:2102.03877</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.03877">pdf</a>, <a href="https://arxiv.org/format/2102.03877">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Materials Science">cond-mat.mtrl-sci</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Noise Reduction in X-ray Photon Correlation Spectroscopy with Convolutional Neural Networks Encoder-Decoder Models
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Konstantinova%2C+T">Tatiana Konstantinova</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wiegart%2C+L">Lutz Wiegart</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rakitin%2C+M">Maksim Rakitin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=DeGennaro%2C+A+M">Anthony M. DeGennaro</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Barbour%2C+A+M">Andi M. Barbour</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.03877v1-abstract-short" style="display: inline;">
        &hellip;X-ray Photon Correlation Spectroscopy is a subject to various kinds of noise. Random and correlated fluctuations and heterogeneities can be present in a two-time correlation <span class="search-hit mathjax">function</span> and obscure the information about the intrinsic dynamics of a sample. Simultaneously addressing the disparate origins of noise in the experimental data is challenging. We propo&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.03877v1-abstract-full').style.display = 'inline'; document.getElementById('2102.03877v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.03877v1-abstract-full" style="display: none;">
        Like other experimental techniques, X-ray Photon Correlation Spectroscopy is a subject to various kinds of noise. Random and correlated fluctuations and heterogeneities can be present in a two-time correlation <span class="search-hit mathjax">function</span> and obscure the information about the intrinsic dynamics of a sample. Simultaneously addressing the disparate origins of noise in the experimental data is challenging. We propose a computational approach for <span class="search-hit mathjax">improving</span> the signal-to-noise ratio in two-time correlation <span class="search-hit mathjax">functions</span> that is based on Convolutional Neural Network Encoder-Decoder (CNN-ED) models. Such models extract features from an image via convolutional layers, project them to a low dimensional space and then reconstruct a clean image from this <span class="search-hit mathjax">reduced</span> representation via transposed convolutional layers. Not only are ED models a general tool for random noise removal, but their <span class="search-hit mathjax">application</span> to low signal-to-noise data can enhance the data quantitative usage since they are able to learn the <span class="search-hit mathjax">functional</span> form of the signal. We demonstrate that the CNN-ED models trained on real-world experimental data help to effectively extract equilibrium dynamics parameters from two-time correlation <span class="search-hit mathjax">functions</span>, containing statistical noise and dynamic heterogeneities. Strategies for <span class="search-hit mathjax">optimizing</span> the models performance and their <span class="search-hit mathjax">applicability</span> limits are discussed.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.03877v1-abstract-full').style.display = 'none'; document.getElementById('2102.03877v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 February, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">5 pages, 10 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.03236">arXiv:2102.03236</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.03236">pdf</a>, <a href="https://arxiv.org/format/2102.03236">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Exact <span class="search-hit mathjax">Optimization</span> of Conformal Predictors via Incremental and Decremental Learning
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Cherubin%2C+G">Giovanni Cherubin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chatzikokolakis%2C+K">Konstantinos Chatzikokolakis</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jaggi%2C+M">Martin Jaggi</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.03236v1-abstract-short" style="display: inline;">
        &hellip;They are suitable for a wide range of problems, from classification and regression to anomaly detection. Unfortunately, their high computational complexity limits their <span class="search-hit mathjax">applicability</span> to large datasets.
  In this work, we show that it is possible to speed up a CP classifier considerably, by studying it in conjunction with the underlying ML method, and by exp&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.03236v1-abstract-full').style.display = 'inline'; document.getElementById('2102.03236v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.03236v1-abstract-full" style="display: none;">
        Conformal Predictors (CP) are wrappers around ML methods, providing error guarantees under weak assumptions on the data distribution. They are suitable for a wide range of problems, from classification and regression to anomaly detection. Unfortunately, their high computational complexity limits their <span class="search-hit mathjax">applicability</span> to large datasets.
  In this work, we show that it is possible to speed up a CP classifier considerably, by studying it in conjunction with the underlying ML method, and by exploiting incremental&amp;decremental learning. For methods such as k-NN, KDE, and kernel LS-SVM, our approach <span class="search-hit mathjax">reduces</span> the running time by one order of magnitude, whilst producing exact solutions. With similar ideas, we also achieve a linear speed up for the harder case of bootstrapping. Finally, we extend these techniques to <span class="search-hit mathjax">improve</span> upon an <span class="search-hit mathjax">optimization</span> of k-NN CP for regression.
  We evaluate our findings empirically, and discuss when methods are suitable for CP <span class="search-hit mathjax">optimization</span>.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.03236v1-abstract-full').style.display = 'none'; document.getElementById('2102.03236v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 5 February, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.03012">arXiv:2102.03012</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.03012">pdf</a>, <a href="https://arxiv.org/format/2102.03012">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A Serverless Cloud-Fog Platform for DNN-Based Video Analytics with Incremental Learning
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+H">Huaizheng Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shen%2C+M">Meng Shen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Huang%2C+Y">Yizheng Huang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wen%2C+Y">Yonggang Wen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Luo%2C+Y">Yong Luo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gao%2C+G">Guanyu Gao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Guan%2C+K">Kyle Guan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.03012v1-abstract-short" style="display: inline;">
        DNN-based video analytics have empowered many new <span class="search-hit mathjax">applications</span> (e.g.,&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.03012v1-abstract-full').style.display = 'inline'; document.getElementById('2102.03012v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.03012v1-abstract-full" style="display: none;">
        DNN-based video analytics have empowered many new <span class="search-hit mathjax">applications</span> (e.g., <span class="search-hit mathjax">automated</span> retail). Meanwhile, the proliferation of fog devices provides developers with more design options to <span class="search-hit mathjax">improve</span> performance and save cost. To the best of our knowledge, this paper presents the first serverless system that takes full advantage of the client-fog-cloud synergy to better serve the DNN-based video analytics. Specifically, the system aims to achieve two goals: 1) Provide the <span class="search-hit mathjax">optimal</span> analytics results under the constraints of lower bandwidth usage and shorter round-trip time (RTT) by judiciously managing the computational and bandwidth resources deployed in the client, fog, and cloud environment. 2) Free developers from tedious administration and operation tasks, including DNN deployment, cloud and fog&#39;s resource management. To this end, we implement a holistic cloud-fog system referred to as VPaaS (Video-Platform-as-a-Service). VPaaS adopts serverless computing to enable developers to build a video analytics pipeline by simply <span class="search-hit mathjax">programming</span> a set of <span class="search-hit mathjax">functions</span> (e.g., model inference), which are then orchestrated to process videos through carefully designed modules. To save bandwidth and <span class="search-hit mathjax">reduce</span> RTT, VPaaS provides a new video streaming protocol that only sends low-quality video to the cloud. The state-of-the-art (SOTA) DNNs deployed at the cloud can identify regions of video frames that need further processing at the fog ends. At the fog ends, misidentified labels in these regions can be corrected using a light-weight DNN model. To address the data drift issues, we incorporate limited human feedback into the system to verify the results and adopt incremental learning to <span class="search-hit mathjax">improve</span> our system continuously. The evaluation demonstrates that VPaaS is superior to several SOTA systems: it maintains high accuracy while <span class="search-hit mathjax">reducing</span> bandwidth usage by up to 21%, RTT by up to 62.5%, and cloud monetary cost by up to 50%.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.03012v1-abstract-full').style.display = 'none'; document.getElementById('2102.03012v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 5 February, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">11 pages, 16 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.01914">arXiv:2102.01914</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.01914">pdf</a>, <a href="https://arxiv.org/ps/2102.01914">ps</a>, <a href="https://arxiv.org/format/2102.01914">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Information Theory">cs.IT</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        <span class="search-hit mathjax">Optimizing</span> QoS for Erasure-<span class="search-hit mathjax">Coded</span> Wireless Data Centers
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Thomdapu%2C+S+T">Srujan Teja Thomdapu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rajawat%2C+K">Ketan Rajawat</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.01914v1-abstract-short" style="display: inline;">
        Cloud computing facilitates the access of <span class="search-hit mathjax">applications</span> and data from any location by a distributed storage system. Erasure&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.01914v1-abstract-full').style.display = 'inline'; document.getElementById('2102.01914v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.01914v1-abstract-full" style="display: none;">
        Cloud computing facilitates the access of <span class="search-hit mathjax">applications</span> and data from any location by a distributed storage system. Erasure <span class="search-hit mathjax">codes</span> offer better data replication technique with <span class="search-hit mathjax">reduced</span> storage costs for more reliability. This paper considers the erasure-<span class="search-hit mathjax">coded</span> data center with multiple servers in a wireless network where each is equipped with a base-station. The cause of latency in the file retrieval process is mainly due to queuing delays at each server. This work puts forth a stochastic <span class="search-hit mathjax">optimization</span> framework for obtaining the <span class="search-hit mathjax">optimal</span> scheduling policy that maximizes users&#39; quality of service (QoS) while adhering to the latency requirements. We further show that the problem has non-linear <span class="search-hit mathjax">functions</span> of expectations in objective and constraints and is impossible to solve with traditional SGD like algorithms. We propose a new algorithm that addresses compositional structure in the problem. Further, we show that the proposed algorithm achieves a faster convergence rate than the best-known results. Finally, we test the efficacy of the proposed method in a simulated environment.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.01914v1-abstract-full').style.display = 'none'; document.getElementById('2102.01914v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 3 February, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">This work is accepted for publication in proceedings of IEEE ICC 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.01048">arXiv:2102.01048</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.01048">pdf</a>, <a href="https://arxiv.org/format/2102.01048">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Databases">cs.DB</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Cryptography and Security">cs.CR</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Secrecy: Secure collaborative analytics on secret-shared data
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Liagouris%2C+J">John Liagouris</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kalavri%2C+V">Vasiliki Kalavri</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Faisal%2C+M">Muhammad Faisal</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Varia%2C+M">Mayank Varia</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.01048v1-abstract-short" style="display: inline;">
        We study the problem of composing and <span class="search-hit mathjax">optimizing</span> relational query plans under secure multi-party computation (MPC). MPC enables mutually distrusting parties to jointly compute arbitrary&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.01048v1-abstract-full').style.display = 'inline'; document.getElementById('2102.01048v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.01048v1-abstract-full" style="display: none;">
        We study the problem of composing and <span class="search-hit mathjax">optimizing</span> relational query plans under secure multi-party computation (MPC). MPC enables mutually distrusting parties to jointly compute arbitrary <span class="search-hit mathjax">functions</span> over private data, while preserving data privacy from each other and from external entities.
  In this paper, we propose a relational MPC framework based on replicated secret sharing. We define a set of oblivious operators, explain the secure primitives they rely on, and provide an analysis of their costs in terms of operations and inter-party communication. We show how these operators can be composed to form end-to-end oblivious queries, and we introduce logical and physical <span class="search-hit mathjax">optimizations</span> that dramatically <span class="search-hit mathjax">reduce</span> the space and communication requirements during query execution, in some cases from quadratic to linear with respect to the cardinality of the input.
  We provide an efficient implementation of our framework, called Secrecy, and evaluate it using real queries from several MPC <span class="search-hit mathjax">application</span> areas. Our results demonstrate that the <span class="search-hit mathjax">optimizations</span> we propose can result in up to 1000x lower execution times compared to baseline approaches, enabling Secrecy to outperform state-of-the-art frameworks and compute MPC queries on millions of input rows with a single thread per party.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.01048v1-abstract-full').style.display = 'none'; document.getElementById('2102.01048v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 1 February, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.00755">arXiv:2102.00755</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.00755">pdf</a>, <a href="https://arxiv.org/format/2102.00755">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Numerical Analysis">math.NA</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computational Engineering, Finance, and Science">cs.CE</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        High Resolution 3D Ultrasonic Breast Imaging by Time-Domain Full Waveform Inversion
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Lucka%2C+F">Felix Lucka</a>, 
      
      <a href="/search/?searchtype=author&amp;query=P%C3%A9rez-Liva%2C+M">Mailyn P√©rez-Liva</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Treeby%2C+B+E">Bradley E. Treeby</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cox%2C+B+T">Ben T. Cox</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.00755v3-abstract-short" style="display: inline;">
        Ultrasound tomography (UST) scanners allow quantitative images of the human breast&#39;s acoustic properties to be derived with potential <span class="search-hit mathjax">applications</span> in screening, diagnosis and therapy planning. Time domain full waveform inversion (TD-FWI) is a promising UST image formation technique that fits the parameter fields of a wave physics model by gradient-based&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.00755v3-abstract-full').style.display = 'inline'; document.getElementById('2102.00755v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.00755v3-abstract-full" style="display: none;">
        Ultrasound tomography (UST) scanners allow quantitative images of the human breast&#39;s acoustic properties to be derived with potential <span class="search-hit mathjax">applications</span> in screening, diagnosis and therapy planning. Time domain full waveform inversion (TD-FWI) is a promising UST image formation technique that fits the parameter fields of a wave physics model by gradient-based <span class="search-hit mathjax">optimization</span>. For high resolution 3D UST, it holds three key challenges: Firstly, its central building block, the computation of the gradient for a single US measurement, has a restrictively large memory footprint. Secondly, this building block needs to be computed for each of the $10^3-10^4$ measurements, resulting in a massive parallel computation usually performed on large computational clusters for days. Lastly, the structure of the underlying <span class="search-hit mathjax">optimization</span> problem may result in slow progression of the solver and convergence to a local minimum. In this work, we design and evaluate a comprehensive computational strategy to overcome these challenges: Firstly, we introduce a novel gradient computation based on time reversal that dramatically <span class="search-hit mathjax">reduces</span> the memory footprint at the expense of one additional wave simulation per source. Secondly, we break the dependence on the number of measurements by using source encoding (SE) to compute stochastic gradient estimates. Also we describe a more accurate, TD-specific SE technique with a finer variance control and use a state-of-the-art stochastic LBFGS method. Lastly, we design an efficient TD multi-grid scheme together with preconditioning to speed up the convergence while avoiding local minima. All components are evaluated in extensive numerical proof-of-concept studies simulating a bowl-shaped 3D UST breast scanner prototype. Finally, we demonstrate that their combination allows us to obtain an accurate 442x442x222 voxel image with a resolution of 0.5mm using Matlab on a single GPU within 24h.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.00755v3-abstract-full').style.display = 'none'; document.getElementById('2102.00755v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 10 March, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 1 February, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.00092">arXiv:2102.00092</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.00092">pdf</a>, <a href="https://arxiv.org/format/2102.00092">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Can Machine Learning Help in Solving Cargo Capacity Management Booking Control Problems?
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Dumouchelle%2C+J">Justin Dumouchelle</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Frejinger%2C+E">Emma Frejinger</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lodi%2C+A">Andrea Lodi</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.00092v1-abstract-short" style="display: inline;">
        &hellip;accept a booking request or reject it to reserve capacity for future bookings with potentially higher revenue. We formulate the problem as a finite-horizon stochastic dynamic <span class="search-hit mathjax">program</span>. The cost of fulfilling the accepted bookings, incurred at the end of the horizon, depends on the packing and routing of the cargo. This is a computationally challenging aspect&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.00092v1-abstract-full').style.display = 'inline'; document.getElementById('2102.00092v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.00092v1-abstract-full" style="display: none;">
        Revenue management is important for carriers (e.g., airlines and railroads). In this paper, we focus on cargo capacity management which has received less attention in the literature than its passenger counterpart. More precisely, we focus on the problem of controlling booking accept/reject decisions: Given a limited capacity, accept a booking request or reject it to reserve capacity for future bookings with potentially higher revenue. We formulate the problem as a finite-horizon stochastic dynamic <span class="search-hit mathjax">program</span>. The cost of fulfilling the accepted bookings, incurred at the end of the horizon, depends on the packing and routing of the cargo. This is a computationally challenging aspect as the latter are solutions to an operational decision-making problem, in our <span class="search-hit mathjax">application</span> a vehicle routing problem (VRP). Seeking a balance between online and offline computation, we propose to train a predictor of the solution costs to the VRPs using supervised learning. In turn, we use the predictions online in approximate dynamic <span class="search-hit mathjax">programming</span> and reinforcement learning algorithms to solve the booking control problem. We compare the results to an existing approach in the literature and show that we are able to obtain control policies that provide increased profit at a <span class="search-hit mathjax">reduced</span> evaluation time. This is achieved thanks to accurate approximation of the operational costs and negligible computing time in comparison to solving the VRPs.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.00092v1-abstract-full').style.display = 'none'; document.getElementById('2102.00092v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 29 January, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2101.11118">arXiv:2101.11118</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2101.11118">pdf</a>, <a href="https://arxiv.org/format/2101.11118">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Can Offline Testing of Deep Neural Networks Replace Their Online Testing?
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Haq%2C+F+U">Fitash Ul Haq</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shin%2C+D">Donghwan Shin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Nejati%2C+S">Shiva Nejati</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Briand%2C+L">Lionel Briand</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2101.11118v2-abstract-short" style="display: inline;">
        &hellip;where DNNs are tested as individual units based on test datasets obtained without involving the DNNs under test, and online testing where DNNs are embedded into a specific <span class="search-hit mathjax">application</span> environment and tested in a closed-loop mode in interaction with the&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.11118v2-abstract-full').style.display = 'inline'; document.getElementById('2101.11118v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2101.11118v2-abstract-full" style="display: none;">
        We distinguish two general modes of testing for Deep Neural Networks (DNNs): Offline testing where DNNs are tested as individual units based on test datasets obtained without involving the DNNs under test, and online testing where DNNs are embedded into a specific <span class="search-hit mathjax">application</span> environment and tested in a closed-loop mode in interaction with the <span class="search-hit mathjax">application</span> environment. Typically, DNNs are subjected to both types of testing during their development life cycle where offline testing is applied immediately after DNN training and online testing follows after offline testing and once a DNN is deployed within a specific <span class="search-hit mathjax">application</span> environment. In this paper, we study the relationship between offline and online testing. Our goal is to determine how offline testing and online testing differ or complement one another and if offline testing results can be used to help <span class="search-hit mathjax">reduce</span> the cost of online testing? Though these questions are generally relevant to all autonomous systems, we study them in the context of <span class="search-hit mathjax">automated</span> driving systems where, as study subjects, we use DNNs <span class="search-hit mathjax">automating</span> end-to-end controls of steering <span class="search-hit mathjax">functions</span> of self-driving vehicles. Our results show that offline testing is less effective than online testing as many safety violations identified by online testing could not be identified by offline testing, while large prediction errors generated by offline testing always led to severe safety violations detectable by online testing. Further, we cannot exploit offline testing results to <span class="search-hit mathjax">reduce</span> the cost of online testing in practice since we are not able to identify specific situations where offline testing could be as accurate as online testing in identifying safety requirement violations.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.11118v2-abstract-full').style.display = 'none'; document.getElementById('2101.11118v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 April, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 26 January, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Journal extension of arXiv:1912.00805; To appear in Empirical <span class="search-hit mathjax">Software</span> Engineering</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2101.10357">arXiv:2101.10357</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2101.10357">pdf</a>, <a href="https://arxiv.org/ps/2101.10357">ps</a>, <a href="https://arxiv.org/format/2101.10357">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Regret-<span class="search-hit mathjax">Optimal</span> Filtering
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Sabag%2C+O">Oron Sabag</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hassibi%2C+B">Babak Hassibi</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2101.10357v1-abstract-short" style="display: inline;">
        We consider the problem of filtering in linear state-space models (e.g., the Kalman filter setting) through the lens of regret <span class="search-hit mathjax">optimization</span>. Different assumptions on the driving disturbance and the observation noise sequences give rise to different estimators: in the stochastic setting to the celebrated Kalman filter, and in the deterministic setting of boun&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.10357v1-abstract-full').style.display = 'inline'; document.getElementById('2101.10357v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2101.10357v1-abstract-full" style="display: none;">
        We consider the problem of filtering in linear state-space models (e.g., the Kalman filter setting) through the lens of regret <span class="search-hit mathjax">optimization</span>. Different assumptions on the driving disturbance and the observation noise sequences give rise to different estimators: in the stochastic setting to the celebrated Kalman filter, and in the deterministic setting of bounded energy disturbances to $H_\infty$ estimators. In this work, we formulate a novel criterion for filter design based on the concept of regret between the estimation error energy of a clairvoyant estimator that has access to all future observations (a so-called smoother) and a causal one that only has access to current and past observations. The regret-<span class="search-hit mathjax">optimal</span> estimator is chosen to minimize this worst-case difference across all bounded-energy noise sequences. The resulting estimator is adaptive in the sense that it aims to mimic the behavior of the clairvoyant estimator, irrespective of what the realization of the noise will be and thus interpolates between the stochastic and deterministic approaches. We provide a solution for the regret estimation problem at two different levels. First, we provide a solution at the operator level by <span class="search-hit mathjax">reducing</span> it to the Nehari problem. Second, for state-space models, we explicitly find the estimator that achieves the <span class="search-hit mathjax">optimal</span> regret. From a computational perspective, the regret-<span class="search-hit mathjax">optimal</span> estimator can be easily implemented by solving three Riccati equations and a single Lyapunov equation. For a state-space model of dimension $n$, the regret-<span class="search-hit mathjax">optimal</span> estimator has a state-space structure of dimension $3n$. We demonstrate the <span class="search-hit mathjax">applicability</span> and efficacy of the estimator in a variety of problems and observe that the estimator has average and worst-case performances that are simultaneously close to their <span class="search-hit mathjax">optimal</span> values. We therefore argue that regret-<span class="search-hit mathjax">optimality</span> is a viable approach to estimator design.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.10357v1-abstract-full').style.display = 'none'; document.getElementById('2101.10357v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 25 January, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted to AISTATS 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2101.09796">arXiv:2101.09796</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2101.09796">pdf</a>, <a href="https://arxiv.org/format/2101.09796">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        The Ifs and Buts of the Development Approaches for IoT <span class="search-hit mathjax">Applications</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Agudelo-Sanabria%2C+S+D">Saitel Daniela Agudelo-Sanabria</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jindal%2C+A">Anshul Jindal</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2101.09796v1-abstract-short" style="display: inline;">
        The recent growth of the Internet of Things (IoT) devices has lead to the rise of various complex <span class="search-hit mathjax">applications</span> where these&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.09796v1-abstract-full').style.display = 'inline'; document.getElementById('2101.09796v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2101.09796v1-abstract-full" style="display: none;">
        The recent growth of the Internet of Things (IoT) devices has lead to the rise of various complex <span class="search-hit mathjax">applications</span> where these <span class="search-hit mathjax">applications</span> involve interactions among large numbers of heterogeneous devices. An important challenge that needs to be addressed is to facilitate the agile development of IoT <span class="search-hit mathjax">applications</span> with minimal effort by the various parties involved in the process. However, IoT <span class="search-hit mathjax">application</span> development is challenging due to the wide variety of hardware and <span class="search-hit mathjax">software</span> technologies that interact in an IoT system. Moreover, it involves dealing with issues that are attributed to different <span class="search-hit mathjax">software</span> life-cycle phases: development, deployment, and progression.
  In this paper, we examine three IoT <span class="search-hit mathjax">application</span> development approaches: Mashup-based development, Model-based development, and <span class="search-hit mathjax">Function</span>-as-a-Service based development. The advantages and disadvantages of each approach are discussed from different perspectives, including reliability, deployment expeditiousness, ease of use, and targeted audience. Finally, we propose a simple solution where these techniques are combined to deliver reliable <span class="search-hit mathjax">applications</span> while <span class="search-hit mathjax">reducing</span> costs and time to release.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.09796v1-abstract-full').style.display = 'none'; document.getElementById('2101.09796v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 24 January, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">7 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2101.09194">arXiv:2101.09194</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2101.09194">pdf</a>, <a href="https://arxiv.org/format/2101.09194">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        It Takes Two to Tango: Combining Visual and Textual Information for Detecting Duplicate Video-Based Bug Reports
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Cooper%2C+N">Nathan Cooper</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bernal-C%C3%A1rdenas%2C+C">Carlos Bernal-C√°rdenas</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chaparro%2C+O">Oscar Chaparro</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moran%2C+K">Kevin Moran</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Poshyvanyk%2C+D">Denys Poshyvanyk</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2101.09194v2-abstract-short" style="display: inline;">
        When a bug manifests in a user-facing <span class="search-hit mathjax">application</span>, it is likely to be exposed through the graphical user interface (GUI). Given the importance of visual information to the process of identifying and understanding such bugs, users are increasingly making use of screenshots and screen-recordings as a means to report issues to developers. However, when such inf&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.09194v2-abstract-full').style.display = 'inline'; document.getElementById('2101.09194v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2101.09194v2-abstract-full" style="display: none;">
        When a bug manifests in a user-facing <span class="search-hit mathjax">application</span>, it is likely to be exposed through the graphical user interface (GUI). Given the importance of visual information to the process of identifying and understanding such bugs, users are increasingly making use of screenshots and screen-recordings as a means to report issues to developers. However, when such information is reported en masse, such as during crowd-sourced testing, managing these artifacts can be a time-consuming process. As the reporting of screen-recordings in particular becomes more popular, developers are likely to face challenges related to manually identifying videos that depict duplicate bugs. Due to their graphical nature, screen-recordings present challenges for <span class="search-hit mathjax">automated</span> analysis that preclude the use of current duplicate bug report detection techniques. To overcome these challenges and aid developers in this task, this paper presents Tango, a duplicate detection technique that operates purely on video-based bug reports by leveraging both visual and textual information. Tango combines tailored computer vision techniques, optical character recognition, and text retrieval. We evaluated multiple configurations of Tango in a comprehensive empirical evaluation on 4,860 duplicate detection tasks that involved a total of 180 screen-recordings from six Android apps. Additionally, we conducted a user study investigating the effort required for developers to manually detect duplicate video-based bug reports and compared this to the effort required to use Tango. The results reveal that Tango&#39;s <span class="search-hit mathjax">optimal</span> configuration is highly effective at detecting duplicate video-based bug reports, accurately ranking target duplicate videos in the top-2 returned results in 83% of the tasks. Additionally, our user study shows that, on average, Tango can <span class="search-hit mathjax">reduce</span> developer effort by over 60%, illustrating its practicality.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.09194v2-abstract-full').style.display = 'none'; document.getElementById('2101.09194v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 5 February, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 22 January, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">13 pages and 1 figure. Published at ICSE&#39;21</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2101.08763">arXiv:2101.08763</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2101.08763">pdf</a>, <a href="https://arxiv.org/ps/2101.08763">ps</a>, <a href="https://arxiv.org/format/2101.08763">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        GPU-Accelerated <span class="search-hit mathjax">Optimizer</span>-Aware Evaluation of Submodular Exemplar Clustering
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Honysz%2C+P">Philipp-Jan Honysz</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Buschj%C3%A4ger%2C+S">Sebastian Buschj√§ger</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Morik%2C+K">Katharina Morik</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2101.08763v1-abstract-short" style="display: inline;">
        The <span class="search-hit mathjax">optimization</span> of submodular&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.08763v1-abstract-full').style.display = 'inline'; document.getElementById('2101.08763v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2101.08763v1-abstract-full" style="display: none;">
        The <span class="search-hit mathjax">optimization</span> of submodular <span class="search-hit mathjax">functions</span> constitutes a viable way to perform clustering. Strong approximation guarantees and feasible <span class="search-hit mathjax">optimization</span> w.r.t. streaming data make this clustering approach favorable. Technically, submodular <span class="search-hit mathjax">functions</span> map subsets of data to real values, which indicate how &#34;representative&#34; a specific subset is. <span class="search-hit mathjax">Optimal</span> sets might then be used to partition the data space and to infer clusters. Exemplar-based clustering is one of the possible submodular <span class="search-hit mathjax">functions</span>, but suffers from high computational complexity. However, for practical <span class="search-hit mathjax">applications</span>, the particular real-time or wall-clock run-time is decisive. In this work, we present a novel way to evaluate this particular <span class="search-hit mathjax">function</span> on GPUs, which keeps the necessities of <span class="search-hit mathjax">optimizers</span> in mind and <span class="search-hit mathjax">reduces</span> wall-clock run-time. To discuss our GPU algorithm, we investigated both the impact of different run-time critical problem properties, like data dimensionality and the number of data points in a subset, and the influence of required floating-point precision. In reproducible experiments, our GPU algorithm was able to achieve competitive speedups of up to 72x depending on whether multi-threaded computation on CPUs was used for comparison and the type of floating-point precision required. Half-precision GPU computation led to large speedups of up to 452x compared to single-precision, single-thread CPU computations.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.08763v1-abstract-full').style.display = 'none'; document.getElementById('2101.08763v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 21 January, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2101.07910">arXiv:2101.07910</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2101.07910">pdf</a>, <a href="https://arxiv.org/format/2101.07910">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A Search-Based Testing Framework for Deep Neural Networks of Source <span class="search-hit mathjax">Code</span> Embedding
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Pour%2C+M+V">Maryam Vahdat Pour</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+Z">Zhuo Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+L">Lei Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hemmati%2C+H">Hadi Hemmati</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2101.07910v1-abstract-short" style="display: inline;">
        Over the past few years, deep neural networks (DNNs) have been continuously expanding their real-world <span class="search-hit mathjax">applications</span> for source&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.07910v1-abstract-full').style.display = 'inline'; document.getElementById('2101.07910v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2101.07910v1-abstract-full" style="display: none;">
        Over the past few years, deep neural networks (DNNs) have been continuously expanding their real-world <span class="search-hit mathjax">applications</span> for source <span class="search-hit mathjax">code</span> processing tasks across the <span class="search-hit mathjax">software</span> engineering domain, e.g., clone detection, <span class="search-hit mathjax">code</span> search, comment generation. Although quite a few recent works have been performed on testing of DNNs in the context of image and speech processing, limited progress has been achieved so far on DNN testing in the context of source <span class="search-hit mathjax">code</span> processing, that exhibits rather unique characteristics and challenges.
  In this paper, we propose a search-based testing framework for DNNs of source <span class="search-hit mathjax">code</span> embedding and its downstream processing tasks like <span class="search-hit mathjax">Code</span> Search. To generate new test inputs, we adopt popular source <span class="search-hit mathjax">code</span> refactoring tools to generate the semantically equivalent variants. For more effective testing, we leverage the DNN mutation testing to guide the testing direction. To demonstrate the usefulness of our technique, we perform a large-scale evaluation on popular DNNs of source <span class="search-hit mathjax">code</span> processing based on multiple state-of-the-art <span class="search-hit mathjax">code</span> embedding methods (i.e., Code2vec, Code2seq and CodeBERT). The testing results show that our generated adversarial samples can on average <span class="search-hit mathjax">reduce</span> the performance of these DNNs from 5.41% to 9.58%. Through retraining the DNNs with our generated adversarial samples, the robustness of DNN can <span class="search-hit mathjax">improve</span> by 23.05% on average. The evaluation results also show that our adversarial test generation strategy has the least negative impact (median of 3.56%), on the performance of the DNNs for regular test data, compared to the other methods.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.07910v1-abstract-full').style.display = 'none'; document.getElementById('2101.07910v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 19 January, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">ICST 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2101.07430">arXiv:2101.07430</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2101.07430">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Neural and Evolutionary Computing">cs.NE</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A Surrogate-Assisted Variable Grouping Algorithm for General Large Scale Global <span class="search-hit mathjax">Optimization</span> Problems
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+A">An Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ren%2C+Z">Zhigang Ren</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+M">Muyi Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liang%2C+Y">Yongsheng Liang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+H">Hanqing Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Du%2C+W">Wenhao Du</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2101.07430v1-abstract-short" style="display: inline;">
        Problem decomposition plays a vital role when applying cooperative coevolution (CC) to large scale global <span class="search-hit mathjax">optimization</span> problems. However, most learning-based decomposition algorithms either only apply to additively separable problems or face the issue of false separability detections. Directing against these limitations, this study proposes a novel decomposi&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.07430v1-abstract-full').style.display = 'inline'; document.getElementById('2101.07430v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2101.07430v1-abstract-full" style="display: none;">
        Problem decomposition plays a vital role when applying cooperative coevolution (CC) to large scale global <span class="search-hit mathjax">optimization</span> problems. However, most learning-based decomposition algorithms either only apply to additively separable problems or face the issue of false separability detections. Directing against these limitations, this study proposes a novel decomposition algorithm called surrogate-assisted variable grouping (SVG). SVG first designs a general-separability-oriented detection criterion according to whether the optimum of a variable changes with other variables. This criterion is consistent with the separability definition and thus endows SVG with broad <span class="search-hit mathjax">applicability</span> and high accuracy. To <span class="search-hit mathjax">reduce</span> the fitness evaluation requirement, SVG seeks the optimum of a variable with the help of a surrogate model rather than the original expensive high-dimensional model. Moreover, it converts the variable grouping process into a dynamic-binary-tree search one, which facilitates reutilizing historical separability detection information and thus <span class="search-hit mathjax">reducing</span> detection times. To evaluate the performance of SVG, a suite of benchmark <span class="search-hit mathjax">functions</span> with up to 2000 dimensions, including additively and non-additively separable ones, were designed. Experimental results on these <span class="search-hit mathjax">functions</span> indicate that, compared with six state-of-the-art decomposition algorithms, SVG possesses broader <span class="search-hit mathjax">applicability</span> and competitive efficiency. Furthermore, it can significantly enhance the <span class="search-hit mathjax">optimization</span> performance of CC.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.07430v1-abstract-full').style.display = 'none'; document.getElementById('2101.07430v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 18 January, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2101.07412">arXiv:2101.07412</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2101.07412">pdf</a>, <a href="https://arxiv.org/format/2101.07412">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Audio and Speech Processing">eess.AS</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Sound">cs.SD</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        <span class="search-hit mathjax">Improved</span> parallel WaveGAN vocoder with perceptually weighted spectrogram loss
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Song%2C+E">Eunwoo Song</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yamamoto%2C+R">Ryuichi Yamamoto</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hwang%2C+M">Min-Jae Hwang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kim%2C+J">Jin-Seob Kim</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kwon%2C+O">Ohsung Kwon</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kim%2C+J">Jae-Min Kim</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2101.07412v1-abstract-short" style="display: inline;">
        &hellip;(MR-STFT) criteria with a generative adversarial network, the light-weight convolutional networks can be effectively trained without any distillation process. To further <span class="search-hit mathjax">improve</span> the vocoding performance, we propose the&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.07412v1-abstract-full').style.display = 'inline'; document.getElementById('2101.07412v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2101.07412v1-abstract-full" style="display: none;">
        This paper proposes a spectral-domain perceptual weighting technique for Parallel WaveGAN-based text-to-speech (TTS) systems. The recently proposed Parallel WaveGAN vocoder successfully generates waveform sequences using a fast non-autoregressive WaveNet model. By employing multi-resolution short-time Fourier transform (MR-STFT) criteria with a generative adversarial network, the light-weight convolutional networks can be effectively trained without any distillation process. To further <span class="search-hit mathjax">improve</span> the vocoding performance, we propose the <span class="search-hit mathjax">application</span> of frequency-dependent weighting to the MR-STFT loss <span class="search-hit mathjax">function</span>. The proposed method penalizes perceptually-sensitive errors in the frequency domain; thus, the model is <span class="search-hit mathjax">optimized</span> toward <span class="search-hit mathjax">reducing</span> auditory noise in the synthesized speech. Subjective listening test results demonstrate that our proposed method achieves 4.21 and 4.26 TTS mean opinion scores for female and male Korean speakers, respectively.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.07412v1-abstract-full').style.display = 'none'; document.getElementById('2101.07412v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 18 January, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">To appear in SLT 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2101.06371">arXiv:2101.06371</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2101.06371">pdf</a>, <a href="https://arxiv.org/format/2101.06371">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        NNStreamer: Efficient and Agile Development of On-Device AI Systems
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ham%2C+M">MyungJoo Ham</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moon%2C+J">Jijoong Moon</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lim%2C+G">Geunsik Lim</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jung%2C+J">Jaeyun Jung</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ahn%2C+H">Hyoungjoo Ahn</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Song%2C+W">Wook Song</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Woo%2C+S">Sangjung Woo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kapoor%2C+P">Parichay Kapoor</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chae%2C+D">Dongju Chae</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jang%2C+G">Gichan Jang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ahn%2C+Y">Yongjoo Ahn</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lee%2C+J">Jihoon Lee</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2101.06371v1-abstract-short" style="display: inline;">
        We propose NNStreamer, a <span class="search-hit mathjax">software</span> system that handles neural networks as filters of stream pipelines, applying the stream processing paradigm to deep neural network&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.06371v1-abstract-full').style.display = 'inline'; document.getElementById('2101.06371v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2101.06371v1-abstract-full" style="display: none;">
        We propose NNStreamer, a <span class="search-hit mathjax">software</span> system that handles neural networks as filters of stream pipelines, applying the stream processing paradigm to deep neural network <span class="search-hit mathjax">applications</span>. A new trend with the wide-spread of deep neural network <span class="search-hit mathjax">applications</span> is on-device AI. It is to process neural networks on mobile devices or edge/IoT devices instead of cloud servers. Emerging privacy issues, data transmission costs, and operational costs signify the need for on-device AI, especially if we deploy a massive number of devices. NNStreamer efficiently handles neural networks with complex data stream pipelines on devices, significantly <span class="search-hit mathjax">improving</span> the overall performance with minimal efforts. Besides, NNStreamer simplifies implementations and allows reusing off-the-shelf media filters directly, which <span class="search-hit mathjax">reduces</span> developmental costs significantly. We are already deploying NNStreamer for a wide range of products and platforms, including the Galaxy series and various consumer electronic devices. The experimental results suggest a reduction in developmental costs and enhanced performance of pipeline architectures and NNStreamer. It is an open-source project incubated by Linux Foundation AI, available to the public and <span class="search-hit mathjax">applicable</span> to various hardware and <span class="search-hit mathjax">software</span> platforms.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.06371v1-abstract-full').style.display = 'none'; document.getElementById('2101.06371v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 January, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">IEEE/ACM ICSE 2021 SEIP (preprint)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2101.01505">arXiv:2101.01505</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2101.01505">pdf</a>, <a href="https://arxiv.org/format/2101.01505">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Delayed Projection Techniques for Linearly Constrained Problems: Convergence Rates, Acceleration, and <span class="search-hit mathjax">Applications</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+X">Xiang Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+Z">Zhihua Zhang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2101.01505v1-abstract-short" style="display: inline;">
        In this work, we study a novel class of projection-based algorithms for linearly constrained problems (LCPs) which have a lot of <span class="search-hit mathjax">applications</span> in statistics,&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.01505v1-abstract-full').style.display = 'inline'; document.getElementById('2101.01505v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2101.01505v1-abstract-full" style="display: none;">
        In this work, we study a novel class of projection-based algorithms for linearly constrained problems (LCPs) which have a lot of <span class="search-hit mathjax">applications</span> in statistics, <span class="search-hit mathjax">optimization</span>, and machine learning. Conventional primal gradient-based methods for LCPs call a projection after each (stochastic) gradient descent, resulting in that the required number of projections equals that of gradient descents (or total iterations). Motivated by the recent progress in distributed <span class="search-hit mathjax">optimization</span>, we propose the delayed projection technique that calls a projection once for a while, lowering the projection frequency and <span class="search-hit mathjax">improving</span> the projection efficiency. Accordingly, we devise a series of stochastic methods for LCPs using the technique, including a variance <span class="search-hit mathjax">reduced</span> method and an accelerated one. We theoretically show that it is feasible to <span class="search-hit mathjax">improve</span> projection efficiency in both strongly convex and generally convex cases. Our analysis is simple and unified and can be easily extended to other methods using delayed projections. When applying our new algorithms to federated <span class="search-hit mathjax">optimization</span>, a newfangled and privacy-preserving subfield in distributed <span class="search-hit mathjax">optimization</span>, we obtain not only a variance <span class="search-hit mathjax">reduced</span> federated algorithm with convergence rates better than previous works, but also the first accelerated method able to handle data heterogeneity inherent in federated <span class="search-hit mathjax">optimization</span>.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.01505v1-abstract-full').style.display = 'none'; document.getElementById('2101.01505v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 5 January, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2101.00958">arXiv:2101.00958</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2101.00958">pdf</a>, <a href="https://arxiv.org/format/2101.00958">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Logic in Computer Science">cs.LO</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Scalable Online Conformance Checking Using Incremental Prefix-Alignment Computation
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Schuster%2C+D">Daniel Schuster</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kolhof%2C+G+J">Gero J. Kolhof</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2101.00958v1-abstract-short" style="display: inline;">
        &hellip;We have, therefore, recently introduced a novel approach to compute exact conformance checking results in an online environment. In this paper, we focus on the practical <span class="search-hit mathjax">application</span> and present a scalable, distributed implementation of the proposed online conformance checking approach. Moreover, we present two extensions to said approach to&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.00958v1-abstract-full').style.display = 'inline'; document.getElementById('2101.00958v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2101.00958v1-abstract-full" style="display: none;">
        Conformance checking techniques aim to collate observed process behavior with normative/modeled process models. The majority of existing approaches focuses on completed process executions, i.e., offline conformance checking. Recently, novel approaches have been designed to monitor ongoing processes, i.e., online conformance checking. Such techniques detect deviations of an ongoing process execution from a normative process model at the moment they occur. Thereby, countermeasures can be taken immediately to prevent a process deviation from causing further, undesired consequences. Most online approaches only allow to detect approximations of deviations. This causes the problem of falsely detected deviations, i.e., detected deviations that are actually no deviations. We have, therefore, recently introduced a novel approach to compute exact conformance checking results in an online environment. In this paper, we focus on the practical <span class="search-hit mathjax">application</span> and present a scalable, distributed implementation of the proposed online conformance checking approach. Moreover, we present two extensions to said approach to <span class="search-hit mathjax">reduce</span> its computational effort and its practical <span class="search-hit mathjax">applicability</span>. We evaluate our implementation using data sets capturing the execution of real processes.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.00958v1-abstract-full').style.display = 'none'; document.getElementById('2101.00958v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 December, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2101.00236">arXiv:2101.00236</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2101.00236">pdf</a>, <a href="https://arxiv.org/format/2101.00236">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        On Stochastic Variance <span class="search-hit mathjax">Reduced</span> Gradient Method for Semidefinite <span class="search-hit mathjax">Optimization</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zeng%2C+J">Jinshan Zeng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zha%2C+Y">Yixuan Zha</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+K">Ke Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yao%2C+Y">Yuan Yao</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2101.00236v1-abstract-short" style="display: inline;">
        The low-rank stochastic semidefinite <span class="search-hit mathjax">optimization</span> has attracted rising attention due to its wide range of&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.00236v1-abstract-full').style.display = 'inline'; document.getElementById('2101.00236v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2101.00236v1-abstract-full" style="display: none;">
        The low-rank stochastic semidefinite <span class="search-hit mathjax">optimization</span> has attracted rising attention due to its wide range of <span class="search-hit mathjax">applications</span>. The nonconvex reformulation based on the low-rank factorization, significantly <span class="search-hit mathjax">improves</span> the computational efficiency but brings some new challenge to the analysis. The stochastic variance <span class="search-hit mathjax">reduced</span> gradient (SVRG) method has been regarded as one of the most effective methods. SVRG in general consists of two loops, where a reference full gradient is first evaluated in the outer loop and then used to yield a variance <span class="search-hit mathjax">reduced</span> estimate of the current gradient in the inner loop. Two options have been suggested to yield the output of the inner loop, where Option I sets the output as its last iterate, and Option II yields the output via random sampling from all the iterates in the inner loop. However, there is a significant gap between the theory and practice of SVRG when adapted to the stochastic semidefinite <span class="search-hit mathjax">programming</span> (SDP). SVRG practically works better with Option I, while most of existing theoretical results focus on Option II. In this paper, we fill this gap via exploiting a new semi-stochastic variant of the original SVRG with Option I adapted to the semidefinite <span class="search-hit mathjax">optimization</span>. Equipped with this, we establish the global linear submanifold convergence (i.e., converging exponentially fast to a submanifold of a global minimum under the orthogonal group action) of the proposed SVRG method, given a provable initialization scheme and under certain smoothness and restricted strongly convex assumptions. Our analysis includes the effects of the mini-batch <span class="search-hit mathjax">size</span> and update frequency in the inner loop as well as two practical step <span class="search-hit mathjax">size</span> strategies, the fixed and stabilized Barzilai-Borwein step <span class="search-hit mathjax">sizes</span>. Some numerical results in matrix sensing demonstrate the efficiency of proposed SVRG method outperforming Option II counterpart as well as others.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.00236v1-abstract-full').style.display = 'none'; document.getElementById('2101.00236v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 1 January, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">27 pages, 5 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2101.00090">arXiv:2101.00090</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2101.00090">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        PHP <span class="search-hit mathjax">code</span> smells in web apps: survival and anomalies
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Rio%2C+A">Am√©rico Rio</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Abreu%2C+F+B+e">Fernando Brito e Abreu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2101.00090v1-abstract-short" style="display: inline;">
        Context: <span class="search-hit mathjax">Code</span> smells are considered symptoms of poor design, leading to future problems, such as&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.00090v1-abstract-full').style.display = 'inline'; document.getElementById('2101.00090v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2101.00090v1-abstract-full" style="display: none;">
        Context: <span class="search-hit mathjax">Code</span> smells are considered symptoms of poor design, leading to future problems, such as <span class="search-hit mathjax">reduced</span> maintainability. Except for anecdotal cases (e. g. <span class="search-hit mathjax">code</span> dropout), a <span class="search-hit mathjax">code</span> smell survives until it gets explicitly refactored or removed. This paper presents a longitudinal study on the survival of <span class="search-hit mathjax">code</span> smells for web apps built with PHP.
  Objectives: RQ: (i) <span class="search-hit mathjax">code</span> smells survival depends on their scope? (ii) practitioners attitudes towards <span class="search-hit mathjax">code</span> smells removal in web apps have changed throughout time? (iii) how long <span class="search-hit mathjax">code</span> smells survive in web <span class="search-hit mathjax">applications</span>? (iv) are there sudden variations (anomalies) in the density of <span class="search-hit mathjax">code</span> smells through the evolution of web apps?
  Method: We analyze the evolution of 6 <span class="search-hit mathjax">code</span> smells in 8 web <span class="search-hit mathjax">applications</span> written in PHP at the server side, across several years, using the survival analysis technique. We classify <span class="search-hit mathjax">code</span> smells according to scope in two categories: scattered and localized. Scattered <span class="search-hit mathjax">code</span> smells are expected to be more harmful since their influence is not circumscribed as in localized <span class="search-hit mathjax">code</span> smells. We split the observations for each web app into two equal and consecutive timeframes, to test the hypothesis that <span class="search-hit mathjax">code</span> smells awareness has increased throughout time. As for the anomalies, we standardize their detection criteria.
  Results: We present some evidence that <span class="search-hit mathjax">code</span> smells survival depends on their scope: the average survival rate decreases in some of them, while the opposite is observed for the remainder. The survival of localized <span class="search-hit mathjax">code</span> smells is around 4 years, while the scattered ones live around 5 years. Around 60% of the smells are removed, and some live through all the <span class="search-hit mathjax">application</span> life. We also show how a graphical representation of anomalies found in the evolution of <span class="search-hit mathjax">code</span> smells allows unveiling the story of a development project and make managers aware of the need for enforcing regular refactoring practices.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.00090v1-abstract-full').style.display = 'none'; document.getElementById('2101.00090v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 31 December, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2021.
      
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          D.2
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2012.10526">arXiv:2012.10526</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2012.10526">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Achieving Operational Scalability Using Razee Continuous Deployment Model and Kubernetes Operators
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Bhagavan%2C+S">Srini Bhagavan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Balasubramanian%2C+S">Saravanan Balasubramanian</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Annem%2C+P+R">Prasad Reddy Annem</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ngo%2C+T">Thuan Ngo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Soundararaj%2C+A">Arun Soundararaj</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2012.10526v1-abstract-short" style="display: inline;">
        Recent advancements in the cloud computing domain have resulted in huge strides toward simplifying the procurement of hardware and <span class="search-hit mathjax">software</span> for diverse needs. By moving enterprise workloads to managed cloud offerings (private, public, hybrid), customers are delegating mundane tasks and labor-intensive maintenance activities related to network connectivity, p&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.10526v1-abstract-full').style.display = 'inline'; document.getElementById('2012.10526v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2012.10526v1-abstract-full" style="display: none;">
        Recent advancements in the cloud computing domain have resulted in huge strides toward simplifying the procurement of hardware and <span class="search-hit mathjax">software</span> for diverse needs. By moving enterprise workloads to managed cloud offerings (private, public, hybrid), customers are delegating mundane tasks and labor-intensive maintenance activities related to network connectivity, procurement of cloud resource, <span class="search-hit mathjax">application</span> deployment, <span class="search-hit mathjax">software</span> patches, and upgrades, etc., This often translates to benefits such as high availability and <span class="search-hit mathjax">reduced</span> cost. The popularity of container and micro-services-based deployment has made Kubernetes the de-facto standard to deliver <span class="search-hit mathjax">applications</span>. However, even with Kubernetes orchestration, cloud service providers frequently have operational scalability issues due to lack of Continuous Integration and Continuous Deployment (CICD) <span class="search-hit mathjax">automation</span> and increased demand for human operators when managing a large number of <span class="search-hit mathjax">software</span> deployments across multiple data centers/availability zones. Kubernetes solves this in a novel way by creating and managing custom <span class="search-hit mathjax">applications</span> using Operators. Agile methodology advocates incremental CICD which are adopted by cloud providers. However, ironically, it is this same continuous delivery feature of <span class="search-hit mathjax">application</span> updates, Kubernetes cluster upgrades, etc., that is also a bane to cloud providers. In this paper, we will demonstrate the use of IBM open-source project Razee as a scalable continuous deployment framework to deploy open-source RStudio and Nginx Operators. We will discuss how IBM Watson SaaS <span class="search-hit mathjax">application</span> Operator, Blockchain <span class="search-hit mathjax">applications</span>, and Kubernetes resources updates, etc., can be deployed similarly and the use of Operators to perform <span class="search-hit mathjax">application</span> life cycle management. We assert that using Razee in conjunction with Operators on Kubernetes simplifies <span class="search-hit mathjax">application</span> life cycle management and increases scalability.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.10526v1-abstract-full').style.display = 'none'; document.getElementById('2012.10526v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 18 December, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">9 pages, 18 figures, 1 table</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          C.0
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2012.08842">arXiv:2012.08842</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2012.08842">pdf</a>, <a href="https://arxiv.org/format/2012.08842">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1007/s11831-021-09566-x">10.1007/s11831-021-09566-x <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        <span class="search-hit mathjax">Code</span> smells detection and visualization: A systematic literature review
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Reis%2C+J+P+d">Jos√© Pereira dos Reis</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Abreu%2C+F+B+e">Fernando Brito e Abreu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Carneiro%2C+G+d+F">Glauco de Figueiredo Carneiro</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Anslow%2C+C">Craig Anslow</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2012.08842v1-abstract-short" style="display: inline;">
        Context: <span class="search-hit mathjax">Code</span> smells (CS) tend to compromise&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.08842v1-abstract-full').style.display = 'inline'; document.getElementById('2012.08842v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2012.08842v1-abstract-full" style="display: none;">
        Context: <span class="search-hit mathjax">Code</span> smells (CS) tend to compromise <span class="search-hit mathjax">software</span> quality and also demand more effort by developers to maintain and evolve the <span class="search-hit mathjax">application</span> throughout its life-cycle. They have long been catalogued with corresponding mitigating solutions called refactoring operations. Objective: This SLR has a twofold goal: the first is to identify the main <span class="search-hit mathjax">code</span> smells detection techniques and tools discussed in the literature, and the second is to analyze to which extent visual techniques have been applied to support the former. Method: Over 83 primary studies indexed in major scientific repositories were identified by our search string in this SLR. Then, following existing best practices for secondary studies, we applied inclusion/exclusion criteria to select the most relevant works, extract their features and classify them. Results: We found that the most commonly used approaches to <span class="search-hit mathjax">code</span> smells detection are search-based (30.1%), and metric-based (24.1%). Most of the studies (83.1%) use open-source <span class="search-hit mathjax">software</span>, with the Java language occupying the first position (77.1%). In terms of <span class="search-hit mathjax">code</span> smells, God Class (51.8%), Feature Envy (33.7%), and Long Method (26.5%) are the most covered ones. Machine learning techniques are used in 35% of the studies. Around 80% of the studies only detect <span class="search-hit mathjax">code</span> smells, without providing visualization techniques. In visualization-based approaches several methods are used, such as: city metaphors, 3D visualization techniques. Conclusions: We confirm that the detection of CS is a non trivial task, and there is still a lot of work to be done in terms of: <span class="search-hit mathjax">reducing</span> the subjectivity associated with the definition and detection of CS; increasing the diversity of detected CS and of supported <span class="search-hit mathjax">programming</span> languages; constructing and sharing oracles and datasets to facilitate the replication of CS detection and visualization techniques validation experiments.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.08842v1-abstract-full').style.display = 'none'; document.getElementById('2012.08842v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 December, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">submitted to ARCO</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          D.2.7
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2012.08181">arXiv:2012.08181</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2012.08181">pdf</a>, <a href="https://arxiv.org/format/2012.08181">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Multiagent Systems">cs.MA</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Social and Information Networks">cs.SI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Fast-Convergent Dynamics for Distributed Resource Allocation Over Sparse Time-Varying Networks
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Doostmohammadian%2C+M">Mohammadreza Doostmohammadian</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Aghasi%2C+A">Alireza Aghasi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Charalambous%2C+T">Themistoklis Charalambous</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2012.08181v2-abstract-short" style="display: inline;">
        &hellip;multi-agent networks. The state of each agent represents the amount of resources used/produced at that agent while the total amount of resources is fixed. The idea is to <span class="search-hit mathjax">optimally</span> allocate the resources among the group of agents by&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.08181v2-abstract-full').style.display = 'inline'; document.getElementById('2012.08181v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2012.08181v2-abstract-full" style="display: none;">
        In this paper, distributed dynamics are deployed to solve resource allocation over time-varying multi-agent networks. The state of each agent represents the amount of resources used/produced at that agent while the total amount of resources is fixed. The idea is to <span class="search-hit mathjax">optimally</span> allocate the resources among the group of agents by <span class="search-hit mathjax">reducing</span> the total cost <span class="search-hit mathjax">functions</span> subject to fixed amount of total resources. The information of each agent is restricted to its own state and cost <span class="search-hit mathjax">function</span> and those of its immediate neighbors. This is motivated by distributed <span class="search-hit mathjax">applications</span> such as in mobile edge-computing, economic dispatch over smart grids, and multi-agent coverage control. The non-Lipschitz dynamics proposed in this work shows fast convergence as compared to the linear and some nonlinear solutions in the literature. Further, the multi-agent network connectivity is more relaxed in this paper. To be more specific, the proposed dynamics even reaches <span class="search-hit mathjax">optimal</span> solution over time-varying disconnected undirected networks as far as the union of these networks over some bounded non-overlapping time-intervals includes a spanning-tree. The proposed convergence analysis can be applied for similar 1st-order resource allocation nonlinear dynamics. We provide simulations to verify our results.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.08181v2-abstract-full').style.display = 'none'; document.getElementById('2012.08181v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 27 February, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 15 December, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2012.07029">arXiv:2012.07029</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2012.07029">pdf</a>, <a href="https://arxiv.org/format/2012.07029">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Efficient Online Trajectory Planning for Integrator Chain Dynamics using Polynomial Elimination
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Rauscher%2C+F">Florentin Rauscher</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sawodny%2C+O">Oliver Sawodny</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2012.07029v1-abstract-short" style="display: inline;">
        Providing smooth reference trajectories can effectively increase performance and accuracy of tracking control <span class="search-hit mathjax">applications</span> while overshoot and unwanted vibrations are&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.07029v1-abstract-full').style.display = 'inline'; document.getElementById('2012.07029v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2012.07029v1-abstract-full" style="display: none;">
        Providing smooth reference trajectories can effectively increase performance and accuracy of tracking control <span class="search-hit mathjax">applications</span> while overshoot and unwanted vibrations are <span class="search-hit mathjax">reduced</span>. Trajectory planning computations can often be simplified significantly by transforming the system dynamics into decoupled integrator chains using methods such as feedback linearization, differential flatness or the controller canonical form. We present an efficient method to plan time <span class="search-hit mathjax">optimal</span> trajectories for integrator chains subject to derivative bound constraints. Therefore, an algebraic precomputation algorithm formulates the necessary conditions for time <span class="search-hit mathjax">optimality</span> in form of a set of polynomial systems, followed by a symbolic polynomial elimination using Gr√∂bner bases. A fast online algorithm then plans the trajectories by calculating the roots of the decomposed polynomial systems. These roots describe the switching time instants of the input signal and the full trajectory simply follows by multiple integration. This method presents a systematic way to compute time <span class="search-hit mathjax">optimal</span> trajectories exactly via algebraic calculations without numerical approximation iterations. It is applied to various trajectory types with different continuity order, asymmetric derivative bounds and non-rest initial and final states.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.07029v1-abstract-full').style.display = 'none'; document.getElementById('2012.07029v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 13 December, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2012.04760">arXiv:2012.04760</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2012.04760">pdf</a>, <a href="https://arxiv.org/format/2012.04760">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Social and Information Networks">cs.SI</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1145/3418209">10.1145/3418209 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Fine-Grained Network Analysis for Modern <span class="search-hit mathjax">Software</span> Ecosystems
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Boldi%2C+P">Paolo Boldi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gousios%2C+G">Georgios Gousios</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2012.04760v1-abstract-short" style="display: inline;">
        Modern <span class="search-hit mathjax">software</span> development is increasingly dependent on components, libraries and frameworks coming from third-party vendors or open-source suppliers and made available through a number of platforms (or forges). This way of writing&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.04760v1-abstract-full').style.display = 'inline'; document.getElementById('2012.04760v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2012.04760v1-abstract-full" style="display: none;">
        Modern <span class="search-hit mathjax">software</span> development is increasingly dependent on components, libraries and frameworks coming from third-party vendors or open-source suppliers and made available through a number of platforms (or forges). This way of writing <span class="search-hit mathjax">software</span> puts an emphasis on reuse and on composition, commoditizing the services which modern <span class="search-hit mathjax">applications</span> require. On the other hand, bugs and vulnerabilities in a single library living in one such ecosystem can affect, directly or by transitivity, a huge number of other libraries and <span class="search-hit mathjax">applications</span>. Currently, only product-level information on library dependencies is used to contain this kind of danger, but this knowledge often reveals itself too imprecise to lead to effective (and possibly <span class="search-hit mathjax">automated</span>) handling policies. We will discuss how fine-grained <span class="search-hit mathjax">function</span>-level dependencies can greatly <span class="search-hit mathjax">improve</span> reliability and <span class="search-hit mathjax">reduce</span> the impact of vulnerabilities on the whole <span class="search-hit mathjax">software</span> ecosystem.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.04760v1-abstract-full').style.display = 'none'; document.getElementById('2012.04760v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 December, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2012.04355">arXiv:2012.04355</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2012.04355">pdf</a>, <a href="https://arxiv.org/format/2012.04355">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        3DIoUMatch: Leveraging IoU Prediction for Semi-Supervised 3D Object Detection
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+H">He Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cong%2C+Y">Yezhen Cong</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Litany%2C+O">Or Litany</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gao%2C+Y">Yue Gao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Guibas%2C+L+J">Leonidas J. Guibas</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2012.04355v3-abstract-short" style="display: inline;">
        3D object detection is an important yet demanding task that heavily relies on difficult to obtain 3D annotations. To <span class="search-hit mathjax">reduce</span> the required amount of supervision, we propose 3DIoUMatch, a novel semi-supervised method for 3D object detection&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.04355v3-abstract-full').style.display = 'inline'; document.getElementById('2012.04355v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2012.04355v3-abstract-full" style="display: none;">
        3D object detection is an important yet demanding task that heavily relies on difficult to obtain 3D annotations. To <span class="search-hit mathjax">reduce</span> the required amount of supervision, we propose 3DIoUMatch, a novel semi-supervised method for 3D object detection <span class="search-hit mathjax">applicable</span> to both indoor and outdoor scenes. We leverage a teacher-student mutual learning framework to propagate information from the labeled to the unlabeled train set in the form of pseudo-labels. However, due to the high task complexity, we observe that the pseudo-labels suffer from significant noise and are thus not directly usable. To that end, we introduce a confidence-based filtering mechanism, inspired by FixMatch. We set confidence thresholds based upon the predicted objectness and class probability to filter low-quality pseudo-labels. While effective, we observe that these two measures do not sufficiently capture localization quality. We therefore propose to use the estimated 3D IoU as a localization metric and set category-aware self-adjusted thresholds to filter poorly localized proposals. We adopt VoteNet as our backbone detector on indoor datasets while we use PV-RCNN on the autonomous driving dataset, KITTI. Our method consistently <span class="search-hit mathjax">improves</span> state-of-the-art methods on both ScanNet and SUN-RGBD benchmarks by significant margins under all label ratios (including fully labeled setting). For example, when training using only 10\% labeled data on ScanNet, 3DIoUMatch achieves 7.7% absolute <span class="search-hit mathjax">improvement</span> on mAP@0.25 and 8.5% absolute <span class="search-hit mathjax">improvement</span> on mAP@0.5 upon the prior art. On KITTI, we are the first to demonstrate semi-supervised 3D object detection and our method surpasses a fully supervised baseline from 1.8% to 7.6% under different label ratios and categories.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.04355v3-abstract-full').style.display = 'none'; document.getElementById('2012.04355v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 6 July, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 8 December, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">CVPR 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2012.01655">arXiv:2012.01655</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2012.01655">pdf</a>, <a href="https://arxiv.org/format/2012.01655">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.4204/EPTCS.330.1">10.4204/EPTCS.330.1 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        VICToRy: Visual Interactive Consistency Management in Tolerant Rule-based Systems
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Weidmann%2C+N">Nils Weidmann</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Anjorin%2C+A">Anthony Anjorin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cheney%2C+J">James Cheney</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2012.01655v1-abstract-short" style="display: inline;">
        &hellip;checking. The supported operations, however, typically run completely in the background with only input and output made visible to the user. We argue that this often <span class="search-hit mathjax">reduces</span> both understandability and controllability. As a step towards&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.01655v1-abstract-full').style.display = 'inline'; document.getElementById('2012.01655v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2012.01655v1-abstract-full" style="display: none;">
        In the field of Model-Driven Engineering, there exist numerous tools that support various consistency management operations including model transformation, synchronisation and consistency checking. The supported operations, however, typically run completely in the background with only input and output made visible to the user. We argue that this often <span class="search-hit mathjax">reduces</span> both understandability and controllability. As a step towards <span class="search-hit mathjax">improving</span> this situation, we present VICToRy, a debugger for model generation and transformation based on Triple Graph Grammars, a well-known rule-based approach to bidirectional transformation. In addition to a fine-grained, step-by-step, interactive visualisation, VICToRy enables the user to actively explore and choose between multiple valid rule <span class="search-hit mathjax">applications</span> thus <span class="search-hit mathjax">improving</span> control and understanding.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.01655v1-abstract-full').style.display = 'none'; document.getElementById('2012.01655v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 2 December, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">In Proceedings GCM 2020, arXiv:2012.01181</span>
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        EPTCS 330, 2020, pp. 1-12
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2012.00506">arXiv:2012.00506</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2012.00506">pdf</a>, <a href="https://arxiv.org/format/2012.00506">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Numerical Analysis">math.NA</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Mathematical Software">cs.MS</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A Parallel Direct Eigensolver for Sequences of Hermitian Eigenvalue Problems with No Tridiagonalization
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+S">Shengguo Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wu%2C+X">Xinzhe Wu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Roman%2C+J+E">Jose E. Roman</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yuan%2C+Z">Ziyang Yuan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cheng%2C+L">Lizhi Cheng</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2012.00506v1-abstract-short" style="display: inline;">
        &hellip;Eigenvalue Problems with no tridiagonalization is proposed, denoted by \texttt{PDESHEP}, and it combines direct methods with iterative methods. \texttt{PDESHEP} first <span class="search-hit mathjax">reduces</span> a Hermitian matrix to its banded form, then applies a spectrum slicing algorithm to the banded matrix, and finally computes the eigenvectors of the original matrix via backtransform. Th&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.00506v1-abstract-full').style.display = 'inline'; document.getElementById('2012.00506v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2012.00506v1-abstract-full" style="display: none;">
        In this paper, a Parallel Direct Eigensolver for Sequences of Hermitian Eigenvalue Problems with no tridiagonalization is proposed, denoted by \texttt{PDESHEP}, and it combines direct methods with iterative methods. \texttt{PDESHEP} first <span class="search-hit mathjax">reduces</span> a Hermitian matrix to its banded form, then applies a spectrum slicing algorithm to the banded matrix, and finally computes the eigenvectors of the original matrix via backtransform. Therefore, compared with conventional direct eigensolvers, \texttt{PDESHEP} avoids tridiagonalization, which consists of many memory-bounded operations. In this work, the iterative method in \texttt{PDESHEP} is based on the contour integral method implemented in FEAST. The combination of direct methods with iterative methods for banded matrices requires some efficient data redistribution algorithms both from 2D to 1D and from 1D to 2D data structures. Hence, some two-step data redistribution algorithms are proposed, which can be $10\times$ faster than ScaLAPACK routine \texttt{PXGEMR2D}. For the symmetric self-consistent field (SCF) eigenvalue problems, \texttt{PDESHEP} can be on average $1.25\times$ faster than the state-of-the-art direct solver in ELPA when using $4096$ processes. Numerical results are obtained for dense Hermitian matrices from real <span class="search-hit mathjax">applications</span> and large real sparse matrices from the SuiteSparse collection.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.00506v1-abstract-full').style.display = 'none'; document.getElementById('2012.00506v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 1 December, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">24 pages and 14 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2011.12886">arXiv:2011.12886</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2011.12886">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        An Empirical Investigation on the Challenges of Creating Custom Static Analysis Rules for Defect Localization
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Mendon%C3%A7a%2C+D+S">Diogo Silveira Mendon√ßa</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kalinowski%2C+M">Marcos Kalinowski</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2011.12886v2-abstract-short" style="display: inline;">
        Background: Custom static analysis rules, i.e., rules specific for one or more <span class="search-hit mathjax">applications</span>, have been successfully applied to perform corrective and preventive&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.12886v2-abstract-full').style.display = 'inline'; document.getElementById('2011.12886v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2011.12886v2-abstract-full" style="display: none;">
        Background: Custom static analysis rules, i.e., rules specific for one or more <span class="search-hit mathjax">applications</span>, have been successfully applied to perform corrective and preventive <span class="search-hit mathjax">software</span> maintenance. Their usage can <span class="search-hit mathjax">reduce</span> the costs of verification and <span class="search-hit mathjax">improve</span> the reliability and security of <span class="search-hit mathjax">applications</span>. Pattern-Driven Maintenance (PDM) is a method designed to support the creation of such rules during <span class="search-hit mathjax">software</span> maintenance. However, as PDM was recently created, few maintainers have reported on its usage. Hence, the challenges and skills needed to apply PDM properly are unknown. Aims: In this paper, we investigate the challenges faced by maintainers on applying PDM for creating custom static analysis rules for defect localization. Method: We conducted an observational study on novice maintainers creating custom static analysis rules by applying PDM. The study was divided into three tasks: (i) identifying a defect pattern, (ii) <span class="search-hit mathjax">programming</span> a static analysis rule to locate instances of the pattern, and (iii) verifying the located instances. We analyzed the efficiency of maintainers on applying each task and their comments on task challenges. We also analyzed the acceptance of PDM by the maintainers. Results: We observed that previous knowledge on debugging, the subject <span class="search-hit mathjax">software</span>, and related technologies influenced the performance of maintainers. However, the method&#39;s bottleneck was static analysis rules <span class="search-hit mathjax">programming</span>, being the task that maintainers had more difficulties in completing. Besides those difficulties, maintainers found PDM useful and demonstrated the intention of using it in practice. Conclusions: The results strengthen our confidence that PDM can help maintainers in producing custom static analysis rules for locating defects. However, a better approach for <span class="search-hit mathjax">programming</span> those rules and the proper selection and training of maintainers is needed to apply PDM effectively.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.12886v2-abstract-full').style.display = 'none'; document.getElementById('2011.12886v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 January, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 25 November, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2011.12715">arXiv:2011.12715</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2011.12715">pdf</a>, <a href="https://arxiv.org/format/2011.12715">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Networking and Internet Architecture">cs.NI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Resonance: Replacing <span class="search-hit mathjax">Software</span> Constants with Context-Aware Models in Real-time Communication
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Gupchup%2C+J">Jayant Gupchup</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Aazami%2C+A">Ashkan Aazami</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fan%2C+Y">Yaran Fan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Filipi%2C+S">Senja Filipi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Finley%2C+T">Tom Finley</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Inglis%2C+S">Scott Inglis</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Asteborg%2C+M">Marcus Asteborg</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Caroll%2C+L">Luke Caroll</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chari%2C+R">Rajan Chari</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cozowicz%2C+M">Markus Cozowicz</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gopal%2C+V">Vishak Gopal</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Prakash%2C+V">Vinod Prakash</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bendapudi%2C+S">Sasikanth Bendapudi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gerrits%2C+J">Jack Gerrits</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lau%2C+E">Eric Lau</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+H">Huazhou Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rossi%2C+M">Marco Rossi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Slobodianyk%2C+D">Dima Slobodianyk</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Birjukov%2C+D">Dmitri Birjukov</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cooper%2C+M">Matty Cooper</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Javar%2C+N">Nilesh Javar</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Perednya%2C+D">Dmitriy Perednya</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Srinivasan%2C+S">Sriram Srinivasan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Langford%2C+J">John Langford</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cutler%2C+R">Ross Cutler</a>
      , et al. (1 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2011.12715v1-abstract-short" style="display: inline;">
        Large <span class="search-hit mathjax">software</span> systems tune hundreds of &#39;constants&#39; to&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.12715v1-abstract-full').style.display = 'inline'; document.getElementById('2011.12715v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2011.12715v1-abstract-full" style="display: none;">
        Large <span class="search-hit mathjax">software</span> systems tune hundreds of &#39;constants&#39; to <span class="search-hit mathjax">optimize</span> their runtime performance. These values are commonly derived through intuition, lab tests, or A/B tests. A &#39;one-<span class="search-hit mathjax">size</span>-fits-all&#39; approach is often sub-<span class="search-hit mathjax">optimal</span> as the best value depends on runtime context. In this paper, we provide an experimental approach to replace constants with learned contextual <span class="search-hit mathjax">functions</span> for Skype - a widely used real-time communication (RTC) <span class="search-hit mathjax">application</span>. We present Resonance, a system based on contextual bandits (CB). We describe experiences from three real-world experiments: applying it to the audio, video, and transport components in Skype. We surface a unique and practical challenge of performing machine learning (ML) inference in large <span class="search-hit mathjax">software</span> systems written using encapsulation principles. Finally, we open-source FeatureBroker, a library to <span class="search-hit mathjax">reduce</span> the friction in adopting ML models in such development environments
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.12715v1-abstract-full').style.display = 'none'; document.getElementById('2011.12715v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 November, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Workshop on ML for Systems at NeurIPS 2020, Accepted</span>
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        ML for Systems, NeurIPS 2020
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2011.12257">arXiv:2011.12257</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2011.12257">pdf</a>, <a href="https://arxiv.org/format/2011.12257">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Dynamical Systems">math.DS</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Safely Learning Dynamical Systems from Short Trajectories
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ahmadi%2C+A+A">Amir Ali Ahmadi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chaudhry%2C+A">Abraar Chaudhry</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sindhwani%2C+V">Vikas Sindhwani</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tu%2C+S">Stephen Tu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2011.12257v1-abstract-short" style="display: inline;">
        A fundamental challenge in learning to control an unknown dynamical system is to <span class="search-hit mathjax">reduce</span> model uncertainty by making measurements while maintaining safety. In this work, we formulate a mathematical definition of what it means to safely learn a dynamical system by sequentially deciding where to initialize the next trajectory. In our framework, the state of the&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.12257v1-abstract-full').style.display = 'inline'; document.getElementById('2011.12257v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2011.12257v1-abstract-full" style="display: none;">
        A fundamental challenge in learning to control an unknown dynamical system is to <span class="search-hit mathjax">reduce</span> model uncertainty by making measurements while maintaining safety. In this work, we formulate a mathematical definition of what it means to safely learn a dynamical system by sequentially deciding where to initialize the next trajectory. In our framework, the state of the system is required to stay within a given safety region under the (possibly repeated) action of all dynamical systems that are consistent with the information gathered so far. For our first two results, we consider the setting of safely learning linear dynamics. We present a linear <span class="search-hit mathjax">programming</span>-based algorithm that either safely recovers the true dynamics from trajectories of length one, or certifies that safe learning is impossible. We also give an efficient semidefinite representation of the set of initial conditions whose resulting trajectories of length two are guaranteed to stay in the safety region. For our final result, we study the problem of safely learning a nonlinear dynamical system. We give a second-order cone <span class="search-hit mathjax">programming</span> based representation of the set of initial conditions that are guaranteed to remain in the safety region after one <span class="search-hit mathjax">application</span> of the system dynamics.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.12257v1-abstract-full').style.display = 'none'; document.getElementById('2011.12257v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 24 November, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2011.11985">arXiv:2011.11985</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2011.11985">pdf</a>, <a href="https://arxiv.org/ps/2011.11985">ps</a>, <a href="https://arxiv.org/format/2011.11985">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Adam$^+$: A Stochastic Method with Adaptive Variance Reduction
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+M">Mingrui Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+W">Wei Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Orabona%2C+F">Francesco Orabona</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yang%2C+T">Tianbao Yang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2011.11985v1-abstract-short" style="display: inline;">
        Adam is a widely used stochastic <span class="search-hit mathjax">optimization</span> method for deep learning <span class="search-hit mathjax">applications</span>. While practitioners prefer Adam because it requires less parameter tuning, its use is problematic from a theoretical point of view since it may not converge. Variants of Adam have been proposed with provable convergence guarantee, but&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.11985v1-abstract-full').style.display = 'inline'; document.getElementById('2011.11985v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2011.11985v1-abstract-full" style="display: none;">
        Adam is a widely used stochastic <span class="search-hit mathjax">optimization</span> method for deep learning <span class="search-hit mathjax">applications</span>. While practitioners prefer Adam because it requires less parameter tuning, its use is problematic from a theoretical point of view since it may not converge. Variants of Adam have been proposed with provable convergence guarantee, but they tend not be competitive with Adam on the practical performance. In this paper, we propose a new method named Adam$^+$ (pronounced as Adam-plus). Adam$^+$ retains some of the key components of Adam but it also has several noticeable differences: (i) it does not maintain the moving average of second moment estimate but instead computes the moving average of first moment estimate at extrapolated points; (ii) its adaptive step <span class="search-hit mathjax">size</span> is formed not by dividing the square root of second moment estimate but instead by dividing the root of the norm of first moment estimate. As a result, Adam$^+$ requires few parameter tuning, as Adam, but it enjoys a provable convergence guarantee. Our analysis further shows that Adam$^+$ enjoys adaptive variance reduction, i.e., the variance of the stochastic gradient estimator <span class="search-hit mathjax">reduces</span> as the algorithm converges, hence enjoying an adaptive convergence. We also propose a more general variant of Adam$^+$ with different adaptive step <span class="search-hit mathjax">sizes</span> and establish their fast convergence rate. Our empirical studies on various deep learning tasks, including image classification, language modeling, and <span class="search-hit mathjax">automatic</span> speech recognition, demonstrate that Adam$^+$ significantly outperforms Adam and achieves comparable performance with best-tuned SGD and momentum SGD.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.11985v1-abstract-full').style.display = 'none'; document.getElementById('2011.11985v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 24 November, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2011.08434">arXiv:2011.08434</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2011.08434">pdf</a>, <a href="https://arxiv.org/format/2011.08434">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Simple and <span class="search-hit mathjax">optimal</span> methods for stochastic variational inequalities, II: Markovian noise and policy evaluation in reinforcement learning
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Kotsalis%2C+G">Georgios Kotsalis</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lan%2C+G">Guanghui Lan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+T">Tianjiao Li</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2011.08434v3-abstract-short" style="display: inline;">
        The focus of this paper is on stochastic variational inequalities (VI) under Markovian noise. A prominent <span class="search-hit mathjax">application</span> of our algorithmic developments is the stochastic policy evaluation problem in reinforcement learning. Prior investigations in the literature focused on temporal difference (TD) learning by employing nonsmooth finite time analysis motivated b&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.08434v3-abstract-full').style.display = 'inline'; document.getElementById('2011.08434v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2011.08434v3-abstract-full" style="display: none;">
        The focus of this paper is on stochastic variational inequalities (VI) under Markovian noise. A prominent <span class="search-hit mathjax">application</span> of our algorithmic developments is the stochastic policy evaluation problem in reinforcement learning. Prior investigations in the literature focused on temporal difference (TD) learning by employing nonsmooth finite time analysis motivated by stochastic subgradient descent leading to certain limitations. These encompass the requirement of analyzing a modified TD algorithm that involves projection to an a-priori defined Euclidean ball, achieving a non-<span class="search-hit mathjax">optimal</span> convergence rate and no clear way of deriving the beneficial effects of parallel implementation. Our approach remedies these shortcomings in the broader context of stochastic VIs and in particular when it comes to stochastic policy evaluation. We developed a variety of simple TD learning type algorithms motivated by its original version that maintain its simplicity, while offering distinct advantages from a non-asymptotic analysis point of view. We first provide an <span class="search-hit mathjax">improved</span> analysis of the standard TD algorithm that can benefit from parallel implementation. Then we present versions of a conditional TD algorithm (CTD), that involves periodic updates of the stochastic iterates, which <span class="search-hit mathjax">reduce</span> the bias and therefore exhibit <span class="search-hit mathjax">improved</span> iteration complexity. This brings us to the fast TD (FTD) algorithm which combines elements of CTD and the stochastic operator extrapolation method of the companion paper. For a novel index resetting policy FTD exhibits the best known convergence rate. We also devised a robust version of the algorithm that is particularly suitable for discounting factors close to 1.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.08434v3-abstract-full').style.display = 'none'; document.getElementById('2011.08434v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 25 January, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 14 November, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">arXiv admin note: text overlap with arXiv:2011.02987</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        
          <span class="has-text-black-bis has-text-weight-semibold">MSC Class:</span>
          90C25; 90C15; 62L20; 68Q25
        

        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2011.08360">arXiv:2011.08360</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2011.08360">pdf</a>, <a href="https://arxiv.org/format/2011.08360">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Numerical Analysis">math.NA</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation">stat.CO</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Recursive Importance Sketching for Rank Constrained Least Squares: Algorithms and High-order Convergence
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Luo%2C+Y">Yuetian Luo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Huang%2C+W">Wen Huang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+X">Xudong Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+A+R">Anru R. Zhang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2011.08360v2-abstract-short" style="display: inline;">
        &hellip;and RISRO offers clear advantages over them. RISRO is easy to implement and computationally efficient, where the core procedure in each iteration is only solving a dimension <span class="search-hit mathjax">reduced</span> least squares problem. Different from numerous existing algorithms with locally geometric convergence rate, we establish the local quadratic-linear and quadratic rate of converge&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.08360v2-abstract-full').style.display = 'inline'; document.getElementById('2011.08360v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2011.08360v2-abstract-full" style="display: none;">
        In this paper, we propose a new {\it \underline{R}ecursive} {\it \underline{I}mportance} {\it \underline{S}ketching} algorithm for {\it \underline{R}ank} constrained least squares {\it \underline{O}ptimization} (RISRO). As its name suggests, the algorithm is based on a new sketching framework, recursive importance sketching. Several existing algorithms in the literature can be reinterpreted under the new sketching framework and RISRO offers clear advantages over them. RISRO is easy to implement and computationally efficient, where the core procedure in each iteration is only solving a dimension <span class="search-hit mathjax">reduced</span> least squares problem. Different from numerous existing algorithms with locally geometric convergence rate, we establish the local quadratic-linear and quadratic rate of convergence for RISRO under some mild conditions. In addition, we discover a deep connection of RISRO to Riemannian manifold <span class="search-hit mathjax">optimization</span> on fixed rank matrices. The effectiveness of RISRO is demonstrated in two <span class="search-hit mathjax">applications</span> in machine learning and statistics: low-rank matrix trace regression and phase retrieval. Simulation studies demonstrate the superior numerical performance of RISRO.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.08360v2-abstract-full').style.display = 'none'; document.getElementById('2011.08360v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 13 March, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 16 November, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2011.08353">arXiv:2011.08353</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2011.08353">pdf</a>, <a href="https://arxiv.org/format/2011.08353">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Hardware Architecture">cs.AR</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        AXES: Approximation Manager for Emerging Memory Architectures
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Maity%2C+B">Biswadip Maity</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Donyanavard%2C+B">Bryan Donyanavard</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Surhonne%2C+A">Anmol Surhonne</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rahmani%2C+A">Amir Rahmani</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Herkersdorf%2C+A">Andreas Herkersdorf</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dutt%2C+N">Nikil Dutt</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2011.08353v1-abstract-short" style="display: inline;">
        &hellip;techniques are commonly limited in scope, targeting individual levels of the memory hierarchy. Existing approximation techniques for a full memory hierarchy determine <span class="search-hit mathjax">optimal</span> configurations at design-time provided a goal and&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.08353v1-abstract-full').style.display = 'inline'; document.getElementById('2011.08353v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2011.08353v1-abstract-full" style="display: none;">
        Memory approximation techniques are commonly limited in scope, targeting individual levels of the memory hierarchy. Existing approximation techniques for a full memory hierarchy determine <span class="search-hit mathjax">optimal</span> configurations at design-time provided a goal and <span class="search-hit mathjax">application</span>. Such policies are rigid: they cannot adapt to unknown workloads and must be redesigned for different memory configurations and technologies. We propose AXES: the first self-<span class="search-hit mathjax">optimizing</span> runtime manager for coordinating configurable approximation knobs across all levels of the memory hierarchy. AXES continuously updates and <span class="search-hit mathjax">optimizes</span> its approximation management policy throughout runtime for diverse workloads. AXES <span class="search-hit mathjax">optimizes</span> the approximate memory configuration to minimize power consumption without compromising the quality threshold specified by <span class="search-hit mathjax">application</span> developers. AXES can (1) learn a policy at runtime to manage variable <span class="search-hit mathjax">application</span> quality of service (QoS) constraints, (2) <span class="search-hit mathjax">automatically</span> <span class="search-hit mathjax">optimize</span> for a target metric within those constraints, and (3) coordinate runtime decisions for interdependent knobs and subsystems. We demonstrate AXES&#39; ability to efficiently provide <span class="search-hit mathjax">functions</span> 1-3 on a RISC-V Linux platform with approximate memory segments in the on-chip cache and main memory. We demonstrate AXES&#39; ability to save up to 37% energy in the memory subsystem without any design-time overhead. We show AXES&#39; ability to <span class="search-hit mathjax">reduce</span> QoS violations by 75% with $&lt;5\%$ additional energy.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.08353v1-abstract-full').style.display = 'none'; document.getElementById('2011.08353v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 November, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">21 pages, 13 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2011.07585">arXiv:2011.07585</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2011.07585">pdf</a>, <a href="https://arxiv.org/ps/2011.07585">ps</a>, <a href="https://arxiv.org/format/2011.07585">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computational Complexity">cs.CC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        An acceleration of decentralized SGD under general assumptions with low stochastic noise
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ekaterina%2C+T">Trimbach Ekaterina</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Alexander%2C+R">Rogozin Alexander</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2011.07585v3-abstract-short" style="display: inline;">
        Distributed <span class="search-hit mathjax">optimization</span> methods are actively researched by&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.07585v3-abstract-full').style.display = 'inline'; document.getElementById('2011.07585v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2011.07585v3-abstract-full" style="display: none;">
        Distributed <span class="search-hit mathjax">optimization</span> methods are actively researched by <span class="search-hit mathjax">optimization</span> community. Due to <span class="search-hit mathjax">applications</span> in distributed machine learning, modern research directions include stochastic objectives, <span class="search-hit mathjax">reducing</span> communication frequency, and time-varying communication network topology. Recently, an analysis unifying several centralized and decentralized approaches to stochastic distributed <span class="search-hit mathjax">optimization</span> was developed in Koloskova et al. (2020). In this work, we employ a Catalyst framework and accelerate the rates of Koloskova et al. (2020) in the case of low stochastic noise.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.07585v3-abstract-full').style.display = 'none'; document.getElementById('2011.07585v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 June, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 15 November, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">MOTOR 2021 conference</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2011.04868">arXiv:2011.04868</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2011.04868">pdf</a>, <a href="https://arxiv.org/format/2011.04868">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Neural Network Compression Via Sparse <span class="search-hit mathjax">Optimization</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+T">Tianyi Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ji%2C+B">Bo Ji</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shi%2C+Y">Yixin Shi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ding%2C+T">Tianyu Ding</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fang%2C+B">Biyi Fang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yi%2C+S">Sheng Yi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tu%2C+X">Xiao Tu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2011.04868v2-abstract-short" style="display: inline;">
        The compression of deep neural networks (DNNs) to <span class="search-hit mathjax">reduce</span> inference cost becomes increasingly important to meet realistic deployment requirements of various&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.04868v2-abstract-full').style.display = 'inline'; document.getElementById('2011.04868v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2011.04868v2-abstract-full" style="display: none;">
        The compression of deep neural networks (DNNs) to <span class="search-hit mathjax">reduce</span> inference cost becomes increasingly important to meet realistic deployment requirements of various <span class="search-hit mathjax">applications</span>. There have been a significant amount of work regarding network compression, while most of them are heuristic rule-based or typically not friendly to be incorporated into varying scenarios. On the other hand, sparse <span class="search-hit mathjax">optimization</span> yielding sparse solutions naturally fits the compression requirement, but due to the limited study of sparse <span class="search-hit mathjax">optimization</span> in stochastic learning, its extension and <span class="search-hit mathjax">application</span> onto model compression is rarely well explored. In this work, we propose a model compression framework based on the recent progress on sparse stochastic <span class="search-hit mathjax">optimization</span>. Compared to existing model compression techniques, our method is effective and requires fewer extra engineering efforts to incorporate with varying <span class="search-hit mathjax">applications</span>, and has been numerically demonstrated on benchmark compression tasks. Particularly, we achieve up to 7.2 and 2.9 times FLOPs reduction with the same level of evaluation accuracy on VGG16 for CIFAR10 and ResNet50 for ImageNet compared to the baseline heavy models, respectively.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.04868v2-abstract-full').style.display = 'none'; document.getElementById('2011.04868v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 11 November, 2020; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 9 November, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2011.04726">arXiv:2011.04726</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2011.04726">pdf</a>, <a href="https://arxiv.org/format/2011.04726">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        TrimTuner: Efficient <span class="search-hit mathjax">Optimization</span> of Machine Learning Jobs in the Cloud via Sub-Sampling
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Mendes%2C+P">Pedro Mendes</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Casimiro%2C+M">Maria Casimiro</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Romano%2C+P">Paolo Romano</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Garlan%2C+D">David Garlan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2011.04726v1-abstract-short" style="display: inline;">
        This work introduces TrimTuner, the first system for <span class="search-hit mathjax">optimizing</span> machine learning jobs in the cloud to exploit sub-sampling techniques to&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.04726v1-abstract-full').style.display = 'inline'; document.getElementById('2011.04726v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2011.04726v1-abstract-full" style="display: none;">
        This work introduces TrimTuner, the first system for <span class="search-hit mathjax">optimizing</span> machine learning jobs in the cloud to exploit sub-sampling techniques to <span class="search-hit mathjax">reduce</span> the cost of the <span class="search-hit mathjax">optimization</span> process while keeping into account user-specified constraints. TrimTuner jointly <span class="search-hit mathjax">optimizes</span> the cloud and <span class="search-hit mathjax">application</span>-specific parameters and, unlike state of the art works for cloud <span class="search-hit mathjax">optimization</span>, eschews the need to train the model with the full training set every time a new configuration is sampled. Indeed, by leveraging sub-sampling techniques and data-sets that are up to 60x smaller than the original one, we show that TrimTuner can <span class="search-hit mathjax">reduce</span> the cost of the <span class="search-hit mathjax">optimization</span> process by up to 50x. Further, TrimTuner speeds-up the recommendation process by 65x with respect to state of the art techniques for hyper-parameter <span class="search-hit mathjax">optimization</span> that use sub-sampling techniques. The reasons for this <span class="search-hit mathjax">improvement</span> are twofold: i) a novel domain specific heuristic that <span class="search-hit mathjax">reduces</span> the number of configurations for which the acquisition <span class="search-hit mathjax">function</span> has to be evaluated; ii) the adoption of an ensemble of decision trees that enables boosting the speed of the recommendation process by one additional order of magnitude.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.04726v1-abstract-full').style.display = 'none'; document.getElementById('2011.04726v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 9 November, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Mascots 2020</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2011.04118">arXiv:2011.04118</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2011.04118">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Joint Estimation of Expertise and Reward Preferences From Human Demonstrations
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Carreno-Medrano%2C+P">Pamela Carreno-Medrano</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Smith%2C+S+L">Stephen L. Smith</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kulic%2C+D">Dana Kulic</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2011.04118v1-abstract-short" style="display: inline;">
        When a robot learns from human examples, most approaches assume that the human partner provides examples of <span class="search-hit mathjax">optimal</span> behavior. However, there are&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.04118v1-abstract-full').style.display = 'inline'; document.getElementById('2011.04118v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2011.04118v1-abstract-full" style="display: none;">
        When a robot learns from human examples, most approaches assume that the human partner provides examples of <span class="search-hit mathjax">optimal</span> behavior. However, there are <span class="search-hit mathjax">applications</span> in which the robot learns from non-expert humans. We argue that the robot should learn not only about the human&#39;s objectives, but also about their expertise level. The robot could then leverage this joint information to <span class="search-hit mathjax">reduce</span> or increase the frequency at which it provides assistance to its human&#39;s partner or be more cautious when learning new skills from novice users. Similarly, by taking into account the human&#39;s expertise, the robot would also be able of inferring a human&#39;s true objectives even when the human&#39;s fails to properly demonstrate these objectives due to a lack of expertise. In this paper, we propose to jointly infer the expertise level and objective <span class="search-hit mathjax">function</span> of a human given observations of their (possibly) non-<span class="search-hit mathjax">optimal</span> demonstrations. Two inference approaches are proposed. In the first approach, inference is done over a finite, discrete set of possible objective <span class="search-hit mathjax">functions</span> and expertise levels. In the second approach, the robot <span class="search-hit mathjax">optimizes</span> over the space of all possible hypotheses and finds the objective <span class="search-hit mathjax">function</span> and expertise level that best explain the observed human behavior. We demonstrate our proposed approaches both in simulation and with real user data.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.04118v1-abstract-full').style.display = 'none'; document.getElementById('2011.04118v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 November, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">17 pages, TRO Submission</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2011.03747">arXiv:2011.03747</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2011.03747">pdf</a>, <a href="https://arxiv.org/format/2011.03747">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Synthesising Privacy by Design Knowledge Towards Explainable Internet of Things <span class="search-hit mathjax">Application</span> Designing in Healthcare
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Alkhariji%2C+L">Lamya Alkhariji</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Alhirabi%2C+N">Nada Alhirabi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Alraja%2C+M+N">Mansour Naser Alraja</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Barhamgi%2C+M">Mahmoud Barhamgi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rana%2C+O">Omer Rana</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Perera%2C+C">Charith Perera</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2011.03747v1-abstract-short" style="display: inline;">
        Privacy by Design (PbD) is the most common approach followed by <span class="search-hit mathjax">software</span> developers who aim to&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.03747v1-abstract-full').style.display = 'inline'; document.getElementById('2011.03747v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2011.03747v1-abstract-full" style="display: none;">
        Privacy by Design (PbD) is the most common approach followed by <span class="search-hit mathjax">software</span> developers who aim to <span class="search-hit mathjax">reduce</span> risks within their <span class="search-hit mathjax">application</span> designs, yet it remains commonplace for developers to retain little conceptual understanding of what is meant by privacy. A vision is to develop an intelligent privacy assistant to whom developers can easily ask questions in order to learn how to incorporate different privacy-preserving ideas into their IoT <span class="search-hit mathjax">application</span> designs. This paper lays the foundations toward developing such a privacy assistant by synthesising existing PbD knowledge so as to elicit requirements. It is believed that such a privacy assistant should not just prescribe a list of privacy-preserving ideas that developers should incorporate into their design. Instead, it should explain how each prescribed idea helps to protect privacy in a given <span class="search-hit mathjax">application</span> design context-this approach is defined as &#39;Explainable Privacy&#39;. A total of 74 privacy patterns were analysed and reviewed using ten different PbD schemes to understand how each privacy pattern is built and how each helps to ensure privacy. Due to page limitations, we have presented a detailed analysis in [3]. In addition, different real-world Internet of Things (IoT) use-cases, including a healthcare <span class="search-hit mathjax">application</span>, were used to demonstrate how each privacy pattern could be applied to a given <span class="search-hit mathjax">application</span> design. By doing so, several knowledge engineering requirements were identified that need to be considered when developing a privacy assistant. It was also found that, when compared to other IoT <span class="search-hit mathjax">application</span> domains, privacy patterns can significantly benefit healthcare <span class="search-hit mathjax">applications</span>. In conclusion, this paper identifies the research challenges that must be addressed if one wishes to construct an intelligent privacy assistant that can truly augment <span class="search-hit mathjax">software</span> developers&#39; capabilities at the design phase.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.03747v1-abstract-full').style.display = 'none'; document.getElementById('2011.03747v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 November, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM) (In-Print)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2011.01850">arXiv:2011.01850</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2011.01850">pdf</a>, <a href="https://arxiv.org/ps/2011.01850">ps</a>, <a href="https://arxiv.org/format/2011.01850">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Numerical Analysis">math.NA</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Mathematical Software">cs.MS</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        <span class="search-hit mathjax">Improving</span> the Performance of the GMRES Method using Mixed-Precision Techniques
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Lindquist%2C+N">Neil Lindquist</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Luszczek%2C+P">Piotr Luszczek</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dongarra%2C+J">Jack Dongarra</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2011.01850v1-abstract-short" style="display: inline;">
        The GMRES method is used to solve sparse, non-symmetric systems of linear equations arising from many scientific <span class="search-hit mathjax">applications</span>. The solver performance within a single node is memory bound, due to the low arithmetic intensity of its computational kernels. To&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.01850v1-abstract-full').style.display = 'inline'; document.getElementById('2011.01850v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2011.01850v1-abstract-full" style="display: none;">
        The GMRES method is used to solve sparse, non-symmetric systems of linear equations arising from many scientific <span class="search-hit mathjax">applications</span>. The solver performance within a single node is memory bound, due to the low arithmetic intensity of its computational kernels. To <span class="search-hit mathjax">reduce</span> the amount of data movement, and thus, to <span class="search-hit mathjax">improve</span> performance, we investigated the effect of using a mix of single and double precision while retaining double-precision accuracy. Previous efforts have explored <span class="search-hit mathjax">reduced</span> precision in the preconditioner, but the use of <span class="search-hit mathjax">reduced</span> precision in the solver itself has received limited attention. We found that GMRES only needs double precision in computing the residual and updating the approximate solution to achieve double-precision accuracy, although it must restart after each <span class="search-hit mathjax">improvement</span> of single-precision accuracy. This finding holds for the tested orthogonalization schemes: Modified Gram-Schmidt (MGS) and Classical Gram-Schmidt with Re-orthogonalization (CGSR). Furthermore, our mixed-precision GMRES, when restarted at least once, performed 19% and 24% faster on average than double-precision GMRES for MGS and CGSR, respectively. Our implementation uses generic <span class="search-hit mathjax">programming</span> techniques to ease the burden of <span class="search-hit mathjax">coding</span> implementations for different data types. Our use of the Kokkos library allowed us to exploit parallelism and <span class="search-hit mathjax">optimize</span> data management. Additionally, KokkosKernels was used when producing performance results. In conclusion, using a mix of single and double precision in GMRES can <span class="search-hit mathjax">improve</span> performance while retaining double-precision accuracy.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.01850v1-abstract-full').style.display = 'none'; document.getElementById('2011.01850v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 3 November, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">16 pages. In the 17th Smoky Mountains Computational Sciences and Engineering Conference</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2011.01207">arXiv:2011.01207</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2011.01207">pdf</a>, <a href="https://arxiv.org/format/2011.01207">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computational Physics">physics.comp-ph</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Mathematical Software">cs.MS</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Chemical Physics">physics.chem-ph</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1021/acs.jctc.0c01164">10.1021/acs.jctc.0c01164 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Tinker-HP : Accelerating Molecular Dynamics Simulations of Large Complex Systems with Advanced Point Dipole Polarizable Force Fields using GPUs and Multi-GPUs systems
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Adjoua%2C+O">Olivier Adjoua</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lagard%C3%A8re%2C+L">Louis Lagard√®re</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jolly%2C+L">Luc-Henri Jolly</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Durocher%2C+A">Arnaud Durocher</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Very%2C+T">Thibaut Very</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dupays%2C+I">Isabelle Dupays</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+Z">Zhi Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Inizan%2C+T+J">Th√©o Jaffrelot Inizan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=C%C3%A9lerse%2C+F">Fr√©d√©ric C√©lerse</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ren%2C+P">Pengyu Ren</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ponder%2C+J+W">Jay W. Ponder</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Piquemal%2C+J">Jean-Philip Piquemal</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2011.01207v4-abstract-short" style="display: inline;">
        &hellip;of our general scalable strategy that relies on OpenACC and CUDA, we discuss the various capabilities of the package. Among them, the multi-precision possibilities of the <span class="search-hit mathjax">code</span> are discussed. If an efficient double precision implementation is provided to preserve the possibility of fast reference computations, we show that a lower precision arithmetic is pref&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.01207v4-abstract-full').style.display = 'inline'; document.getElementById('2011.01207v4-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2011.01207v4-abstract-full" style="display: none;">
        We present the extension of the Tinker-HP package (Lagard√®re et al., Chem. Sci., 2018,9, 956-972) to the use of Graphics Processing Unit (GPU) cards to accelerate molecular dynamics simulations using polarizable many-body force fields. The new high-performance module allows for an efficient use of single- and multi-GPU architectures ranging from research laboratories to modern supercomputer centers. After detailing an analysis of our general scalable strategy that relies on OpenACC and CUDA, we discuss the various capabilities of the package. Among them, the multi-precision possibilities of the <span class="search-hit mathjax">code</span> are discussed. If an efficient double precision implementation is provided to preserve the possibility of fast reference computations, we show that a lower precision arithmetic is preferred providing a similar accuracy for molecular dynamics while exhibiting superior performances. As Tinker-HP is mainly dedicated to accelerate simulations using new generation point dipole polarizable force field, we focus our study on the implementation of the AMOEBA model. Testing various NVIDIA platforms including 2080Ti, 3090, V100 and A100 cards, we provide illustrative benchmarks of the <span class="search-hit mathjax">code</span> for single- and multi-cards simulations on large biosystems encompassing up to millions of atoms. The new <span class="search-hit mathjax">code</span> strongly <span class="search-hit mathjax">reduces</span> time to solution and offers the best performances to date obtained using the AMOEBA polarizable force field. Perspectives toward the strong-scaling performance of our multi-node massive parallelization strategy, unsupervised adaptive sampling and large scale <span class="search-hit mathjax">applicability</span> of the Tinker-HP <span class="search-hit mathjax">code</span> in biophysics are discussed. The present <span class="search-hit mathjax">software</span> has been released in phase advance on GitHub in link with the High Performance Computing community COVID-19 research efforts and is free for Academics (see https://github.com/TinkerTools/tinker-hp).
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.01207v4-abstract-full').style.display = 'none'; document.getElementById('2011.01207v4-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 3 March, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 2 November, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2020.
      
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        Journal of Chemical Theory and Computation, 2021, 17, 4, 2034-2053
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2011.00289">arXiv:2011.00289</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2011.00289">pdf</a>, <a href="https://arxiv.org/format/2011.00289">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Methodology">stat.ME</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Smoothly Adaptively Centered Ridge Estimator
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Belli%2C+E">Edoardo Belli</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2011.00289v1-abstract-short" style="display: inline;">
        With a focus on linear models with smooth <span class="search-hit mathjax">functional</span> covariates, we propose a penalization framework (SACR) based on the nonzero centered ridge, where the center of the penalty is&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.00289v1-abstract-full').style.display = 'inline'; document.getElementById('2011.00289v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2011.00289v1-abstract-full" style="display: none;">
        With a focus on linear models with smooth <span class="search-hit mathjax">functional</span> covariates, we propose a penalization framework (SACR) based on the nonzero centered ridge, where the center of the penalty is <span class="search-hit mathjax">optimally</span> reweighted in a supervised way, starting from the ordinary ridge solution as the initial centerfunction. In particular, we introduce a convex formulation that jointly estimates the model&#39;s coefficients and the weight <span class="search-hit mathjax">function</span>, with a roughness penalty on the centerfunction and constraints on the weights in order to recover a possibly smooth and/or sparse solution. This allows for a non-iterative and continuous variable selection mechanism, as the weight <span class="search-hit mathjax">function</span> can either inflate or deflate the initial center, in order to target the penalty towards a suitable center, with the objective to <span class="search-hit mathjax">reduce</span> the unwanted shrinkage on the nonzero coefficients, instead of uniformly shrinking the whole coefficient <span class="search-hit mathjax">function</span>. As empirical evidence of the interpretability and predictive power of our method, we provide a simulation study and two real world spectroscopy <span class="search-hit mathjax">applications</span> with both classification and regression.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.00289v1-abstract-full').style.display = 'none'; document.getElementById('2011.00289v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 31 October, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2011.00046">arXiv:2011.00046</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2011.00046">pdf</a>, <a href="https://arxiv.org/format/2011.00046">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Measure Inducing Classification and Regression Trees for <span class="search-hit mathjax">Functional</span> Data
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Belli%2C+E">Edoardo Belli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Vantini%2C+S">Simone Vantini</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2011.00046v1-abstract-short" style="display: inline;">
        We propose a tree-based algorithm for classification and regression problems in the context of <span class="search-hit mathjax">functional</span> data analysis, which allows to leverage representation learning and multiple splitting rules at the node level,&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.00046v1-abstract-full').style.display = 'inline'; document.getElementById('2011.00046v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2011.00046v1-abstract-full" style="display: none;">
        We propose a tree-based algorithm for classification and regression problems in the context of <span class="search-hit mathjax">functional</span> data analysis, which allows to leverage representation learning and multiple splitting rules at the node level, <span class="search-hit mathjax">reducing</span> generalization error while retaining the interpretability of a tree. This is achieved by learning a weighted <span class="search-hit mathjax">functional</span> $L^{2}$ space by means of constrained convex <span class="search-hit mathjax">optimization</span>, which is then used to extract multiple weighted integral features from the input <span class="search-hit mathjax">functions</span>, in order to determine the binary split for each internal node of the tree. The approach is designed to manage multiple <span class="search-hit mathjax">functional</span> inputs and/or outputs, by defining suitable splitting rules and loss <span class="search-hit mathjax">functions</span> that can depend on the specific problem and can also be combined with scalar and categorical data, as the tree is grown with the original greedy CART algorithm. We focus on the case of scalar-valued <span class="search-hit mathjax">functional</span> inputs defined on unidimensional domains and illustrate the effectiveness of our method in both classification and regression tasks, through a simulation study and four real world <span class="search-hit mathjax">applications</span>.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.00046v1-abstract-full').style.display = 'none'; document.getElementById('2011.00046v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 October, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2010.14702">arXiv:2010.14702</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2010.14702">pdf</a>, <a href="https://arxiv.org/format/2010.14702">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Graphics">cs.GR</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        <span class="search-hit mathjax">Optimal</span> Textures: Fast and Robust Texture Synthesis and Style Transfer through <span class="search-hit mathjax">Optimal</span> Transport
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Risser%2C+E">Eric Risser</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2010.14702v1-abstract-short" style="display: inline;">
        This paper presents a light-weight, high-quality texture synthesis algorithm that easily generalizes to other <span class="search-hit mathjax">applications</span> such as style transfer and texture mixing. We represent texture features through the deep neural activation vectors within the bottleneck layer of an auto-encoder and frame the texture synthesis problem as&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2010.14702v1-abstract-full').style.display = 'inline'; document.getElementById('2010.14702v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2010.14702v1-abstract-full" style="display: none;">
        This paper presents a light-weight, high-quality texture synthesis algorithm that easily generalizes to other <span class="search-hit mathjax">applications</span> such as style transfer and texture mixing. We represent texture features through the deep neural activation vectors within the bottleneck layer of an auto-encoder and frame the texture synthesis problem as <span class="search-hit mathjax">optimal</span> transport between the activation values of the image being synthesized and those of an exemplar texture. To find this <span class="search-hit mathjax">optimal</span> transport mapping, we utilize an N-dimensional probability density <span class="search-hit mathjax">function</span> (PDF) transfer process that iterates over multiple random rotations of the PDF basis and matches the 1D marginal distributions across each dimension. This achieves quality and flexibility on par with expensive back-propagation based neural texture synthesis methods, but with the potential of achieving interactive rates. We demonstrate that first order statistics offer a more robust representation for texture than the second order statistics that are used today. We propose an extension of this algorithm that <span class="search-hit mathjax">reduces</span> the dimensionality of the neural feature space. We utilize a multi-scale coarse-to-fine synthesis pyramid to capture and preserve larger image features; unify color and style transfer under one framework; and further augment this system with a novel masking scheme that re-samples and re-weights the feature distribution for user-guided texture painting and targeted style transfer.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2010.14702v1-abstract-full').style.display = 'none'; document.getElementById('2010.14702v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 27 October, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2010.14258">arXiv:2010.14258</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2010.14258">pdf</a>, <a href="https://arxiv.org/format/2010.14258">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Signal Processing">eess.SP</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Information Theory">cs.IT</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Physics-Based Deep Learning for Fiber-Optic Communication Systems
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=H%C3%A4ger%2C+C">Christian H√§ger</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pfister%2C+H+D">Henry D. Pfister</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2010.14258v1-abstract-short" style="display: inline;">
        &hellip;by the nonlinear Schr√∂dinger equation (NLSE). Our main observation is that the popular split-step method (SSM) for numerically solving the NLSE has essentially the same <span class="search-hit mathjax">functional</span> form as a deep multi-layer neural network; in both cases, one alternates linear steps and pointwise nonlinearities. We exploit this connection by parameterizing the SSM and viewing&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2010.14258v1-abstract-full').style.display = 'inline'; document.getElementById('2010.14258v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2010.14258v1-abstract-full" style="display: none;">
        We propose a new machine-learning approach for fiber-optic communication systems whose signal propagation is governed by the nonlinear Schr√∂dinger equation (NLSE). Our main observation is that the popular split-step method (SSM) for numerically solving the NLSE has essentially the same <span class="search-hit mathjax">functional</span> form as a deep multi-layer neural network; in both cases, one alternates linear steps and pointwise nonlinearities. We exploit this connection by parameterizing the SSM and viewing the linear steps as general linear <span class="search-hit mathjax">functions</span>, similar to the weight matrices in a neural network. The resulting physics-based machine-learning model has several advantages over &#34;black-box&#34; <span class="search-hit mathjax">function</span> approximators. For example, it allows us to examine and interpret the learned solutions in order to understand why they perform well. As an <span class="search-hit mathjax">application</span>, low-complexity nonlinear equalization is considered, where the task is to efficiently invert the NLSE. This is commonly referred to as digital backpropagation (DBP). Rather than employing neural networks, the proposed algorithm, dubbed learned DBP (LDBP), uses the physics-based model with trainable filters in each step and its complexity is <span class="search-hit mathjax">reduced</span> by progressively pruning filter taps during gradient descent. Our main finding is that the filters can be pruned to remarkably short lengths-as few as 3 taps/step-without sacrificing performance. As a result, the complexity can be <span class="search-hit mathjax">reduced</span> by orders of magnitude in comparison to prior work. By inspecting the filter responses, an additional theoretical justification for the learned parameter configurations is provided. Our work illustrates that combining data-driven <span class="search-hit mathjax">optimization</span> with existing domain knowledge can generate new insights into old communications problems.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2010.14258v1-abstract-full').style.display = 'none'; document.getElementById('2010.14258v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 27 October, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">15 pages, 11 figures, submitted to IEEE J. Sel. Areas Commun., <span class="search-hit mathjax">code</span> available at https://github.com/chaeger/LDBP, extension of arXiv:1710.06234(1), arXiv:1804.02799(1), arXiv:1901.07592(2)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2010.13888">arXiv:2010.13888</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2010.13888">pdf</a>, <a href="https://arxiv.org/ps/2010.13888">ps</a>, <a href="https://arxiv.org/format/2010.13888">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Data Structures and Algorithms">cs.DS</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Unifying Matrix Data Structures: Simplifying and Speeding up Iterative Algorithms
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Brand%2C+J+v+d">Jan van den Brand</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2010.13888v1-abstract-short" style="display: inline;">
        Many algorithms use data structures that maintain properties of matrices undergoing some changes. The <span class="search-hit mathjax">applications</span> are wide-ranging and include for example matchings, shortest paths, linear&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2010.13888v1-abstract-full').style.display = 'inline'; document.getElementById('2010.13888v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2010.13888v1-abstract-full" style="display: none;">
        Many algorithms use data structures that maintain properties of matrices undergoing some changes. The <span class="search-hit mathjax">applications</span> are wide-ranging and include for example matchings, shortest paths, linear <span class="search-hit mathjax">programming</span>, semi-definite <span class="search-hit mathjax">programming</span>, convex hull and volume computation. Given the wide range of <span class="search-hit mathjax">applications</span>, the exact property these data structures must maintain varies from one <span class="search-hit mathjax">application</span> to another, forcing algorithm designers to invent them from scratch or modify existing ones. Thus it is not surprising that these data structures and their proofs are usually tailor-made for their specific <span class="search-hit mathjax">application</span> and that maintaining more complicated properties results in more complicated proofs.
  In this paper we present a unifying framework that captures a wide range of these data structures. The simplicity of this framework allows us to give short proofs for many existing data structures regardless of how complicated the to be maintained property is. We also show how the framework can be used to speed up existing iterative algorithms, such as the simplex algorithm.
  More formally, consider any rational <span class="search-hit mathjax">function</span> $f(A_1,...,A_d)$ with input matrices $A_1,...,A_d$. We show that the task of maintaining $f(A_1,...,A_d)$ under updates to $A_1,...,A_d$ can be <span class="search-hit mathjax">reduced</span> to the much simpler problem of maintaining some matrix inverse $M^{-1}$ under updates to $M$. The latter is a well studied problem called dynamic matrix inverse. By applying our reduction and using known algorithms for dynamic matrix inverse we can obtain fast data structures and iterative algorithms for much more general problems.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2010.13888v1-abstract-full').style.display = 'none'; document.getElementById('2010.13888v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 26 October, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">SOSA&#39;21</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2010.13887">arXiv:2010.13887</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2010.13887">pdf</a>, <a href="https://arxiv.org/format/2010.13887">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Mathematical Software">cs.MS</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        LightSeq: A High Performance Inference Library for Transformers
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+X">Xiaohui Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xiong%2C+Y">Ying Xiong</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wei%2C+Y">Yang Wei</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+M">Mingxuan Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+L">Lei Li</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2010.13887v4-abstract-short" style="display: inline;">
        Transformer, BERT and their variants have achieved great success in natural language processing. Since Transformer models are huge in <span class="search-hit mathjax">size</span>, serving these models is a challenge for real industrial&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2010.13887v4-abstract-full').style.display = 'inline'; document.getElementById('2010.13887v4-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2010.13887v4-abstract-full" style="display: none;">
        Transformer, BERT and their variants have achieved great success in natural language processing. Since Transformer models are huge in <span class="search-hit mathjax">size</span>, serving these models is a challenge for real industrial <span class="search-hit mathjax">applications</span>. In this paper, we propose LightSeq, a highly efficient inference library for models in the Transformer family. LightSeq includes a series of GPU <span class="search-hit mathjax">optimization</span> techniques to to streamline the computation of neural layers and to <span class="search-hit mathjax">reduce</span> memory footprint. LightSeq can easily import models trained using PyTorch and Tensorflow. Experimental results on machine translation benchmarks show that LightSeq achieves up to 14x speedup compared with TensorFlow and 1.4x compared with FasterTransformer, a concurrent CUDA implementation. The <span class="search-hit mathjax">code</span> is available at https://github.com/bytedance/lightseq.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2010.13887v4-abstract-full').style.display = 'none'; document.getElementById('2010.13887v4-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 April, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 23 October, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">8 pages, 6 figures, accepted by NAACL 2021 Industry Track</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2010.13433">arXiv:2010.13433</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2010.13433">pdf</a>, <a href="https://arxiv.org/format/2010.13433">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A Weakly-Supervised Semantic Segmentation Approach based on the Centroid Loss: <span class="search-hit mathjax">Application</span> to Quality Control and Inspection
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Yao%2C+K">Kai Yao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ortiz%2C+A">Alberto Ortiz</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bonnin-Pascual%2C+F">Francisco Bonnin-Pascual</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2010.13433v3-abstract-short" style="display: inline;">
        &hellip;is particularly difficult for semantic segmentation tasks since the annotation must be ideally generated at the pixel level. Weakly-supervised semantic segmentation aims at <span class="search-hit mathjax">reducing</span> this cost by employing simpler annotations that, hence, are easier, cheaper and quicker to produce. In this paper, we propose and assess a new weakly-supervised semantic segmenta&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2010.13433v3-abstract-full').style.display = 'inline'; document.getElementById('2010.13433v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2010.13433v3-abstract-full" style="display: none;">
        It is generally accepted that one of the critical parts of current vision algorithms based on deep learning and convolutional neural networks is the annotation of a sufficient number of images to achieve competitive performance. This is particularly difficult for semantic segmentation tasks since the annotation must be ideally generated at the pixel level. Weakly-supervised semantic segmentation aims at <span class="search-hit mathjax">reducing</span> this cost by employing simpler annotations that, hence, are easier, cheaper and quicker to produce. In this paper, we propose and assess a new weakly-supervised semantic segmentation approach making use of a novel loss <span class="search-hit mathjax">function</span> whose goal is to counteract the effects of weak annotations. To this end, this loss <span class="search-hit mathjax">function</span> comprises several terms based on partial cross-entropy losses, being one of them the Centroid Loss. This term induces a clustering of the image pixels in the object classes under consideration, whose aim is to <span class="search-hit mathjax">improve</span> the training of the segmentation network by guiding the <span class="search-hit mathjax">optimization</span>. The performance of the approach is evaluated against datasets from two different industry-related case studies: while one involves the detection of instances of a number of different object classes in the context of a quality control <span class="search-hit mathjax">application</span>, the other stems from the visual inspection domain and deals with the localization of images areas whose pixels correspond to scene surface points affected by a specific sort of defect. The detection results that are reported for both cases show that, despite the differences among them and the particular challenges, the use of weak annotations do not prevent from achieving a competitive performance level for both.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2010.13433v3-abstract-full').style.display = 'none'; document.getElementById('2010.13433v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 4 March, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 26 October, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2010.13072">arXiv:2010.13072</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2010.13072">pdf</a>, <a href="https://arxiv.org/format/2010.13072">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        LIRO: Tightly Coupled Lidar-Inertia-Ranging Odometry
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Nguyen%2C+T">Thien-Minh Nguyen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cao%2C+M">Muqing Cao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yuan%2C+S">Shenghai Yuan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lyu%2C+Y">Yang Lyu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Nguyen%2C+T+H">Thien Hoang Nguyen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xie%2C+L">Lihua Xie</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2010.13072v1-abstract-short" style="display: inline;">
        In recent years, thanks to the continuously <span class="search-hit mathjax">reduced</span> cost and weight of 3D Lidar, the&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2010.13072v1-abstract-full').style.display = 'inline'; document.getElementById('2010.13072v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2010.13072v1-abstract-full" style="display: none;">
        In recent years, thanks to the continuously <span class="search-hit mathjax">reduced</span> cost and weight of 3D Lidar, the <span class="search-hit mathjax">applications</span> of this type of sensor in robotics community have become increasingly popular. Despite many progresses, estimation drift and tracking loss are still prevalent concerns associated with these systems. However, in theory these issues can be resolved with the use of some observations to fixed landmarks in the environments. This motivates us to investigate a tightly coupled sensor fusion scheme of Ultra-Wideband (UWB) range measurements with Lidar and inertia measurements. First, data from IMU, Lidar and UWB are associated with the robot&#39;s states on a sliding windows based on their timestamps. Then, we construct a cost <span class="search-hit mathjax">function</span> comprising of factors from UWB, Lidar and IMU preintegration measurements. Finally an <span class="search-hit mathjax">optimization</span> process is carried out to estimate the robot&#39;s position and orientation. Via some real world experiments, we show that the method can effectively resolve the drift issue, while only requiring two or three anchors deployed in the environment.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2010.13072v1-abstract-full').style.display = 'none'; document.getElementById('2010.13072v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 25 October, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2010.11264">arXiv:2010.11264</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2010.11264">pdf</a>, <a href="https://arxiv.org/ps/2010.11264">ps</a>, <a href="https://arxiv.org/format/2010.11264">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        An Efficient Real-Time NMPC for Quadrotor Position Control under Communication Time-Delay
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Carlos%2C+B+B">Barbara Barros Carlos</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sartor%2C+T">Tommaso Sartor</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zanelli%2C+A">Andrea Zanelli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Frison%2C+G">Gianluca Frison</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Burgard%2C+W">Wolfram Burgard</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Diehl%2C+M">Moritz Diehl</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Oriolo%2C+G">Giuseppe Oriolo</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2010.11264v2-abstract-short" style="display: inline;">
        The advances in computer processor technology have enabled the <span class="search-hit mathjax">application</span> of nonlinear model predictive control (NMPC) to agile systems, such as quadrotors. These systems are characterized by their underactuation, nonlinearities, bounded inputs, and time-delays. Classical control solutions fall short in overcoming these difficulties and fully exploiting the&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2010.11264v2-abstract-full').style.display = 'inline'; document.getElementById('2010.11264v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2010.11264v2-abstract-full" style="display: none;">
        The advances in computer processor technology have enabled the <span class="search-hit mathjax">application</span> of nonlinear model predictive control (NMPC) to agile systems, such as quadrotors. These systems are characterized by their underactuation, nonlinearities, bounded inputs, and time-delays. Classical control solutions fall short in overcoming these difficulties and fully exploiting the capabilities offered by such platforms. This paper presents the design and implementation of an efficient position controller for quadrotors based on real-time NMPC with time-delay compensation and bounds enforcement on the actuators. To deal with the limited computational resources onboard, an offboard control architecture is proposed. It is implemented using the high-performance <span class="search-hit mathjax">software</span> package acados, which solves <span class="search-hit mathjax">optimal</span> control problems and implements a real-time iteration (RTI) variant of a sequential quadratic <span class="search-hit mathjax">programming</span> (SQP) scheme with Gauss-Newton Hessian approximation. The quadratic subproblems (QP) in the SQP scheme are solved with HPIPM, an interior-point method solver, built on top of the linear algebra library BLASFEO, finely tuned for multiple CPU architectures. Solution times are further <span class="search-hit mathjax">reduced</span> by reformulating the QPs using the efficient partial condensing algorithm implemented in HPIPM. We demonstrate the capabilities of our architecture using the Crazyflie 2.1 nano-quadrotor.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2010.11264v2-abstract-full').style.display = 'none'; document.getElementById('2010.11264v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 23 October, 2020; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 21 October, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">This paper has been accepted for publication at the 16th International Conference on Control, Automation, Robotics and Vision (ICARCV), Shenzhen, China, December 13-15, 2020, IEEE</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2010.11160">arXiv:2010.11160</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2010.11160">pdf</a>, <a href="https://arxiv.org/format/2010.11160">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        <span class="search-hit mathjax">Improving</span> the Iterative Closest Point Algorithm using Lie Algebra
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Vaidis%2C+M">Maxime Vaidis</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Laconte%2C+J">Johann Laconte</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kubelka%2C+V">Vladim√≠r Kubelka</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pomerleau%2C+F">Fran√ßois Pomerleau</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2010.11160v1-abstract-short" style="display: inline;">
        Mapping algorithms that rely on registering point clouds inevitably suffer from local drift, both in localization and in the built map. <span class="search-hit mathjax">Applications</span> that require accurate maps, such as environmental monitoring, benefit from additional sensor modalities that&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2010.11160v1-abstract-full').style.display = 'inline'; document.getElementById('2010.11160v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2010.11160v1-abstract-full" style="display: none;">
        Mapping algorithms that rely on registering point clouds inevitably suffer from local drift, both in localization and in the built map. <span class="search-hit mathjax">Applications</span> that require accurate maps, such as environmental monitoring, benefit from additional sensor modalities that <span class="search-hit mathjax">reduce</span> such drift. In our work, we target the family of mappers based on the Iterative Closest Point (ICP) algorithm which use additional orientation sources such as the Inertial Measurement Unit (IMU). We introduce a new angular penalty term derived from Lie algebra. Our formulation avoids the need for tuning arbitrary parameters. Orientation covariance is used instead, and the resulting error term fits into the ICP cost <span class="search-hit mathjax">function</span> minimization problem. Experiments performed on our own real-world data and on the KITTI dataset show consistent behavior while suppressing the effect of outlying IMU measurements. We further discuss promising experiments, which should lead to <span class="search-hit mathjax">optimal</span> combination of all error terms in the ICP cost <span class="search-hit mathjax">function</span> minimization problem, allowing us to smoothly combine the geometric and inertial information provided by robot sensors.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2010.11160v1-abstract-full').style.display = 'none'; document.getElementById('2010.11160v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 21 October, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Final version published in the International Conference on Intelligent Robots and Systems (IROS) workshop in October 2020</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2010.10248">arXiv:2010.10248</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2010.10248">pdf</a>, <a href="https://arxiv.org/format/2010.10248">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Mathematical Software">cs.MS</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Performance">cs.PF</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Temporal blocking of finite-difference stencil operators with sparse &#34;off-the-grid&#34; sources
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Bisbas%2C+G">George Bisbas</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Luporini%2C+F">Fabio Luporini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Louboutin%2C+M">Mathias Louboutin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Nelson%2C+R">Rhodri Nelson</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gorman%2C+G">Gerard Gorman</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kelly%2C+P+H+J">Paul H. J. Kelly</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2010.10248v2-abstract-short" style="display: inline;">
        Stencil kernels dominate a range of scientific <span class="search-hit mathjax">applications</span>, including seismic and medical imaging, image processing, and neural networks. Temporal blocking is a performance&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2010.10248v2-abstract-full').style.display = 'inline'; document.getElementById('2010.10248v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2010.10248v2-abstract-full" style="display: none;">
        Stencil kernels dominate a range of scientific <span class="search-hit mathjax">applications</span>, including seismic and medical imaging, image processing, and neural networks. Temporal blocking is a performance <span class="search-hit mathjax">optimization</span> that aims to <span class="search-hit mathjax">reduce</span> the required memory bandwidth of stencil computations by re-using data from the cache for multiple time steps. It has already been shown to be beneficial for this class of algorithms. However, applying temporal blocking to practical <span class="search-hit mathjax">applications</span>&#39; stencils remains challenging. These computations often consist of sparsely located operators not aligned with the computational grid (&#34;off-the-grid&#34;). Our work is motivated by modeling problems in which source injections result in wavefields that must then be measured at receivers by interpolation from the grided wavefield. The resulting data dependencies make the adoption of temporal blocking much more challenging. We propose a methodology to inspect these data dependencies and reorder the computation, leading to performance gains in stencil <span class="search-hit mathjax">codes</span> where temporal blocking has not been <span class="search-hit mathjax">applicable</span>. We implement this novel scheme in the Devito domain-specific compiler toolchain. Devito implements a domain-specific language embedded in Python to generate <span class="search-hit mathjax">optimized</span> partial differential equation solvers using the finite-difference method from high-level symbolic problem definitions. We evaluate our scheme using isotropic acoustic, anisotropic acoustic, and isotropic elastic wave propagators of industrial significance. After auto-tuning, performance evaluation shows that this enables substantial performance <span class="search-hit mathjax">improvement</span> through temporal blocking over highly-<span class="search-hit mathjax">optimized</span> vectorized spatially-blocked <span class="search-hit mathjax">code</span> of up to 1.6x.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2010.10248v2-abstract-full').style.display = 'none'; document.getElementById('2010.10248v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 25 February, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 20 October, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted for publication at 35th IEEE International Parallel &amp; Distributed Processing Symposium</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2010.09977">arXiv:2010.09977</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2010.09977">pdf</a>, <a href="https://arxiv.org/format/2010.09977">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Industry-scale IR-based Bug Localization: A Perspective from Facebook
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Murali%2C+V">Vijayaraghavan Murali</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gross%2C+L">Lee Gross</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Qian%2C+R">Rebecca Qian</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chandra%2C+S">Satish Chandra</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2010.09977v2-abstract-short" style="display: inline;">
        We explore the <span class="search-hit mathjax">application</span> of Information Retrieval (IR) based bug localization methods at a large industrial setting, Facebook. Facebook&#39;s&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2010.09977v2-abstract-full').style.display = 'inline'; document.getElementById('2010.09977v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2010.09977v2-abstract-full" style="display: none;">
        We explore the <span class="search-hit mathjax">application</span> of Information Retrieval (IR) based bug localization methods at a large industrial setting, Facebook. Facebook&#39;s <span class="search-hit mathjax">code</span> base evolves rapidly, with thousands of <span class="search-hit mathjax">code</span> changes being committed to a monolithic repository every day. When a bug is detected, it is often time-sensitive and imperative to identify the commit causing the bug in order to either revert it or fix it. This is complicated by the fact that bugs often manifest with complex and unwieldy features, such as stack traces and other metadata. <span class="search-hit mathjax">Code</span> commits also have various features associated with them, ranging from developer comments to test results. This poses unique challenges to bug localization methods, making it a highly non-trivial operation.
  In this paper we lay out several practical concerns for industry-level IR-based bug localization, and propose Bug2Commit, a tool that is designed to address these concerns. We also assess the effectiveness of existing IR-based localization techniques from the <span class="search-hit mathjax">software</span> engineering community, and find that in the presence of complex queries or documents, which are common at Facebook, existing approaches do not perform as well as Bug2Commit. We evaluate Bug2Commit on three <span class="search-hit mathjax">applications</span> at Facebook: client-side crashes from the mobile app, server-side performance regressions, and mobile simulation tests for performance. We find that Bug2Commit outperforms the accuracy of existing approaches by up to 17%, leading to <span class="search-hit mathjax">reduced</span> time for triaging regressions and attributing bugs found in simulations.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2010.09977v2-abstract-full').style.display = 'none'; document.getElementById('2010.09977v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 March, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 19 October, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2010.09746">arXiv:2010.09746</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2010.09746">pdf</a>, <a href="https://arxiv.org/format/2010.09746">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Quantum Physics">quant-ph</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computational Physics">physics.comp-ph</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Fast simulation of quantum algorithms using circuit <span class="search-hit mathjax">optimization</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Guerreschi%2C+G+G">Gian Giacomo Guerreschi</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2010.09746v2-abstract-short" style="display: inline;">
        Classical simulators play a major role in the development and benchmark of quantum algorithms and practically any <span class="search-hit mathjax">software</span> framework for quantum computation provides the option of running the algorithms on simulators. However, the development of quantum simulators was substantially separated from the rest of the&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2010.09746v2-abstract-full').style.display = 'inline'; document.getElementById('2010.09746v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2010.09746v2-abstract-full" style="display: none;">
        Classical simulators play a major role in the development and benchmark of quantum algorithms and practically any <span class="search-hit mathjax">software</span> framework for quantum computation provides the option of running the algorithms on simulators. However, the development of quantum simulators was substantially separated from the rest of the <span class="search-hit mathjax">software</span> frameworks which, instead, focus on usability and compilation. In practice, simulators are considered just one of many possible backends. Here, we demonstrate the advantage of co-developing and integrating simulators and compilers by proposing a specialized compiler pass to <span class="search-hit mathjax">reduce</span> the simulation time for arbitrary circuits. While the concept is broadly <span class="search-hit mathjax">applicable</span>, we present a concrete implementation based on the Intel Quantum Simulator, a high-performance distributed simulator. As part of this work, we extend its implementation with additional <span class="search-hit mathjax">functionalities</span> related to the representation of quantum states. The communication overhead is <span class="search-hit mathjax">reduced</span> by changing the order in which state amplitudes are stored in the distributed memory, a concept analogous to the distinction between local and global qubits for distributed Schroedinger-type simulators. We then implement a compiler pass to exploit the novel <span class="search-hit mathjax">functionalities</span> by introducing special instructions governing data movement as part of the quantum circuit. Those instructions target unique capabilities of simulators and have no analogue in actual quantum devices. To quantify the advantage, we compare the time required to simulate random circuits with and without our <span class="search-hit mathjax">optimization</span>. The simulation time is typically halved.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2010.09746v2-abstract-full').style.display = 'none'; document.getElementById('2010.09746v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 December, 2020; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 19 October, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2010.09161">arXiv:2010.09161</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2010.09161">pdf</a>, <a href="https://arxiv.org/format/2010.09161">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1109/TSE.2020.3032557">10.1109/TSE.2020.3032557 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Can Clean New <span class="search-hit mathjax">Code</span> <span class="search-hit mathjax">reduce</span> Technical Debt Density?
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Digkas%2C+G">George Digkas</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chatzigeorgiou%2C+A">Alexander Chatzigeorgiou</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ampatzoglou%2C+A">Apostolos Ampatzoglou</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Avgeriou%2C+P">Paris Avgeriou</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2010.09161v1-abstract-short" style="display: inline;">
        While technical debt grows in absolute numbers as <span class="search-hit mathjax">software</span> systems evolve over time, the density of technical debt (technical debt divided by lines of&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2010.09161v1-abstract-full').style.display = 'inline'; document.getElementById('2010.09161v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2010.09161v1-abstract-full" style="display: none;">
        While technical debt grows in absolute numbers as <span class="search-hit mathjax">software</span> systems evolve over time, the density of technical debt (technical debt divided by lines of <span class="search-hit mathjax">code</span>) is <span class="search-hit mathjax">reduced</span> in some cases. This can be explained by either the <span class="search-hit mathjax">application</span> of refactorings or the development of new artifacts with limited Technical Debt. In this paper we explore the second explanation, by investigating the relation between the amount of Technical Debt in new <span class="search-hit mathjax">code</span> and the evolution of Technical Debt in the system. To this end, we compare the Technical Debt Density of new <span class="search-hit mathjax">code</span> with existing <span class="search-hit mathjax">code</span>, and we investigate which of the three major types of <span class="search-hit mathjax">code</span> changes (additions, deletions and modifications) is primarily responsible for changes in the evolution of Technical Debt density. Furthermore, we study whether there is a relation between <span class="search-hit mathjax">code</span> quality practices and the &#39;cleanness&#39; of new <span class="search-hit mathjax">code</span>. To obtain the required data, we have performed a large-scale case study on twenty-seven open-source <span class="search-hit mathjax">software</span> projects by the Apache <span class="search-hit mathjax">Software</span> Foundation, analyzing 66,661 classes and 56,890 commits. The results suggest that writing &#34;clean&#34; (or at least &#34;cleaner&#34;) new <span class="search-hit mathjax">code</span> can be an efficient strategy for <span class="search-hit mathjax">reducing</span> Technical Debt Density, and thus preventing <span class="search-hit mathjax">software</span> decay over time. The findings also suggest that projects adopting an explicit policy for quality <span class="search-hit mathjax">improvement</span>, e.g. through discussions on <span class="search-hit mathjax">code</span> quality in board meetings, are associated with a higher frequency of cleaner new <span class="search-hit mathjax">code</span> commits. Therefore, we champion the establishment of processes that monitor the density of Technical Debt of new <span class="search-hit mathjax">code</span> to control the accumulation of Technical Debt in a <span class="search-hit mathjax">software</span> system.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2010.09161v1-abstract-full').style.display = 'none'; document.getElementById('2010.09161v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 18 October, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2010.08244">arXiv:2010.08244</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2010.08244">pdf</a>, <a href="https://arxiv.org/format/2010.08244">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Auxiliary Task Reweighting for Minimum-data Learning
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Shi%2C+B">Baifeng Shi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hoffman%2C+J">Judy Hoffman</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Saenko%2C+K">Kate Saenko</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Darrell%2C+T">Trevor Darrell</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xu%2C+H">Huijuan Xu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2010.08244v1-abstract-short" style="display: inline;">
        Supervised learning requires a large amount of training data, limiting its <span class="search-hit mathjax">application</span> where labeled data is scarce. To compensate for data scarcity, one possible method is to utilize auxiliary tasks to provide additional supervision for the main task. Assigning and&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2010.08244v1-abstract-full').style.display = 'inline'; document.getElementById('2010.08244v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2010.08244v1-abstract-full" style="display: none;">
        Supervised learning requires a large amount of training data, limiting its <span class="search-hit mathjax">application</span> where labeled data is scarce. To compensate for data scarcity, one possible method is to utilize auxiliary tasks to provide additional supervision for the main task. Assigning and <span class="search-hit mathjax">optimizing</span> the importance weights for different auxiliary tasks remains an crucial and largely understudied research question. In this work, we propose a method to <span class="search-hit mathjax">automatically</span> reweight auxiliary tasks in order to <span class="search-hit mathjax">reduce</span> the data requirement on the main task. Specifically, we formulate the weighted likelihood <span class="search-hit mathjax">function</span> of auxiliary tasks as a surrogate prior for the main task. By adjusting the auxiliary task weights to minimize the divergence between the surrogate prior and the true prior of the main task, we obtain a more accurate prior estimation, achieving the goal of minimizing the required amount of training data for the main task and avoiding a costly grid search. In multiple experimental settings (e.g. semi-supervised learning, multi-label classification), we demonstrate that our algorithm can effectively utilize limited labeled data of the main task with the benefit of auxiliary tasks compared with previous task reweighting methods. We also show that under extreme cases with only a few extra examples (e.g. few-shot domain adaptation), our algorithm results in significant <span class="search-hit mathjax">improvement</span> over the baseline.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2010.08244v1-abstract-full').style.display = 'none'; document.getElementById('2010.08244v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 October, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">NeurIPS 2020. Project page: https://sites.google.com/view/auxiliary-task-reweighting/home</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2010.05187">arXiv:2010.05187</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2010.05187">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        On the Road from Edge Computing to the Edge Mesh
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Oikonomou%2C+P">Panagiotis Oikonomou</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Karanika%2C+A">Anna Karanika</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Anagnostopoulos%2C+C">Christos Anagnostopoulos</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kolomvatsos%2C+K">Kostas Kolomvatsos</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2010.05187v1-abstract-short" style="display: inline;">
        &hellip;However, even if the communication with the Cloud back end lasts for some seconds there are cases where problems in the network or the need for supporting real time <span class="search-hit mathjax">applications</span> require a&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2010.05187v1-abstract-full').style.display = 'inline'; document.getElementById('2010.05187v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2010.05187v1-abstract-full" style="display: none;">
        Nowadays, we are witnessing the advent of the Internet of Things (EC) with numerous devices performing interactions between them or with end users. The huge number of devices leads to huge volumes of collected data that demand the appropriate processing. The &#39;legacy&#39; approach is to rely on Cloud where increased computational resources can be adopted to realize any processing. However, even if the communication with the Cloud back end lasts for some seconds there are cases where problems in the network or the need for supporting real time <span class="search-hit mathjax">applications</span> require a <span class="search-hit mathjax">reduced</span> latency in the provision of responses/outcomes. Edge Computing (EC) comes into the scene as the &#39;solver&#39; of the latency problem (and not only). Any processing can be performed close to data sources, i.e., at EC nodes having direct connection with IoT devices. Hence, an ecosystem of processing nodes can be present at the edge of the network giving the opportunity to apply novel services upon the collected data. Various challenges should be met before we talk about a fully <span class="search-hit mathjax">automated</span> ecosystem where EC nodes can cooperate or understand the status of them and the environment to be capable of efficiently serving end users or <span class="search-hit mathjax">applications</span>. In this paper, we perform a survey of the relevant research activities targeting to support the vision of Edge Mesh (EM), i.e., a &#39;cover&#39; of intelligence upon the EC infrastructure. We present all the parts of the EC/EM framework starting from the necessary hardware and discussing research outcomes in every aspect of EC nodes <span class="search-hit mathjax">functioning</span>. We present technologies and theories adopted for data, tasks and resource management while discussing how (deep) machine learning and <span class="search-hit mathjax">optimization</span> techniques are adopted to solve various problems. Our aim is to provide a starting point for novel research to conclude efficient services/<span class="search-hit mathjax">applications</span> opening up the path to realize the future EC form.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2010.05187v1-abstract-full').style.display = 'none'; document.getElementById('2010.05187v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 11 October, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2010.03896">arXiv:2010.03896</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2010.03896">pdf</a>, <a href="https://arxiv.org/format/2010.03896">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A practical guide towards agile test-driven development for scientific <span class="search-hit mathjax">software</span> projects
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Teschner%2C+T">Tom-Robin Teschner</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2010.03896v1-abstract-short" style="display: inline;">
        <span class="search-hit mathjax">Software</span> testing has received much attention over the last years and has reached such critical importance that agile&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2010.03896v1-abstract-full').style.display = 'inline'; document.getElementById('2010.03896v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2010.03896v1-abstract-full" style="display: none;">
        <span class="search-hit mathjax">Software</span> testing has received much attention over the last years and has reached such critical importance that agile <span class="search-hit mathjax">software</span> development practices put <span class="search-hit mathjax">software</span> testing at its core. Agile <span class="search-hit mathjax">software</span> development is successfully applied in large-scale industrial <span class="search-hit mathjax">software</span> developments but due to its granular responsibilities with roles assigned to various members of the development team, these practices may not be <span class="search-hit mathjax">applicable</span> to scientific <span class="search-hit mathjax">code</span> development, especially in an academic environment, where it is not uncommon that the codebase is developed, maintained and used by a single person. Even for collaborative scientific <span class="search-hit mathjax">software</span> development, financed through external grants, the end-users are typically still part of the development team. This is in contrast to how <span class="search-hit mathjax">software</span> is developed in many industries, where the development team and end-users are two separate entities. There are, however, many good <span class="search-hit mathjax">code</span> development practices that can be adopted for scientific <span class="search-hit mathjax">software</span> projects. Specifically, the intention of this article is to take the centrepiece of agile <span class="search-hit mathjax">software</span> development and tailor it to scientific and academic, single-user <span class="search-hit mathjax">code</span> development. In this study, a c++ starter project is developed and made available, based on the meson build system, which provides native support for <span class="search-hit mathjax">software</span> testing. It is used to show how a simple linear algebra <span class="search-hit mathjax">application</span>, found in many scientific and academic <span class="search-hit mathjax">applications</span>, can be developed and how simple unit, integration and system tests can be created that are managed through the meson build system. In this way, we are able to minimise <span class="search-hit mathjax">software</span> defects and <span class="search-hit mathjax">reduce</span> the risk to interpret incorrect data generated by erroneous <span class="search-hit mathjax">software</span> that may result in the wrong conclusions to be drawn. Each layer of testing presents one additional layer of protection and we will explore how these may be incorporated with minimum overhead to produce bug-free <span class="search-hit mathjax">software</span>.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2010.03896v1-abstract-full').style.display = 'none'; document.getElementById('2010.03896v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 October, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">The manuscript contains 26 pages, 14 <span class="search-hit mathjax">code</span> listings and 3 figures. It has not been submitted for publication in a journal or conference. Supporting <span class="search-hit mathjax">software</span> developed within the manuscript can be found at https://zenodo.org/record/3892227</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2010.03115">arXiv:2010.03115</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2010.03115">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1109/TGRS.2020.3011429">10.1109/TGRS.2020.3011429 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        SLCRF: Subspace Learning with Conditional Random Field for Hyperspectral Image Classification
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Cao%2C+Y">Yun Cao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mei%2C+J">Jie Mei</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+Y">Yuebin Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+L">Liqiang Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Peng%2C+J">Junhuan Peng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+B">Bing Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+L">Lihua Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zheng%2C+Y">Yibo Zheng</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2010.03115v1-abstract-short" style="display: inline;">
        Subspace learning (SL) plays an important role in hyperspectral image (HSI) classification, since it can provide an effective solution to <span class="search-hit mathjax">reduce</span> the redundant information in the image pixels of HSIs. Previous works about SL aim to&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2010.03115v1-abstract-full').style.display = 'inline'; document.getElementById('2010.03115v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2010.03115v1-abstract-full" style="display: none;">
        Subspace learning (SL) plays an important role in hyperspectral image (HSI) classification, since it can provide an effective solution to <span class="search-hit mathjax">reduce</span> the redundant information in the image pixels of HSIs. Previous works about SL aim to <span class="search-hit mathjax">improve</span> the accuracy of HSI recognition. Using a large number of labeled samples, related methods can train the parameters of the proposed solutions to obtain better representations of HSI pixels. However, the data instances may not be sufficient enough to learn a precise model for HSI classification in real <span class="search-hit mathjax">applications</span>. Moreover, it is well-known that it takes much time, labor and human expertise to label HSI images. To avoid the aforementioned problems, a novel SL method that includes the probability assumption called subspace learning with conditional random field (SLCRF) is developed. In SLCRF, first, the 3D convolutional autoencoder (3DCAE) is introduced to remove the redundant information in HSI pixels. In addition, the relationships are also constructed using the spectral-spatial information among the adjacent pixels. Then, the conditional random field (CRF) framework can be constructed and further embedded into the HSI SL procedure with the semi-supervised approach. Through the linearized alternating direction method termed LADMAP, the objective <span class="search-hit mathjax">function</span> of SLCRF is <span class="search-hit mathjax">optimized</span> using a defined iterative algorithm. The proposed method is comprehensively evaluated using the challenging public HSI datasets. We can achieve stateof-the-art performance using these HSI sets.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2010.03115v1-abstract-full').style.display = 'none'; document.getElementById('2010.03115v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 6 October, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">13 pages, 6 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2010.02488">arXiv:2010.02488</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2010.02488">pdf</a>, <a href="https://arxiv.org/ps/2010.02488">ps</a>, <a href="https://arxiv.org/format/2010.02488">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        RANP: Resource Aware Neuron Pruning at Initialization for 3D CNNs
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Xu%2C+Z">Zhiwei Xu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ajanthan%2C+T">Thalaiyasingam Ajanthan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Vineet%2C+V">Vibhav Vineet</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hartley%2C+R">Richard Hartley</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2010.02488v3-abstract-short" style="display: inline;">
        Although 3D Convolutional Neural Networks (CNNs) are essential for most learning based <span class="search-hit mathjax">applications</span> involving dense 3D data, their&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2010.02488v3-abstract-full').style.display = 'inline'; document.getElementById('2010.02488v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2010.02488v3-abstract-full" style="display: none;">
        Although 3D Convolutional Neural Networks (CNNs) are essential for most learning based <span class="search-hit mathjax">applications</span> involving dense 3D data, their <span class="search-hit mathjax">applicability</span> is limited due to excessive memory and computational requirements. Compressing such networks by pruning therefore becomes highly desirable. However, pruning 3D CNNs is largely unexplored possibly because of the complex nature of typical pruning algorithms that embeds pruning into an iterative <span class="search-hit mathjax">optimization</span> paradigm. In this work, we introduce a Resource Aware Neuron Pruning (RANP) algorithm that prunes 3D CNNs at initialization to high sparsity levels. Specifically, the core idea is to obtain an importance score for each neuron based on their sensitivity to the loss <span class="search-hit mathjax">function</span>. This neuron importance is then reweighted according to the neuron resource consumption related to FLOPs or memory. We demonstrate the effectiveness of our pruning method on 3D semantic segmentation with widely used 3D-UNets on ShapeNet and BraTS&#39;18 as well as on video classification with MobileNetV2 and I3D on UCF101 dataset. In these experiments, our RANP leads to roughly 50-95 reduction in FLOPs and 35-80 reduction in memory with negligible loss in accuracy compared to the unpruned networks. This significantly <span class="search-hit mathjax">reduces</span> the computational resources required to train 3D CNNs. The pruned network obtained by our algorithm can also be easily scaled up and transferred to another dataset for training.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2010.02488v3-abstract-full').style.display = 'none'; document.getElementById('2010.02488v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 25 October, 2020; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 6 October, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">International Conference on 3D Vision (3DV), 2020 (Oral)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2010.01921">arXiv:2010.01921</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2010.01921">pdf</a>, <a href="https://arxiv.org/format/2010.01921">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computational Physics">physics.comp-ph</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        $Œæ$-torch: differentiable scientific computing library
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Kasim%2C+M+F">Muhammad F. Kasim</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Vinko%2C+S+M">Sam M. Vinko</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2010.01921v1-abstract-short" style="display: inline;">
        &hellip;training physics-informed deep neural networks requires some aspect of physical simulations to be written in a differentiable manner.
  Unfortunately, some operations and <span class="search-hit mathjax">functionals</span> commonly used in physical simulations are scattered, hard to integrate, and lack higher order derivatives which are needed in physical simulations.
  In this work, we present&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2010.01921v1-abstract-full').style.display = 'inline'; document.getElementById('2010.01921v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2010.01921v1-abstract-full" style="display: none;">
        Physics-informed learning has shown to have a better generalization than learning without physical priors.
  However, training physics-informed deep neural networks requires some aspect of physical simulations to be written in a differentiable manner.
  Unfortunately, some operations and <span class="search-hit mathjax">functionals</span> commonly used in physical simulations are scattered, hard to integrate, and lack higher order derivatives which are needed in physical simulations.
  In this work, we present $Œæ$-torch, a library of differentiable <span class="search-hit mathjax">functionals</span> for scientific simulations.
  Example <span class="search-hit mathjax">functionals</span> are a root finder and an initial value problem solver, among others.
  The gradient of <span class="search-hit mathjax">functionals</span> in $Œæ$-torch are written based on their analytical expression to <span class="search-hit mathjax">improve</span> numerical stability and <span class="search-hit mathjax">reduce</span> memory requirements.
  $Œæ$-torch also provides second and higher order derivatives of the <span class="search-hit mathjax">functionals</span> which are rarely available in existing packages.
  We show two <span class="search-hit mathjax">applications</span> of this library in <span class="search-hit mathjax">optimizing</span> parameters in physics simulations.
  The library and all test cases in this work can be found at https://github.com/xitorch/xitorch/ and the documentation at https://xitorch.readthedocs.io.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2010.01921v1-abstract-full').style.display = 'none'; document.getElementById('2010.01921v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 5 October, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2009.13609">arXiv:2009.13609</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2009.13609">pdf</a>, <a href="https://arxiv.org/format/2009.13609">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Multiagent Systems">cs.MA</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Compositionality of Linearly Solvable <span class="search-hit mathjax">Optimal</span> Control in Networked Multi-Agent Systems
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Song%2C+L">Lin Song</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wan%2C+N">Neng Wan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gahlawat%2C+A">Aditya Gahlawat</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hovakimyan%2C+N">Naira Hovakimyan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Theodorou%2C+E+A">Evangelos A. Theodorou</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2009.13609v2-abstract-short" style="display: inline;">
        In this paper, we discuss the methodology of generalizing the <span class="search-hit mathjax">optimal</span> control law from learned component tasks to unlearned composite tasks on Multi-Agent Systems (MASs), by using the linearity composition principle of linearly solvable&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2009.13609v2-abstract-full').style.display = 'inline'; document.getElementById('2009.13609v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2009.13609v2-abstract-full" style="display: none;">
        In this paper, we discuss the methodology of generalizing the <span class="search-hit mathjax">optimal</span> control law from learned component tasks to unlearned composite tasks on Multi-Agent Systems (MASs), by using the linearity composition principle of linearly solvable <span class="search-hit mathjax">optimal</span> control (LSOC) problems. The proposed approach achieves both the compositionality and <span class="search-hit mathjax">optimality</span> of control actions simultaneously within the cooperative MAS framework in both discrete- and continuous-time in a sample-efficient manner, which <span class="search-hit mathjax">reduces</span> the burden of re-computation of the <span class="search-hit mathjax">optimal</span> control solutions for the new task on the MASs. We investigate the <span class="search-hit mathjax">application</span> of the proposed approach on the MAS with coordination between agents. The experiments show feasible results in investigated scenarios, including both discrete and continuous dynamical systems for task generalization without resampling.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2009.13609v2-abstract-full').style.display = 'none'; document.getElementById('2009.13609v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 March, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 28 September, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted to the 2021 American Control Conference (ACC)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2009.12250">arXiv:2009.12250</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2009.12250">pdf</a>, <a href="https://arxiv.org/ps/2009.12250">ps</a>, <a href="https://arxiv.org/format/2009.12250">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Formal Languages and Automata Theory">cs.FL</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Logic in Computer Science">cs.LO</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Trace-Checking CPS Properties: Bridging the Cyber-Physical Gap
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Menghi%2C+C">Claudio Menghi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Vigan%C3%B2%2C+E">Enrico Vigan√≤</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bianculli%2C+D">Domenico Bianculli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Briand%2C+L+C">Lionel C. Briand</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2009.12250v2-abstract-short" style="display: inline;">
        Cyber-physical systems combine <span class="search-hit mathjax">software</span> and physical components. Specification-driven trace-checking tools for CPS usually provide users with a specification language to express the requirements of interest, and an&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2009.12250v2-abstract-full').style.display = 'inline'; document.getElementById('2009.12250v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2009.12250v2-abstract-full" style="display: none;">
        Cyber-physical systems combine <span class="search-hit mathjax">software</span> and physical components. Specification-driven trace-checking tools for CPS usually provide users with a specification language to express the requirements of interest, and an <span class="search-hit mathjax">automatic</span> procedure to check whether these requirements hold on the execution traces of a CPS. Although there exist several specification languages for CPS, they are often not sufficiently expressive to allow the specification of complex CPS properties related to the <span class="search-hit mathjax">software</span> and the physical components and their interactions.
  In this paper, we propose (i) the Hybrid Logic of Signals (HLS), a logic-based language that allows the specification of complex CPS requirements, and (ii) ThEodorE, an efficient SMT-based trace-checking procedure. This procedure <span class="search-hit mathjax">reduces</span> the problem of checking a CPS requirement over an execution trace, to checking the satisfiability of an SMT formula.
  We evaluated our contributions by using a representative industrial case study in the satellite domain. We assessed the expressiveness of HLS by considering 212 requirements of our case study. HLS could express all the 212 requirements. We also assessed the <span class="search-hit mathjax">applicability</span> of ThEodorE by running the trace-checking procedure for 747 trace-requirement combinations. ThEodorE was able to produce a verdict in 74.5% of the cases. Finally, we compared HLS and ThEodorE with other specification languages and trace-checking tools from the literature. Our results show that, from a practical standpoint, our approach offers a better trade-off between expressiveness and performance.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2009.12250v2-abstract-full').style.display = 'none'; document.getElementById('2009.12250v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 28 September, 2020; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 25 September, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2009.12009">arXiv:2009.12009</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2009.12009">pdf</a>, <a href="https://arxiv.org/format/2009.12009">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Mathematical Software">cs.MS</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computational Engineering, Finance, and Science">cs.CE</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        AMReX: Block-Structured Adaptive Mesh Refinement for Multiphysics <span class="search-hit mathjax">Applications</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+W">Weiqun Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Myers%2C+A">Andrew Myers</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gott%2C+K">Kevin Gott</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Almgren%2C+A">Ann Almgren</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bell%2C+J">John Bell</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2009.12009v1-abstract-short" style="display: inline;">
        Block-structured adaptive mesh refinement (AMR) provides the basis for the temporal and spatial discretization strategy for a number of ECP <span class="search-hit mathjax">applications</span> in the areas of accelerator design, additive manufacturing, astrophysics, combustion, cosmology, multiphase flow, and wind plant modelling. AMReX is a&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2009.12009v1-abstract-full').style.display = 'inline'; document.getElementById('2009.12009v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2009.12009v1-abstract-full" style="display: none;">
        Block-structured adaptive mesh refinement (AMR) provides the basis for the temporal and spatial discretization strategy for a number of ECP <span class="search-hit mathjax">applications</span> in the areas of accelerator design, additive manufacturing, astrophysics, combustion, cosmology, multiphase flow, and wind plant modelling. AMReX is a <span class="search-hit mathjax">software</span> framework that provides a unified infrastructure with the <span class="search-hit mathjax">functionality</span> needed for these and other AMR <span class="search-hit mathjax">applications</span> to be able to effectively and efficiently utilize machines from laptops to exascale architectures. AMR <span class="search-hit mathjax">reduces</span> the computational cost and memory footprint compared to a uniform mesh while preserving accurate descriptions of different physical processes in complex multi-physics algorithms. AMReX supports algorithms that solve systems of partial differential equations (PDEs) in simple or complex geometries, and those that use particles and/or particle-mesh operations to represent component physical processes. In this paper, we will discuss the core elements of the AMReX framework such as data containers and iterators as well as several specialized operations to meet the needs of the <span class="search-hit mathjax">application</span> projects. In addition we will highlight the strategy that the AMReX team is pursuing to achieve highly performant <span class="search-hit mathjax">code</span> across a range of accelerator-based architectures for a variety of different <span class="search-hit mathjax">applications</span>.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2009.12009v1-abstract-full').style.display = 'none'; document.getElementById('2009.12009v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 24 September, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">16 pages, 9 figures, submitted to IJHPCA</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2009.11722">arXiv:2009.11722</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2009.11722">pdf</a>, <a href="https://arxiv.org/format/2009.11722">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.3390/s20195450">10.3390/s20195450 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Cloud2Edge Elastic AI Framework for Prototyping and Deployment of AI Inference Engines in Autonomous Vehicles
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Grigorescu%2C+S">Sorin Grigorescu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cocias%2C+T">Tiberiu Cocias</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Trasnea%2C+B">Bogdan Trasnea</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Margheri%2C+A">Andrea Margheri</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lombardi%2C+F">Federico Lombardi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Aniello%2C+L">Leonardo Aniello</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2009.11722v1-abstract-short" style="display: inline;">
        &hellip;future of mobility altogether. Although the integration of novel technologies such as Artificial Intelligence (AI) and Cloud/Edge computing provides golden opportunities to <span class="search-hit mathjax">improve</span> autonomous driving&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2009.11722v1-abstract-full').style.display = 'inline'; document.getElementById('2009.11722v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2009.11722v1-abstract-full" style="display: none;">
        Self-driving cars and autonomous vehicles are revolutionizing the automotive sector, shaping the future of mobility altogether. Although the integration of novel technologies such as Artificial Intelligence (AI) and Cloud/Edge computing provides golden opportunities to <span class="search-hit mathjax">improve</span> autonomous driving <span class="search-hit mathjax">applications</span>, there is the need to modernize accordingly the whole prototyping and deployment cycle of AI components. This paper proposes a novel framework for developing so-called AI Inference Engines for autonomous driving <span class="search-hit mathjax">applications</span> based on deep learning modules, where training tasks are deployed elastically over both Cloud and Edge resources, with the purpose of <span class="search-hit mathjax">reducing</span> the required network bandwidth, as well as mitigating privacy issues. Based on our proposed data driven V-Model, we introduce a simple yet elegant solution for the AI components development cycle, where prototyping takes place in the cloud according to the <span class="search-hit mathjax">Software</span>-in-the-Loop (SiL) paradigm, while deployment and evaluation on the target ECUs (Electronic Control Units) is performed as Hardware-in-the-Loop (HiL) testing. The effectiveness of the proposed framework is demonstrated using two real-world use-cases of AI inference engines for autonomous vehicles, that is environment perception and most probable path prediction.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2009.11722v1-abstract-full').style.display = 'none'; document.getElementById('2009.11722v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 23 September, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">21 pages Published in Sensors: https://www.mdpi.com/1424-8220/20/19/5450</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2009.11097">arXiv:2009.11097</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2009.11097">pdf</a>, <a href="https://arxiv.org/format/2009.11097">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1109/TCST.2020.3001387">10.1109/TCST.2020.3001387 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Factor Graph-Based Smoothing Without Matrix Inversion for Highly Precise Localization
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Chauchat%2C+P">Paul Chauchat</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Barrau%2C+A">Axel Barrau</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bonnabel%2C+S">Silv√®re Bonnabel</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2009.11097v1-abstract-short" style="display: inline;">
        &hellip;depending on the context. To infer knowledge from sensors&#39; measurements, while drawing on a priori knowledge about the vehicle&#39;s dynamics, modern approaches solve an <span class="search-hit mathjax">optimization</span> problem to compute the most likely trajectory given all past observations, an approach known as smoothing.&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2009.11097v1-abstract-full').style.display = 'inline'; document.getElementById('2009.11097v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2009.11097v1-abstract-full" style="display: none;">
        We consider the problem of localizing a manned, semi-autonomous, or autonomous vehicle in the environment using information coming from the vehicle&#39;s sensors, a problem known as navigation or simultaneous localization and mapping (SLAM) depending on the context. To infer knowledge from sensors&#39; measurements, while drawing on a priori knowledge about the vehicle&#39;s dynamics, modern approaches solve an <span class="search-hit mathjax">optimization</span> problem to compute the most likely trajectory given all past observations, an approach known as smoothing. <span class="search-hit mathjax">Improving</span> smoothing solvers is an active field of research in the SLAM community. Most work is focused on <span class="search-hit mathjax">reducing</span> computation load by inverting the involved linear system while preserving its sparsity. The present paper raises an issue which, to the knowledge of the authors, has not been addressed yet: standard smoothing solvers require explicitly using the inverse of sensor noise covariance matrices. This means the parameters that reflect the noise magnitude must be sufficiently large for the smoother to properly <span class="search-hit mathjax">function</span>. When matrices are close to singular, which is the case when using high precision modern inertial measurement units (IMU), numerical issues necessarily arise, especially with 32-bits implementation demanded by most industrial aerospace <span class="search-hit mathjax">applications</span>. We discuss these issues and propose a solution that builds upon the Kalman filter to <span class="search-hit mathjax">improve</span> smoothing algorithms. We then leverage the results to devise a localization algorithm based on fusion of IMU and vision sensors. Successful real experiments using an actual car equipped with a tactical grade high performance IMU and a LiDAR illustrate the relevance of the approach to the field of autonomous vehicles.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2009.11097v1-abstract-full').style.display = 'none'; document.getElementById('2009.11097v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 September, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2020.
      
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        IEEE Transactions on Control Systems Technology, Institute of Electrical and Electronics Engineers, 2020, pp.1-14
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2009.10867">arXiv:2009.10867</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2009.10867">pdf</a>, <a href="https://arxiv.org/format/2009.10867">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Online AUC <span class="search-hit mathjax">Optimization</span> for Sparse High-Dimensional Datasets
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zhou%2C+B">Baojian Zhou</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ying%2C+Y">Yiming Ying</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Skiena%2C+S">Steven Skiena</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2009.10867v1-abstract-short" style="display: inline;">
        The Area Under the ROC Curve (AUC) is a widely used performance measure for imbalanced classification arising from many <span class="search-hit mathjax">application</span> domains where high-dimensional sparse data is abundant. In such cases, each $d$ dimensional sample has only $k$ non-zero features with $k \ll d$, and data arrives sequentially in a streaming form. Current online AUC&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2009.10867v1-abstract-full').style.display = 'inline'; document.getElementById('2009.10867v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2009.10867v1-abstract-full" style="display: none;">
        The Area Under the ROC Curve (AUC) is a widely used performance measure for imbalanced classification arising from many <span class="search-hit mathjax">application</span> domains where high-dimensional sparse data is abundant. In such cases, each $d$ dimensional sample has only $k$ non-zero features with $k \ll d$, and data arrives sequentially in a streaming form. Current online AUC <span class="search-hit mathjax">optimization</span> algorithms have high per-iteration cost $\mathcal{O}(d)$ and usually produce non-sparse solutions in general, and hence are not suitable for handling the data challenge mentioned above.
  In this paper, we aim to directly <span class="search-hit mathjax">optimize</span> the AUC score for high-dimensional sparse datasets under online learning setting and propose a new algorithm, \textsc{FTRL-AUC}. Our proposed algorithm can process data in an online fashion with a much cheaper per-iteration cost $\mathcal{O}(k)$, making it amenable for high-dimensional sparse streaming data analysis. Our new algorithmic design critically depends on a novel reformulation of the U-statistics AUC objective <span class="search-hit mathjax">function</span> as the empirical saddle point reformulation, and the innovative introduction of the &#34;lazy update&#34; rule so that the per-iteration complexity is dramatically <span class="search-hit mathjax">reduced</span> from $\mathcal{O}(d)$ to $\mathcal{O}(k)$. Furthermore, \textsc{FTRL-AUC} can inherently capture sparsity more effectively by applying a generalized Follow-The-Regularized-Leader (FTRL) framework.
  Experiments on real-world datasets demonstrate that \textsc{FTRL-AUC} significantly <span class="search-hit mathjax">improves</span> both run time and model sparsity while achieving competitive AUC scores compared with the state-of-the-art methods. Comparison with the online learning method for logistic loss demonstrates that \textsc{FTRL-AUC} achieves higher AUC scores especially when datasets are imbalanced.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2009.10867v1-abstract-full').style.display = 'none'; document.getElementById('2009.10867v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 September, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">20th IEEE International Conference on Data Mining</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2009.09815">arXiv:2009.09815</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2009.09815">pdf</a>, <a href="https://arxiv.org/ps/2009.09815">ps</a>, <a href="https://arxiv.org/format/2009.09815">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Information Theory">cs.IT</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Mobile Cellular-Connected UAVs: Reinforcement Learning for Sky Limits
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Azari%2C+M+M">M. Mahdi Azari</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Arani%2C+A+H">Atefeh Hajijamali Arani</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rosas%2C+F">Fernando Rosas</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2009.09815v1-abstract-short" style="display: inline;">
        &hellip;several key challenges concerning connectivity and energy efficiency. Through a learning-based strategy, we propose a general novel multi-armed bandit (MAB) algorithm to <span class="search-hit mathjax">reduce</span> disconnectivity time, handover rate, and energy consumption of UAV by taking into account its time of task completion. By formulating the problem as a&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2009.09815v1-abstract-full').style.display = 'inline'; document.getElementById('2009.09815v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2009.09815v1-abstract-full" style="display: none;">
        A cellular-connected unmanned aerial vehicle (UAV)faces several key challenges concerning connectivity and energy efficiency. Through a learning-based strategy, we propose a general novel multi-armed bandit (MAB) algorithm to <span class="search-hit mathjax">reduce</span> disconnectivity time, handover rate, and energy consumption of UAV by taking into account its time of task completion. By formulating the problem as a <span class="search-hit mathjax">function</span> of UAV&#39;s velocity, we show how each of these performance indicators (PIs) is <span class="search-hit mathjax">improved</span> by adopting a proper range of corresponding learning parameter, e.g. 50% reduction in HO rate as compared to a blind strategy. However, results reveal that the <span class="search-hit mathjax">optimal</span> combination of the learning parameters depends critically on any specific <span class="search-hit mathjax">application</span> and the weights of PIs on the final objective <span class="search-hit mathjax">function</span>.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2009.09815v1-abstract-full').style.display = 'none'; document.getElementById('2009.09815v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 21 September, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted to present at IEEE Globecom2020</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2009.09523">arXiv:2009.09523</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2009.09523">pdf</a>, <a href="https://arxiv.org/format/2009.09523">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        VirtualFlow: Decoupling Deep Learning Models from the Underlying Hardware
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Or%2C+A">Andrew Or</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+H">Haoyu Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Freedman%2C+M+J">Michael J. Freedman</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2009.09523v2-abstract-short" style="display: inline;">
        State-of-the-art deep learning systems such as TensorFlow and PyTorch tightly couple the model with the underlying hardware. This coupling requires the user to modify <span class="search-hit mathjax">application</span> logic in order to run the same job across a different set of resources, thereby limiting the choice of hardware for a given workload and potentially forcing the user to forgo more e&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2009.09523v2-abstract-full').style.display = 'inline'; document.getElementById('2009.09523v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2009.09523v2-abstract-full" style="display: none;">
        State-of-the-art deep learning systems such as TensorFlow and PyTorch tightly couple the model with the underlying hardware. This coupling requires the user to modify <span class="search-hit mathjax">application</span> logic in order to run the same job across a different set of resources, thereby limiting the choice of hardware for a given workload and potentially forcing the user to forgo more efficient hardware configurations.
  We propose VirtualFlow, a system leveraging a novel abstraction called virtual node processing to decouple the model from the hardware. In each step of training or inference, the batch of input data is split across virtual nodes instead of hardware accelerators (e.g. GPUs and TPUs). Mapping multiple virtual nodes to each accelerator and processing them sequentially effectively time slices the batch, thereby allowing users to <span class="search-hit mathjax">reduce</span> the memory requirement of their workloads and mimic large batch <span class="search-hit mathjax">sizes</span> on small clusters.
  Using this technique, VirtualFlow enables many new use cases, such as reproducing training results across different hardware, resource elasticity, and heterogeneous training. In our evaluation, our implementation of VirtualFlow for TensorFlow achieved strong convergence guarantees across different hardware with out-of-the-box hyperparameters, up to 48% lower job completion times with resource elasticity, and up to 42% higher throughput with heterogeneous training.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2009.09523v2-abstract-full').style.display = 'none'; document.getElementById('2009.09523v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 11 May, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 20 September, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">12 pages, 29 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2009.06592">arXiv:2009.06592</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2009.06592">pdf</a>, <a href="https://arxiv.org/format/2009.06592">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Programming Languages">cs.PL</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Analogy-Making as a Core Primitive in the <span class="search-hit mathjax">Software</span> Engineering Toolbox
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Sotoudeh%2C+M">Matthew Sotoudeh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Thakur%2C+A+V">Aditya V. Thakur</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2009.06592v1-abstract-short" style="display: inline;">
        &hellip;by developing the Copycat algorithm for completing analogies between letter sequences. In this paper, we argue that analogy making should be seen as a core primitive in <span class="search-hit mathjax">software</span> engineering. We motivate this argument by showing how complex&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2009.06592v1-abstract-full').style.display = 'inline'; document.getElementById('2009.06592v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2009.06592v1-abstract-full" style="display: none;">
        An analogy is an identification of structural similarities and correspondences between two objects. Computational models of analogy making have been studied extensively in the field of cognitive science to better understand high-level human cognition. For instance, Melanie Mitchell and Douglas Hofstadter sought to better understand high-level perception by developing the Copycat algorithm for completing analogies between letter sequences. In this paper, we argue that analogy making should be seen as a core primitive in <span class="search-hit mathjax">software</span> engineering. We motivate this argument by showing how complex <span class="search-hit mathjax">software</span> engineering problems such as <span class="search-hit mathjax">program</span> understanding and source-<span class="search-hit mathjax">code</span> transformation learning can be <span class="search-hit mathjax">reduced</span> to an instance of the analogy-making problem. We demonstrate this idea using Sifter, a new analogy-making algorithm suitable for <span class="search-hit mathjax">software</span> engineering <span class="search-hit mathjax">applications</span> that adapts and extends ideas from Copycat. In particular, Sifter <span class="search-hit mathjax">reduces</span> analogy-making to searching for a sequence of update rule <span class="search-hit mathjax">applications</span>. Sifter uses a novel representation for mathematical structures capable of effectively representing the wide variety of information embedded in <span class="search-hit mathjax">software</span>. We conclude by listing major areas of future work for Sifter and analogy-making in <span class="search-hit mathjax">software</span> engineering.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2009.06592v1-abstract-full').style.display = 'none'; document.getElementById('2009.06592v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 September, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Conference paper at SPLASH 'Onward!' 2020. <span class="search-hit mathjax">Code</span> is available at https://github.com/95616ARG/sifter</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2009.05618">arXiv:2009.05618</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2009.05618">pdf</a>, <a href="https://arxiv.org/format/2009.05618">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Learning an Interpretable Graph Structure in Multi-Task Learning
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Yu%2C+S">Shujian Yu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Alesiani%2C+F">Francesco Alesiani</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shaker%2C+A">Ammar Shaker</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yin%2C+W">Wenzhe Yin</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2009.05618v1-abstract-short" style="display: inline;">
        &hellip;relationship among tasks in the specific prediction problem. We characterize graph structure with its weighted adjacency matrix and show that the overall objective can be <span class="search-hit mathjax">optimized</span> alternatively until convergence. We also show that our methodology can be simply extended to a nonlinear form by being embedded into a multi-head radial basis&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2009.05618v1-abstract-full').style.display = 'inline'; document.getElementById('2009.05618v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2009.05618v1-abstract-full" style="display: none;">
        We present a novel methodology to jointly perform multi-task learning and infer intrinsic relationship among tasks by an interpretable and sparse graph. Unlike existing multi-task learning methodologies, the graph structure is not assumed to be known a priori or estimated separately in a preprocessing step. Instead, our graph is learned simultaneously with model parameters of each task, thus it reflects the critical relationship among tasks in the specific prediction problem. We characterize graph structure with its weighted adjacency matrix and show that the overall objective can be <span class="search-hit mathjax">optimized</span> alternatively until convergence. We also show that our methodology can be simply extended to a nonlinear form by being embedded into a multi-head radial basis <span class="search-hit mathjax">function</span> network (RBFN). Extensive experiments, against six state-of-the-art methodologies, on both synthetic data and real-world <span class="search-hit mathjax">applications</span> suggest that our methodology is able to <span class="search-hit mathjax">reduce</span> generalization error, and, at the same time, reveal a sparse graph over tasks that is much easier to interpret.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2009.05618v1-abstract-full').style.display = 'none'; document.getElementById('2009.05618v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 11 September, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">11 pages, 7 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2009.05234">arXiv:2009.05234</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2009.05234">pdf</a>, <a href="https://arxiv.org/ps/2009.05234">ps</a>, <a href="https://arxiv.org/format/2009.05234">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        An unsupervised deep learning framework via integrated <span class="search-hit mathjax">optimization</span> of representation learning and GMM-based modeling
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+J">Jinghua Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jiang%2C+J">Jianmin Jiang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2009.05234v1-abstract-short" style="display: inline;">
        While supervised deep learning has achieved great success in a range of <span class="search-hit mathjax">applications</span>, relatively little work has studied the discovery of knowledge from unlabeled data. In this paper, we propose an unsupervised deep learning framework to provide a potential solution for the problem that existing deep learning techniques require large labeled data sets for co&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2009.05234v1-abstract-full').style.display = 'inline'; document.getElementById('2009.05234v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2009.05234v1-abstract-full" style="display: none;">
        While supervised deep learning has achieved great success in a range of <span class="search-hit mathjax">applications</span>, relatively little work has studied the discovery of knowledge from unlabeled data. In this paper, we propose an unsupervised deep learning framework to provide a potential solution for the problem that existing deep learning techniques require large labeled data sets for completing the training process. Our proposed introduces a new principle of joint learning on both deep representations and GMM (Gaussian Mixture Model)-based deep modeling, and thus an integrated objective <span class="search-hit mathjax">function</span> is proposed to facilitate the principle. In comparison with the existing work in similar areas, our objective <span class="search-hit mathjax">function</span> has two learning targets, which are created to be jointly <span class="search-hit mathjax">optimized</span> to achieve the best possible unsupervised learning and knowledge discovery from unlabeled data sets. While maximizing the first target enables the GMM to achieve the best possible modeling of the data representations and each Gaussian component corresponds to a compact cluster, maximizing the second term will enhance the separability of the Gaussian components and hence the inter-cluster distances. As a result, the compactness of clusters is significantly enhanced by <span class="search-hit mathjax">reducing</span> the intra-cluster distances, and the separability is <span class="search-hit mathjax">improved</span> by increasing the inter-cluster distances. Extensive experimental results show that the propose method can <span class="search-hit mathjax">improve</span> the clustering performance compared with benchmark methods.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2009.05234v1-abstract-full').style.display = 'none'; document.getElementById('2009.05234v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 11 September, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2020.
      
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        ACCV2018
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2009.05207">arXiv:2009.05207</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2009.05207">pdf</a>, <a href="https://arxiv.org/format/2009.05207">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Can Microtask <span class="search-hit mathjax">Programming</span> Work in Industry?
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Saito%2C+S">Shinobu Saito</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Iimura%2C+Y">Yukako Iimura</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Aghayi%2C+E">Emad Aghayi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=LaToza%2C+T+D">Thomas D. LaToza</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2009.05207v1-abstract-short" style="display: inline;">
        A critical issue in <span class="search-hit mathjax">software</span> development projects in IT service companies is finding the right people at the right time. By enabling assignments of tasks to people to be more fluid, the use of crowdsourcing approaches within a company offers a potential solution to this challenge. Inside a company, as multiple system development projects are ongoing separate&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2009.05207v1-abstract-full').style.display = 'inline'; document.getElementById('2009.05207v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2009.05207v1-abstract-full" style="display: none;">
        A critical issue in <span class="search-hit mathjax">software</span> development projects in IT service companies is finding the right people at the right time. By enabling assignments of tasks to people to be more fluid, the use of crowdsourcing approaches within a company offers a potential solution to this challenge. Inside a company, as multiple system development projects are ongoing separately, developers with slack time on one project might use this time to contribute to other projects. In this paper, we report on a case study of the <span class="search-hit mathjax">application</span> of crowdsourcing within an industrial web <span class="search-hit mathjax">application</span> system development project in a large telecommunications company. Developers worked with system specifications which were organized into a set of microtasks, offering a set of short and self-contained descriptions. When crowd workers in other projects had slack time, they fetched and completed microtasks. Our results offer initial evidence for the potential value of microtask <span class="search-hit mathjax">programming</span> in increasing the fluidity of team assignments within a company. Crowd contributors to the project were able to onboard and contribute to a new project in less than 2 hours. After onboarding, the crowd workers were together able to successfully implement a small <span class="search-hit mathjax">program</span> which contained only a small number of defects. Interview and survey data gathered from project participants revealed that crowd workers reported that they perceived onboarding costs to be <span class="search-hit mathjax">reduced</span> and did not experience issues with the <span class="search-hit mathjax">reduced</span> face to face communication, but experienced challenges with motivation.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2009.05207v1-abstract-full').style.display = 'none'; document.getElementById('2009.05207v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 10 September, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2008.12110">arXiv:2008.12110</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2008.12110">pdf</a>, <a href="https://arxiv.org/format/2008.12110">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Data Structures and Algorithms">cs.DS</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Interior-point methods for unconstrained geometric <span class="search-hit mathjax">programming</span> and scaling problems
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=B%C3%BCrgisser%2C+P">Peter B√ºrgisser</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+Y">Yinan Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Nieuwboer%2C+H">Harold Nieuwboer</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Walter%2C+M">Michael Walter</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2008.12110v1-abstract-short" style="display: inline;">
        We provide a condition-based analysis of two interior-point methods for unconstrained geometric <span class="search-hit mathjax">programs</span>, a class of convex&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2008.12110v1-abstract-full').style.display = 'inline'; document.getElementById('2008.12110v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2008.12110v1-abstract-full" style="display: none;">
        We provide a condition-based analysis of two interior-point methods for unconstrained geometric <span class="search-hit mathjax">programs</span>, a class of convex <span class="search-hit mathjax">programs</span> that arise naturally in <span class="search-hit mathjax">applications</span> including matrix scaling, matrix balancing, and entropy maximization. Our condition numbers are natural geometric quantities associated with the Newton polytope of the geometric <span class="search-hit mathjax">program</span>, and lead to diameter bounds on approximate minimizers. We also provide effective bounds on the condition numbers both in general and under combinatorial assumptions on the Newton polytope. In this way, we generalize the iteration complexity of recent interior-point methods for matrix scaling and matrix balancing. Recently, there has been much work on algorithms for certain <span class="search-hit mathjax">optimization</span> problems on Lie groups, known as capacity and scaling problems. For commutative groups, these problems <span class="search-hit mathjax">reduce</span> to unconstrained geometric <span class="search-hit mathjax">programs</span>, which serves as a particular source of motivation for our work.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2008.12110v1-abstract-full').style.display = 'none'; document.getElementById('2008.12110v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 27 August, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">33 pages, 2 figures</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        
          <span class="has-text-black-bis has-text-weight-semibold">MSC Class:</span>
          90C51 (Primary) 68Q25; 90C25; 14L24 (Secondary)
        

        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2008.11348">arXiv:2008.11348</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2008.11348">pdf</a>, <a href="https://arxiv.org/format/2008.11348">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Variance-<span class="search-hit mathjax">Reduced</span> Proximal and Splitting Schemes for Monotone Stochastic Generalized Equations
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Cui%2C+S">Shisheng Cui</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shanbhag%2C+U+V">Uday V. Shanbhag</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2008.11348v2-abstract-short" style="display: inline;">
        We consider monotone inclusion problems where the operators may be expectation-valued. A direct <span class="search-hit mathjax">application</span> of proximal and splitting schemes is complicated by resolving problems with expectation-valued maps at each step, a concern that is addressed by using sampling. Accordingly, we propose avenues for addressing uncertainty in the mapping. (i) Variance-&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2008.11348v2-abstract-full').style.display = 'inline'; document.getElementById('2008.11348v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2008.11348v2-abstract-full" style="display: none;">
        We consider monotone inclusion problems where the operators may be expectation-valued. A direct <span class="search-hit mathjax">application</span> of proximal and splitting schemes is complicated by resolving problems with expectation-valued maps at each step, a concern that is addressed by using sampling. Accordingly, we propose avenues for addressing uncertainty in the mapping. (i) Variance-<span class="search-hit mathjax">reduced</span> stochastic proximal point method (vr-SPP). We develop amongst the first variance-<span class="search-hit mathjax">reduced</span> stochastic proximal-point schemes that achieves deterministic rates of convergence in terms of solving proximal-point problems. In addition, it is shown that the schemes are characterized by either <span class="search-hit mathjax">optimal</span> or near-<span class="search-hit mathjax">optimal</span> oracle (or sample) complexity guarantees. Finally, the generated sequences are shown to be convergent to a solution in an almost-sure sense in both monotone and strongly monotone regimes; (ii) Variance-<span class="search-hit mathjax">reduced</span> stochastic modified forward-backward splitting scheme (vr-SMFBS). In constrained settings, we consider structured settings when the map can be decomposed into an expectation-valued map $A$ and a maximal monotone map $B$ with a tractable resolvent. Akin to (i), we show that the proposed schemes are equipped with a.s. convergence guarantees, linear (strongly monotone $A$) and $\mathcal{O}(1/k)$ (monotone $A$) rates of convergence while achieving <span class="search-hit mathjax">optimal</span> oracle complexity bounds. Of these, the rate statements in monotone regimes rely on leveraging the Fitzpatrick gap <span class="search-hit mathjax">function</span> for monotone inclusions. Furthermore, the schemes rely on weaker moment requirements on noise as well as allow for weakening unbiasedness requirements on oracles in strongly monotone regimes. Preliminary numerics reflect these findings and show that the variance-<span class="search-hit mathjax">reduced</span> schemes outperform stochastic approximation schemes, stochastic splitting and proximal point schemes, and sample-average approximation approaches.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2008.11348v2-abstract-full').style.display = 'none'; document.getElementById('2008.11348v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 19 December, 2020; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 25 August, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2008.09589">arXiv:2008.09589</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2008.09589">pdf</a>, <a href="https://arxiv.org/format/2008.09589">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computational Engineering, Finance, and Science">cs.CE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Instrumentation and Methods for Astrophysics">astro-ph.IM</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Data Analysis, Statistics and Probability">physics.data-an</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation">stat.CO</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        ParaDRAM: A Cross-Language Toolbox for Parallel High-Performance Delayed-Rejection Adaptive Metropolis Markov Chain Monte Carlo Simulations
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Shahmoradi%2C+A">Amir Shahmoradi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bagheri%2C+F">Fatemeh Bagheri</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2008.09589v1-abstract-short" style="display: inline;">
        We present ParaDRAM, a high-performance Parallel Delayed-Rejection Adaptive Metropolis Markov Chain Monte Carlo <span class="search-hit mathjax">software</span> for&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2008.09589v1-abstract-full').style.display = 'inline'; document.getElementById('2008.09589v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2008.09589v1-abstract-full" style="display: none;">
        We present ParaDRAM, a high-performance Parallel Delayed-Rejection Adaptive Metropolis Markov Chain Monte Carlo <span class="search-hit mathjax">software</span> for <span class="search-hit mathjax">optimization</span>, sampling, and integration of mathematical objective <span class="search-hit mathjax">functions</span> encountered in scientific inference. ParaDRAM is currently accessible from several popular <span class="search-hit mathjax">programming</span> languages including C/C++, Fortran, MATLAB, Python and is part of the ParaMonte open-source project with the following principal design goals: 1. full <span class="search-hit mathjax">automation</span> of Monte Carlo simulations, 2. interoperability of the core library with as many <span class="search-hit mathjax">programming</span> languages as possible, thus, providing a unified <span class="search-hit mathjax">Application</span> <span class="search-hit mathjax">Programming</span> Interface and Monte Carlo simulation environment across all <span class="search-hit mathjax">programming</span> languages, 3. high-performance 4. parallelizability and scalability of simulations from personal laptops to supercomputers, 5. virtually zero-dependence on external libraries, 6. fully-deterministic reproducibility of simulations, 7. <span class="search-hit mathjax">automatic</span> comprehensive reporting and post-processing of the simulation results. We present and discuss several novel techniques implemented in ParaDRAM to <span class="search-hit mathjax">automatically</span> and dynamically ensure the good-mixing and the diminishing-adaptation of the resulting pseudo-Markov chains from ParaDRAM. We also discuss the implementation of an efficient data storage method used in ParaDRAM that <span class="search-hit mathjax">reduces</span> the average memory and storage requirements of the algorithm by, a factor of 4 for simple simulation problems, to an order of magnitude and more for sampling complex high-dimensional mathematical objective <span class="search-hit mathjax">functions</span>. Finally, we discuss how the design goals of ParaDRAM can help users readily and efficiently solve a variety of machine learning and scientific inference problems on a wide range of computing platforms.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2008.09589v1-abstract-full').style.display = 'none'; document.getElementById('2008.09589v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 21 August, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2008.09510">arXiv:2008.09510</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2008.09510">pdf</a>, <a href="https://arxiv.org/format/2008.09510">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1016/j.infsof.2020.106393">10.1016/j.infsof.2020.106393 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Assessing Safety-Critical Systems from Operational Testing: A Study on Autonomous Vehicles
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zhao%2C+X">Xingyu Zhao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Salako%2C+K">Kizito Salako</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Strigini%2C+L">Lorenzo Strigini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Robu%2C+V">Valentin Robu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Flynn%2C+D">David Flynn</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2008.09510v1-abstract-short" style="display: inline;">
        &hellip;with those proposed by a highly-cited study. Method: We apply new theorems extending Conservative Bayesian Inference (CBI), which exploit the rigour of Bayesian methods while <span class="search-hit mathjax">reducing</span> the risk of involuntary misuse associated with now-common&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2008.09510v1-abstract-full').style.display = 'inline'; document.getElementById('2008.09510v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2008.09510v1-abstract-full" style="display: none;">
        Context: Demonstrating high reliability and safety for safety-critical systems (SCSs) remains a hard problem. Diverse evidence needs to be combined in a rigorous way: in particular, results of operational testing with other evidence from design and verification. Growing use of machine learning in SCSs, by precluding most established methods for gaining assurance, makes operational testing even more important for supporting safety and reliability claims. Objective: We use Autonomous Vehicles (AVs) as a current example to revisit the problem of demonstrating high reliability. AVs are making their debut on public roads: methods for assessing whether an AV is safe enough are urgently needed. We demonstrate how to answer 5 questions that would arise in assessing an AV type, starting with those proposed by a highly-cited study. Method: We apply new theorems extending Conservative Bayesian Inference (CBI), which exploit the rigour of Bayesian methods while <span class="search-hit mathjax">reducing</span> the risk of involuntary misuse associated with now-common <span class="search-hit mathjax">applications</span> of Bayesian inference; we define additional conditions needed for applying these methods to AVs. Results: Prior knowledge can bring substantial advantages if the AV design allows strong expectations of safety before road testing. We also show how naive attempts at conservative assessment may lead to over-<span class="search-hit mathjax">optimism</span> instead; why extrapolating the trend of disengagements is not suitable for safety claims; use of knowledge that an AV has moved to a less stressful environment. Conclusion: While some reliability targets will remain too high to be practically verifiable, CBI removes a major source of doubt: it allows use of prior knowledge without inducing dangerously optimistic biases. For certain ranges of required reliability and prior beliefs, CBI thus supports feasible, sound arguments. Useful conservative claims can be derived from limited prior knowledge.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2008.09510v1-abstract-full').style.display = 'none'; document.getElementById('2008.09510v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 19 August, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted by Information and <span class="search-hit mathjax">Software</span> Technology. arXiv admin note: substantial text overlap with arXiv:1908.06540</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2008.08891">arXiv:2008.08891</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2008.08891">pdf</a>, <a href="https://arxiv.org/format/2008.08891">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Quantum Physics">quant-ph</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1088/1361-648X/abe34f">10.1088/1361-648X/abe34f <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Resource-efficient adaptive Bayesian tracking of magnetic fields with a quantum sensor
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Craigie%2C+K">K. Craigie</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gauger%2C+E+M">E. M. Gauger</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Altmann%2C+Y">Y. Altmann</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bonato%2C+C">C. Bonato</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2008.08891v2-abstract-short" style="display: inline;">
        Single-spin quantum sensors, for example based on nitrogen-vacancy centres in diamond, provide nanoscale mapping of magnetic fields. In <span class="search-hit mathjax">applications</span> where the magnetic field may be changing rapidly, total sensing time is crucial and must be minimised. Bayesian estimation and adaptive experiment optimisation can speed up the sensing process by&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2008.08891v2-abstract-full').style.display = 'inline'; document.getElementById('2008.08891v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2008.08891v2-abstract-full" style="display: none;">
        Single-spin quantum sensors, for example based on nitrogen-vacancy centres in diamond, provide nanoscale mapping of magnetic fields. In <span class="search-hit mathjax">applications</span> where the magnetic field may be changing rapidly, total sensing time is crucial and must be minimised. Bayesian estimation and adaptive experiment optimisation can speed up the sensing process by <span class="search-hit mathjax">reducing</span> the number of measurements required. These protocols consist of computing and updating the probability distribution of the magnetic field based on measurement outcomes and of determining <span class="search-hit mathjax">optimized</span> acquisition settings for the next measurement. However, the computational steps feeding into the measurement settings of the next iteration must be performed quickly enough to allow for real-time updates. This article addresses the issue of computational speed by implementing an approximate Bayesian estimation technique, where probability distributions are approximated by a finite sum of Gaussian <span class="search-hit mathjax">functions</span>. Given that only three parameters are required to fully describe a Gaussian density, we find that in many cases, the magnetic field probability distribution can be described by fewer than ten parameters, achieving a reduction in computation time by factor 10 compared to existing approaches. For T2* = 1 micro second, only a small decrease in computation time is achieved. However, in these regimes, the proposed Gaussian protocol outperforms the existing one in tracking accuracy.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2008.08891v2-abstract-full').style.display = 'none'; document.getElementById('2008.08891v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 26 January, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 20 August, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">14 pages, 4 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2008.07071">arXiv:2008.07071</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2008.07071">pdf</a>, <a href="https://arxiv.org/format/2008.07071">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Image and Video Processing">eess.IV</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Towards Cardiac Intervention Assistance: Hardware-aware Neural Architecture Exploration for Real-Time 3D Cardiac Cine MRI Segmentation
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zeng%2C+D">Dewen Zeng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jiang%2C+W">Weiwen Jiang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+T">Tianchen Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xu%2C+X">Xiaowei Xu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yuan%2C+H">Haiyun Yuan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Huang%2C+M">Meiping Huang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhuang%2C+J">Jian Zhuang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hu%2C+J">Jingtong Hu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shi%2C+Y">Yiyu Shi</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2008.07071v2-abstract-short" style="display: inline;">
        &hellip;the computation is preferably done on local hardware. State-of-the-art MRI segmentation methods mostly focus on accuracy only, and can hardly be adopted for real-time <span class="search-hit mathjax">application</span> or on local hardware. In this work, we present the first hardware-aware multi-scale neural architecture search (NAS) framework for real-time 3D cardiac cine MRI segmentation. The p&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2008.07071v2-abstract-full').style.display = 'inline'; document.getElementById('2008.07071v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2008.07071v2-abstract-full" style="display: none;">
        Real-time cardiac magnetic resonance imaging (MRI) plays an increasingly important role in guiding various cardiac interventions. In order to provide better visual assistance, the cine MRI frames need to be segmented on-the-fly to avoid noticeable visual lag. In addition, considering reliability and patient data privacy, the computation is preferably done on local hardware. State-of-the-art MRI segmentation methods mostly focus on accuracy only, and can hardly be adopted for real-time <span class="search-hit mathjax">application</span> or on local hardware. In this work, we present the first hardware-aware multi-scale neural architecture search (NAS) framework for real-time 3D cardiac cine MRI segmentation. The proposed framework incorporates a latency regularization term into the loss <span class="search-hit mathjax">function</span> to handle real-time constraints, with the consideration of underlying hardware. In addition, the formulation is fully differentiable with respect to the architecture parameters, so that stochastic gradient descent (SGD) can be used for <span class="search-hit mathjax">optimization</span> to <span class="search-hit mathjax">reduce</span> the computation cost while maintaining <span class="search-hit mathjax">optimization</span> quality. Experimental results on ACDC MICCAI 2017 dataset demonstrate that our hardware-aware multi-scale NAS framework can <span class="search-hit mathjax">reduce</span> the latency by up to 3.5 times and satisfy the real-time constraints, while still achieving competitive segmentation accuracy, compared with the state-of-the-art NAS segmentation framework.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2008.07071v2-abstract-full').style.display = 'none'; document.getElementById('2008.07071v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 13 December, 2020; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 16 August, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">8 pages, conference</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2008.06668">arXiv:2008.06668</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2008.06668">pdf</a>, <a href="https://arxiv.org/format/2008.06668">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Accountable Off-Policy Evaluation With Kernel Bellman Statistics
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Feng%2C+Y">Yihao Feng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ren%2C+T">Tongzheng Ren</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tang%2C+Z">Ziyang Tang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+Q">Qiang Liu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2008.06668v1-abstract-short" style="display: inline;">
        &hellip;evaluates the performance of a new policy from observed data collected from previous experiments, without requiring the execution of the new policy. This finds important <span class="search-hit mathjax">applications</span> in areas with high execution cost or safety concerns, such as medical diagnosis, recommendation systems and robotics. In practice, due to the limited information from off-policy&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2008.06668v1-abstract-full').style.display = 'inline'; document.getElementById('2008.06668v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2008.06668v1-abstract-full" style="display: none;">
        We consider off-policy evaluation (OPE), which evaluates the performance of a new policy from observed data collected from previous experiments, without requiring the execution of the new policy. This finds important <span class="search-hit mathjax">applications</span> in areas with high execution cost or safety concerns, such as medical diagnosis, recommendation systems and robotics. In practice, due to the limited information from off-policy data, it is highly desirable to construct rigorous confidence intervals, not just point estimation, for the policy performance. In this work, we propose a new variational framework which <span class="search-hit mathjax">reduces</span> the problem of calculating tight confidence bounds in OPE into an <span class="search-hit mathjax">optimization</span> problem on a feasible set that catches the true state-action value <span class="search-hit mathjax">function</span> with high probability. The feasible set is constructed by leveraging statistical properties of a recently proposed kernel Bellman loss (Feng et al., 2019). We design an efficient computational approach for calculating our bounds, and extend it to perform post-hoc diagnosis and correction for existing estimators. Empirical results show that our method yields tight confidence intervals in different settings.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2008.06668v1-abstract-full').style.display = 'none'; document.getElementById('2008.06668v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 August, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">22 pages, 4 figures, ICML 2020</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2008.06431">arXiv:2008.06431</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2008.06431">pdf</a>, <a href="https://arxiv.org/format/2008.06431">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Efficient hyperparameter <span class="search-hit mathjax">optimization</span> by way of PAC-Bayes bound minimization
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Cherian%2C+J+J">John J. Cherian</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Taube%2C+A+G">Andrew G. Taube</a>, 
      
      <a href="/search/?searchtype=author&amp;query=McGibbon%2C+R+T">Robert T. McGibbon</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Angelikopoulos%2C+P">Panagiotis Angelikopoulos</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Blanc%2C+G">Guy Blanc</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Snarski%2C+M">Michael Snarski</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Richman%2C+D+D">Daniel D. Richman</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Klepeis%2C+J+L">John L. Klepeis</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shaw%2C+D+E">David E. Shaw</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2008.06431v1-abstract-short" style="display: inline;">
        Identifying <span class="search-hit mathjax">optimal</span> values for a high-dimensional set of hyperparameters is a problem that has received growing attention given its importance to large-scale machine learning&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2008.06431v1-abstract-full').style.display = 'inline'; document.getElementById('2008.06431v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2008.06431v1-abstract-full" style="display: none;">
        Identifying <span class="search-hit mathjax">optimal</span> values for a high-dimensional set of hyperparameters is a problem that has received growing attention given its importance to large-scale machine learning <span class="search-hit mathjax">applications</span> such as neural architecture search. Recently developed <span class="search-hit mathjax">optimization</span> methods can be used to select thousands or even millions of hyperparameters. Such methods often yield overfit models, however, leading to poor performance on unseen data. We argue that this overfitting results from using the standard hyperparameter <span class="search-hit mathjax">optimization</span> objective <span class="search-hit mathjax">function</span>. Here we present an alternative objective that is equivalent to a Probably Approximately Correct-Bayes (PAC-Bayes) bound on the expected out-of-sample error. We then devise an efficient gradient-based algorithm to minimize this objective; the proposed method has asymptotic space and time complexity equal to or better than other gradient-based hyperparameter <span class="search-hit mathjax">optimization</span> methods. We show that this new method significantly <span class="search-hit mathjax">reduces</span> out-of-sample error when applied to hyperparameter <span class="search-hit mathjax">optimization</span> problems known to be prone to overfitting.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2008.06431v1-abstract-full').style.display = 'none'; document.getElementById('2008.06431v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 August, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2008.04516">arXiv:2008.04516</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2008.04516">pdf</a>, <a href="https://arxiv.org/format/2008.04516">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Cryptography and Security">cs.CR</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Localizing Patch Points From One Exploit
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Shen%2C+S">Shiqi Shen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kolluri%2C+A">Aashish Kolluri</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dong%2C+Z">Zhen Dong</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Saxena%2C+P">Prateek Saxena</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Roychoudhury%2C+A">Abhik Roychoudhury</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2008.04516v1-abstract-short" style="display: inline;">
        <span class="search-hit mathjax">Automatic</span> patch generation can significantly&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2008.04516v1-abstract-full').style.display = 'inline'; document.getElementById('2008.04516v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2008.04516v1-abstract-full" style="display: none;">
        <span class="search-hit mathjax">Automatic</span> patch generation can significantly <span class="search-hit mathjax">reduce</span> the window of exposure after a vulnerability is disclosed. Towards this goal, a long-standing problem has been that of patch localization: to find a <span class="search-hit mathjax">program</span> point at which a patch can be synthesized. We present PatchLoc, one of the first systems which <span class="search-hit mathjax">automatically</span> identifies such a location in a vulnerable binary, given just one exploit, with high accuracy. PatchLoc does not make any assumptions about the availability of source <span class="search-hit mathjax">code</span>, test suites, or specialized knowledge of the vulnerability. PatchLoc pinpoints valid patch locations in large real-world <span class="search-hit mathjax">applications</span> with high accuracy for about 88% of 43 CVEs we study. These results stem from a novel approach to <span class="search-hit mathjax">automatically</span> synthesizing a test-suite which enables probabilistically ranking and effectively differentiating between candidate <span class="search-hit mathjax">program</span> patch locations.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2008.04516v1-abstract-full').style.display = 'none'; document.getElementById('2008.04516v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 11 August, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2008.04447">arXiv:2008.04447</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2008.04447">pdf</a>, <a href="https://arxiv.org/format/2008.04447">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Mathematical Software">cs.MS</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Spectral Theory">math.SP</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Randomized Projection for Rank-Revealing Matrix Factorizations and Low-Rank Approximations
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Duersch%2C+J+A">Jed A. Duersch</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gu%2C+M">Ming Gu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2008.04447v1-abstract-short" style="display: inline;">
        &hellip;from a much smaller sample matrix, which we can construct to reside in a faster level of memory than the original matrix. This technique may be understood as trading vastly <span class="search-hit mathjax">reduced</span> communication for a controlled increase in uncertainty during the decision process. For rank-revealing purposes, the selection mechanism in RQRCP produces results that are the sam&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2008.04447v1-abstract-full').style.display = 'inline'; document.getElementById('2008.04447v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2008.04447v1-abstract-full" style="display: none;">
        Rank-revealing matrix decompositions provide an essential tool in spectral analysis of matrices, including the Singular Value Decomposition (SVD) and related low-rank approximation techniques. QR with Column Pivoting (QRCP) is usually suitable for these purposes, but it can be much slower than the unpivoted QR algorithm. For large matrices, the difference in performance is due to increased communication between the processor and slow memory, which QRCP needs in order to choose pivots during decomposition. Our main algorithm, Randomized QR with Column Pivoting (RQRCP), uses randomized projection to make pivot decisions from a much smaller sample matrix, which we can construct to reside in a faster level of memory than the original matrix. This technique may be understood as trading vastly <span class="search-hit mathjax">reduced</span> communication for a controlled increase in uncertainty during the decision process. For rank-revealing purposes, the selection mechanism in RQRCP produces results that are the same quality as the standard algorithm, but with performance near that of unpivoted QR (often an order of magnitude faster for large matrices). We also propose two formulas that facilitate further performance <span class="search-hit mathjax">improvements</span>. The first efficiently updates sample matrices to avoid computing new randomized projections. The second avoids large trailing updates during the decomposition in truncated low-rank approximations. Our truncated version of RQRCP also provides a key initial step in our truncated SVD approximation, TUXV. These advances open up a new performance domain for large matrix factorizations that will support efficient problem-solving techniques for challenging <span class="search-hit mathjax">applications</span> in science, engineering, and data analysis.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2008.04447v1-abstract-full').style.display = 'none'; document.getElementById('2008.04447v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 10 August, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Revised from Randomized QR with Column Pivoting for publication in SIGEST</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        
          <span class="has-text-black-bis has-text-weight-semibold">MSC Class:</span>
          68W20; 15A23; 15A18; 65F25
        

        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2008.02164">arXiv:2008.02164</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2008.02164">pdf</a>, <a href="https://arxiv.org/format/2008.02164">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Supporting Robotic <span class="search-hit mathjax">Software</span> Migration Using Static Analysis and Model-Driven Engineering
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Wood%2C+S">Sophie Wood</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Matragkas%2C+N">Nicholas Matragkas</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kolovos%2C+D">Dimitris Kolovos</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Paige%2C+R">Richard Paige</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gerasimou%2C+S">Simos Gerasimou</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2008.02164v1-abstract-short" style="display: inline;">
        The wide use of robotic systems contributed to developing robotic <span class="search-hit mathjax">software</span> highly coupled to the hardware platform running the robotic system. Due to increased maintenance cost or changing business priorities, the robotic hardware is infrequently upgraded, thus increasing the risk for technology stagnation.&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2008.02164v1-abstract-full').style.display = 'inline'; document.getElementById('2008.02164v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2008.02164v1-abstract-full" style="display: none;">
        The wide use of robotic systems contributed to developing robotic <span class="search-hit mathjax">software</span> highly coupled to the hardware platform running the robotic system. Due to increased maintenance cost or changing business priorities, the robotic hardware is infrequently upgraded, thus increasing the risk for technology stagnation. <span class="search-hit mathjax">Reducing</span> this risk entails migrating the system and its <span class="search-hit mathjax">software</span> to a new hardware platform. Conventional <span class="search-hit mathjax">software</span> engineering practices such as complete re-development and <span class="search-hit mathjax">code</span>-based migration, albeit useful in mitigating these obsolescence issues, they are time-consuming and overly expensive. Our RoboSMi model-driven approach supports the migration of the <span class="search-hit mathjax">software</span> controlling a robotic system between hardware platforms. First, RoboSMi executes static analysis on the robotic <span class="search-hit mathjax">software</span> of the source hardware platform to identify platform-dependent and platform-agnostic <span class="search-hit mathjax">software</span> constructs. By analysing a model that expresses the architecture of robotic components on the target platform, RoboSMi establishes the hardware configuration of those components and suggests <span class="search-hit mathjax">software</span> libraries for each component whose execution will enable the robotic <span class="search-hit mathjax">software</span> to control the components. Finally, RoboSMi through <span class="search-hit mathjax">code</span>-generation produces <span class="search-hit mathjax">software</span> for the target platform and indicates areas that require manual intervention by robotic engineers to complete the migration. We evaluate the <span class="search-hit mathjax">applicability</span> of RoboSMi and analyse the level of <span class="search-hit mathjax">automation</span> and performance provided from its use by migrating two robotic systems deployed for an environmental monitoring and a line following mission from a Propeller Activity Board to an Arduino Uno.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2008.02164v1-abstract-full').style.display = 'none'; document.getElementById('2008.02164v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 5 August, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">10 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2008.00357">arXiv:2008.00357</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2008.00357">pdf</a>, <a href="https://arxiv.org/format/2008.00357">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A Causal Lens for Peeking into Black Box Predictive Models: Predictive Model Interpretation via Causal Attribution
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Khademi%2C+A">Aria Khademi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Honavar%2C+V">Vasant Honavar</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2008.00357v1-abstract-short" style="display: inline;">
        With the increasing adoption of predictive models trained using machine learning across a wide range of high-stakes <span class="search-hit mathjax">applications</span>, e.g., health care, security, criminal justice, finance, and education, there is a growing need for effective techniques for explaining such models and their predictions. We aim to address this problem in settings where the predict&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2008.00357v1-abstract-full').style.display = 'inline'; document.getElementById('2008.00357v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2008.00357v1-abstract-full" style="display: none;">
        With the increasing adoption of predictive models trained using machine learning across a wide range of high-stakes <span class="search-hit mathjax">applications</span>, e.g., health care, security, criminal justice, finance, and education, there is a growing need for effective techniques for explaining such models and their predictions. We aim to address this problem in settings where the predictive model is a black box; That is, we can only observe the response of the model to various inputs, but have no knowledge about the internal structure of the predictive model, its parameters, the objective <span class="search-hit mathjax">function</span>, and the algorithm used to <span class="search-hit mathjax">optimize</span> the model. We <span class="search-hit mathjax">reduce</span> the problem of interpreting a black box predictive model to that of estimating the causal effects of each of the model inputs on the model output, from observations of the model inputs and the corresponding outputs. We estimate the causal effects of model inputs on model output using variants of the Rubin Neyman potential outcomes framework for estimating causal effects from observational data. We show how the resulting causal attribution of responsibility for model output to the different model inputs can be used to interpret the predictive model and to explain its predictions. We present results of experiments that demonstrate the effectiveness of our approach to the interpretation of black box predictive models via causal attribution in the case of deep neural network models trained on one synthetic data set (where the input variables that impact the output variable are known by design) and two real-world data sets: Handwritten digit classification, and Parkinson&#39;s disease severity prediction. Because our approach does not require knowledge about the predictive model algorithm and is free of assumptions regarding the black box predictive model except that its input-output responses be observable, it can be applied, in principle, to any black box predictive model.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2008.00357v1-abstract-full').style.display = 'none'; document.getElementById('2008.00357v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 1 August, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2007.14209">arXiv:2007.14209</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2007.14209">pdf</a>, <a href="https://arxiv.org/ps/2007.14209">ps</a>, <a href="https://arxiv.org/format/2007.14209">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Langevin Monte Carlo: random coordinate descent and variance reduction
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ding%2C+Z">Zhiyan Ding</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+Q">Qin Li</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2007.14209v5-abstract-short" style="display: inline;">
        Sampling from a log-concave distribution <span class="search-hit mathjax">function</span> on $\mathbb{R}^d$ (with $d\gg 1$) is a popular problem that has wide&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2007.14209v5-abstract-full').style.display = 'inline'; document.getElementById('2007.14209v5-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2007.14209v5-abstract-full" style="display: none;">
        Sampling from a log-concave distribution <span class="search-hit mathjax">function</span> on $\mathbb{R}^d$ (with $d\gg 1$) is a popular problem that has wide <span class="search-hit mathjax">applications</span>. In this paper we study the <span class="search-hit mathjax">application</span> of random coordinate descent method (RCD) on the Langevin Monte Carlo (LMC) sampling method, and we find two sides of the theory:
  1. The direct <span class="search-hit mathjax">application</span> of RCD on LMC does <span class="search-hit mathjax">reduce</span> the number of finite differencing approximations per iteration, but it induces a large variance error term. More iterations are then needed, and ultimately the method gains no computational advantage;
  2. When variance reduction techniques (such as SAGA and SVRG) are incorporated in RCD-LMC, the variance error term is <span class="search-hit mathjax">reduced</span>. The new methods, compared to the vanilla LMC, <span class="search-hit mathjax">reduce</span> the total computational cost by $d$ folds, and achieve the <span class="search-hit mathjax">optimal</span> cost rate.
  We perform our investigations in both overdamped and underdamped settings.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2007.14209v5-abstract-full').style.display = 'none'; document.getElementById('2007.14209v5-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 3 July, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 26 July, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">arXiv admin note: text overlap with arXiv:2006.06068</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2007.12397">arXiv:2007.12397</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2007.12397">pdf</a>, <a href="https://arxiv.org/format/2007.12397">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Learning the Solution Manifold in <span class="search-hit mathjax">Optimization</span> and Its <span class="search-hit mathjax">Application</span> in Motion Planning
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Osa%2C+T">Takayuki Osa</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2007.12397v1-abstract-short" style="display: inline;">
        <span class="search-hit mathjax">Optimization</span> is an essential component for solving problems in wide-ranging fields. Ideally, the objective&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2007.12397v1-abstract-full').style.display = 'inline'; document.getElementById('2007.12397v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2007.12397v1-abstract-full" style="display: none;">
        <span class="search-hit mathjax">Optimization</span> is an essential component for solving problems in wide-ranging fields. Ideally, the objective <span class="search-hit mathjax">function</span> should be designed such that the solution is unique and the <span class="search-hit mathjax">optimization</span> problem can be solved stably. However, the objective <span class="search-hit mathjax">function</span> used in a practical <span class="search-hit mathjax">application</span> is usually non-convex, and sometimes it even has an infinite set of solutions. To address this issue, we propose to learn the solution manifold in <span class="search-hit mathjax">optimization</span>. We train a model conditioned on the latent variable such that the model represents an infinite set of solutions. In our framework, we <span class="search-hit mathjax">reduce</span> this problem to density estimation by using importance sampling, and the latent representation of the solutions is learned by maximizing the variational lower bound. We apply the proposed algorithm to motion-planning problems, which involve the <span class="search-hit mathjax">optimization</span> of high-dimensional parameters. The experimental results indicate that the solution manifold can be learned with the proposed algorithm, and the trained model represents an infinite set of homotopic solutions for motion-planning problems.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2007.12397v1-abstract-full').style.display = 'none'; document.getElementById('2007.12397v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 24 July, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2007.11671">arXiv:2007.11671</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2007.11671">pdf</a>, <a href="https://arxiv.org/format/2007.11671">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        DeepClone: Modeling Clones to Generate <span class="search-hit mathjax">Code</span> Predictions
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Hammad%2C+M">Muhammad Hammad</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Babur%2C+%C3%96">√ñnder Babur</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Basit%2C+H+A">Hamid Abdul Basit</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Brand%2C+M+v+d">Mark van den Brand</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2007.11671v2-abstract-short" style="display: inline;">
        Programmers often reuse <span class="search-hit mathjax">code</span> from source&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2007.11671v2-abstract-full').style.display = 'inline'; document.getElementById('2007.11671v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2007.11671v2-abstract-full" style="display: none;">
        Programmers often reuse <span class="search-hit mathjax">code</span> from source <span class="search-hit mathjax">code</span> repositories to <span class="search-hit mathjax">reduce</span> the development effort. <span class="search-hit mathjax">Code</span> clones are candidates for reuse in exploratory or rapid development, as they represent often repeated <span class="search-hit mathjax">functionality</span> in <span class="search-hit mathjax">software</span> systems. To facilitate <span class="search-hit mathjax">code</span> clone reuse, we propose DeepClone, a novel approach utilizing a deep learning algorithm for modeling <span class="search-hit mathjax">code</span> clones to predict the next set of tokens (possibly a complete clone method body) based on the <span class="search-hit mathjax">code</span> written so far. The predicted tokens require minimal customization to fit the context. DeepClone applies natural language processing techniques to learn from a large <span class="search-hit mathjax">code</span> corpus, and generates <span class="search-hit mathjax">code</span> tokens using the model learned. We have quantitatively evaluated our solution to assess (1) our model&#39;s quality and its accuracy in token prediction, and (2) its performance and effectiveness in clone method prediction. We also discuss various <span class="search-hit mathjax">application</span> scenarios for our approach.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2007.11671v2-abstract-full').style.display = 'none'; document.getElementById('2007.11671v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 5 December, 2020; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 22 July, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">16 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2007.10876">arXiv:2007.10876</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2007.10876">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Challenges in Developing Secure Mobile Health <span class="search-hit mathjax">Applications</span>, A Systematic Review
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Aljedaani%2C+B">Bakheet Aljedaani</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Babar%2C+M+A">M. Ali Babar</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2007.10876v2-abstract-short" style="display: inline;">
        Mobile health (mHealth) <span class="search-hit mathjax">applications</span> (apps) have gained significant popularity over the last few years due to its tremendous benefits, such as lowering healthcare cost and increasing patient awareness. However, the sensitivity of healthcare data makes the security of mHealth apps a serious concern. In this review, we aim to identify and analyse the reported&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2007.10876v2-abstract-full').style.display = 'inline'; document.getElementById('2007.10876v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2007.10876v2-abstract-full" style="display: none;">
        Mobile health (mHealth) <span class="search-hit mathjax">applications</span> (apps) have gained significant popularity over the last few years due to its tremendous benefits, such as lowering healthcare cost and increasing patient awareness. However, the sensitivity of healthcare data makes the security of mHealth apps a serious concern. In this review, we aim to identify and analyse the reported challenges that the developers of mHealth apps face concerning security. Additionally, our study aimed to develop a conceptual framework with the challenges faced by mHealth apps development organization for developing secure apps. The knowledge of such challenges can help to <span class="search-hit mathjax">reduce</span> the risk of developing insecure mHealth apps. We followed the Systematic Literature Review method for this review. We selected studies that have been published between January 2008 and October 2020. We selected 32 primary studies using predefined criteria and used thematic analysis method for analysing the extracted data. We identified nine challenges that can affect the development of secure mHealth apps. Such as 1) lack of security guidelines and regulations for developing secure mHealth apps, 2) developers lack of knowledge and expertise for secure mHealth app development, 3) lack of stakeholders involvement during mHealth app development, etc . Based on our analysis, we have presented a conceptual framework which highlights the correlation between the identified challenges. We conclude that our findings can help them identify their weaknesses and <span class="search-hit mathjax">improve</span> their security practices. Similarly, mHealth apps developers can identify the challenges they face to develop mHealth apps that do not pose security risks for users. Our review is a step towards providing insights into the development of secure mHealth apps. Our proposed conceptual framework can act as a practice guideline for practitioners to enhance secure mHealth apps development.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2007.10876v2-abstract-full').style.display = 'none'; document.getElementById('2007.10876v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 January, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 21 July, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">This paper has 5 figures and 1 table</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2007.09881">arXiv:2007.09881</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2007.09881">pdf</a>, <a href="https://arxiv.org/ps/2007.09881">ps</a>, <a href="https://arxiv.org/format/2007.09881">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        DeepCO: Offline Combinatorial <span class="search-hit mathjax">Optimization</span> Framework Utilizing Deep Learning
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Wei%2C+W">Wenpeng Wei</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Aizono%2C+T">Toshiko Aizono</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2007.09881v1-abstract-short" style="display: inline;">
        Combinatorial <span class="search-hit mathjax">optimization</span> serves as an essential part in many modern industrial&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2007.09881v1-abstract-full').style.display = 'inline'; document.getElementById('2007.09881v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2007.09881v1-abstract-full" style="display: none;">
        Combinatorial <span class="search-hit mathjax">optimization</span> serves as an essential part in many modern industrial <span class="search-hit mathjax">applications</span>. A great number of the problems are offline setting due to safety and/or cost issues. While simulation-based approaches appear difficult to realise for complicated systems, in this research, we propose DeepCO, an offline combinatorial <span class="search-hit mathjax">optimization</span> framework utilizing deep learning. We also design an offline variation of Travelling Salesman Problem (TSP) to model warehouse operation sequence <span class="search-hit mathjax">optimization</span> problem for evaluation. With only limited historical data, novel proposed distribution regularized <span class="search-hit mathjax">optimization</span> method outperforms existing baseline method in offline TSP experiment <span class="search-hit mathjax">reducing</span> route length by 5.7% averagely and shows great potential in real world problems.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2007.09881v1-abstract-full').style.display = 'none'; document.getElementById('2007.09881v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 20 July, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2007.08577">arXiv:2007.08577</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2007.08577">pdf</a>, <a href="https://arxiv.org/format/2007.08577">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Re-weighting and 1-Point RANSAC-Based PnP Solution to Handle Outliers
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zhou%2C+H">Haoyin Zhou</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+T">Tao Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jayender%2C+J">Jagadeesan Jayender</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2007.08577v1-abstract-short" style="display: inline;">
        The ability to handle outliers is essential for performing the perspective-n-point (PnP) approach in practical <span class="search-hit mathjax">applications</span>, but conventional RANSAC+P3P or P4P methods have high time complexities. We propose a fast PnP solution named R1PPnP to handle outliers by utilizing a soft re-weighting mechanism and the 1-point RANSAC scheme. We first present a PnP alg&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2007.08577v1-abstract-full').style.display = 'inline'; document.getElementById('2007.08577v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2007.08577v1-abstract-full" style="display: none;">
        The ability to handle outliers is essential for performing the perspective-n-point (PnP) approach in practical <span class="search-hit mathjax">applications</span>, but conventional RANSAC+P3P or P4P methods have high time complexities. We propose a fast PnP solution named R1PPnP to handle outliers by utilizing a soft re-weighting mechanism and the 1-point RANSAC scheme. We first present a PnP algorithm, which serves as the core of R1PPnP, for solving the PnP problem in outlier-free situations. The core algorithm is an <span class="search-hit mathjax">optimal</span> process minimizing an objective <span class="search-hit mathjax">function</span> conducted with a random control point. Then, to <span class="search-hit mathjax">reduce</span> the impact of outliers, we propose a reprojection error-based re-weighting method and integrate it into the core algorithm. Finally, we employ the 1-point RANSAC scheme to try different control points. Experiments with synthetic and real-world data demonstrate that R1PPnP is faster than RANSAC+P3P or P4P methods especially when the percentage of outliers is large, and is accurate. Besides, comparisons with outlier-free synthetic data show that R1PPnP is among the most accurate and fast PnP solutions, which usually serve as the final refinement step of RANSAC+P3P or P4P. Compared with REPPnP, which is the state-of-the-art PnP algorithm with an explicit outliers-handling mechanism, R1PPnP is slower but does not suffer from the percentage of outliers limitation as REPPnP.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2007.08577v1-abstract-full').style.display = 'none'; document.getElementById('2007.08577v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 July, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">https://github.com/haoyinzhou/PnP_Toolbox</span>
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        IEEE transactions on pattern analysis and machine intelligence 41, no. 12 (2018): 3022-3033
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2007.07539">arXiv:2007.07539</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2007.07539">pdf</a>, <a href="https://arxiv.org/format/2007.07539">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Mathematical Software">cs.MS</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Hardware Architecture">cs.AR</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Performance">cs.PF</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Accelerating Geometric Multigrid Preconditioning with Half-Precision Arithmetic on GPUs
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Oo%2C+K+L">Kyaw L. Oo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Vogel%2C+A">Andreas Vogel</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2007.07539v1-abstract-short" style="display: inline;">
        With the hardware support for half-precision arithmetic on NVIDIA V100 GPUs, high-performance computing <span class="search-hit mathjax">applications</span> can benefit from lower precision at appropriate spots to speed up the overall execution time. In this paper, we investigate a mixed-precision geometric multigrid method to solve large sparse systems of equations stemming from discretization of&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2007.07539v1-abstract-full').style.display = 'inline'; document.getElementById('2007.07539v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2007.07539v1-abstract-full" style="display: none;">
        With the hardware support for half-precision arithmetic on NVIDIA V100 GPUs, high-performance computing <span class="search-hit mathjax">applications</span> can benefit from lower precision at appropriate spots to speed up the overall execution time. In this paper, we investigate a mixed-precision geometric multigrid method to solve large sparse systems of equations stemming from discretization of elliptic PDEs. While the final solution is always computed with high-precision accuracy, an iterative refinement approach with multigrid preconditioning in lower precision and residuum scaling is employed. We compare the FP64 baseline for Poisson&#39;s equation to purely FP16 multigrid preconditioning and to the employment of FP16-FP32-FP64 combinations within a mesh hierarchy. While the iteration count is almost not affected by using lower accuracy, the solver runtime is considerably decreased due to the <span class="search-hit mathjax">reduced</span> memory transfer and a speedup of up to 2.5x is gained for the overall solver. We investigate the performance of selected kernels with the hierarchical Roofline model.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2007.07539v1-abstract-full').style.display = 'none'; document.getElementById('2007.07539v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 July, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2007.07488">arXiv:2007.07488</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2007.07488">pdf</a>, <a href="https://arxiv.org/format/2007.07488">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Data Structures and Algorithms">cs.DS</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        An algorithm for integrating peer-to-peer ridesharing and schedule-based transit system for first mile/last mile access
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Kumar%2C+P">Pramesh Kumar</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Khani%2C+A">Alireza Khani</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2007.07488v1-abstract-short" style="display: inline;">
        &hellip;ridesharing matching algorithm to solve this problem. The method leverages the schedule-based transit shortest path to generate feasible matches and then solves a matching <span class="search-hit mathjax">optimization</span>&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2007.07488v1-abstract-full').style.display = 'inline'; document.getElementById('2007.07488v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2007.07488v1-abstract-full" style="display: none;">
        Due to limited transit network coverage and infrequent service, suburban commuters often face the transit first mile/last mile (FMLM) problem. To deal with this, they either drive to a park-and-ride location to take transit, use carpooling, or drive directly to their destination to avoid inconvenience. Ridesharing, an emerging mode of transportation, can solve the transit first mile/last mile problem. In this setup, a driver can drive a ride-seeker to a transit station, from where the rider can take transit to her respective destination. The problem requires solving a ridesharing matching problem with the routing of riders in a multimodal transportation network. We develop a transit-based ridesharing matching algorithm to solve this problem. The method leverages the schedule-based transit shortest path to generate feasible matches and then solves a matching <span class="search-hit mathjax">optimization</span> <span class="search-hit mathjax">program</span> to find an <span class="search-hit mathjax">optimal</span> match between riders and drivers. The proposed method not only assigns an <span class="search-hit mathjax">optimal</span> driver to the rider but also assigns an <span class="search-hit mathjax">optimal</span> transit stop and a transit vehicle trip departing from that stop for the rest of the rider&#39;s itinerary. We also introduce the <span class="search-hit mathjax">application</span> of space-time prism (STP) (the geographical area which can be reached by a traveler given the time constraints) in the context of ridesharing to <span class="search-hit mathjax">reduce</span> the computational time by <span class="search-hit mathjax">reducing</span> the network search. An algorithm to solve this problem dynamically using a rolling horizon approach is also presented. We use simulated data obtained from the activity-based travel demand model of Twin Cities, MN to show that the transit-based ridesharing can solve the FMLM problem and save a significant number of vehicle-hours spent in the system.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2007.07488v1-abstract-full').style.display = 'none'; document.getElementById('2007.07488v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 July, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">36 pages, 15 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2007.03317">arXiv:2007.03317</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2007.03317">pdf</a>, <a href="https://arxiv.org/format/2007.03317">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Efficient Learning of Generative Models via Finite-Difference Score Matching
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Pang%2C+T">Tianyu Pang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xu%2C+K">Kun Xu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+C">Chongxuan Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Song%2C+Y">Yang Song</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ermon%2C+S">Stefano Ermon</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhu%2C+J">Jun Zhu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2007.03317v2-abstract-short" style="display: inline;">
        Several machine learning <span class="search-hit mathjax">applications</span> involve the&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2007.03317v2-abstract-full').style.display = 'inline'; document.getElementById('2007.03317v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2007.03317v2-abstract-full" style="display: none;">
        Several machine learning <span class="search-hit mathjax">applications</span> involve the <span class="search-hit mathjax">optimization</span> of higher-order derivatives (e.g., gradients of gradients) during training, which can be expensive in respect to memory and computation even with <span class="search-hit mathjax">automatic</span> differentiation. As a typical example in generative modeling, score matching (SM) involves the <span class="search-hit mathjax">optimization</span> of the trace of a Hessian. To <span class="search-hit mathjax">improve</span> computing efficiency, we rewrite the SM objective and its variants in terms of directional derivatives, and present a generic strategy to efficiently approximate any-order directional derivative with finite difference (FD). Our approximation only involves <span class="search-hit mathjax">function</span> evaluations, which can be executed in parallel, and no gradient computations. Thus, it <span class="search-hit mathjax">reduces</span> the total computational cost while also <span class="search-hit mathjax">improving</span> numerical stability. We provide two instantiations by reformulating variants of SM objectives into the FD forms. Empirically, we demonstrate that our methods produce results comparable to the gradient-based counterparts while being much more computationally efficient.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2007.03317v2-abstract-full').style.display = 'none'; document.getElementById('2007.03317v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 25 November, 2020; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 7 July, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">NeurIPS 2020</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2007.03117">arXiv:2007.03117</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2007.03117">pdf</a>, <a href="https://arxiv.org/ps/2007.03117">ps</a>, <a href="https://arxiv.org/format/2007.03117">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Multi-Fidelity Bayesian <span class="search-hit mathjax">Optimization</span> via Deep Neural Networks
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+S">Shibo Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xing%2C+W">Wei Xing</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kirby%2C+M">Mike Kirby</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhe%2C+S">Shandian Zhe</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2007.03117v4-abstract-short" style="display: inline;">
        Bayesian <span class="search-hit mathjax">optimization</span> (BO) is a popular framework to&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2007.03117v4-abstract-full').style.display = 'inline'; document.getElementById('2007.03117v4-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2007.03117v4-abstract-full" style="display: none;">
        Bayesian <span class="search-hit mathjax">optimization</span> (BO) is a popular framework to <span class="search-hit mathjax">optimize</span> black-box <span class="search-hit mathjax">functions</span>. In many <span class="search-hit mathjax">applications</span>, the objective <span class="search-hit mathjax">function</span> can be evaluated at multiple fidelities to enable a trade-off between the cost and accuracy. To <span class="search-hit mathjax">reduce</span> the <span class="search-hit mathjax">optimization</span> cost, many multi-fidelity BO methods have been proposed. Despite their success, these methods either ignore or over-simplify the strong, complex correlations across the fidelities, and hence can be inefficient in estimating the objective <span class="search-hit mathjax">function</span>. To address this issue, we propose Deep Neural Network Multi-Fidelity Bayesian <span class="search-hit mathjax">Optimization</span> (DNN-MFBO) that can flexibly capture all kinds of complicated relationships between the fidelities to <span class="search-hit mathjax">improve</span> the objective <span class="search-hit mathjax">function</span> estimation and hence the <span class="search-hit mathjax">optimization</span> performance. We use sequential, fidelity-wise Gauss-Hermite quadrature and moment-matching to fulfill a mutual information-based acquisition <span class="search-hit mathjax">function</span>, which is computationally tractable and efficient. We show the advantages of our method in both synthetic benchmark datasets and real-world <span class="search-hit mathjax">applications</span> in engineering design.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2007.03117v4-abstract-full').style.display = 'none'; document.getElementById('2007.03117v4-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 10 December, 2020; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 6 July, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2007.02753">arXiv:2007.02753</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2007.02753">pdf</a>, <a href="https://arxiv.org/format/2007.02753">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        robo-gym -- An Open Source Toolkit for Distributed Deep Reinforcement Learning on Real and Simulated Robots
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Lucchi%2C+M">Matteo Lucchi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zindler%2C+F">Friedemann Zindler</a>, 
      
      <a href="/search/?searchtype=author&amp;query=M%C3%BChlbacher-Karrer%2C+S">Stephan M√ºhlbacher-Karrer</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pichler%2C+H">Horst Pichler</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2007.02753v2-abstract-short" style="display: inline;">
        &hellip;of transfer learning, it often requires a lot of additional work and fine-tuning to make the setup work effectively. In order to increase the use of DRL with real robots and <span class="search-hit mathjax">reduce</span> the gap between simulation and real world robotics, we propose an open source toolkit: robo-gym. We demonstrate a unified setup for simulation and real environments which enables&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2007.02753v2-abstract-full').style.display = 'inline'; document.getElementById('2007.02753v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2007.02753v2-abstract-full" style="display: none;">
        Applying Deep Reinforcement Learning (DRL) to complex tasks in the field of robotics has proven to be very successful in the recent years. However, most of the publications focus either on applying it to a task in simulation or to a task in a real world setup. Although there are great examples of combining the two worlds with the help of transfer learning, it often requires a lot of additional work and fine-tuning to make the setup work effectively. In order to increase the use of DRL with real robots and <span class="search-hit mathjax">reduce</span> the gap between simulation and real world robotics, we propose an open source toolkit: robo-gym. We demonstrate a unified setup for simulation and real environments which enables a seamless transfer from training in simulation to <span class="search-hit mathjax">application</span> on the robot. We showcase the capabilities and the effectiveness of the framework with two real world <span class="search-hit mathjax">applications</span> featuring industrial robots: a mobile robot and a robot arm. The distributed capabilities of the framework enable several advantages like using distributed algorithms, separating the workload of simulation and training on different physical machines as well as enabling the future opportunity to train in simulation and real world at the same time. Finally we offer an overview and comparison of robo-gym with other frequently used state-of-the-art DRL frameworks.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2007.02753v2-abstract-full').style.display = 'none'; document.getElementById('2007.02753v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 November, 2020; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 6 July, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2007.00708">arXiv:2007.00708</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2007.00708">pdf</a>, <a href="https://arxiv.org/format/2007.00708">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Learning Search Space Partition for Black-box <span class="search-hit mathjax">Optimization</span> using Monte Carlo Tree Search
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+L">Linnan Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fonseca%2C+R">Rodrigo Fonseca</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tian%2C+Y">Yuandong Tian</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2007.00708v1-abstract-short" style="display: inline;">
        High dimensional black-box <span class="search-hit mathjax">optimization</span> has broad <span class="search-hit mathjax">applications</span> but remains a challenging problem to solve. Given a set of samples $\{\vx_i, y_i\}$, building a global model (like Bayesian&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2007.00708v1-abstract-full').style.display = 'inline'; document.getElementById('2007.00708v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2007.00708v1-abstract-full" style="display: none;">
        High dimensional black-box <span class="search-hit mathjax">optimization</span> has broad <span class="search-hit mathjax">applications</span> but remains a challenging problem to solve. Given a set of samples $\{\vx_i, y_i\}$, building a global model (like Bayesian <span class="search-hit mathjax">Optimization</span> (BO)) suffers from the curse of dimensionality in the high-dimensional search space, while a greedy search may lead to sub-<span class="search-hit mathjax">optimality</span>. By recursively splitting the search space into regions with high/low <span class="search-hit mathjax">function</span> values, recent works like LaNAS shows good performance in Neural Architecture Search (NAS), <span class="search-hit mathjax">reducing</span> the sample complexity empirically. In this paper, we coin LA-MCTS that extends LaNAS to other domains. Unlike previous approaches, LA-MCTS learns the partition of the search space using a few samples and their <span class="search-hit mathjax">function</span> values in an online fashion. While LaNAS uses linear partition and performs uniform sampling in each region, our LA-MCTS adopts a nonlinear decision boundary and learns a local model to pick good candidates. If the nonlinear partition <span class="search-hit mathjax">function</span> and the local model fits well with ground-truth black-box <span class="search-hit mathjax">function</span>, then good partitions and candidates can be reached with much fewer samples. LA-MCTS serves as a \emph{meta-algorithm} by using existing black-box <span class="search-hit mathjax">optimizers</span> (e.g., BO, TuRBO) as its local models, achieving strong performance in general black-box <span class="search-hit mathjax">optimization</span> and reinforcement learning benchmarks, in particular for high-dimensional problems.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2007.00708v1-abstract-full').style.display = 'none'; document.getElementById('2007.00708v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 1 July, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2007.00324">arXiv:2007.00324</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2007.00324">pdf</a>, <a href="https://arxiv.org/format/2007.00324">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Graphics">cs.GR</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Mathematical Software">cs.MS</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        On Designing GPU Algorithms with <span class="search-hit mathjax">Applications</span> to Mesh Refinement
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+Z">Zhenghai Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tan%2C+T">Tiow-Seng Tan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ong%2C+H">Hong-Yang Ong</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2007.00324v1-abstract-short" style="display: inline;">
        We present a set of rules to guide the design of GPU algorithms. These rules are grounded on the principle of <span class="search-hit mathjax">reducing</span> waste in GPU utility to achieve good speed up. In accordance to these rules, we propose GPU algorithms for 2D constrained, 3D constrained and 3D Restricted Delaunay refinement problems respectively. Our algorithms take a 2D planar straight l&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2007.00324v1-abstract-full').style.display = 'inline'; document.getElementById('2007.00324v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2007.00324v1-abstract-full" style="display: none;">
        We present a set of rules to guide the design of GPU algorithms. These rules are grounded on the principle of <span class="search-hit mathjax">reducing</span> waste in GPU utility to achieve good speed up. In accordance to these rules, we propose GPU algorithms for 2D constrained, 3D constrained and 3D Restricted Delaunay refinement problems respectively. Our algorithms take a 2D planar straight line graph (PSLG) or 3D piecewise linear complex (PLC) $\mathcal{G}$ as input, and generate quality meshes conforming or approximating to $\mathcal{G}$. The implementation of our algorithms shows that they are the first to run an order of magnitude faster than current state-of-the-art counterparts in sequential and parallel manners while using similar numbers of Steiner points to produce triangulations of comparable qualities. It thus <span class="search-hit mathjax">reduces</span> the computing time of mesh refinement from possibly hours to a few seconds or minutes for possible use in interactive graphics <span class="search-hit mathjax">applications</span>.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2007.00324v1-abstract-full').style.display = 'none'; document.getElementById('2007.00324v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 1 July, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2007.00119">arXiv:2007.00119</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2007.00119">pdf</a>, <a href="https://arxiv.org/format/2007.00119">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Graph Neural Networks Including Sparse Interpretability
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Lin%2C+C">Chris Lin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sun%2C+G+J">Gerald J. Sun</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bulusu%2C+K+C">Krishna C. Bulusu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dry%2C+J+R">Jonathan R. Dry</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hernandez%2C+M">Marylens Hernandez</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2007.00119v1-abstract-short" style="display: inline;">
        Graph Neural Networks (GNNs) are versatile, powerful machine learning methods that enable graph structure and feature representation learning, and have <span class="search-hit mathjax">applications</span> across many domains. For&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2007.00119v1-abstract-full').style.display = 'inline'; document.getElementById('2007.00119v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2007.00119v1-abstract-full" style="display: none;">
        Graph Neural Networks (GNNs) are versatile, powerful machine learning methods that enable graph structure and feature representation learning, and have <span class="search-hit mathjax">applications</span> across many domains. For <span class="search-hit mathjax">applications</span> critically requiring interpretation, attention-based GNNs have been leveraged. However, these approaches either rely on specific model architectures or lack a joint consideration of graph structure and node features in their interpretation. Here we present a model-agnostic framework for interpreting important graph structure and node features, Graph neural networks Including SparSe inTerpretability (GISST). With any GNN model, GISST combines an attention mechanism and sparsity regularization to yield an important subgraph and node feature subset related to any graph-based task. Through a single self-attention layer, a GISST model learns an importance probability for each node feature and edge in the input graph. By including these importance probabilities in the model loss <span class="search-hit mathjax">function</span>, the probabilities are <span class="search-hit mathjax">optimized</span> end-to-end and tied to the task-specific performance. Furthermore, GISST sparsifies these importance probabilities with entropy and L1 regularization to <span class="search-hit mathjax">reduce</span> noise in the input graph topology and node features. Our GISST models achieve superior node feature and edge explanation precision in synthetic datasets, as compared to alternative interpretation approaches. Moreover, our GISST models are able to identify important graph structure in real-world datasets. We demonstrate in theory that edge feature importance and multiple edge types can be considered by incorporating them into the GISST edge probability computation. By jointly accounting for topology, node features, and edge features, GISST inherently provides simple and relevant interpretations for any GNN models and tasks.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2007.00119v1-abstract-full').style.display = 'none'; document.getElementById('2007.00119v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 June, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2006.15212">arXiv:2006.15212</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2006.15212">pdf</a>, <a href="https://arxiv.org/format/2006.15212">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Hybrid Models for Learning to Branch
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Gupta%2C+P">Prateek Gupta</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gasse%2C+M">Maxime Gasse</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Khalil%2C+E+B">Elias B. Khalil</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kumar%2C+M+P">M. Pawan Kumar</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lodi%2C+A">Andrea Lodi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bengio%2C+Y">Yoshua Bengio</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2006.15212v3-abstract-short" style="display: inline;">
        A recent Graph Neural Network (GNN) approach for learning to branch has been shown to successfully <span class="search-hit mathjax">reduce</span> the running time of branch-and-bound algorithms for Mixed Integer Linear&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2006.15212v3-abstract-full').style.display = 'inline'; document.getElementById('2006.15212v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2006.15212v3-abstract-full" style="display: none;">
        A recent Graph Neural Network (GNN) approach for learning to branch has been shown to successfully <span class="search-hit mathjax">reduce</span> the running time of branch-and-bound algorithms for Mixed Integer Linear <span class="search-hit mathjax">Programming</span> (MILP). While the GNN relies on a GPU for inference, MILP solvers are purely CPU-based. This severely limits its <span class="search-hit mathjax">application</span> as many practitioners may not have access to high-end GPUs. In this work, we ask two key questions. First, in a more realistic setting where only a CPU is available, is the GNN model still competitive? Second, can we devise an alternate computationally inexpensive model that retains the predictive power of the GNN architecture? We answer the first question in the negative, and address the second question by proposing a new hybrid architecture for efficient branching on CPU machines. The proposed architecture combines the expressive power of GNNs with computationally inexpensive multi-layer perceptrons (MLP) for branching. We evaluate our methods on four classes of MILP problems, and show that they lead to up to 26% reduction in solver running time compared to state-of-the-art methods without a GPU, while extrapolating to harder problems than it was trained on. The <span class="search-hit mathjax">code</span> for this project is publicly available at https://github.com/pg2455/Hybrid-learn2branch.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2006.15212v3-abstract-full').style.display = 'none'; document.getElementById('2006.15212v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 23 October, 2020; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 26 June, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2006.13610">arXiv:2006.13610</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2006.13610">pdf</a>, <a href="https://arxiv.org/format/2006.13610">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Signal Processing">eess.SP</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Energy Minimization in UAV-Aided Networks: Actor-Critic Learning for Constrained Scheduling <span class="search-hit mathjax">Optimization</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Yuan%2C+Y">Yaxiong Yuan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lei%2C+L">Lei Lei</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Vu%2C+T+X">Thang Xuan Vu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chatzinotas%2C+S">Symeon Chatzinotas</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sun%2C+S">Sumei Sun</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ottersten%2C+B">Bjorn Ottersten</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2006.13610v2-abstract-short" style="display: inline;">
        In unmanned aerial vehicle (UAV) <span class="search-hit mathjax">applications</span>, the UAV&#39;s limited energy supply and storage have triggered the development of intelligent energy-conserving scheduling solutions. In this paper, we investigate energy minimization for UAV-aided communication networks by jointly&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2006.13610v2-abstract-full').style.display = 'inline'; document.getElementById('2006.13610v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2006.13610v2-abstract-full" style="display: none;">
        In unmanned aerial vehicle (UAV) <span class="search-hit mathjax">applications</span>, the UAV&#39;s limited energy supply and storage have triggered the development of intelligent energy-conserving scheduling solutions. In this paper, we investigate energy minimization for UAV-aided communication networks by jointly <span class="search-hit mathjax">optimizing</span> data-transmission scheduling and UAV hovering time. The formulated problem is combinatorial and non-convex with bilinear constraints. To tackle the problem, firstly, we provide an <span class="search-hit mathjax">optimal</span> relax-and-approximate solution and develop a near-<span class="search-hit mathjax">optimal</span> algorithm. Both the proposed solutions are served as offline performance benchmarks but might not be suitable for online operation. To this end, we develop a solution from a deep reinforcement learning (DRL) aspect. The conventional RL/DRL, e.g., deep Q-learning, however, is limited in dealing with two main issues in constrained combinatorial <span class="search-hit mathjax">optimization</span>, i.e., exponentially increasing action space and infeasible actions. The novelty of solution development lies in handling these two issues. To address the former, we propose an actor-critic-based deep stochastic online scheduling (AC-DSOS) algorithm and develop a set of approaches to confine the action space. For the latter, we design a tailored reward <span class="search-hit mathjax">function</span> to guarantee the solution feasibility. Numerical results show that, by consuming equal magnitude of time, AC-DSOS is able to provide feasible solutions and saves 29.94% energy compared with a conventional deep actor-critic method. Compared to the developed near-<span class="search-hit mathjax">optimal</span> algorithm, AC-DSOS consumes around 10% higher energy but <span class="search-hit mathjax">reduces</span> the computational time from minute-level to millisecond-level.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2006.13610v2-abstract-full').style.display = 'none'; document.getElementById('2006.13610v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 29 June, 2020; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 24 June, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">12 pages, 11 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2006.13261">arXiv:2006.13261</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2006.13261">pdf</a>, <a href="https://arxiv.org/format/2006.13261">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computational Engineering, Finance, and Science">cs.CE</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1109/JERM.2020.3043383">10.1109/JERM.2020.3043383 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Fast <span class="search-hit mathjax">Optimization</span> of Temperature Focusing in Hyperthermia Treatment of Sub-Superficial Tumors
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Gaffoglio%2C+R">Rossella Gaffoglio</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Righero%2C+M">Marco Righero</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Giordanengo%2C+G">Giorgio Giordanengo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zucchi%2C+M">Marcello Zucchi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Vecchi%2C+G">Giuseppe Vecchi</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2006.13261v2-abstract-short" style="display: inline;">
        &hellip;of an antenna array equipped with a proper cooling system (the water bolus) to avoid overheating of the skin. In patient-specific treatment planning, antenna feedings are <span class="search-hit mathjax">optimized</span> to maximize the specific absorption rate (SAR) inside the tumor, or to directly maximize the temperature there, involving a higher numerical cost. We present here a method to effe&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2006.13261v2-abstract-full').style.display = 'inline'; document.getElementById('2006.13261v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2006.13261v2-abstract-full" style="display: none;">
        Microwave hyperthermia aims at selectively heating cancer cells to a supra-physiological temperature. For non-superficial tumors, this can be achieved by means of an antenna array equipped with a proper cooling system (the water bolus) to avoid overheating of the skin. In patient-specific treatment planning, antenna feedings are <span class="search-hit mathjax">optimized</span> to maximize the specific absorption rate (SAR) inside the tumor, or to directly maximize the temperature there, involving a higher numerical cost. We present here a method to effect a low-complexity temperature-based planning. It arises from recognizing that SAR and temperature have shifted peaks due to thermal boundary conditions at the water bolus and for physiological effects like air flow in respiratory ducts. In our method, temperature focusing on the tumor is achieved via a SAR-based <span class="search-hit mathjax">optimization</span> of the antenna excitations, but <span class="search-hit mathjax">optimizing</span> its target to account for the cooling effects. The temperature <span class="search-hit mathjax">optimization</span> process is turned into finding a SAR peak position that maximizes the chosen temperature objective <span class="search-hit mathjax">function</span>. <span class="search-hit mathjax">Application</span> of this method to the 3D head and neck region provides a temperature coverage that is consistently better than that obtained with SAR-<span class="search-hit mathjax">optimization</span> alone, also considering uncertainties in thermal parameters. This <span class="search-hit mathjax">improvement</span> is obtained by solving the bioheat equation a <span class="search-hit mathjax">reduced</span> number of times, avoiding its inclusion in a global <span class="search-hit mathjax">optimization</span> process.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2006.13261v2-abstract-full').style.display = 'none'; document.getElementById('2006.13261v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 December, 2020; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 23 June, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">7 pages, 6 figure, accepted for publication in IEEE Journal of Electromagnetics, RF and Microwaves in Medicine and Biology</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2006.12940">arXiv:2006.12940</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2006.12940">pdf</a>, <a href="https://arxiv.org/format/2006.12940">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Neural and Evolutionary Computing">cs.NE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Signal Processing">eess.SP</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Particle Swarm <span class="search-hit mathjax">Optimization</span> for Energy Disaggregation in Industrial and Commercial Buildings
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Brucke%2C+K">Karoline Brucke</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Arens%2C+S">Stefan Arens</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Telle%2C+J">Jan-Simon Telle</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sunke%7ESchl%C3%BCters"> Sunke~Schl√ºters</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hanke%2C+B">Benedikt Hanke</a>, 
      
      <a href="/search/?searchtype=author&amp;query=von+Maydell%2C+K">Karsten von Maydell</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Agert%2C+C">Carsten Agert</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2006.12940v1-abstract-short" style="display: inline;">
        This paper provides a formalization of the energy disaggregation problem for particle swarm <span class="search-hit mathjax">optimization</span> and shows the successful&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2006.12940v1-abstract-full').style.display = 'inline'; document.getElementById('2006.12940v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2006.12940v1-abstract-full" style="display: none;">
        This paper provides a formalization of the energy disaggregation problem for particle swarm <span class="search-hit mathjax">optimization</span> and shows the successful <span class="search-hit mathjax">application</span> of particle swarm <span class="search-hit mathjax">optimization</span> for disaggregation in a multi-tenant commercial building. The developed mathmatical description of the disaggregation problem using a state changes matrix belongs to the group of non-event based methods for energy disaggregation. This work includes the development of an objective <span class="search-hit mathjax">function</span> in the power domain and the description of position and velocity of each particle in a high dimensional state space. For the particle swarm <span class="search-hit mathjax">optimization</span>, four adaptions have been applied to <span class="search-hit mathjax">improve</span> the results of disaggregation, increase the robustness of the <span class="search-hit mathjax">optimizer</span> regarding local optima and <span class="search-hit mathjax">reduce</span> the computational time. The adaptions are varying movement constants, shaking of particles, framing and an early stopping criterion. In this work we use two unlabelled power datasets with a granularity of 1 s. Therefore, the results are validated in the power domain in which good results regarding multiple error measures like root mean squared error or the percentage energy error can be shown.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2006.12940v1-abstract-full').style.display = 'none'; document.getElementById('2006.12940v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 23 June, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">10 pages, 13 figures, 3 tables</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        
          <span class="has-text-black-bis has-text-weight-semibold">MSC Class:</span>
          68W50; 68W15; 90C90
        

        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2006.12838">arXiv:2006.12838</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2006.12838">pdf</a>, <a href="https://arxiv.org/format/2006.12838">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computational Physics">physics.comp-ph</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computational Geometry">cs.CG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Fluid Dynamics">physics.flu-dyn</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Analytic Solution to the Piecewise Linear Interface Construction Problem and its <span class="search-hit mathjax">Application</span> in Curvature Calculation for Volume-of-Fluid Simulation <span class="search-hit mathjax">Codes</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Lehmann%2C+M">Moritz Lehmann</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gekle%2C+S">Stephan Gekle</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2006.12838v2-abstract-short" style="display: inline;">
        &hellip;around in literature since 1984 and iterative solutions to it have been used as part of piecewise linear interface construction (PLIC) in computational fluid dynamics simulation <span class="search-hit mathjax">codes</span> ever since. In many cases, PLIC is the bottleneck of these simulations regarding compute time, so a faster, analytic solution to the plane-cube intersection would greatly&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2006.12838v2-abstract-full').style.display = 'inline'; document.getElementById('2006.12838v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2006.12838v2-abstract-full" style="display: none;">
        The plane-cube intersection problem has been around in literature since 1984 and iterative solutions to it have been used as part of piecewise linear interface construction (PLIC) in computational fluid dynamics simulation <span class="search-hit mathjax">codes</span> ever since. In many cases, PLIC is the bottleneck of these simulations regarding compute time, so a faster, analytic solution to the plane-cube intersection would greatly <span class="search-hit mathjax">reduce</span> compute time for such simulations. We derive an analytic solution for all intersection cases and compare it to the one previous solution from Scardovelli and Zaleski (Ruben Scardovelli and Stephane Zaleski. &#34;Analytical relations connecting linear interfaces and volume fractions in rectangular grids&#34;. In: Journal of Computational Physics 164.1 (2000), pp. 228-237.), which we further <span class="search-hit mathjax">improve</span> to include edge cases and micro-<span class="search-hit mathjax">optimize</span> to <span class="search-hit mathjax">reduce</span> arithmetic operations and branching. We then extend our comparison regarding compute time and accuracy to include two different iterative solutions as well. We find that the best choice depends on the employed hardware platform: on the CPU, Newton-Raphson is fastest with vectorization while analytic solutions perform better without. The reason for this is that vectorization instruction sets do not include trigonometric <span class="search-hit mathjax">functions</span> as used in the analytic solutions. On the GPU, the fastest method is our <span class="search-hit mathjax">optimized</span> version of the analytic SZ solution. We finally provide details on one of the <span class="search-hit mathjax">applications</span> of PLIC: curvature calculation for the Volume-of-Fluid model used for free surface fluid simulations in combination with the lattice Boltzmann method.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2006.12838v2-abstract-full').style.display = 'none'; document.getElementById('2006.12838v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 18 February, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 23 June, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">18 pages, 6 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2006.12735">arXiv:2006.12735</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2006.12735">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1109/EICT.2015.7392017">10.1109/EICT.2015.7392017 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Helping <span class="search-hit mathjax">Software</span> Developers through Offline Repository Based API Searching in Data MiningIntegrated Environment
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ashraf%2C+R+U">Ratul Uddin Ashraf</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Das%2C+A">Anujoy Das</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rahman%2C+Z">Ziaur Rahman</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bahar%2C+A+N">Ali Newaz Bahar</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rubaiyeat%2C+H+A">Husne Ara Rubaiyeat</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2006.12735v1-abstract-short" style="display: inline;">
        <span class="search-hit mathjax">Software</span> development is getting changed so rapidly. It will be highly benefited if we can accelerate&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2006.12735v1-abstract-full').style.display = 'inline'; document.getElementById('2006.12735v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2006.12735v1-abstract-full" style="display: none;">
        <span class="search-hit mathjax">Software</span> development is getting changed so rapidly. It will be highly benefited if we can accelerate <span class="search-hit mathjax">software</span> development process by guiding developers. Appropriate guidelines and accurate recommendations to developers during development process can <span class="search-hit mathjax">reduce</span> <span class="search-hit mathjax">software</span> development expenses, as well as can save valuable times of developers. There are a number of approaches to speed up the <span class="search-hit mathjax">software</span> development process. It can be done through <span class="search-hit mathjax">code</span> assistance tools that help developers by recommending relevant items from searching particular repository of <span class="search-hit mathjax">Application</span> <span class="search-hit mathjax">Programming</span> Interface (API). Some approaches are based on online searching that have some drawbacks due to request and response latency as it has to deal with the extra-large files in a server. Developers generally uses previously completed resources as well as libraries or frameworks to generate relevant snippets which are supplied by the referral repository of APIs. Developers find it hard to choose the appropriate methods as there are thousands of methods in which some are not properly documented. In this paper we have proposed a concept and its respective framework to guide developers that suggests relevant API methods from an offline mined repository. From the investigation we made, we can say that our approach works much better than some of the existing approaches.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2006.12735v1-abstract-full').style.display = 'none'; document.getElementById('2006.12735v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 21 June, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">4 Pages, 4 Figures 3 Tables</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          K.6.3
        
      </p>
    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        2015 2nd International Conference on Electrical Information and Communication Technologies (EICT)
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2006.11401">arXiv:2006.11401</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2006.11401">pdf</a>, <a href="https://arxiv.org/format/2006.11401">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        DEED: A General Quantization Scheme for Communication Efficiency in Bits
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ye%2C+T">Tian Ye</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xiao%2C+P">Peijun Xiao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sun%2C+R">Ruoyu Sun</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2006.11401v1-abstract-short" style="display: inline;">
        In distributed <span class="search-hit mathjax">optimization</span>, a popular technique to <span class="search-hit mathjax">reduce</span> communication is quantization. In this paper, we provide a general analysis framework for inexact gradient descent that is <span class="search-hit mathjax">applicable</span> to quantization schemes. We also propose a quantization scheme Double Encoding and Erro&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2006.11401v1-abstract-full').style.display = 'inline'; document.getElementById('2006.11401v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2006.11401v1-abstract-full" style="display: none;">
        In distributed <span class="search-hit mathjax">optimization</span>, a popular technique to <span class="search-hit mathjax">reduce</span> communication is quantization. In this paper, we provide a general analysis framework for inexact gradient descent that is <span class="search-hit mathjax">applicable</span> to quantization schemes. We also propose a quantization scheme Double Encoding and Error Diminishing (DEED). DEED can achieve small communication complexity in three settings: frequent-communication large-memory, frequent-communication small-memory, and infrequent-communication (e.g. federated learning). More specifically, in the frequent-communication large-memory setting, DEED can be easily combined with Nesterov&#39;s method, so that the total number of bits required is $\tilde{O}( \sqrtŒ∫ \log 1/Œµ)$, where $\tilde{O}$ hides numerical constant and $\log Œ∫$ factors. In the frequent-communication small-memory setting, DEED combined with SGD only requires $\tilde{O}( Œ∫\log 1/Œµ)$ number of bits in the interpolation regime. In the infrequent communication setting, DEED combined with Federated averaging requires a smaller total number of bits than Federated Averaging. All these algorithms converge at the same rate as their non-quantized versions, while using a smaller number of bits.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2006.11401v1-abstract-full').style.display = 'none'; document.getElementById('2006.11401v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 19 June, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2020.
      
    </p>
    

    
      <p class="comments is-size-7">
        

        
          <span class="has-text-black-bis has-text-weight-semibold">MSC Class:</span>
          68Q11; 90C25; 68W15
        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          G.1.6
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2006.10123">arXiv:2006.10123</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2006.10123">pdf</a>, <a href="https://arxiv.org/format/2006.10123">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A block coordinate descent <span class="search-hit mathjax">optimizer</span> for classification problems exploiting convexity
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Patel%2C+R+G">Ravi G. Patel</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Trask%2C+N+A">Nathaniel A. Trask</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gulian%2C+M+A">Mamikon A. Gulian</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cyr%2C+E+C">Eric C. Cyr</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2006.10123v1-abstract-short" style="display: inline;">
        Second-order <span class="search-hit mathjax">optimizers</span> hold intriguing potential for deep learning, but suffer from increased cost and sensitivity to the non-convexity of the loss surface as compared to gradient-based approaches. We introduce a coordinate descent method to train deep neural networks for classification tasks that exploits global convexity of the cross-entropy loss in the w&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2006.10123v1-abstract-full').style.display = 'inline'; document.getElementById('2006.10123v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2006.10123v1-abstract-full" style="display: none;">
        Second-order <span class="search-hit mathjax">optimizers</span> hold intriguing potential for deep learning, but suffer from increased cost and sensitivity to the non-convexity of the loss surface as compared to gradient-based approaches. We introduce a coordinate descent method to train deep neural networks for classification tasks that exploits global convexity of the cross-entropy loss in the weights of the linear layer. Our hybrid Newton/Gradient Descent (NGD) method is consistent with the interpretation of hidden layers as providing an adaptive basis and the linear layer as providing an <span class="search-hit mathjax">optimal</span> fit of the basis to data. By alternating between a second-order method to find globally <span class="search-hit mathjax">optimal</span> parameters for the linear layer and gradient descent to train the hidden layers, we ensure an <span class="search-hit mathjax">optimal</span> fit of the adaptive basis to data throughout training. The <span class="search-hit mathjax">size</span> of the Hessian in the second-order step scales only with the number weights in the linear layer and not the depth and width of the hidden layers; furthermore, the approach is <span class="search-hit mathjax">applicable</span> to arbitrary hidden layer architecture. Previous work applying this adaptive basis perspective to regression problems demonstrated significant <span class="search-hit mathjax">improvements</span> in accuracy at <span class="search-hit mathjax">reduced</span> training cost, and this work can be viewed as an extension of this approach to classification problems. We first prove that the resulting Hessian matrix is symmetric semi-definite, and that the Newton step realizes a global minimizer. By studying classification of manufactured two-dimensional point cloud data, we demonstrate both an <span class="search-hit mathjax">improvement</span> in validation error and a striking qualitative difference in the basis <span class="search-hit mathjax">functions</span> encoded in the hidden layer when trained using NGD. <span class="search-hit mathjax">Application</span> to image classification benchmarks for both dense and convolutional architectures reveals <span class="search-hit mathjax">improved</span> training accuracy, suggesting possible gains of second-order methods over gradient descent.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2006.10123v1-abstract-full').style.display = 'none'; document.getElementById('2006.10123v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 June, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">10 pages, 4 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2006.09361">arXiv:2006.09361</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2006.09361">pdf</a>, <a href="https://arxiv.org/format/2006.09361">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Gradient Free Minimax <span class="search-hit mathjax">Optimization</span>: Variance Reduction and Faster Convergence
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Xu%2C+T">Tengyu Xu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+Z">Zhe Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liang%2C+Y">Yingbin Liang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Poor%2C+H+V">H. Vincent Poor</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2006.09361v3-abstract-short" style="display: inline;">
        Many important machine learning <span class="search-hit mathjax">applications</span> amount to solving minimax&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2006.09361v3-abstract-full').style.display = 'inline'; document.getElementById('2006.09361v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2006.09361v3-abstract-full" style="display: none;">
        Many important machine learning <span class="search-hit mathjax">applications</span> amount to solving minimax <span class="search-hit mathjax">optimization</span> problems, and in many cases there is no access to the gradient information, but only the <span class="search-hit mathjax">function</span> values. In this paper, we focus on such a gradient-free setting, and consider the nonconvex-strongly-concave minimax stochastic <span class="search-hit mathjax">optimization</span> problem. In the literature, various zeroth-order (i.e., gradient-free) minimax methods have been proposed, but none of them achieve the potentially feasible computational complexity of $\mathcal{O}(Œµ^{-3})$ suggested by the stochastic nonconvex minimization theorem. In this paper, we adopt the variance reduction technique to design a novel zeroth-order variance <span class="search-hit mathjax">reduced</span> gradient descent ascent (ZO-VRGDA) algorithm. We show that the ZO-VRGDA algorithm achieves the best known query complexity of $\mathcal{O}(Œ∫(d_1 + d_2)Œµ^{-3})$, which outperforms all previous complexity bound by orders of magnitude, where $d_1$ and $d_2$ denote the dimensions of the <span class="search-hit mathjax">optimization</span> variables and $Œ∫$ denotes the condition number. In particular, with a new analysis technique that we develop, our result does not rely on a diminishing or accuracy-dependent stepsize usually required in the existing methods. To our best knowledge, this is the first study of zeroth-order minimax <span class="search-hit mathjax">optimization</span> with variance reduction. Experimental results on the black-box distributional robust <span class="search-hit mathjax">optimization</span> problem demonstrates the advantageous performance of our new algorithm.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2006.09361v3-abstract-full').style.display = 'none'; document.getElementById('2006.09361v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 March, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 16 June, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">This is an updated version to replace the previous arXiv post titled "Enhanced First and Zeroth Order Variance Reduced Algorithms for Min-Max <span class="search-hit mathjax">Optimization</span>" on 17 Jun, 2020</span>
    </p>
    

    

    
  </li>

</ol>


  <nav class="pagination is-small is-centered breathe-horizontal" role="navigation" aria-label="pagination">
    
    <a href=""
      class="pagination-previous is-invisible">Previous
    </a>
    
    
      <a href="/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=%28code+OR+program+OR+software+OR+application%29+AND+%28optimize+OR+optimizing+OR+optimization+OR+improve+OR+improving+OR+improvement+OR+automated+OR+automatically+OR+reduce+OR+reducing%29+AND+%28functional+OR+functionality+OR+size+OR+slimming+OR+bloat+OR+debloating%29&amp;terms-0-field=all&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=200&amp;order=-announced_date_first&amp;start=200"
        class="pagination-next" >Next
      </a>
    
    <ul class="pagination-list">

      <li>
        <a href="/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=%28code+OR+program+OR+software+OR+application%29+AND+%28optimize+OR+optimizing+OR+optimization+OR+improve+OR+improving+OR+improvement+OR+automated+OR+automatically+OR+reduce+OR+reducing%29+AND+%28functional+OR+functionality+OR+size+OR+slimming+OR+bloat+OR+debloating%29&amp;terms-0-field=all&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=200&amp;order=-announced_date_first&amp;start=0"
          class="pagination-link is-current"
          aria-label="Goto page 1">1
        </a>
      </li>

      
        
        <li>
          <a href="/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=%28code+OR+program+OR+software+OR+application%29+AND+%28optimize+OR+optimizing+OR+optimization+OR+improve+OR+improving+OR+improvement+OR+automated+OR+automatically+OR+reduce+OR+reducing%29+AND+%28functional+OR+functionality+OR+size+OR+slimming+OR+bloat+OR+debloating%29&amp;terms-0-field=all&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=200&amp;order=-announced_date_first&amp;start=200"
            class="pagination-link "
            aria-label="Page 2"
            aria-current="page">2
          </a>
        </li>
        
        <li>
          <a href="/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=%28code+OR+program+OR+software+OR+application%29+AND+%28optimize+OR+optimizing+OR+optimization+OR+improve+OR+improving+OR+improvement+OR+automated+OR+automatically+OR+reduce+OR+reducing%29+AND+%28functional+OR+functionality+OR+size+OR+slimming+OR+bloat+OR+debloating%29&amp;terms-0-field=all&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=200&amp;order=-announced_date_first&amp;start=400"
            class="pagination-link "
            aria-label="Page 3"
            aria-current="page">3
          </a>
        </li>
        
        <li>
          <a href="/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=%28code+OR+program+OR+software+OR+application%29+AND+%28optimize+OR+optimizing+OR+optimization+OR+improve+OR+improving+OR+improvement+OR+automated+OR+automatically+OR+reduce+OR+reducing%29+AND+%28functional+OR+functionality+OR+size+OR+slimming+OR+bloat+OR+debloating%29&amp;terms-0-field=all&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=200&amp;order=-announced_date_first&amp;start=600"
            class="pagination-link "
            aria-label="Page 4"
            aria-current="page">4
          </a>
        </li>
        
        <li>
          <a href="/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=%28code+OR+program+OR+software+OR+application%29+AND+%28optimize+OR+optimizing+OR+optimization+OR+improve+OR+improving+OR+improvement+OR+automated+OR+automatically+OR+reduce+OR+reducing%29+AND+%28functional+OR+functionality+OR+size+OR+slimming+OR+bloat+OR+debloating%29&amp;terms-0-field=all&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=200&amp;order=-announced_date_first&amp;start=800"
            class="pagination-link "
            aria-label="Page 5"
            aria-current="page">5
          </a>
        </li>
        
      
    </ul>
  </nav>
  

    
  

      <div class="is-hidden-tablet">
        <!-- feedback for mobile only -->
        <span class="help" style="display: inline-block;"><a href="https://github.com/arXiv/arxiv-search/releases">Search v0.5.6 released 2020-02-24</a>&nbsp;&nbsp;</span>
        <button class="button is-small" id="feedback-button">Feedback?</button>
      </div>
    </div>

  </main>
  <footer>
    
    <div class="columns is-desktop" role="navigation" aria-label="Secondary">
  <!-- MetaColumn 1 -->
  <div class="column">
    <div class="columns">
      <div class="column">
        <ul class="nav-spaced">
          <li><a href="https://arxiv.org/about">About</a></li>
          <li><a href="https://arxiv.org/help">Help</a></li>
        </ul>
      </div>
      <div class="column">
        <ul class="nav-spaced">
          <li>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
            <a href="https://arxiv.org/help/contact"> Contact</a>
          </li>
          <li>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
            <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
          </li>
        </ul>
      </div>
    </div>
  </div> <!-- end MetaColumn 1 -->
  <!-- MetaColumn 2 -->
  <div class="column">
    <div class="columns">
      <div class="column">
        <ul class="nav-spaced">
          <li><a href="https://arxiv.org/help/license">Copyright</a></li>
          <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
        </ul>
      </div>
      <div class="column sorry-app-links">
        <ul class="nav-spaced">
          <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
          <li>
            <p class="help">
              <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
              Get status notifications via
              <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
              or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
            </p>
          </li>
        </ul>
      </div>
    </div>
  </div> <!-- end MetaColumn 2 -->
</div>
    
  </footer>
  </body>
</html>