
Line wrapï¿¼
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<!-- new favicon config and versions by realfavicongenerator.net -->
<link rel="apple-touch-icon" sizes="180x180" href="https://static.arxiv.org/static/base/0.17.2.1/images/icons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://static.arxiv.org/static/base/0.17.2.1/images/icons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://static.arxiv.org/static/base/0.17.2.1/images/icons/favicon-16x16.png">
<link rel="manifest" href="https://static.arxiv.org/static/base/0.17.2.1/images/icons/site.webmanifest">
<link rel="mask-icon" href="https://static.arxiv.org/static/base/0.17.2.1/images/icons/safari-pinned-tab.svg" color="#b31b1b">
<link rel="shortcut icon" href="https://static.arxiv.org/static/base/0.17.2.1/images/icons/favicon.ico">
<meta name="msapplication-TileColor" content="#b31b1b">
<meta name="msapplication-config" content="images/icons/browserconfig.xml">
<meta name="theme-color" content="#b31b1b">
<!-- end favicon config -->
<title>Advanced Search | arXiv e-print repository</title>
<script defer src="https://static.arxiv.org/static/base/0.17.2.1/fontawesome-free-5.11.2-web/js/all.js"></script>
<link rel="stylesheet" href="https://static.arxiv.org/static/base/0.17.2.1/css/arxivstyle.css" />
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    messageStyle: "none",
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true,
      ignoreClass: '.*',
      processClass: 'mathjax.*'
    },
    TeX: {
        extensions: ["AMSmath.js", "AMSsymbols.js", "noErrors.js"],
        noErrors: {
          inlineDelimiters: ["$","$"],
          multiLine: false,
          style: {
            "font-size": "normal",
            "border": ""
          }
        }
    },
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>
<script src='//static.arxiv.org/MathJax-2.7.3/MathJax.js'></script>
<script src="https://static.arxiv.org/static/base/0.17.2.1/js/notification.js"></script>

    
  <link rel="stylesheet" href="https://static.arxiv.org/static/search/0.5.6/css/bulma-tooltip.min.css" />
  <link rel="stylesheet" href="https://static.arxiv.org/static/search/0.5.6/css/search.css" />
  <script
    src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
    integrity="sha256-k2WSCIexGzOj3Euiig+TlR8gA0EmPjuc79OEeY5L45g="
    crossorigin="anonymous"></script>

  <script src="https://static.arxiv.org/static/search/0.5.6/js/fieldset.js"></script>
  <style>
  radio#cf-customfield_11400 {
    display: none;
  }
  </style>
  <script type="text/javascript" src="https://arxiv-org.atlassian.net/s/d41d8cd98f00b204e9800998ecf8427e-T/-tqqyqk/b/20/a44af77267a987a660377e5c46e0fb64/_/download/batch/com.atlassian.jira.collector.plugin.jira-issue-collector-plugin:issuecollector/com.atlassian.jira.collector.plugin.jira-issue-collector-plugin:issuecollector.js?locale=en-US&collectorId=3b3dcb4c"></script>

    <script type="text/javascript">
    window.ATL_JQ_PAGE_PROPS =  {
    	"triggerFunction": function(showCollectorDialog) {
    		//Requires that jQuery is available!
    		$("#feedback-button").click(function(e) {
    			e.preventDefault();
    			showCollectorDialog();
    		});
    	},
      fieldValues: {
        "components": ["16000"],  // Search component.
        "versions": ["14260"],  // Release search-0.5.6
        "customfield_11401": window.location.href
      }
    };
    </script>

    <!-- Pendo -->
    <script>
     (function(apiKey){
         (function(p,e,n,d,o){var v,w,x,y,z;o=p[d]=p[d]||{};o._q=[];
             v=['initialize','identify','updateOptions','pageLoad'];for(w=0,x=v.length;w<x;++w)(function(m){
                 o[m]=o[m]||function(){o._q[m===v[0]?'unshift':'push']([m].concat([].slice.call(arguments,0)));};})(v[w]);
             y=e.createElement(n);y.async=!0;y.src='https://content.analytics.arxiv.org/agent/static/'+apiKey+'/pendo.js';
             z=e.getElementsByTagName(n)[0];z.parentNode.insertBefore(y,z);})(window,document,'script','pendo');

         // Call this whenever information about your visitors becomes available
         // Please use Strings, Numbers, or Bools for value types.
         pendo.initialize({
             visitor: {
                 id:              'VISITOR-UNIQUE-ID'   // Required if user is logged in
                 // email:        // Recommended if using Pendo Feedback, or NPS Email
                 // full_name:    // Recommended if using Pendo Feedback
                 // role:         // Optional

                 // You can add any additional visitor level key-values here,
                 // as long as it's not one of the above reserved names.
             },

             account: {
                 id:           'ACCOUNT-UNIQUE-ID' // Highly recommended
                 // name:         // Optional
                 // is_paying:    // Recommended if using Pendo Feedback
                 // monthly_value:// Recommended if using Pendo Feedback
                 // planLevel:    // Optional
                 // planPrice:    // Optional
                 // creationDate: // Optional

                 // You can add any additional account level key-values here,
                 // as long as it's not one of the above reserved names.
             }
         });
     })('d6494389-b427-4103-7c76-03182ecc8e60');
    </script>
    <!-- End Pendo -->


  </head>
  <body>
  
  
  <header><a href="#main-container" class="is-sr-only">Skip to main content</a>
    
    <!-- contains Cornell logo and sponsor statement -->
<div class="attribution level is-marginless" role="banner">
  <div class="level-left">
    <a class="level-item" href="https://cornell.edu/"><img src="https://static.arxiv.org/static/base/0.17.2.1/images/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" aria-label="logo" /></a>
  </div>
  <div class="level-right is-marginless"><p class="sponsors level-item is-marginless"><a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a></p></div>
</div>
<!-- contains arXiv identity and search bar -->
<div class="identity level is-marginless">
  <div class="level-left">
    <div class="level-item">
      <a class="arxiv" href="https://arxiv.org/" aria-label="arxiv-logo"><img src="https://static.arxiv.org/static/base/0.17.2.1/images/arxiv-logo-web.svg" alt="arXiv" aria-label="logo" width="85" /></a>
    </div>
  </div>
  
  <div class="search-block level-right">
    <form class="level-item mini-search" method="GET" action="https://arxiv.org/search">
      <div class="field has-addons">
        <div class="control">
          <input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" />
          <p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
        </div>
        <div class="control">
          <div class="select is-small">
            <select name="searchtype" aria-label="Field to search">
              <option value="all" selected="selected">All fields</option>
              <option value="title">Title</option>
              <option value="author">Author</option>
              <option value="abstract">Abstract</option>
              <option value="comments">Comments</option>
              <option value="journal_ref">Journal reference</option>
              <option value="acm_class">ACM classification</option>
              <option value="msc_class">MSC classification</option>
              <option value="report_num">Report number</option>
              <option value="paper_id">arXiv identifier</option>
              <option value="doi">DOI</option>
              <option value="orcid">ORCID</option>
              <option value="author_id">arXiv author ID</option>
              <option value="help">Help pages</option>
              <option value="full_text">Full text</option>
            </select>
          </div>
        </div>
        <input type="hidden" name="source" value="header">
        <button class="button is-small is-cul-darker">Search</button>
      </div>
    </form>
  </div>
</div> <!-- closes identity -->

<div class="container">
    <div class="user-tools is-size-7 has-text-right has-text-weight-bold" role="navigation" aria-label="User menu">
      <a href="https://arxiv.org/login">Login</a>
    </div>
</div>
    
  </header>
  <main class="container" id="main-container">
    


    
  <div class="level is-marginless">
    <div class="level-left">
      <h1 class="title is-clearfix">
    
        Showing 1&ndash;200 of 1,268 results
    
</h1>
    </div>
    <div class="level-right is-hidden-mobile">
      <!-- feedback for mobile is moved to footer -->
      <span class="help" style="display: inline-block;"><a href="https://github.com/arXiv/arxiv-search/releases">Search v0.5.6 released 2020-02-24</a>&nbsp;&nbsp;</span>
      <button class="button is-small" id="feedback-button">Feedback?</button>
    </div>
  </div>
    <div class="content">
      
  
    

    <div class="columns">
      <div class="column is-two-thirds-tablet">
        <p style="margin-bottom: .5em">Query: <a href="/search/advanced?terms-0-operator=AND&amp;terms-0-term=%28code+OR+program+OR+software+OR+application%29+AND+%28optimize+OR+optimizing+OR+optimization+OR+improve+OR+improving+OR+improvement+OR+automated+OR+automatically+OR+reduce+OR+reducing%29+AND+%28time+OR+runtime+OR+speed+OR+speedup+OR+fast+OR+faster%29&amp;terms-0-field=all&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=200&amp;order=-announced_date_first">order: -announced_date_first; size: 200; classification: Computer Science (cs); include_cross_list: True; terms: AND all=(code OR program OR software OR application) AND (optimize OR optimizing OR optimization OR improve OR improving OR improvement OR automated OR automatically OR reduce OR reducing) AND (time OR runtime OR speed OR speedup OR fast OR faster)</a></p>
        <div class="buttons">
          <a class="button is-link" href="/search/advanced?terms-0-operator=AND&amp;terms-0-term=%28code+OR+program+OR+software+OR+application%29+AND+%28optimize+OR+optimizing+OR+optimization+OR+improve+OR+improving+OR+improvement+OR+automated+OR+automatically+OR+reduce+OR+reducing%29+AND+%28time+OR+runtime+OR+speed+OR+speedup+OR+fast+OR+faster%29&amp;terms-0-field=all&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=200&amp;order=-announced_date_first">Refine query</a><a class="button" href="/search/advanced">New search</a>
        </div>
      </div>
      <div class="column is-one-third-tablet is-hidden-mobile">
        <p class="has-text-right" style="margin-top: 1em">
          
          <a href="/search/?order=-announced_date_first&amp;size=200">Simple Search</a>
          
        </p>
      </div>
    </div>

    
        
<div class="level breathe-horizontal">
  <div class="level-left">
    <form method="GET" action="/search/advanced">
      <div style="display: none;">
        
          
            <input id="advanced" name="advanced" type="hidden" value="">
          
        
          
            <ul id="terms"><li><label for="terms-0">Terms-0</label> <table id="terms-0"><tr><th><label for="terms-0-term">Search term...</label></th><td><input id="terms-0-term" name="terms-0-term" type="text" value="(code OR program OR software OR application) AND (optimize OR optimizing OR optimization OR improve OR improving OR improvement OR automated OR automatically OR reduce OR reducing) AND (time OR runtime OR speed OR speedup OR fast OR faster)"></td></tr><tr><th><label for="terms-0-operator">Operator</label></th><td><select id="terms-0-operator" name="terms-0-operator"><option selected value="AND">AND</option><option value="OR">OR</option><option value="NOT">NOT</option></select></td></tr><tr><th><label for="terms-0-field">Field</label></th><td><select id="terms-0-field" name="terms-0-field"><option value="title">Title</option><option value="author">Author(s)</option><option value="abstract">Abstract</option><option value="comments">Comments</option><option value="journal_ref">Journal reference</option><option value="acm_class">ACM classification</option><option value="msc_class">MSC classification</option><option value="report_num">Report number</option><option value="paper_id">arXiv identifier</option><option value="cross_list_category">Cross-list category</option><option value="doi">DOI</option><option value="orcid">ORCID</option><option value="author_id">arXiv author ID</option><option selected value="all">All fields</option></select></td></tr></table></li></ul>
          
        
          
            <table id="classification"><tr><th><label for="classification-computer_science">Computer Science (cs)</label></th><td><input checked id="classification-computer_science" name="classification-computer_science" type="checkbox" value="y"></td></tr><tr><th><label for="classification-economics">Economics (econ)</label></th><td><input id="classification-economics" name="classification-economics" type="checkbox" value="y"></td></tr><tr><th><label for="classification-eess">Electrical Engineering and Systems Science (eess)</label></th><td><input id="classification-eess" name="classification-eess" type="checkbox" value="y"></td></tr><tr><th><label for="classification-mathematics">Mathematics (math)</label></th><td><input id="classification-mathematics" name="classification-mathematics" type="checkbox" value="y"></td></tr><tr><th><label for="classification-physics">Physics</label></th><td><input id="classification-physics" name="classification-physics" type="checkbox" value="y"></td></tr><tr><th><label for="classification-physics_archives">Physics Archives</label></th><td><select id="classification-physics_archives" name="classification-physics_archives"><option selected value="all">all</option><option value="astro-ph">astro-ph</option><option value="cond-mat">cond-mat</option><option value="gr-qc">gr-qc</option><option value="hep-ex">hep-ex</option><option value="hep-lat">hep-lat</option><option value="hep-ph">hep-ph</option><option value="hep-th">hep-th</option><option value="math-ph">math-ph</option><option value="nlin">nlin</option><option value="nucl-ex">nucl-ex</option><option value="nucl-th">nucl-th</option><option value="physics">physics</option><option value="quant-ph">quant-ph</option></select></td></tr><tr><th><label for="classification-q_biology">Quantitative Biology (q-bio)</label></th><td><input id="classification-q_biology" name="classification-q_biology" type="checkbox" value="y"></td></tr><tr><th><label for="classification-q_finance">Quantitative Finance (q-fin)</label></th><td><input id="classification-q_finance" name="classification-q_finance" type="checkbox" value="y"></td></tr><tr><th><label for="classification-statistics">Statistics (stat)</label></th><td><input id="classification-statistics" name="classification-statistics" type="checkbox" value="y"></td></tr><tr><th><label for="classification-include_cross_list">Include cross-list</label></th><td><ul id="classification-include_cross_list"><li><input checked id="classification-include_cross_list-0" name="classification-include_cross_list" type="radio" value="include"> <label for="classification-include_cross_list-0">Include cross-listed papers</label></li><li><input id="classification-include_cross_list-1" name="classification-include_cross_list" type="radio" value="exclude"> <label for="classification-include_cross_list-1">Exclude cross-listed papers</label></li></ul></td></tr></table>
          
        
          
            <table id="date"><tr><th><label for="date-filter_by">Filter by</label></th><td><ul id="date-filter_by"><li><input checked id="date-filter_by-0" name="date-filter_by" type="radio" value="all_dates"> <label for="date-filter_by-0">All dates</label></li><li><input id="date-filter_by-1" name="date-filter_by" type="radio" value="past_12"> <label for="date-filter_by-1">Past 12 months</label></li><li><input id="date-filter_by-2" name="date-filter_by" type="radio" value="specific_year"> <label for="date-filter_by-2">Specific year</label></li><li><input id="date-filter_by-3" name="date-filter_by" type="radio" value="date_range"> <label for="date-filter_by-3">Date range</label></li></ul></td></tr><tr><th><label for="date-year">Year</label></th><td><input id="date-year" name="date-year" type="text" value=""></td></tr><tr><th><label for="date-from_date">From</label></th><td><input id="date-from_date" name="date-from_date" type="text" value=""></td></tr><tr><th><label for="date-to_date">to</label></th><td><input id="date-to_date" name="date-to_date" type="text" value=""></td></tr><tr><th><label for="date-date_type">Apply to</label></th><td><ul id="date-date_type"><li><input checked id="date-date_type-0" name="date-date_type" type="radio" value="submitted_date"> <label for="date-date_type-0">Submission date (most recent)</label></li><li><input id="date-date_type-1" name="date-date_type" type="radio" value="submitted_date_first"> <label for="date-date_type-1">Submission date (original)</label></li><li><input id="date-date_type-2" name="date-date_type" type="radio" value="announced_date_first"> <label for="date-date_type-2">Announcement date</label></li></ul></td></tr></table>
          
        
          
        
          
        
          
            <input id="include_older_versions" name="include_older_versions" type="checkbox" value="y">
          
        
          
            <ul id="abstracts"><li><input checked id="abstracts-0" name="abstracts" type="radio" value="show"> <label for="abstracts-0">Show abstracts</label></li><li><input id="abstracts-1" name="abstracts" type="radio" value="hide"> <label for="abstracts-1">Hide abstracts</label></li></ul>
          
        
      </div>
      <div class="box field is-grouped is-grouped-multiline level-item">
        <div class="control">
          <span class="select is-small">
            <select id="size" name="size"><option value="25">25</option><option value="50">50</option><option value="100">100</option><option selected value="200">200</option></select>
          </span>
          <label for="size">results per page</label>.
        </div>
        <div class="control">
          <label for="order">Sort results by</label>
          <span class="select is-small">
            <select id="order" name="order"><option selected value="-announced_date_first">Announcement date (newest first)</option><option value="announced_date_first">Announcement date (oldest first)</option><option value="-submitted_date">Submission date (newest first)</option><option value="submitted_date">Submission date (oldest first)</option><option value="">Relevance</option></select>
          </span>
        </div>
        <div class="control">
          <button class="button is-small is-link">Go</button>
        </div>
      </div>
    </form>
  </div>
</div>
        


  <nav class="pagination is-small is-centered breathe-horizontal" role="navigation" aria-label="pagination">
    
    <a href=""
      class="pagination-previous is-invisible">Previous
    </a>
    
    
      <a href="/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=%28code+OR+program+OR+software+OR+application%29+AND+%28optimize+OR+optimizing+OR+optimization+OR+improve+OR+improving+OR+improvement+OR+automated+OR+automatically+OR+reduce+OR+reducing%29+AND+%28time+OR+runtime+OR+speed+OR+speedup+OR+fast+OR+faster%29&amp;terms-0-field=all&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=200&amp;order=-announced_date_first&amp;start=200"
        class="pagination-next" >Next
      </a>
    
    <ul class="pagination-list">

      <li>
        <a href="/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=%28code+OR+program+OR+software+OR+application%29+AND+%28optimize+OR+optimizing+OR+optimization+OR+improve+OR+improving+OR+improvement+OR+automated+OR+automatically+OR+reduce+OR+reducing%29+AND+%28time+OR+runtime+OR+speed+OR+speedup+OR+fast+OR+faster%29&amp;terms-0-field=all&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=200&amp;order=-announced_date_first&amp;start=0"
          class="pagination-link is-current"
          aria-label="Goto page 1">1
        </a>
      </li>

      
        
        <li>
          <a href="/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=%28code+OR+program+OR+software+OR+application%29+AND+%28optimize+OR+optimizing+OR+optimization+OR+improve+OR+improving+OR+improvement+OR+automated+OR+automatically+OR+reduce+OR+reducing%29+AND+%28time+OR+runtime+OR+speed+OR+speedup+OR+fast+OR+faster%29&amp;terms-0-field=all&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=200&amp;order=-announced_date_first&amp;start=200"
            class="pagination-link "
            aria-label="Page 2"
            aria-current="page">2
          </a>
        </li>
        
        <li>
          <a href="/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=%28code+OR+program+OR+software+OR+application%29+AND+%28optimize+OR+optimizing+OR+optimization+OR+improve+OR+improving+OR+improvement+OR+automated+OR+automatically+OR+reduce+OR+reducing%29+AND+%28time+OR+runtime+OR+speed+OR+speedup+OR+fast+OR+faster%29&amp;terms-0-field=all&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=200&amp;order=-announced_date_first&amp;start=400"
            class="pagination-link "
            aria-label="Page 3"
            aria-current="page">3
          </a>
        </li>
        
        <li>
          <a href="/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=%28code+OR+program+OR+software+OR+application%29+AND+%28optimize+OR+optimizing+OR+optimization+OR+improve+OR+improving+OR+improvement+OR+automated+OR+automatically+OR+reduce+OR+reducing%29+AND+%28time+OR+runtime+OR+speed+OR+speedup+OR+fast+OR+faster%29&amp;terms-0-field=all&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=200&amp;order=-announced_date_first&amp;start=600"
            class="pagination-link "
            aria-label="Page 4"
            aria-current="page">4
          </a>
        </li>
        
        <li>
          <a href="/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=%28code+OR+program+OR+software+OR+application%29+AND+%28optimize+OR+optimizing+OR+optimization+OR+improve+OR+improving+OR+improvement+OR+automated+OR+automatically+OR+reduce+OR+reducing%29+AND+%28time+OR+runtime+OR+speed+OR+speedup+OR+fast+OR+faster%29&amp;terms-0-field=all&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=200&amp;order=-announced_date_first&amp;start=800"
            class="pagination-link "
            aria-label="Page 5"
            aria-current="page">5
          </a>
        </li>
        
        <li>
          <a href="/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=%28code+OR+program+OR+software+OR+application%29+AND+%28optimize+OR+optimizing+OR+optimization+OR+improve+OR+improving+OR+improvement+OR+automated+OR+automatically+OR+reduce+OR+reducing%29+AND+%28time+OR+runtime+OR+speed+OR+speedup+OR+fast+OR+faster%29&amp;terms-0-field=all&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=200&amp;order=-announced_date_first&amp;start=1000"
            class="pagination-link "
            aria-label="Page 6"
            aria-current="page">6
          </a>
        </li>
        
        <li>
          <a href="/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=%28code+OR+program+OR+software+OR+application%29+AND+%28optimize+OR+optimizing+OR+optimization+OR+improve+OR+improving+OR+improvement+OR+automated+OR+automatically+OR+reduce+OR+reducing%29+AND+%28time+OR+runtime+OR+speed+OR+speedup+OR+fast+OR+faster%29&amp;terms-0-field=all&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=200&amp;order=-announced_date_first&amp;start=1200"
            class="pagination-link "
            aria-label="Page 7"
            aria-current="page">7
          </a>
        </li>
        
      
    </ul>
  </nav>
  



<ol class="breathe-horizontal" start="1"> 


  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2107.03347">arXiv:2107.03347</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2107.03347">pdf</a>, <a href="https://arxiv.org/format/2107.03347">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Social and Information Networks">cs.SI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        <span class="search-hit mathjax">Optimal</span> Edge Weight Perturbations to Attack Shortest Paths
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Miller%2C+B+A">Benjamin A. Miller</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shafi%2C+Z">Zohair Shafi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ruml%2C+W">Wheeler Ruml</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Vorobeychik%2C+Y">Yevgeniy Vorobeychik</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Eliassi-Rad%2C+T">Tina Eliassi-Rad</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Alfeld%2C+S">Scott Alfeld</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2107.03347v1-abstract-short" style="display: inline;">
        Finding shortest paths in a given network (e.g., a computer network or a road network) is a well-studied task with many <span class="search-hit mathjax">applications</span>. We consider this task under the presence of an adversary, who can manipulate the network by perturbing its edge weights to gain an advantage over others. Specifically, we introduce the Force Path Problem as follows. Given a ne&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2107.03347v1-abstract-full').style.display = 'inline'; document.getElementById('2107.03347v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2107.03347v1-abstract-full" style="display: none;">
        Finding shortest paths in a given network (e.g., a computer network or a road network) is a well-studied task with many <span class="search-hit mathjax">applications</span>. We consider this task under the presence of an adversary, who can manipulate the network by perturbing its edge weights to gain an advantage over others. Specifically, we introduce the Force Path Problem as follows. Given a network, the adversary&#39;s goal is to make a specific path the shortest by adding weights to edges in the network. The version of this problem in which the adversary can cut edges is NP-complete. However, we show that Force Path can be solved to within arbitrary numerical precision in polynomial <span class="search-hit mathjax">time</span>. We propose the PATHPERTURB algorithm, which uses constraint generation to build a set of constraints that require paths other than the adversary&#39;s target to be sufficiently long. Across a highly varied set of synthetic and real networks, we show that the <span class="search-hit mathjax">optimal</span> solution often <span class="search-hit mathjax">reduces</span> the required perturbation budget by about half when compared to a greedy baseline method.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2107.03347v1-abstract-full').style.display = 'none'; document.getElementById('2107.03347v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 July, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2107.03096">arXiv:2107.03096</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2107.03096">pdf</a>, <a href="https://arxiv.org/format/2107.03096">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Hardware Architecture">cs.AR</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        R2F: A Remote Retraining Framework for AIoT Processors with Computing Errors
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Xu%2C+D">Dawen Xu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=He%2C+M">Meng He</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+C">Cheng Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+Y">Ying Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cheng%2C+L">Long Cheng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+H">Huawei Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+X">Xiaowei Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cheng%2C+K">Kwang-Ting Cheng</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2107.03096v1-abstract-short" style="display: inline;">
        &hellip;processors with computing errors. It takes the remote AIoT processor with soft errors in the training loop such that the on-site computing errors can be learned with the <span class="search-hit mathjax">application</span> data on the server and the retrained models can be resilient to the soft errors. Meanwhile, we propose an&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2107.03096v1-abstract-full').style.display = 'inline'; document.getElementById('2107.03096v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2107.03096v1-abstract-full" style="display: none;">
        AIoT processors fabricated with newer technology nodes suffer rising soft errors due to the shrinking transistor sizes and lower power supply. Soft errors on the AIoT processors particularly the deep learning accelerators (DLAs) with massive computing may cause substantial computing errors. These computing errors are difficult to be captured by the conventional training on general purposed processors like CPUs and GPUs in a server. Applying the offline trained neural network models to the edge accelerators with errors directly may lead to considerable prediction accuracy loss.
  To address the problem, we propose a remote retraining framework (R2F) for remote AIoT processors with computing errors. It takes the remote AIoT processor with soft errors in the training loop such that the on-site computing errors can be learned with the <span class="search-hit mathjax">application</span> data on the server and the retrained models can be resilient to the soft errors. Meanwhile, we propose an <span class="search-hit mathjax">optimized</span> partial TMR strategy to enhance the retraining. According to our experiments, R2F enables elastic design trade-offs between the model accuracy and the performance penalty. The top-5 model accuracy can be <span class="search-hit mathjax">improved</span> by 1.93%-13.73% with 0%-200% performance penalty at high fault error rate. In addition, we notice that the retraining requires massive data transmission and even dominates the training <span class="search-hit mathjax">time</span>, and propose a sparse increment compression approach for the data transmission <span class="search-hit mathjax">optimization</span>, which <span class="search-hit mathjax">reduces</span> the retraining <span class="search-hit mathjax">time</span> by 38%-88% on average with negligible accuracy loss over a straightforward remote retraining.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2107.03096v1-abstract-full').style.display = 'none'; document.getElementById('2107.03096v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 July, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2107.01405">arXiv:2107.01405</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2107.01405">pdf</a>, <a href="https://arxiv.org/format/2107.01405">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A Fuzzy Scheduling Strategy for Deadline-Based Workflow <span class="search-hit mathjax">Applications</span> in Uncertain Edge-Cloud Environments
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Lin%2C+B">Bing Lin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lin%2C+C">Chaowei Lin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+X">Xing Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xiong%2C+N+N">Neal N. Xiong</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hua%2C+P">Peisong Hua</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shen%2C+Q">Qiang Shen</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2107.01405v1-abstract-short" style="display: inline;">
        Workflow scheduling is critical to performing many practical workflow <span class="search-hit mathjax">applications</span>. Scheduling based on edge-cloud computing can help addressing the high complexity of workflow&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2107.01405v1-abstract-full').style.display = 'inline'; document.getElementById('2107.01405v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2107.01405v1-abstract-full" style="display: none;">
        Workflow scheduling is critical to performing many practical workflow <span class="search-hit mathjax">applications</span>. Scheduling based on edge-cloud computing can help addressing the high complexity of workflow <span class="search-hit mathjax">applications</span>, while decreasing the data transmission delay. However, due to the nature of heterogeneous resources in edge-cloud environments and the complicated data dependencies between the tasks in such a workflow, significant challenges for workflow scheduling remain, including the selection of an <span class="search-hit mathjax">optimal</span> tasks-servers solution from the possible numerous combinations. Existing studies are mainly done subject to rigorous conditions without fluctuations, ignoring the fact that workflow scheduling is typically present in uncertain environments. In this study, we focus on <span class="search-hit mathjax">reducing</span> the execution cost of workflow <span class="search-hit mathjax">applications</span> mainly caused by task computation and data transmission, while satisfying the workflow deadline in uncertain edge-cloud environments. The Triangular Fuzzy Numbers (TFNs) are adopted to represent task processing <span class="search-hit mathjax">time</span> and data transferring <span class="search-hit mathjax">time</span>. A cost-driven fuzzy scheduling strategy based on an Adaptive Discrete Particle Swarm <span class="search-hit mathjax">Optimization</span> (ADPSO) algorithm is proposed, which is employed the operators of Genetic Algorithm (GA). This strategy introduces the randomly two-point crossover operator, neighborhood mutation operator, and adaptive multipoint mutation operator of GA to effectively avoid converging on local optima. The experimental results show that our strategy can effectively <span class="search-hit mathjax">reduce</span> the workflow execution cost in uncertain edge-cloud environments, compared with other benchmark solutions.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2107.01405v1-abstract-full').style.display = 'none'; document.getElementById('2107.01405v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 3 July, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2107.01093">arXiv:2107.01093</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2107.01093">pdf</a>, <a href="https://arxiv.org/format/2107.01093">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Model Checking C++ <span class="search-hit mathjax">Programs</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Monteiro%2C+F+R">Felipe R. Monteiro</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gadelha%2C+M+R">Mikhail R. Gadelha</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cordeiro%2C+L+C">Lucas C. Cordeiro</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2107.01093v1-abstract-short" style="display: inline;">
        In the last three decades, memory safety issues in system <span class="search-hit mathjax">programming</span> languages such as C or C++ have been one of the significant sources of security vulnerabilities. However, there exist only a few attempts with limited success to cope with the complexity of C++&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2107.01093v1-abstract-full').style.display = 'inline'; document.getElementById('2107.01093v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2107.01093v1-abstract-full" style="display: none;">
        In the last three decades, memory safety issues in system <span class="search-hit mathjax">programming</span> languages such as C or C++ have been one of the significant sources of security vulnerabilities. However, there exist only a few attempts with limited success to cope with the complexity of C++ <span class="search-hit mathjax">program</span> verification. Here we describe and evaluate a novel verification approach based on bounded model checking (BMC) and satisfiability modulo theories (SMT) to verify C++ <span class="search-hit mathjax">programs</span> formally. Our verification approach analyzes bounded C++ <span class="search-hit mathjax">programs</span> by encoding into SMT various sophisticated features that the C++ <span class="search-hit mathjax">programming</span> language offers, such as templates, inheritance, polymorphism, exception handling, and the Standard C++ Libraries. We formalize these features within our formal verification framework using a decidable fragment of first-order logic and then show how state-of-the-art SMT solvers can efficiently handle that. We implemented our verification approach on top of ESBMC. We compare ESBMC to LLBMC and DIVINE, which are state-of-the-art verifiers to check C++ <span class="search-hit mathjax">programs</span> directly from the LLVM bitcode. Experimental results show that ESBMC can handle a wide range of C++ <span class="search-hit mathjax">programs</span>, presenting a higher number of correct verification results. At the same <span class="search-hit mathjax">time</span>, it <span class="search-hit mathjax">reduces</span> the verification <span class="search-hit mathjax">time</span> if compared to LLBMC and DIVINE tools. Additionally, ESBMC has been applied to a commercial C++ <span class="search-hit mathjax">application</span> in the telecommunication domain and successfully detected arithmetic overflow errors, potentially leading to security vulnerabilities.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2107.01093v1-abstract-full').style.display = 'none'; document.getElementById('2107.01093v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 2 July, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">30 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2107.01025">arXiv:2107.01025</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2107.01025">pdf</a>, <a href="https://arxiv.org/format/2107.01025">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Networking and Internet Architecture">cs.NI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Structure-aware reinforcement learning for node-overload protection in mobile edge computing
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Jitani%2C+A">Anirudha Jitani</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mahajan%2C+A">Aditya Mahajan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhu%2C+Z">Zhongwen Zhu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Abou-zeid%2C+H">Hatem Abou-zeid</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fapi%2C+E+T">Emmanuel T. Fapi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Purmehdi%2C+H">Hakimeh Purmehdi</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2107.01025v1-abstract-short" style="display: inline;">
        Mobile Edge Computing (MEC) refers to the concept of placing computational capability and <span class="search-hit mathjax">applications</span> at the edge of the network, providing benefits such as&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2107.01025v1-abstract-full').style.display = 'inline'; document.getElementById('2107.01025v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2107.01025v1-abstract-full" style="display: none;">
        Mobile Edge Computing (MEC) refers to the concept of placing computational capability and <span class="search-hit mathjax">applications</span> at the edge of the network, providing benefits such as <span class="search-hit mathjax">reduced</span> latency in handling client requests, <span class="search-hit mathjax">reduced</span> network congestion, and <span class="search-hit mathjax">improved</span> performance of <span class="search-hit mathjax">applications</span>. The performance and reliability of MEC are degraded significantly when one or several edge servers in the cluster are overloaded. Especially when a server crashes due to the overload, it causes service failures in MEC. In this work, an adaptive admission control policy to prevent edge node from getting overloaded is presented. This approach is based on a recently-proposed low complexity RL (Reinforcement Learning) algorithm called SALMUT (Structure-Aware Learning for Multiple Thresholds), which exploits the structure of the <span class="search-hit mathjax">optimal</span> admission control policy in multi-class queues for an average-cost setting. We extend the framework to work for node overload-protection problem in a discounted-cost setting. The proposed solution is validated using several scenarios mimicking real-world deployments in two different settings - computer simulations and a docker testbed. Our empirical evaluations show that the total discounted cost incurred by SALMUT is similar to state-of-the-art deep RL algorithms such as PPO (Proximal Policy <span class="search-hit mathjax">Optimization</span>) and A2C (Advantage Actor Critic) but requires an order of magnitude less <span class="search-hit mathjax">time</span> to train, outputs easily interpretable policy, and can be deployed in an online manner.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2107.01025v1-abstract-full').style.display = 'none'; document.getElementById('2107.01025v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 29 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">16 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2107.00615">arXiv:2107.00615</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2107.00615">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Medical Physics">physics.med-ph</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computational Engineering, Finance, and Science">cs.CE</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Signal Processing">eess.SP</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A linear phase evolution model for reduction of temporal unwrapping and field estimation errors in multi-echo GRE
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Paul%2C+J+S">Joseph Suresh Paul</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Madhusoodhanan%2C+S">Sreekanth Madhusoodhanan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2107.00615v1-abstract-short" style="display: inline;">
        This article aims at developing a model based <span class="search-hit mathjax">optimization</span> for reduction of temporal unwrapping and field estimation errors in multi-echo acquisition of Gradient Echo sequence. Using the assumption that the phase is linear along the temporal dimension, the field estimation is performed by&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2107.00615v1-abstract-full').style.display = 'inline'; document.getElementById('2107.00615v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2107.00615v1-abstract-full" style="display: none;">
        This article aims at developing a model based <span class="search-hit mathjax">optimization</span> for reduction of temporal unwrapping and field estimation errors in multi-echo acquisition of Gradient Echo sequence. Using the assumption that the phase is linear along the temporal dimension, the field estimation is performed by <span class="search-hit mathjax">application</span> of unity rank approximation to the Hankel matrix formed using the complex exponential of the channel combined phase at each echo <span class="search-hit mathjax">time</span>. For the purpose of maintaining consistency with the observed complex data, the linear phase evolution model is formulated as an <span class="search-hit mathjax">optimization</span> problem with a cost function that involves a fidelity term and a unity rank prior, implemented using alternating minimization. Itoh s algorithm applied to the multi-echo phase estimated from this linear phase evolution model is able to <span class="search-hit mathjax">reduce</span> the unwrapping errors as compared to the unwrapping when directly applied to the measured phase. Secondly, the <span class="search-hit mathjax">improved</span> accuracy of the frequency fit in comparison to estimation using weighted least-square regression and penalized maximum likelihood is demonstrated using numerical simulation of field perturbation due to magnetic susceptibility effect. It is shown that the field can be estimated with 80 percent reduction in mean absolute error in comparison to wLSR and 66 percent reduction with respect to penalized maximum likelihood. The <span class="search-hit mathjax">improvement</span> in performance becomes more pronounced with increasing strengths of field gradient magnitudes and echo spacing.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2107.00615v1-abstract-full').style.display = 'none'; document.getElementById('2107.00615v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 26 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">29pages, 8 figures</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          J.2
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2107.00465">arXiv:2107.00465</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2107.00465">pdf</a>, <a href="https://arxiv.org/format/2107.00465">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Physics-Informed Neural Networks for Minimising Worst-Case Violations in DC <span class="search-hit mathjax">Optimal</span> Power Flow
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Nellikkath%2C+R">Rahul Nellikkath</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chatzivasileiadis%2C+S">Spyros Chatzivasileiadis</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2107.00465v1-abstract-short" style="display: inline;">
        &hellip;neural networks exploit the existing models of the underlying physical systems to generate higher accuracy results with fewer data. Such approaches can help drastically <span class="search-hit mathjax">reduce</span> the computation&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2107.00465v1-abstract-full').style.display = 'inline'; document.getElementById('2107.00465v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2107.00465v1-abstract-full" style="display: none;">
        Physics-informed neural networks exploit the existing models of the underlying physical systems to generate higher accuracy results with fewer data. Such approaches can help drastically <span class="search-hit mathjax">reduce</span> the computation <span class="search-hit mathjax">time</span> and generate a good estimate of computationally intensive processes in power systems, such as dynamic security assessment or <span class="search-hit mathjax">optimal</span> power flow. Combined with the extraction of worst-case guarantees for the neural network performance, such neural networks can be applied in safety-critical <span class="search-hit mathjax">applications</span> in power systems and build a high level of trust among power system operators. This paper takes the first step and applies, for the first <span class="search-hit mathjax">time</span> to our knowledge, Physics-Informed Neural Networks with Worst-Case Guarantees for the DC <span class="search-hit mathjax">Optimal</span> Power Flow problem. We look for guarantees related to (i) maximum constraint violations, (ii) maximum distance between predicted and <span class="search-hit mathjax">optimal</span> decision variables, and (iii) maximum sub-<span class="search-hit mathjax">optimality</span> in the entire input domain. In a range of PGLib-OPF networks, we demonstrate how physics-informed neural networks can be supplied with worst-case guarantees and how they can lead to <span class="search-hit mathjax">reduced</span> worst-case violations compared with conventional neural networks.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2107.00465v1-abstract-full').style.display = 'none'; document.getElementById('2107.00465v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 28 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">The <span class="search-hit mathjax">code</span> to reproduce all simulation results is available online in https://github.com/RahulNellikkath/Physics-Informed-Neural-Network-for-DC-OPF</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.15878">arXiv:2106.15878</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.15878">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Formal Languages and Automata Theory">cs.FL</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Programming Languages">cs.PL</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Towards establishing formal verification and inductive <span class="search-hit mathjax">code</span> synthesis in the PLC domain
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Wei%C3%9F%2C+M">Matthias WeiÃ</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Marks%2C+P">Philipp Marks</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Maschler%2C+B">Benjamin Maschler</a>, 
      
      <a href="/search/?searchtype=author&amp;query=White%2C+D">Dustin White</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kesseli%2C+P">Pascal Kesseli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Weyrich%2C+M">Michael Weyrich</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.15878v1-abstract-short" style="display: inline;">
        Nowadays, formal methods are used in various areas for the verification of <span class="search-hit mathjax">programs</span> or for&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.15878v1-abstract-full').style.display = 'inline'; document.getElementById('2106.15878v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.15878v1-abstract-full" style="display: none;">
        Nowadays, formal methods are used in various areas for the verification of <span class="search-hit mathjax">programs</span> or for <span class="search-hit mathjax">code</span> generation from models in order to increase the quality of <span class="search-hit mathjax">software</span> and to <span class="search-hit mathjax">reduce</span> costs. However, there are still fields in which formal methods have not been widely adopted, despite the large set of possible benefits offered. This is the case for the area of programmable logic controllers (PLC). This article aims to evaluate the potential of formal methods in the context of PLC development. For this purpose, the general concepts of formal methods are first introduced and then transferred to the PLC area, resulting in an engineering-oriented description of the technology that is based on common concepts from PLC development. Based on this description, PLC professionals with varying degrees of experience were interviewed for their perspective on the topic and to identify possible use cases within the PLC domain. The survey results indicate the technology&#39;s high potential in the PLC area, either as a tool to directly support the developer or as a key element within a model-based systems engineering toolchain. The evaluation of the survey results is performed with the aid of a demo <span class="search-hit mathjax">application</span> that communicates with the Totally Integrated <span class="search-hit mathjax">Automation</span> Portal from Siemens and generates <span class="search-hit mathjax">programs</span> via Fastsynth, a model-based open source <span class="search-hit mathjax">code</span> generator. Benchmarks based on an industry-related PLC project show satisfactory synthesis <span class="search-hit mathjax">times</span> and a successful integration into the workflow of a PLC developer.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.15878v1-abstract-full').style.display = 'none'; document.getElementById('2106.15878v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">8 pages, 6 figures, 1 table. Accepted for publication at IEEE INDIN 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.15490">arXiv:2106.15490</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.15490">pdf</a>, <a href="https://arxiv.org/format/2106.15490">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Quantum Physics">quant-ph</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Emerging Technologies">cs.ET</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1109/ISCA52012.2021.00071">10.1109/ISCA52012.2021.00071 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Designing calibration and expressivity-efficient instruction sets for quantum computing
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Murali%2C+P">Prakash Murali</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lao%2C+L">Lingling Lao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Martonosi%2C+M">Margaret Martonosi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Browne%2C+D">Dan Browne</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.15490v1-abstract-short" style="display: inline;">
        &hellip;(QC) systems have limited qubit counts, high gate (instruction) error rates, and typically support a minimal instruction set having one type of two-qubit gate (2Q). To <span class="search-hit mathjax">reduce</span>&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.15490v1-abstract-full').style.display = 'inline'; document.getElementById('2106.15490v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.15490v1-abstract-full" style="display: none;">
        Near-term quantum computing (QC) systems have limited qubit counts, high gate (instruction) error rates, and typically support a minimal instruction set having one type of two-qubit gate (2Q). To <span class="search-hit mathjax">reduce</span> <span class="search-hit mathjax">program</span> instruction counts and <span class="search-hit mathjax">improve</span> <span class="search-hit mathjax">application</span> expressivity, vendors have proposed, and shown proof-of-concept demonstrations of richer instruction sets such as XY gates (Rigetti) and fSim gates (Google). These instruction sets comprise of families of 2Q gate types parameterized by continuous qubit rotation angles. However, having such a large number of gate types is problematic because each gate type has to be calibrated periodically, across the full system, to obtain high fidelity implementations. This results in substantial recurring calibration overheads even on current systems which use only a few gate types. Our work aims to navigate this tradeoff between <span class="search-hit mathjax">application</span> expressivity and calibration overhead, and identify what instructions vendors should implement to get the best expressivity with acceptable calibration <span class="search-hit mathjax">time</span>. We develop NuOp, a flexible compilation pass based on numerical <span class="search-hit mathjax">optimization</span>, to efficiently decompose <span class="search-hit mathjax">application</span> operations into arbitrary hardware gate types. Using NuOp and four important quantum <span class="search-hit mathjax">applications</span>, we study the instruction set proposals of Rigetti and Google, with realistic noise simulations and a calibration model. Our experiments show that implementing 4-8 types of 2Q gates is sufficient to attain nearly the same expressivity as a full continuous gate family, while <span class="search-hit mathjax">reducing</span> the calibration overhead by two orders of magnitude. With several vendors proposing rich gate families as means to higher fidelity, our work has potential to provide valuable instruction set design guidance for near-term QC systems.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.15490v1-abstract-full').style.display = 'none'; document.getElementById('2106.15490v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 29 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">14 pages, 11 figures</span>
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        2021 ACM/IEEE 48th Annual International Symposium on Computer Architecture (ISCA):846-859
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.14830">arXiv:2106.14830</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.14830">pdf</a>, <a href="https://arxiv.org/format/2106.14830">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Databases">cs.DB</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        THUE: Discovering Top-K High Utility Episodes
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Wan%2C+S">Shicheng Wan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+J">Jiahui Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gan%2C+W">Wensheng Gan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+G">Guoting Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Goyal%2C+V">Vikram Goyal</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.14830v1-abstract-short" style="display: inline;">
        Episode discovery from an event is a popular framework for data mining tasks and has many real-world <span class="search-hit mathjax">applications</span>. An episode is a partially ordered set of objects (e.g., item, node), and each object is associated with an event type. This episode can also be considered as a complex event sub-sequence. High-utility episode mining is an interesting utility-dri&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.14830v1-abstract-full').style.display = 'inline'; document.getElementById('2106.14830v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.14830v1-abstract-full" style="display: none;">
        Episode discovery from an event is a popular framework for data mining tasks and has many real-world <span class="search-hit mathjax">applications</span>. An episode is a partially ordered set of objects (e.g., item, node), and each object is associated with an event type. This episode can also be considered as a complex event sub-sequence. High-utility episode mining is an interesting utility-driven mining task in the real world. Traditional episode mining algorithms, by setting a threshold, usually return a huge episode that is neither intuitive nor saves <span class="search-hit mathjax">time</span>. In general, finding a suitable threshold in a pattern-mining algorithm is a trivial and <span class="search-hit mathjax">time</span>-consuming task. In this paper, we propose a novel algorithm, called Top-K High Utility Episode (THUE) mining within the complex event sequence, which redefines the previous mining task by obtaining the K highest episodes. We introduce several threshold-raising strategies and <span class="search-hit mathjax">optimize</span> the episode-weighted utilization upper bounds to <span class="search-hit mathjax">speed</span> up the mining process and effectively <span class="search-hit mathjax">reduce</span> the memory cost. Finally, the experimental results on both real-life and synthetic datasets reveal that the THUE algorithm can offer six to eight orders of magnitude running <span class="search-hit mathjax">time</span> performance <span class="search-hit mathjax">improvement</span> over the state-of-the-art algorithm and has low memory consumption.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.14830v1-abstract-full').style.display = 'none'; document.getElementById('2106.14830v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 28 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Preprint. 6 figures, 9 tables</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.14577">arXiv:2106.14577</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.14577">pdf</a>, <a href="https://arxiv.org/format/2106.14577">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Cryptography and Security">cs.CR</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Image and Video Processing">eess.IV</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Privacy-Preserving Image Acquisition Using Trainable Optical Kernel
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Sepehri%2C+Y">Yamin Sepehri</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pad%2C+P">Pedram Pad</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Frossard%2C+P">Pascal Frossard</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dunbar%2C+L+A">L. Andrea Dunbar</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.14577v1-abstract-short" style="display: inline;">
        Preserving privacy is a growing concern in our society where sensors and cameras are ubiquitous. In this work, for the first <span class="search-hit mathjax">time</span>, we propose a trainable image acquisition method that removes the sensitive identity revealing information in the optical domain before it reaches the image sensor. The method benefits from a trainable optical convolution kernel w&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.14577v1-abstract-full').style.display = 'inline'; document.getElementById('2106.14577v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.14577v1-abstract-full" style="display: none;">
        Preserving privacy is a growing concern in our society where sensors and cameras are ubiquitous. In this work, for the first <span class="search-hit mathjax">time</span>, we propose a trainable image acquisition method that removes the sensitive identity revealing information in the optical domain before it reaches the image sensor. The method benefits from a trainable optical convolution kernel which transmits the desired information while filters out the sensitive content. As the sensitive content is suppressed before it reaches the image sensor, it does not enter the digital domain therefore is unretrievable by any sort of privacy attack. This is in contrast with the current digital privacy-preserving methods that are all vulnerable to direct access attack. Also, in contrast with the previous optical privacy-preserving methods that cannot be trained, our method is data-driven and <span class="search-hit mathjax">optimized</span> for the specific <span class="search-hit mathjax">application</span> at hand. Moreover, there is no additional computation, memory, or power burden on the acquisition system since this processing happens passively in the optical domain and can even be used together and on top of the fully digital privacy-preserving systems. The proposed approach is adaptable to different digital neural networks and content. We demonstrate it for several scenarios such as smile detection as the desired attribute while the gender is filtered out as the sensitive content. We trained the optical kernel in conjunction with two adversarial neural networks where the analysis network tries to detect the desired attribute and the adversarial network tries to detect the sensitive content. We show that this method can <span class="search-hit mathjax">reduce</span> 65.1% of sensitive content when it is selected to be the gender and it only loses 7.3% of the desired content. Moreover, we reconstruct the original faces using the deep reconstruction method that confirms the ineffectiveness of reconstruction attacks to obtain the sensitive content.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.14577v1-abstract-full').style.display = 'none'; document.getElementById('2106.14577v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 28 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">9 pages, 9 figures</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          I.2.10; I.5.0
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.12007">arXiv:2106.12007</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.12007">pdf</a>, <a href="https://arxiv.org/format/2106.12007">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1109/TPDS.2021.3090334">10.1109/TPDS.2021.3090334 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Energy hardware and workload aware job scheduling towards interconnected HPC environments
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=D%27Amico%2C+M">Marco D&#39;Amico</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Corbalan%2C+J">Julita Corbalan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.12007v1-abstract-short" style="display: inline;">
        New HPC machines are getting close to the exascale. Power consumption for those machines has been increasing, and researchers are studying ways to <span class="search-hit mathjax">reduce</span> it. A second trend is HPC machines&#39; growing complexity, with increasing heterogeneous hardware components and different clusters architectures cooperating in the same machine. We refer to these environm&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.12007v1-abstract-full').style.display = 'inline'; document.getElementById('2106.12007v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.12007v1-abstract-full" style="display: none;">
        New HPC machines are getting close to the exascale. Power consumption for those machines has been increasing, and researchers are studying ways to <span class="search-hit mathjax">reduce</span> it. A second trend is HPC machines&#39; growing complexity, with increasing heterogeneous hardware components and different clusters architectures cooperating in the same machine. We refer to these environments with the term heterogeneous multi-cluster environments. With the aim of <span class="search-hit mathjax">optimizing</span> performance and energy consumption in these environments, this paper proposes an Energy-Aware-Multi-Cluster (EAMC) job scheduling policy. EAMC-policy is able to <span class="search-hit mathjax">optimize</span> the scheduling and placement of jobs by predicting performance and energy consumption of arriving jobs for different hardware architectures and processor frequencies, <span class="search-hit mathjax">reducing</span> workload&#39;s energy consumption, makespan, and response <span class="search-hit mathjax">time</span>. The policy assigns a different priority to each job-resource combination so that the most efficient ones are favored, while less efficient ones are still considered on a variable degree, <span class="search-hit mathjax">reducing</span> response <span class="search-hit mathjax">time</span> and increasing cluster utilization. We implemented EAMC-policy in Slurm, and we evaluated a scenario in which two CPU clusters collaborate in the same machine. Simulations of workloads running <span class="search-hit mathjax">applications</span> modeled from real-world show a reduction of response <span class="search-hit mathjax">time</span> and makespan by up to 25% and 6% while saving up to 20% of total energy consumed when compared to policies minimizing <span class="search-hit mathjax">runtime</span>, and by 49%, 26%, and 6% compared to policies minimizing energy.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.12007v1-abstract-full').style.display = 'none'; document.getElementById('2106.12007v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        Transactions on Parallel and Distributed Systems 2021
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.11851">arXiv:2106.11851</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.11851">pdf</a>, <a href="https://arxiv.org/format/2106.11851">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Stochastic Polyak Stepsize with a Moving Target
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Gower%2C+R+M">Robert M. Gower</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Defazio%2C+A">Aaron Defazio</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rabbat%2C+M">Michael Rabbat</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.11851v1-abstract-short" style="display: inline;">
        We propose a new stochastic gradient method that uses recorded past loss values to <span class="search-hit mathjax">reduce</span> the variance. Our method can be interpreted as a new stochastic variant of the Polyak Stepsize that converges globally without assuming interpolation. Our method introduces auxiliary variables, one for each data point, that track the loss value for each data point. We p&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.11851v1-abstract-full').style.display = 'inline'; document.getElementById('2106.11851v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.11851v1-abstract-full" style="display: none;">
        We propose a new stochastic gradient method that uses recorded past loss values to <span class="search-hit mathjax">reduce</span> the variance. Our method can be interpreted as a new stochastic variant of the Polyak Stepsize that converges globally without assuming interpolation. Our method introduces auxiliary variables, one for each data point, that track the loss value for each data point. We provide a global convergence theory for our method by showing that it can be interpreted as a special variant of online SGD. The new method only stores a single scalar per data point, opening up new <span class="search-hit mathjax">applications</span> for variance reduction where memory is the bottleneck.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.11851v1-abstract-full').style.display = 'none'; document.getElementById('2106.11851v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">41 pages, 13 figures, 1 table</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        
          <span class="has-text-black-bis has-text-weight-semibold">MSC Class:</span>
          90C53; 74S60; 90C06; 62L20; 68W20; 15B52; 65Y20; 68W40
        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          G.1.6
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.11756">arXiv:2106.11756</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.11756">pdf</a>, <a href="https://arxiv.org/format/2106.11756">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Trinity: A No-<span class="search-hit mathjax">Code</span> AI platform for complex spatial datasets
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Iyer%2C+C+V+K">C. V. Krishnakumar Iyer</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hou%2C+F">Feili Hou</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+H">Henry Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+Y">Yonghong Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Oh%2C+K">Kay Oh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ganguli%2C+S">Swetava Ganguli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pandey%2C+V">Vipul Pandey</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.11756v5-abstract-short" style="display: inline;">
        We present a no-<span class="search-hit mathjax">code</span> Artificial Intelligence (AI) platform called Trinity with the main design goal of enabling both machine learning researchers and non-technical geospatial domain experts to experiment with domain-specific signals and datasets for solving a variety of complex problems on their own. This versatility to solve diverse problems is achieved by&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.11756v5-abstract-full').style.display = 'inline'; document.getElementById('2106.11756v5-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.11756v5-abstract-full" style="display: none;">
        We present a no-<span class="search-hit mathjax">code</span> Artificial Intelligence (AI) platform called Trinity with the main design goal of enabling both machine learning researchers and non-technical geospatial domain experts to experiment with domain-specific signals and datasets for solving a variety of complex problems on their own. This versatility to solve diverse problems is achieved by transforming complex Spatio-temporal datasets to make them consumable by standard deep learning models, in this case, Convolutional Neural Networks (CNNs), and giving the ability to formulate disparate problems in a standard way, eg. semantic segmentation. With an intuitive user interface, a feature store that hosts derivatives of complex feature engineering, a deep learning kernel, and a scalable data processing mechanism, Trinity provides a powerful platform for domain experts to share the stage with scientists and engineers in solving business-critical problems. It enables quick prototyping, rapid experimentation and <span class="search-hit mathjax">reduces</span> the <span class="search-hit mathjax">time</span> to production by standardizing model building and deployment. In this paper, we present our motivation behind Trinity and its design along with showcasing sample <span class="search-hit mathjax">applications</span> to motivate the idea of lowering the bar to using AI.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.11756v5-abstract-full').style.display = 'none'; document.getElementById('2106.11756v5-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 1 July, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 21 June, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">12 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.11396">arXiv:2106.11396</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.11396">pdf</a>, <a href="https://arxiv.org/ps/2106.11396">ps</a>, <a href="https://arxiv.org/format/2106.11396">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        BiAdam: <span class="search-hit mathjax">Fast</span> Adaptive Bilevel <span class="search-hit mathjax">Optimization</span> Methods
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Huang%2C+F">Feihu Huang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Huang%2C+H">Heng Huang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.11396v2-abstract-short" style="display: inline;">
        Bilevel <span class="search-hit mathjax">optimization</span> recently has attracted increased interest in machine learning due to its many&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.11396v2-abstract-full').style.display = 'inline'; document.getElementById('2106.11396v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.11396v2-abstract-full" style="display: none;">
        Bilevel <span class="search-hit mathjax">optimization</span> recently has attracted increased interest in machine learning due to its many <span class="search-hit mathjax">applications</span> such as hyper-parameter <span class="search-hit mathjax">optimization</span> and policy <span class="search-hit mathjax">optimization</span>. Although some methods recently have been proposed to solve the bilevel problems, these methods do not consider using adaptive learning rates. To fill this gap, in the paper, we propose a class of <span class="search-hit mathjax">fast</span> and effective adaptive methods for solving bilevel <span class="search-hit mathjax">optimization</span> problems that the outer problem is possibly nonconvex and the inner problem is strongly-convex. Specifically, we propose a <span class="search-hit mathjax">fast</span> single-loop BiAdam algorithm based on the basic momentum technique, which achieves a sample complexity of $\tilde{O}(Îµ^{-4})$ for finding an $Îµ$-stationary point. At the same <span class="search-hit mathjax">time</span>, we propose an accelerated version of BiAdam algorithm (VR-BiAdam) by using variance <span class="search-hit mathjax">reduced</span> technique, which reaches the best known sample complexity of $\tilde{O}(Îµ^{-3})$. To further <span class="search-hit mathjax">reduce</span> computation in estimating derivatives, we propose a <span class="search-hit mathjax">fast</span> single-loop stochastic approximated BiAdam algorithm (saBiAdam) by avoiding the Hessian inverse, which still achieves a sample complexity of $\tilde{O}(Îµ^{-4})$ without large batches. We further present an accelerated version of saBiAdam algorithm (VR-saBiAdam), which also reaches the best known sample complexity of $\tilde{O}(Îµ^{-3})$. We apply the unified adaptive matrices to our methods as the SUPER-ADAM \citep{huang2021super}, which including many types of adaptive learning rates. Moreover, our framework can flexibly use the momentum and variance <span class="search-hit mathjax">reduced</span> techniques. In particular, we provide a useful convergence analysis framework for both the constrained and unconstrained bilevel <span class="search-hit mathjax">optimization</span>. To the best of our knowledge, we first study the adaptive bilevel <span class="search-hit mathjax">optimization</span> methods with adaptive learning rates.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.11396v2-abstract-full').style.display = 'none'; document.getElementById('2106.11396v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 June, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 21 June, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">66 pages, 2 tables. We add the detailed proofs</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.11246">arXiv:2106.11246</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.11246">pdf</a>, <a href="https://arxiv.org/format/2106.11246">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Quantum Physics">quant-ph</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Emerging Technologies">cs.ET</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        LEAP: Scaling Numerical <span class="search-hit mathjax">Optimization</span> Based Synthesis Using an Incremental Approach
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Smith%2C+E">Ethan Smith</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Davis%2C+M+G">Marc G. Davis</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Larson%2C+J+M">Jeffrey M. Larson</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Younis%2C+E">Ed Younis</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Iancu%2C+C">Costin Iancu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lavrijsen%2C+W">Wim Lavrijsen</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.11246v1-abstract-short" style="display: inline;">
        While showing great promise, circuit synthesis techniques that combine numerical <span class="search-hit mathjax">optimization</span> with search over circuit structures face scalability challenges due to large number of parameters, exponential search spaces, and complex objective functions. The LEAP algorithm&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.11246v1-abstract-full').style.display = 'inline'; document.getElementById('2106.11246v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.11246v1-abstract-full" style="display: none;">
        While showing great promise, circuit synthesis techniques that combine numerical <span class="search-hit mathjax">optimization</span> with search over circuit structures face scalability challenges due to large number of parameters, exponential search spaces, and complex objective functions. The LEAP algorithm <span class="search-hit mathjax">improves</span> scaling across these dimensions using iterative circuit synthesis, incremental reoptimization, dimensionality reduction, and <span class="search-hit mathjax">improved</span> numerical <span class="search-hit mathjax">optimization</span>. LEAP draws on the design of the <span class="search-hit mathjax">optimal</span> synthesis algorithm QSearch by extending it with an incremental approach to determine constant prefix solutions for a circuit. By narrowing the search space, LEAP <span class="search-hit mathjax">improves</span> scalability from four to six qubit circuits. LEAP was evaluated with known quantum circuits such as QFT and physical simulation circuits like the VQE, TFIM and QITE. LEAP is able to compile four qubit unitaries up to <span class="search-hit mathjax">$59\times$</span> <span class="search-hit mathjax">faster</span> than QSearch and five and six qubit unitaries with up to <span class="search-hit mathjax">$1.2\times$</span> fewer CNOTs compared to the advanced QFAST package. LEAP is able to <span class="search-hit mathjax">reduce</span> the CNOT count by up to <span class="search-hit mathjax">$48\times$</span>, or <span class="search-hit mathjax">$11\times$</span> on average, compared to the IBM Qiskit compiler. Although employing heuristics, LEAP has generated <span class="search-hit mathjax">optimal</span> depth circuits for all test cases where a solution is known a priori. The techniques introduced by LEAP are <span class="search-hit mathjax">applicable</span> to other numerical <span class="search-hit mathjax">optimization</span> based synthesis approaches.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.11246v1-abstract-full').style.display = 'none'; document.getElementById('2106.11246v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 21 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">20 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.10423">arXiv:2106.10423</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.10423">pdf</a>, <a href="https://arxiv.org/format/2106.10423">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Networking and Internet Architecture">cs.NI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Signal Processing">eess.SP</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Joint <span class="search-hit mathjax">Speed</span> Control and Energy Replenishment <span class="search-hit mathjax">Optimization</span> for UAV-assisted IoT Data Collection with Deep Reinforcement Transfer Learning
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Chu%2C+N+H">Nam H. Chu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hoang%2C+D+T">Dinh Thai Hoang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Nguyen%2C+D+N">Diep N. Nguyen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Van+Huynh%2C+N">Nguyen Van Huynh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dutkiewicz%2C+E">Eryk Dutkiewicz</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.10423v1-abstract-short" style="display: inline;">
        Unmanned aerial vehicle (UAV)-assisted data collection has been emerging as a prominent <span class="search-hit mathjax">application</span> due to its flexibility, mobility, and low operational cost. However, under the dynamic and uncertainty of IoT data collection and energy replenishment processes,&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.10423v1-abstract-full').style.display = 'inline'; document.getElementById('2106.10423v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.10423v1-abstract-full" style="display: none;">
        Unmanned aerial vehicle (UAV)-assisted data collection has been emerging as a prominent <span class="search-hit mathjax">application</span> due to its flexibility, mobility, and low operational cost. However, under the dynamic and uncertainty of IoT data collection and energy replenishment processes, <span class="search-hit mathjax">optimizing</span> the performance for UAV collectors is a very challenging task. Thus, this paper introduces a novel framework that jointly <span class="search-hit mathjax">optimizes</span> the flying <span class="search-hit mathjax">speed</span> and energy replenishment for each UAV to significantly <span class="search-hit mathjax">improve</span> the data collection performance. Specifically, we first develop a Markov decision process to help the UAV <span class="search-hit mathjax">automatically</span> and dynamically make <span class="search-hit mathjax">optimal</span> decisions under the dynamics and uncertainties of the environment. We then propose a highly-effective reinforcement learning algorithm leveraging deep Q-learning, double deep Q-learning, and a deep dueling neural network architecture to quickly obtain the UAV&#39;s <span class="search-hit mathjax">optimal</span> policy. The core ideas of this algorithm are to estimate the state values and action advantages separately and simultaneously and to employ double estimators for estimating the action values. Thus, these proposed techniques can stabilize the learning process and effectively address the overestimation problem of conventional Q-learning algorithms. To further <span class="search-hit mathjax">reduce</span> the learning <span class="search-hit mathjax">time</span> as well as significantly <span class="search-hit mathjax">improve</span> learning quality, we develop advanced transfer learning techniques to allow UAVs to ``share&#39;&#39; and ``transfer&#39;&#39; learning knowledge. Extensive simulations demonstrate that our proposed solution can <span class="search-hit mathjax">improve</span> the average data collection performance of the system up to 200% compared with those of current methods.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.10423v1-abstract-full').style.display = 'none'; document.getElementById('2106.10423v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 19 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.10022">arXiv:2106.10022</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.10022">pdf</a>, <a href="https://arxiv.org/format/2106.10022">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Local AdaGrad-Type Algorithm for Stochastic Convex-Concave Minimax Problems
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Liao%2C+L">Luofeng Liao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shen%2C+L">Li Shen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Duan%2C+J">Jia Duan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kolar%2C+M">Mladen Kolar</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tao%2C+D">Dacheng Tao</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.10022v1-abstract-short" style="display: inline;">
        Large scale convex-concave minimax problems arise in numerous <span class="search-hit mathjax">applications</span>, including game theory, robust training, and training of generative adversarial networks. Despite their wide&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.10022v1-abstract-full').style.display = 'inline'; document.getElementById('2106.10022v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.10022v1-abstract-full" style="display: none;">
        Large scale convex-concave minimax problems arise in numerous <span class="search-hit mathjax">applications</span>, including game theory, robust training, and training of generative adversarial networks. Despite their wide <span class="search-hit mathjax">applicability</span>, solving such problems efficiently and effectively is challenging in the presence of large amounts of data using existing stochastic minimax methods. We study a class of stochastic minimax methods and develop a communication-efficient distributed stochastic extragradient algorithm, LocalAdaSEG, with an adaptive learning rate suitable for solving convex-concave minimax problem in the Parameter-Server model. LocalAdaSEG has three main features: (i) periodic communication strategy <span class="search-hit mathjax">reduces</span> the communication cost between workers and the server; (ii) an adaptive learning rate that is computed locally and allows for tuning-free implementation; and (iii) theoretically, a nearly linear <span class="search-hit mathjax">speed</span>-up with respect to the dominant variance term, arising from estimation of the stochastic gradient, is proven in both the smooth and nonsmooth convex-concave settings. LocalAdaSEG is used to solve a stochastic bilinear game, and train generative adversarial network. We compare LocalAdaSEG against several existing <span class="search-hit mathjax">optimizers</span> for minimax problems and demonstrate its efficacy through several experiments in both the homogeneous and heterogeneous settings.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.10022v1-abstract-full').style.display = 'none'; document.getElementById('2106.10022v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 18 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">24 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.09877">arXiv:2106.09877</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.09877">pdf</a>, <a href="https://arxiv.org/format/2106.09877">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Numerical Analysis">math.NA</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Mathematical Software">cs.MS</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        HIFIR: Hybrid Incomplete Factorization with Iterative Refinement for Preconditioning Ill-conditioned and Singular Systems
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+Q">Qiao Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jiao%2C+X">Xiangmin Jiao</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.09877v1-abstract-short" style="display: inline;">
        We introduce a <span class="search-hit mathjax">software</span> package called HIFIR for preconditioning sparse, unsymmetric, ill-conditioned, and potentially singular systems. HIFIR computes a hybrid incomplete factorization, which combines multilevel incomplete LU factorization with a truncated, rank-revealing QR factorization on the final Schur complement. This novel hybridization is based on t&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.09877v1-abstract-full').style.display = 'inline'; document.getElementById('2106.09877v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.09877v1-abstract-full" style="display: none;">
        We introduce a <span class="search-hit mathjax">software</span> package called HIFIR for preconditioning sparse, unsymmetric, ill-conditioned, and potentially singular systems. HIFIR computes a hybrid incomplete factorization, which combines multilevel incomplete LU factorization with a truncated, rank-revealing QR factorization on the final Schur complement. This novel hybridization is based on the new theory of approximate generalized inverse and $Îµ$-accuracy. It enables near-<span class="search-hit mathjax">optimal</span> preconditioners for consistent systems and enables flexible GMRES to solve inconsistent systems when coupled with iterative refinement. In this paper, we focus on some practical algorithmic and <span class="search-hit mathjax">software</span> issues of HIFIR. In particular, we introduce a new inverse-based rook pivoting into ILU, which <span class="search-hit mathjax">improves</span> the robustness and the overall efficiency for some ill-conditioned systems by significantly <span class="search-hit mathjax">reducing</span> the size of the final Schur complement for some systems. We also describe the <span class="search-hit mathjax">software</span> design of HIFIR in terms of its efficient data structures for supporting rook pivoting in a multilevel setting, its template-based generic <span class="search-hit mathjax">programming</span> interfaces for mixed-precision real and complex values in C++, and its user-friendly high-level interfaces in MATLAB and Python. We demonstrate the effectiveness of HIFIR for ill-conditioned or singular systems arising from several <span class="search-hit mathjax">applications</span>, including the Helmholtz equation, linear elasticity, stationary incompressible Navier--Stokes equations, and <span class="search-hit mathjax">time</span>-dependent advection-diffusion equation.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.09877v1-abstract-full').style.display = 'none'; document.getElementById('2106.09877v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Submitted to ACM Transactions on Mathematical <span class="search-hit mathjax">Software</span> (TOMS)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.09028">arXiv:2106.09028</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.09028">pdf</a>, <a href="https://arxiv.org/ps/2106.09028">ps</a>, <a href="https://arxiv.org/format/2106.09028">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Quantum Physics">quant-ph</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Exponential Error Convergence in Data Classification with <span class="search-hit mathjax">Optimized</span> Random Features: Acceleration by Quantum Machine Learning
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Yamasaki%2C+H">Hayata Yamasaki</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sonoda%2C+S">Sho Sonoda</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.09028v1-abstract-short" style="display: inline;">
        &hellip;algorithms based on kernel methods. A recent work has shown that an algorithm for machine learning by quantum computer, quantum machine learning (QML), can exponentially <span class="search-hit mathjax">speed</span> up sampling of&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.09028v1-abstract-full').style.display = 'inline'; document.getElementById('2106.09028v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.09028v1-abstract-full" style="display: none;">
        Random features are a central technique for scalable learning algorithms based on kernel methods. A recent work has shown that an algorithm for machine learning by quantum computer, quantum machine learning (QML), can exponentially <span class="search-hit mathjax">speed</span> up sampling of <span class="search-hit mathjax">optimized</span> random features, even without imposing restrictive assumptions on sparsity and low-rankness of matrices that had limited <span class="search-hit mathjax">applicability</span> of conventional QML algorithms; this QML algorithm makes it possible to significantly <span class="search-hit mathjax">reduce</span> and provably minimize the required number of features for regression tasks. However, a major interest in the field of QML is how widely the advantages of quantum computation can be exploited, not only in the regression tasks. We here construct a QML algorithm for a classification task accelerated by the <span class="search-hit mathjax">optimized</span> random features. We prove that the QML algorithm for sampling <span class="search-hit mathjax">optimized</span> random features, combined with stochastic gradient descent (SGD), can achieve state-of-the-art exponential convergence <span class="search-hit mathjax">speed</span> of <span class="search-hit mathjax">reducing</span> classification error in a classification task under a low-noise condition; at the same <span class="search-hit mathjax">time</span>, our algorithm with <span class="search-hit mathjax">optimized</span> random features can take advantage of the significant reduction of the required number of features so as to accelerate each iteration in the SGD and evaluation of the classifier obtained from our algorithm. These results discover a promising <span class="search-hit mathjax">application</span> of QML to significant acceleration of the leading classification algorithm based on kernel methods, without ruining its <span class="search-hit mathjax">applicability</span> to a practical class of data sets and the exponential error-convergence <span class="search-hit mathjax">speed</span>.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.09028v1-abstract-full').style.display = 'none'; document.getElementById('2106.09028v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">28 pages, no figure</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.08253">arXiv:2106.08253</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.08253">pdf</a>, <a href="https://arxiv.org/ps/2106.08253">ps</a>, <a href="https://arxiv.org/format/2106.08253">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        <span class="search-hit mathjax">Code</span> Generation Based on Deep Learning: a Brief Review
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zhu%2C+Q">Qihao Zhu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+W">Wenjie Zhang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.08253v4-abstract-short" style="display: inline;">
        <span class="search-hit mathjax">Automatic</span>&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.08253v4-abstract-full').style.display = 'inline'; document.getElementById('2106.08253v4-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.08253v4-abstract-full" style="display: none;">
        <span class="search-hit mathjax">Automatic</span> <span class="search-hit mathjax">software</span> development has been a research hot spot in the field of <span class="search-hit mathjax">software</span> engineering (SE) in the past decade. In particular, deep learning (DL) has been applied and achieved a lot of progress in various SE tasks. Among all <span class="search-hit mathjax">applications</span>, <span class="search-hit mathjax">automatic</span> <span class="search-hit mathjax">code</span> generation by machines as a general concept, including <span class="search-hit mathjax">code</span> completion and <span class="search-hit mathjax">code</span> synthesis, is a common expectation in the field of SE, which may greatly <span class="search-hit mathjax">reduce</span> the development burden of the <span class="search-hit mathjax">software</span> developers and <span class="search-hit mathjax">improves</span> the efficiency and quality of the <span class="search-hit mathjax">software</span> development process to a certain extent. <span class="search-hit mathjax">Code</span> completion is an important part of modern integrated development environments (IDEs). <span class="search-hit mathjax">Code</span> completion technology effectively helps programmers complete <span class="search-hit mathjax">code</span> class names, method names, and key-words, etc., which <span class="search-hit mathjax">improves</span> the efficiency of <span class="search-hit mathjax">program</span> development and <span class="search-hit mathjax">reduces</span> spelling errors in the <span class="search-hit mathjax">coding</span> process. Such tools use static analysis on the <span class="search-hit mathjax">code</span> and provide candidates for completion arranged in alphabetical order. <span class="search-hit mathjax">Code</span> synthesis is implemented from two aspects, one based on input-output samples and the other based on functionality description. In this study, we introduce existing techniques of these two aspects and the corresponding DL techniques, and present some possible future research directions.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.08253v4-abstract-full').style.display = 'none'; document.getElementById('2106.08253v4-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 4 July, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 15 June, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">10 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.07778">arXiv:2106.07778</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.07778">pdf</a>, <a href="https://arxiv.org/format/2106.07778">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Networking and Internet Architecture">cs.NI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        fybrrLink: Efficient QoS-aware Routing in SDN enabled Next-Gen Satellite Networks
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Kumar%2C+P">Prashant Kumar</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bhushan%2C+S">Saksham Bhushan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Halder%2C+D">Debajyoti Halder</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Baswade%2C+A+M">Anand M. Baswade</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.07778v1-abstract-short" style="display: inline;">
        Providing high-<span class="search-hit mathjax">speed</span> Internet service using satellite network has attracted researchers from both academia and industry mainly due to the characteristics of Low Earth Orbit (LEO) satellite networks such as global coverage, scalability, and lower transmission delay. With the recent advancements in the&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.07778v1-abstract-full').style.display = 'inline'; document.getElementById('2106.07778v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.07778v1-abstract-full" style="display: none;">
        Providing high-<span class="search-hit mathjax">speed</span> Internet service using satellite network has attracted researchers from both academia and industry mainly due to the characteristics of Low Earth Orbit (LEO) satellite networks such as global coverage, scalability, and lower transmission delay. With the recent advancements in the <span class="search-hit mathjax">Software</span>-Defined Network (SDN), implementation of SDN in Non-Terrestrial Networks (NTN) can help to achieve the set goals for 5G and beyond networks. Since satellite networks have a distinct architecture, some of the traditional protocols no longer remain useful. Therefore, to satisfy the diverse Quality of Service (QoS) requirements for a variety of <span class="search-hit mathjax">applications</span>, we propose a novel and centralized QoS-aware routing algorithm, called fybrrLink in which the global view of the network in SDN is utilized. We implement a modified Bresenham&#39;s algorithm and Dijkstra&#39;s algorithm to find the <span class="search-hit mathjax">optimal</span> path in a significantly <span class="search-hit mathjax">reduced</span> computation <span class="search-hit mathjax">time</span>. Also, taking advantage of the deterministic satellite constellation, we propose a flow rule transfer algorithm and a topology monitoring algorithm. Further, fybrrLink is evaluated with multiple NS3 simulations, and results confirm its supremacy over other state-of-the-art algorithms.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.07778v1-abstract-full').style.display = 'none'; document.getElementById('2106.07778v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.07537">arXiv:2106.07537</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.07537">pdf</a>, <a href="https://arxiv.org/format/2106.07537">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A Wasserstein Minimax Framework for Mixed Linear Regression
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Diamandis%2C+T">Theo Diamandis</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Eldar%2C+Y+C">Yonina C. Eldar</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fallah%2C+A">Alireza Fallah</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farnia%2C+F">Farzan Farnia</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ozdaglar%2C+A">Asuman Ozdaglar</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.07537v2-abstract-short" style="display: inline;">
        &hellip;distributions are commonly used to model clustered data in statistical learning tasks. In this paper, we consider the Mixed Linear Regression (MLR) problem. We propose an <span class="search-hit mathjax">optimal</span> transport-based framework for MLR problems, Wasserstein Mixed Linear Regression (WMLR), which minimizes the Wasserstein distance between the learned and target mixture regression mo&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.07537v2-abstract-full').style.display = 'inline'; document.getElementById('2106.07537v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.07537v2-abstract-full" style="display: none;">
        Multi-modal distributions are commonly used to model clustered data in statistical learning tasks. In this paper, we consider the Mixed Linear Regression (MLR) problem. We propose an <span class="search-hit mathjax">optimal</span> transport-based framework for MLR problems, Wasserstein Mixed Linear Regression (WMLR), which minimizes the Wasserstein distance between the learned and target mixture regression models. Through a model-based duality analysis, WMLR <span class="search-hit mathjax">reduces</span> the underlying MLR task to a nonconvex-concave minimax <span class="search-hit mathjax">optimization</span> problem, which can be provably solved to find a minimax stationary point by the Gradient Descent Ascent (GDA) algorithm. In the special case of mixtures of two linear regression models, we show that WMLR enjoys global convergence and generalization guarantees. We prove that WMLR&#39;s sample complexity grows linearly with the dimension of data. Finally, we discuss the <span class="search-hit mathjax">application</span> of WMLR to the federated learning task where the training samples are collected by multiple agents in a network. Unlike the Expectation Maximization algorithm, WMLR directly extends to the distributed, federated learning setting. We support our theoretical results through several numerical experiments, which highlight our framework&#39;s ability to handle the federated learning setting with mixture models.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.07537v2-abstract-full').style.display = 'none'; document.getElementById('2106.07537v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 June, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 14 June, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">To appear in 38th International Conference on Machine Learning (ICML 2021)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.07520">arXiv:2106.07520</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.07520">pdf</a>, <a href="https://arxiv.org/format/2106.07520">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        JUGE: An Infrastructure for Benchmarking Java Unit Test Generators
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Devroey%2C+X">Xavier Devroey</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gambi%2C+A">Alessio Gambi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Galeotti%2C+J+P">Juan Pablo Galeotti</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Just%2C+R">RenÃ© Just</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kifetew%2C+F">Fitsum Kifetew</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Panichella%2C+A">Annibale Panichella</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Panichella%2C+S">Sebastiano Panichella</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.07520v1-abstract-short" style="display: inline;">
        Researchers and practitioners have designed and implemented various <span class="search-hit mathjax">automated</span> test case generators to support effective&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.07520v1-abstract-full').style.display = 'inline'; document.getElementById('2106.07520v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.07520v1-abstract-full" style="display: none;">
        Researchers and practitioners have designed and implemented various <span class="search-hit mathjax">automated</span> test case generators to support effective <span class="search-hit mathjax">software</span> testing. Such generators exist for various languages (e.g., Java, C#, or Python) and for various platforms (e.g., desktop, web, or mobile <span class="search-hit mathjax">applications</span>). Such generators exhibit varying effectiveness and efficiency, depending on the testing goals they aim to satisfy (e.g., unit-testing of libraries vs. system-testing of entire <span class="search-hit mathjax">applications</span>) and the underlying techniques they implement. In this context, practitioners need to be able to compare different generators to identify the most suited one for their requirements, while researchers seek to identify future research directions. This can be achieved through the systematic execution of large-scale evaluations of different generators. However, the execution of such empirical evaluations is not trivial and requires a substantial effort to collect benchmarks, setup the evaluation infrastructure, and collect and analyse the results. In this paper, we present our JUnit Generation benchmarking infrastructure (JUGE) supporting generators (e.g., search-based, random-based, symbolic execution, etc.) seeking to <span class="search-hit mathjax">automate</span> the production of unit tests for various purposes (e.g., validation, regression testing, fault localization, etc.). The primary goal is to <span class="search-hit mathjax">reduce</span> the overall effort, ease the comparison of several generators, and enhance the knowledge transfer between academia and industry by standardizing the evaluation and comparison process. Since 2013, eight editions of a unit testing tool competition, co-located with the Search-Based <span class="search-hit mathjax">Software</span> Testing Workshop, have taken place and used and updated JUGE. As a result, an increasing amount of tools (over ten) from both academia and industry have been evaluated on JUGE, matured over the years, and allowed the identification of future research directions.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.07520v1-abstract-full').style.display = 'none'; document.getElementById('2106.07520v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.07243">arXiv:2106.07243</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.07243">pdf</a>, <a href="https://arxiv.org/ps/2106.07243">ps</a>, <a href="https://arxiv.org/format/2106.07243">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Multiagent Systems">cs.MA</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Signal Processing">eess.SP</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Compressed Gradient Tracking for Decentralized <span class="search-hit mathjax">Optimization</span> Over General Directed Networks
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Song%2C+Z">Zhuoqing Song</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shi%2C+L">Lei Shi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pu%2C+S">Shi Pu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yan%2C+M">Ming Yan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.07243v1-abstract-short" style="display: inline;">
        In this paper, we propose two communication-efficient algorithms for decentralized <span class="search-hit mathjax">optimization</span> over a multi-agent network with general directed network topology. In the first part, we consider a novel communication-efficient gradient tracking based method, termed Compressed Push-Pull (CPP), which combines the Push-Pull method with communication compression.&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.07243v1-abstract-full').style.display = 'inline'; document.getElementById('2106.07243v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.07243v1-abstract-full" style="display: none;">
        In this paper, we propose two communication-efficient algorithms for decentralized <span class="search-hit mathjax">optimization</span> over a multi-agent network with general directed network topology. In the first part, we consider a novel communication-efficient gradient tracking based method, termed Compressed Push-Pull (CPP), which combines the Push-Pull method with communication compression. We show that CPP is <span class="search-hit mathjax">applicable</span> to a general class of unbiased compression operators and achieves linear convergence for strongly convex and smooth objective functions. In the second part, we propose a broadcast-like version of CPP (B-CPP), which also achieves linear convergence rate under the same conditions for the objective functions. B-CPP can be applied in an asynchronous broadcast setting and further <span class="search-hit mathjax">reduce</span> communication costs compared to CPP. Numerical experiments complement the theoretical analysis and confirm the effectiveness of the proposed methods.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.07243v1-abstract-full').style.display = 'none'; document.getElementById('2106.07243v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">working paper</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.04916">arXiv:2106.04916</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.04916">pdf</a>, <a href="https://arxiv.org/format/2106.04916">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Erratum: Leveraging Flexible Tree Matching to Repair Broken Locators in Web <span class="search-hit mathjax">Automation</span> Scripts
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Brisset%2C+S">Sacha Brisset</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rouvoy%2C+R">Romain Rouvoy</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Seinturier%2C+L">Lionel Seinturier</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pawlak%2C+R">Renaud Pawlak</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.04916v1-abstract-short" style="display: inline;">
        Web <span class="search-hit mathjax">applications</span> are constantly evolving to integrate new features and fix reported bugs. Even an imperceptible change can sometimes entail significant modifications of the Document Object Model (DOM), which is the underlying model used by browsers to render all the elements included in a web&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.04916v1-abstract-full').style.display = 'inline'; document.getElementById('2106.04916v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.04916v1-abstract-full" style="display: none;">
        Web <span class="search-hit mathjax">applications</span> are constantly evolving to integrate new features and fix reported bugs. Even an imperceptible change can sometimes entail significant modifications of the Document Object Model (DOM), which is the underlying model used by browsers to render all the elements included in a web <span class="search-hit mathjax">application</span>. Scripts that interact with web <span class="search-hit mathjax">applications</span> (e.g. web test scripts, crawlers, or robotic process <span class="search-hit mathjax">automation</span>) rely on this continuously evolving DOM which means they are often particularly fragile. More precisely, the major cause of breakages observed in <span class="search-hit mathjax">automation</span> scripts are element locators, which are identifiers used by <span class="search-hit mathjax">automation</span> scripts to navigate across the DOM. When the DOM evolves, these identifiers tend to break, thus causing the related scripts to no longer locate the intended target elements. For this reason, several contributions explored the idea of <span class="search-hit mathjax">automatically</span> repairing broken locators on a page. These works attempt to repair a given broken locator by scanning all elements in the new DOM to find the most similar one. Unfortunately, this approach fails to scale when the complexity of web pages grows, leading either to long computation <span class="search-hit mathjax">times</span> or incorrect element repairs. This article, therefore, adopts a different perspective on this problem by introducing a new locator repair solution that leverages tree matching algorithms to relocate broken locators. This solution, named Erratum, implements a holistic approach to <span class="search-hit mathjax">reduce</span> the element search space, which greatly eases the locator repair task and drastically <span class="search-hit mathjax">improves</span> repair accuracy. We compare the robustness of Erratum on a large-scale benchmark composed of realistic and synthetic mutations applied to popular web <span class="search-hit mathjax">applications</span> currently deployed in production. Our empirical results demonstrate that Erratum outperforms the accuracy of WATER, a state-of-the-art solution, by 67%.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.04916v1-abstract-full').style.display = 'none'; document.getElementById('2106.04916v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 9 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.04729">arXiv:2106.04729</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.04729">pdf</a>, <a href="https://arxiv.org/format/2106.04729">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Drones for Medical Delivery Considering Different Demands Classes: A Markov Decision Process Approach for Managing Health Centers Dispatching Medical Products
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Asadi%2C+A">Amin Asadi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pinkley%2C+S+N">Sarah Nurre Pinkley</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.04729v1-abstract-short" style="display: inline;">
        We consider the problem of <span class="search-hit mathjax">optimizing</span> the distribution operations of a hub using drones to deliver medical supplies to different geographic regions. Drones are an innovative method with many benefits including low-contact delivery thereby&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.04729v1-abstract-full').style.display = 'inline'; document.getElementById('2106.04729v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.04729v1-abstract-full" style="display: none;">
        We consider the problem of <span class="search-hit mathjax">optimizing</span> the distribution operations of a hub using drones to deliver medical supplies to different geographic regions. Drones are an innovative method with many benefits including low-contact delivery thereby <span class="search-hit mathjax">reducing</span> the spread of pandemic and vaccine-preventable diseases. While we focus on medical supply delivery for this work, it is <span class="search-hit mathjax">applicable</span> to drone delivery for many other <span class="search-hit mathjax">applications</span>, including food, postal items, and e-commerce delivery. In this paper, our goal is to address drone delivery challenges by <span class="search-hit mathjax">optimizing</span> the distribution operations at a drone hub that dispatch drones to different geographic locations generating stochastic demands for medical supplies. By considering different geographic locations, we consider different classes of demand that require different flight ranges, which is directly related to the amount of charge held in a drone battery. We classify the stochastic demands based on their distance from the drone hub, use a Markov decision process to model the problem, and perform computational tests using realistic data representing a prominent drone delivery company. We solve the problem using a reinforcement learning method and show its high performance compared with the exact solution found using dynamic <span class="search-hit mathjax">programming</span>. Finally, we analyze the results and provide insights for managing the drone hub operations.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.04729v1-abstract-full').style.display = 'none'; document.getElementById('2106.04729v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.04618">arXiv:2106.04618</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.04618">pdf</a>, <a href="https://arxiv.org/format/2106.04618">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Neural and Evolutionary Computing">cs.NE</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        EXPObench: Benchmarking Surrogate-based Optimisation Algorithms on Expensive Black-box Functions
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Bliek%2C+L">Laurens Bliek</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Guijt%2C+A">Arthur Guijt</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Karlsson%2C+R">Rickard Karlsson</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Verwer%2C+S">Sicco Verwer</a>, 
      
      <a href="/search/?searchtype=author&amp;query=de+Weerdt%2C+M">Mathijs de Weerdt</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.04618v1-abstract-short" style="display: inline;">
        &hellip;the literature, these algorithms are usually evaluated with synthetic benchmarks which are well established but have no expensive objective, and only on one or two real-life <span class="search-hit mathjax">applications</span> which vary wildly between papers. There is a clear lack of standardisation when it comes to benchmarking surrogate algorithms on real-life, expensive, black-box objective fu&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.04618v1-abstract-full').style.display = 'inline'; document.getElementById('2106.04618v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.04618v1-abstract-full" style="display: none;">
        Surrogate algorithms such as Bayesian optimisation are especially designed for black-box optimisation problems with expensive objectives, such as hyperparameter tuning or simulation-based optimisation. In the literature, these algorithms are usually evaluated with synthetic benchmarks which are well established but have no expensive objective, and only on one or two real-life <span class="search-hit mathjax">applications</span> which vary wildly between papers. There is a clear lack of standardisation when it comes to benchmarking surrogate algorithms on real-life, expensive, black-box objective functions. This makes it very difficult to draw conclusions on the effect of algorithmic contributions. A new benchmark library, EXPObench, provides first steps towards such a standardisation. The library is used to provide an extensive comparison of six different surrogate algorithms on four expensive optimisation problems from different real-life <span class="search-hit mathjax">applications</span>. This has led to new insights regarding the relative importance of exploration, the evaluation <span class="search-hit mathjax">time</span> of the objective, and the used model. A further contribution is that we make the algorithms and benchmark problem instances publicly available, contributing to more uniform analysis of surrogate algorithms. Most importantly, we include the performance of the six algorithms on all evaluated problem instances. This results in a unique new dataset that lowers the bar for researching new methods as the number of expensive evaluations required for comparison is significantly <span class="search-hit mathjax">reduced</span>.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.04618v1-abstract-full').style.display = 'none'; document.getElementById('2106.04618v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">13 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.04508">arXiv:2106.04508</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.04508">pdf</a>, <a href="https://arxiv.org/format/2106.04508">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Energy-Efficient Adaptive System Reconfiguration for Dynamic Deadlines in Autonomous Driving
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Yi%2C+S">Saehanseul Yi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kim%2C+T">Tae-Wook Kim</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kim%2C+J">Jong-Chan Kim</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dutt%2C+N">Nikil Dutt</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.04508v1-abstract-short" style="display: inline;">
        The increasing computing demands of autonomous driving <span class="search-hit mathjax">applications</span> make energy&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.04508v1-abstract-full').style.display = 'inline'; document.getElementById('2106.04508v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.04508v1-abstract-full" style="display: none;">
        The increasing computing demands of autonomous driving <span class="search-hit mathjax">applications</span> make energy <span class="search-hit mathjax">optimizations</span> critical for <span class="search-hit mathjax">reducing</span> battery capacity and vehicle weight. Current energy <span class="search-hit mathjax">optimization</span> methods typically target traditional real-<span class="search-hit mathjax">time</span> systems with static deadlines, resulting in conservative energy savings that are unable to exploit additional energy <span class="search-hit mathjax">optimizations</span> due to dynamic deadlines arising from the vehicle&#39;s change in velocity and driving context. We present an adaptive system <span class="search-hit mathjax">optimization</span> and reconfiguration approach that dynamically adapts the scheduling parameters and processor <span class="search-hit mathjax">speeds</span> to satisfy dynamic deadlines while consuming as little energy as possible. Our experimental results with an autonomous driving task set from Bosch and real-world driving data show energy reductions up to 46.4% on average in typical dynamic driving scenarios compared with traditional static energy <span class="search-hit mathjax">optimization</span> methods, demonstrating great potential for dynamic energy <span class="search-hit mathjax">optimization</span> gains by exploiting dynamic deadlines.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.04508v1-abstract-full').style.display = 'none'; document.getElementById('2106.04508v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 3 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">IEEE ISORC 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.04494">arXiv:2106.04494</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.04494">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Information Retrieval">cs.IR</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        <span class="search-hit mathjax">Optimization</span> of Service Addition in Multilevel Index Model for Edge Computing
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Gu%2C+J">Jiayan Gu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wu%2C+Y">Yan Wu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Anjum%2C+A">Ashiq Anjum</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Panneerselvam%2C+J">John Panneerselvam</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lu%2C+Y">Yao Lu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yuan%2C+B">Bo Yuan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.04494v2-abstract-short" style="display: inline;">
        &hellip;(AI) technologies, edge devices are witnessed to generate data at unprecedented volume. The Edge Intelligence (EI) has led to the emergence of edge devices in various <span class="search-hit mathjax">application</span> domains. The EI can provide efficient services to delay-sensitive&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.04494v2-abstract-full').style.display = 'inline'; document.getElementById('2106.04494v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.04494v2-abstract-full" style="display: none;">
        With the development of Edge Computing and Artificial Intelligence (AI) technologies, edge devices are witnessed to generate data at unprecedented volume. The Edge Intelligence (EI) has led to the emergence of edge devices in various <span class="search-hit mathjax">application</span> domains. The EI can provide efficient services to delay-sensitive <span class="search-hit mathjax">applications</span>, where the edge devices are deployed as edge nodes to host the majority of execution, which can effectively manage services and <span class="search-hit mathjax">improve</span> service discovery efficiency. The multilevel index model is a well-known model used for indexing service, such a model is being introduced and <span class="search-hit mathjax">optimized</span> in the edge environments to efficiently services discovery whilst managing large volumes of data. However, effectively updating the multilevel index model by adding new services <span class="search-hit mathjax">timely</span> and precisely in the dynamic Edge Computing environments is still a challenge. Addressing this issue, this paper proposes a designated key selection method to <span class="search-hit mathjax">improve</span> the efficiency of adding services in the multilevel index models. Our experimental results show that in the partial index and the full index of multilevel index model, our method <span class="search-hit mathjax">reduces</span> the service addition <span class="search-hit mathjax">time</span> by around 84% and 76%, respectively when compared with the original key selection method and by around 78% and 66%, respectively when compared with the random selection method. Our proposed method significantly <span class="search-hit mathjax">improves</span> the service addition efficiency in the multilevel index model, when compared with existing state-of-the-art key selection methods, without compromising the service retrieval stability to any notable level.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.04494v2-abstract-full').style.display = 'none'; document.getElementById('2106.04494v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 19 June, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 8 June, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.04217">arXiv:2106.04217</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.04217">pdf</a>, <a href="https://arxiv.org/format/2106.04217">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Dynamic Sparse Training for Deep Reinforcement Learning
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Sokar%2C+G">Ghada Sokar</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mocanu%2C+E">Elena Mocanu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mocanu%2C+D+C">Decebal Constantin Mocanu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pechenizkiy%2C+M">Mykola Pechenizkiy</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Stone%2C+P">Peter Stone</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.04217v1-abstract-short" style="display: inline;">
        Deep reinforcement learning has achieved significant success in many decision-making tasks in various fields. However, it requires a large training <span class="search-hit mathjax">time</span> of dense neural networks to obtain a good performance. This hinders its&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.04217v1-abstract-full').style.display = 'inline'; document.getElementById('2106.04217v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.04217v1-abstract-full" style="display: none;">
        Deep reinforcement learning has achieved significant success in many decision-making tasks in various fields. However, it requires a large training <span class="search-hit mathjax">time</span> of dense neural networks to obtain a good performance. This hinders its <span class="search-hit mathjax">applicability</span> on low-resource devices where memory and computation are strictly constrained. In a step towards enabling deep reinforcement learning agents to be applied to low-resource devices, in this work, we propose for the first <span class="search-hit mathjax">time</span> to dynamically train deep reinforcement learning agents with sparse neural networks from scratch. We adopt the evolution principles of dynamic sparse training in the reinforcement learning paradigm and introduce a training algorithm that <span class="search-hit mathjax">optimizes</span> the sparse topology and the weight values jointly to dynamically fit the incoming data. Our approach is easy to be integrated into existing deep reinforcement learning algorithms and has many favorable advantages. First, it allows for significant compression of the network size which <span class="search-hit mathjax">reduces</span> the memory and computation costs substantially. This would accelerate not only the agent inference but also its training process. Second, it <span class="search-hit mathjax">speeds</span> up the agent learning process and allows for <span class="search-hit mathjax">reducing</span> the number of required training steps. Third, it can achieve higher performance than training the dense counterpart network. We evaluate our approach on OpenAI gym continuous control tasks. The experimental results show the effectiveness of our approach in achieving higher performance than one of the state-of-art baselines with a 50\% reduction in the network size and floating-point operations (FLOPs). Moreover, our proposed approach can reach the same performance achieved by the dense network with a 40-50\% reduction in the number of training steps.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.04217v1-abstract-full').style.display = 'none'; document.getElementById('2106.04217v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Preprint</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.03799">arXiv:2106.03799</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.03799">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Data Structures and Algorithms">cs.DS</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Deterministic Iteratively Built KD-Tree with KNN Search for Exact <span class="search-hit mathjax">Applications</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Naim%2C+A">Aryan Naim</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bowkett%2C+J">Joseph Bowkett</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Karumanchi%2C+S">Sisir Karumanchi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tavallali%2C+P">Peyman Tavallali</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kennedy%2C+B">Brett Kennedy</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.03799v1-abstract-short" style="display: inline;">
        K-Nearest Neighbors (KNN) search is a fundamental algorithm in artificial intelligence <span class="search-hit mathjax">software</span> with&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.03799v1-abstract-full').style.display = 'inline'; document.getElementById('2106.03799v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.03799v1-abstract-full" style="display: none;">
        K-Nearest Neighbors (KNN) search is a fundamental algorithm in artificial intelligence <span class="search-hit mathjax">software</span> with <span class="search-hit mathjax">applications</span> in robotics, and autonomous vehicles. These wide-ranging <span class="search-hit mathjax">applications</span> utilize KNN either directly for simple classification or combine KNN results as input to other algorithms such as Locally Weighted Learning (LWL). Similar to binary trees, kd-trees become unbalanced as new data is added in online <span class="search-hit mathjax">applications</span> which can lead to rapid degradation in search performance unless the tree is rebuilt. Although approximate methods are suitable for graphics <span class="search-hit mathjax">applications</span>, which prioritize query <span class="search-hit mathjax">speed</span> over query accuracy, they are unsuitable for certain <span class="search-hit mathjax">applications</span> in autonomous systems, aeronautics, and robotic manipulation where exact solutions are desired. In this paper, we will attempt to assess the performance of non-recursive deterministic kd-tree functions and KNN functions. We will also present a &#34;forest of interval kd-trees&#34; which <span class="search-hit mathjax">reduces</span> the number of tree rebuilds, without compromising the exactness of query results.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.03799v1-abstract-full').style.display = 'none'; document.getElementById('2106.03799v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.03368">arXiv:2106.03368</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.03368">pdf</a>, <a href="https://arxiv.org/format/2106.03368">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1007/978-3-319-64119-5_14">10.1007/978-3-319-64119-5_14 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Verification of Component Fault Trees Using Error Effect Simulations
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Reiter%2C+S">Sebastian Reiter</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zeller%2C+M">Marc Zeller</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hoefig%2C+K">Kai Hoefig</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Viehl%2C+A">Alexander Viehl</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bringmann%2C+O">Oliver Bringmann</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rosenstiel%2C+W">Wolfgang Rosenstiel</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.03368v1-abstract-short" style="display: inline;">
        The growing complexity of safety-relevant systems causes an increasing effort for safety assurance. The reduction of development costs and <span class="search-hit mathjax">time</span>-to-market, while guaranteeing safe operation, is therefore a major challenge. In order to enable efficient safety assessment of complex architectures, we present an approach, which combines deductive safety analyses,&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.03368v1-abstract-full').style.display = 'inline'; document.getElementById('2106.03368v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.03368v1-abstract-full" style="display: none;">
        The growing complexity of safety-relevant systems causes an increasing effort for safety assurance. The reduction of development costs and <span class="search-hit mathjax">time</span>-to-market, while guaranteeing safe operation, is therefore a major challenge. In order to enable efficient safety assessment of complex architectures, we present an approach, which combines deductive safety analyses, in form of Component Fault Trees (CFTs), with an Error Effect Simulation (EES) for sanity checks. The combination <span class="search-hit mathjax">reduces</span> the drawbacks of both analyses, such as the subjective failure propagation assumptions in the CFTs or the determination of relevant fault scenarios for the EES. Both CFTs and the EES provide a modular, reusable and compositional safety analysis and are <span class="search-hit mathjax">applicable</span> throughout the whole design process. They support continuous model refinement and the reuse of conducted safety analysis and simulation models. Hence, safety goal violations can be identified in early design stages and the reuse of conducted safety analyses <span class="search-hit mathjax">reduces</span> the overhead for safety assessment.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.03368v1-abstract-full').style.display = 'none'; document.getElementById('2106.03368v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.03353">arXiv:2106.03353</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.03353">pdf</a>, <a href="https://arxiv.org/format/2106.03353">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Programming Languages">cs.PL</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Understanding Neural <span class="search-hit mathjax">Code</span> Intelligence Through <span class="search-hit mathjax">Program</span> Simplification
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Rabin%2C+M+R+I">Md Rafiqul Islam Rabin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hellendoorn%2C+V+J">Vincent J. Hellendoorn</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Alipour%2C+M+A">Mohammad Amin Alipour</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.03353v1-abstract-short" style="display: inline;">
        A wide range of <span class="search-hit mathjax">code</span> intelligence (CI) tools, powered by deep neural networks, have been developed recently to&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.03353v1-abstract-full').style.display = 'inline'; document.getElementById('2106.03353v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.03353v1-abstract-full" style="display: none;">
        A wide range of <span class="search-hit mathjax">code</span> intelligence (CI) tools, powered by deep neural networks, have been developed recently to <span class="search-hit mathjax">improve</span> <span class="search-hit mathjax">programming</span> productivity and perform <span class="search-hit mathjax">program</span> analysis. To reliably use such tools, developers often need to reason about the behavior of the underlying models and the factors that affect them. This is especially challenging for tools backed by deep neural networks. Various methods have tried to <span class="search-hit mathjax">reduce</span> this opacity in the vein of &#34;transparent/interpretable-AI&#34;. However, these approaches are often specific to a particular set of network architectures, even requiring access to the network&#39;s parameters. This makes them difficult to use for the average programmer, which hinders the reliable adoption of neural CI systems. In this paper, we propose a simple, model-agnostic approach to identify critical input features for models in CI systems, by drawing on <span class="search-hit mathjax">software</span> debugging research, specifically delta debugging. Our approach, SIVAND, uses simplification techniques that <span class="search-hit mathjax">reduce</span> the size of input <span class="search-hit mathjax">programs</span> of a CI model while preserving the predictions of the model. We show that this approach yields remarkably small outputs and is broadly <span class="search-hit mathjax">applicable</span> across many model architectures and problem domains. We find that the models in our experiments often rely heavily on just a few syntactic features in input <span class="search-hit mathjax">programs</span>. We believe that SIVAND&#39;s extracted features may help understand neural CI systems&#39; predictions and learned behavior.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.03353v1-abstract-full').style.display = 'none'; document.getElementById('2106.03353v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">The 29th ACM Joint European <span class="search-hit mathjax">Software</span> Engineering Conference and Symposium on the Foundations of <span class="search-hit mathjax">Software</span> Engineering (ESEC/FSE'21)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.03272">arXiv:2106.03272</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.03272">pdf</a>, <a href="https://arxiv.org/format/2106.03272">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computational Finance">q-fin.CP</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Signatured Deep Fictitious Play for Mean Field Games with Common Noise
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Min%2C+M">Ming Min</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hu%2C+R">Ruimeng Hu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.03272v1-abstract-short" style="display: inline;">
        &hellip;structure with millions of simulations of common noise paths in order to produce accurate solutions, which results in prohibitive computational cost and limits the <span class="search-hit mathjax">applications</span> to a large extent. In this paper, based on the rough path theory, we propose a novel single-loop algorithm, named signatured deep fictitious play, by which we can work with the unfixe&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.03272v1-abstract-full').style.display = 'inline'; document.getElementById('2106.03272v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.03272v1-abstract-full" style="display: none;">
        Existing deep learning methods for solving mean-field games (MFGs) with common noise fix the sampling common noise paths and then solve the corresponding MFGs. This leads to a nested-loop structure with millions of simulations of common noise paths in order to produce accurate solutions, which results in prohibitive computational cost and limits the <span class="search-hit mathjax">applications</span> to a large extent. In this paper, based on the rough path theory, we propose a novel single-loop algorithm, named signatured deep fictitious play, by which we can work with the unfixed common noise setup to avoid the nested-loop structure and <span class="search-hit mathjax">reduce</span> the computational complexity significantly. The proposed algorithm can accurately capture the effect of common uncertainty changes on mean-field equilibria without further training of neural networks, as previously needed in the existing machine learning algorithms. The efficiency is supported by three <span class="search-hit mathjax">applications</span>, including linear-quadratic MFGs, mean-field portfolio game, and mean-field game of <span class="search-hit mathjax">optimal</span> consumption and investment. Overall, we provide a new point of view from the rough path theory to solve MFGs with common noise with significantly <span class="search-hit mathjax">improved</span> efficiency and an extensive range of <span class="search-hit mathjax">applications</span>. In addition, we report the first deep learning work to deal with extended MFGs (a mean-field interaction via both the states and controls) with common noise.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.03272v1-abstract-full').style.display = 'none'; document.getElementById('2106.03272v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 6 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Published at ICML 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.02140">arXiv:2106.02140</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.02140">pdf</a>, <a href="https://arxiv.org/format/2106.02140">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1007/978-3-319-10557-4_43">10.1007/978-3-319-10557-4_43 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Towards a Cross-Domain <span class="search-hit mathjax">Software</span> Safety Assurance Process for Embedded Systems
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zeller%2C+M">Marc Zeller</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hoefig%2C+K">Kai Hoefig</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rothfelder%2C+M">Martin Rothfelder</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.02140v1-abstract-short" style="display: inline;">
        In this work, we outline a cross-domain assurance process for safety-relevant <span class="search-hit mathjax">software</span> in embedded systems. This process aims to be applied in various different <span class="search-hit mathjax">application</span> domains and in conjunction with any development methodology. With this approach we plan to <span class="search-hit mathjax">reduce</span> the growi&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.02140v1-abstract-full').style.display = 'inline'; document.getElementById('2106.02140v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.02140v1-abstract-full" style="display: none;">
        In this work, we outline a cross-domain assurance process for safety-relevant <span class="search-hit mathjax">software</span> in embedded systems. This process aims to be applied in various different <span class="search-hit mathjax">application</span> domains and in conjunction with any development methodology. With this approach we plan to <span class="search-hit mathjax">reduce</span> the growing effort for safety assessment in embedded systems by reusing safety analysis techniques and tools for the product development in different domains.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.02140v1-abstract-full').style.display = 'none'; document.getElementById('2106.02140v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 3 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.02018">arXiv:2106.02018</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.02018">pdf</a>, <a href="https://arxiv.org/format/2106.02018">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Nonlinear Matrix Approximation with Radial Basis Function Components
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Rebrova%2C+E">Elizaveta Rebrova</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tang%2C+Y">Yu-Hang Tang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.02018v2-abstract-short" style="display: inline;">
        &hellip;us to compute the decomposition for any real matrix that is not necessarily symmetric or positive definite. We formulate the problem of seeking such a decomposition as an <span class="search-hit mathjax">optimization</span> problem with a nonlinear and non-convex loss function. Several modern versions of the gradient descent method, including their scalable stochastic counterparts, are used to sol&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.02018v2-abstract-full').style.display = 'inline'; document.getElementById('2106.02018v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.02018v2-abstract-full" style="display: none;">
        We introduce and investigate matrix approximation by decomposition into a sum of radial basis function (RBF) components. An RBF component is a generalization of the outer product between a pair of vectors, where an RBF function replaces the scalar multiplication between individual vector elements. Even though the RBF functions are positive definite, the summation across components is not restricted to convex combinations and allows us to compute the decomposition for any real matrix that is not necessarily symmetric or positive definite. We formulate the problem of seeking such a decomposition as an <span class="search-hit mathjax">optimization</span> problem with a nonlinear and non-convex loss function. Several modern versions of the gradient descent method, including their scalable stochastic counterparts, are used to solve this problem. We provide extensive empirical evidence of the effectiveness of the RBF decomposition and that of the gradient-based fitting algorithm. While being conceptually motivated by singular value decomposition (SVD), our proposed nonlinear counterpart outperforms SVD by drastically <span class="search-hit mathjax">reducing</span> the memory required to approximate a data matrix with the same L2 error for a wide range of matrix types. For example, it leads to 2 to 6 <span class="search-hit mathjax">times</span> memory save for Gaussian noise, graph adjacency matrices, and kernel matrices. Moreover, this proximity-based decomposition can offer additional interpretability in <span class="search-hit mathjax">applications</span> that involve, e.g., capturing the inner low-dimensional structure of the data, retaining graph connectivity structure, and preserving the acutance of images.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.02018v2-abstract-full').style.display = 'none'; document.getElementById('2106.02018v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 23 June, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 3 June, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.01847">arXiv:2106.01847</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.01847">pdf</a>, <a href="https://arxiv.org/format/2106.01847">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Performance">cs.PF</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Towards Cost-<span class="search-hit mathjax">Optimal</span> Policies for DAGs to Utilize IaaS Clouds with Online Learning
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Wu%2C+X">Xiaohu Wu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yu%2C+H">Han Yu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Casale%2C+G">Giuliano Casale</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gao%2C+G">Guanyu Gao</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.01847v1-abstract-short" style="display: inline;">
        Premier cloud service providers (CSPs) offer two types of purchase options, namely on-demand and spot instances, with <span class="search-hit mathjax">time</span>-varying features in availability and price. Users like startups have to operate on a limited budget and similarly others hope to&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.01847v1-abstract-full').style.display = 'inline'; document.getElementById('2106.01847v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.01847v1-abstract-full" style="display: none;">
        Premier cloud service providers (CSPs) offer two types of purchase options, namely on-demand and spot instances, with <span class="search-hit mathjax">time</span>-varying features in availability and price. Users like startups have to operate on a limited budget and similarly others hope to <span class="search-hit mathjax">reduce</span> their costs. While interacting with a CSP, central to their concerns is the process of cost-effectively utilizing different purchase options possibly in addition to self-owned instances. A job in data-intensive <span class="search-hit mathjax">applications</span> is typically represented by a directed acyclic graph which can further be transformed into a chain of tasks. The key to achieving cost efficiency is determining the allocation of a specific deadline to each task, as well as the allocation of different types of instances to the task. In this paper, we propose a framework that determines the <span class="search-hit mathjax">optimal</span> allocation of deadlines to tasks. The framework also features an <span class="search-hit mathjax">optimal</span> policy to determine the allocation of spot and on-demand instances in a predefined <span class="search-hit mathjax">time</span> window, and a near-<span class="search-hit mathjax">optimal</span> policy for allocating self-owned instances. The policies are designed to be parametric to support the usage of online learning to infer the <span class="search-hit mathjax">optimal</span> values against the dynamics of cloud markets. Finally, several intuitive heuristics are used as baselines to validate the cost <span class="search-hit mathjax">improvement</span> brought by the proposed solutions. We show that the cost <span class="search-hit mathjax">improvement</span> over the state-of-the-art is up to 24.87% when spot and on-demand instances are considered and up to 59.05% when self-owned instances are considered.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.01847v1-abstract-full').style.display = 'none'; document.getElementById('2106.01847v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 3 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.01766">arXiv:2106.01766</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.01766">pdf</a>, <a href="https://arxiv.org/ps/2106.01766">ps</a>, <a href="https://arxiv.org/format/2106.01766">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1109/ISPRAS.2018.00009">10.1109/ISPRAS.2018.00009 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Dynamic Analysis of ARINC 653 RTOS with LLVM
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Cheptsov%2C+V">Vitaly Cheptsov</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Khoroshilov%2C+A">Alexey Khoroshilov</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.01766v1-abstract-short" style="display: inline;">
        Existing standards for airborne-embedded <span class="search-hit mathjax">software</span> systems impose a number of requirements&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.01766v1-abstract-full').style.display = 'inline'; document.getElementById('2106.01766v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.01766v1-abstract-full" style="display: none;">
        Existing standards for airborne-embedded <span class="search-hit mathjax">software</span> systems impose a number of requirements <span class="search-hit mathjax">applicable</span> to the <span class="search-hit mathjax">software</span> development cycle of hard real-<span class="search-hit mathjax">time</span> operating systems found in modern aircraft. The measures taken are meant to <span class="search-hit mathjax">reduce</span> the risks of undesired consequences, but have strongly varying costs. Dynamic instrumentation and static analysis are common practices used to <span class="search-hit mathjax">automatically</span> find <span class="search-hit mathjax">software</span> defects, from strictly non-conforming <span class="search-hit mathjax">code</span> constructions to memory corruptions or invalid control flow. LLVM analyser and sanitizer infrastructure, while regularly applied to general-purpose <span class="search-hit mathjax">software</span>, originally was not thought to be introduced to heavily restricted environments. In this paper we discuss the specifics of airborne systems with regards to dynamic instrumentation and provide practical considerations to be taken into account for the effective use of general-purpose instrumentation tools. We bring a complete LLVM stack support to JetOS, a prospective onboard real-<span class="search-hit mathjax">time</span> operating system currently being developed at ISP RAS in collaboration with GosNIIAS. As an example, we port AddressSanitizer, MemorySanitizer, and UndefinedBehaviorSanitizer and provide the details against the caveats on all relevant sides: a sanitizer, a compiler, and an operating system. In addition we suggest uninvolved optimisations and enhancements to the <span class="search-hit mathjax">runtimes</span> to maximise the effects of the tools.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.01766v1-abstract-full').style.display = 'none'; document.getElementById('2106.01766v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 3 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">7 pages</span>
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        2018 Ivannikov Ispras Open Conference (ISPRAS), 2018, pp. 9-15
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.01674">arXiv:2106.01674</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.01674">pdf</a>, <a href="https://arxiv.org/format/2106.01674">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Information Retrieval">cs.IR</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        JIZHI: A <span class="search-hit mathjax">Fast</span> and Cost-Effective Model-As-A-Service System for Web-Scale Online Inference at Baidu
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+H">Hao Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gao%2C+Q">Qian Gao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+J">Jiang Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liao%2C+X">Xiaochao Liao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xiong%2C+H">Hao Xiong</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+G">Guangxing Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+W">Wenlin Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yang%2C+G">Guobao Yang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zha%2C+Z">Zhiwei Zha</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dong%2C+D">Daxiang Dong</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dou%2C+D">Dejing Dou</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xiong%2C+H">Haoyi Xiong</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.01674v1-abstract-short" style="display: inline;">
        In modern internet industries, deep learning based recommender systems have became an indispensable building block for a wide spectrum of <span class="search-hit mathjax">applications</span>, such as search engine, news feed, and short video clips. However, it remains challenging to carry the well-trained deep models for online real-&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.01674v1-abstract-full').style.display = 'inline'; document.getElementById('2106.01674v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.01674v1-abstract-full" style="display: none;">
        In modern internet industries, deep learning based recommender systems have became an indispensable building block for a wide spectrum of <span class="search-hit mathjax">applications</span>, such as search engine, news feed, and short video clips. However, it remains challenging to carry the well-trained deep models for online real-<span class="search-hit mathjax">time</span> inference serving, with respect to the <span class="search-hit mathjax">time</span>-varying web-scale traffics from billions of users, in a cost-effective manner. In this work, we present JIZHI - a Model-as-a-Service system - that per second handles hundreds of millions of online inference requests to huge deep models with more than trillions of sparse parameters, for over twenty real-<span class="search-hit mathjax">time</span> recommendation services at Baidu, Inc. In JIZHI, the inference workflow of every recommendation request is transformed to a Staged Event-Driven Pipeline (SEDP), where each node in the pipeline refers to a staged computation or I/O intensive task processor. With traffics of real-<span class="search-hit mathjax">time</span> inference requests arrived, each modularized processor can be run in a fully asynchronized way and managed separately. Besides, JIZHI introduces heterogeneous and hierarchical storage to further accelerate the online inference process by <span class="search-hit mathjax">reducing</span> unnecessary computations and potential data access latency induced by ultra-sparse model parameters. Moreover, an intelligent resource manager has been deployed to maximize the throughput of JIZHI over the shared infrastructure by searching the <span class="search-hit mathjax">optimal</span> resource allocation plan from historical logs and fine-tuning the load shedding policies over intermediate system feedback. Extensive experiments have been done to demonstrate the advantages of JIZHI from the perspectives of end-to-end service latency, system-wide throughput, and resource consumption. JIZHI has helped Baidu saved more than ten million US dollars in hardware and utility costs while handling 200% more traffics without sacrificing inference efficiency.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.01674v1-abstract-full').style.display = 'none'; document.getElementById('2106.01674v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 3 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted to SIGKDD 2021 applied data science track</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.01357">arXiv:2106.01357</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.01357">pdf</a>, <a href="https://arxiv.org/format/2106.01357">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Probability">math.PR</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Diffusion SchrÃ¶dinger Bridge with <span class="search-hit mathjax">Applications</span> to Score-Based Generative Modeling
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=De+Bortoli%2C+V">Valentin De Bortoli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Thornton%2C+J">James Thornton</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Heng%2C+J">Jeremy Heng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Doucet%2C+A">Arnaud Doucet</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.01357v2-abstract-short" style="display: inline;">
        &hellip;Reversing this dynamic defines a generative model. When the forward noising process is given by a Stochastic Differential Equation (SDE), Song et al. (2021) demonstrate how the <span class="search-hit mathjax">time</span> inhomogeneous drift of the associated reverse-&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.01357v2-abstract-full').style.display = 'inline'; document.getElementById('2106.01357v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.01357v2-abstract-full" style="display: none;">
        Progressively applying Gaussian noise transforms complex data distributions to approximately Gaussian. Reversing this dynamic defines a generative model. When the forward noising process is given by a Stochastic Differential Equation (SDE), Song et al. (2021) demonstrate how the <span class="search-hit mathjax">time</span> inhomogeneous drift of the associated reverse-<span class="search-hit mathjax">time</span> SDE may be estimated using score-matching. A limitation of this approach is that the forward-<span class="search-hit mathjax">time</span> SDE must be run for a sufficiently long <span class="search-hit mathjax">time</span> for the final distribution to be approximately Gaussian. In contrast, solving the SchrÃ¶dinger Bridge problem (SB), i.e. an entropy-regularized <span class="search-hit mathjax">optimal</span> transport problem on path spaces, yields diffusions which generate samples from the data distribution in finite <span class="search-hit mathjax">time</span>. We present Diffusion SB (DSB), an original approximation of the Iterative Proportional Fitting (IPF) procedure to solve the SB problem, and provide theoretical analysis along with generative modeling experiments. The first DSB iteration recovers the methodology proposed by Song et al. (2021), with the flexibility of using shorter <span class="search-hit mathjax">time</span> intervals, as subsequent DSB iterations <span class="search-hit mathjax">reduce</span> the discrepancy between the final-<span class="search-hit mathjax">time</span> marginal of the forward (resp. backward) SDE with respect to the prior (resp. data) distribution. Beyond generative modeling, DSB offers a widely <span class="search-hit mathjax">applicable</span> computational <span class="search-hit mathjax">optimal</span> transport tool as the continuous state-space analogue of the popular Sinkhorn algorithm (Cuturi, 2013).
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.01357v2-abstract-full').style.display = 'none'; document.getElementById('2106.01357v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 June, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 1 June, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">57 pages, 17 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.00730">arXiv:2106.00730</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.00730">pdf</a>, <a href="https://arxiv.org/format/2106.00730">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Data Structures and Algorithms">cs.DS</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Enabling Efficiency-Precision Trade-offs for Label Trees in Extreme Classification
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Baharav%2C+T+Z">Tavor Z. Baharav</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jiang%2C+D+L">Daniel L. Jiang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kolluri%2C+K">Kedarnath Kolluri</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sanghavi%2C+S">Sujay Sanghavi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dhillon%2C+I+S">Inderjit S. Dhillon</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.00730v1-abstract-short" style="display: inline;">
        &hellip;multi-label classification (XMC) aims to learn a model that can tag data points with a subset of relevant labels from an extremely large label set. Real world e-commerce <span class="search-hit mathjax">applications</span> like personalized recommendations and product advertising can be formulated as XMC problems, where the objective is to predict for a user a small subset of items from a catalog&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.00730v1-abstract-full').style.display = 'inline'; document.getElementById('2106.00730v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.00730v1-abstract-full" style="display: none;">
        Extreme multi-label classification (XMC) aims to learn a model that can tag data points with a subset of relevant labels from an extremely large label set. Real world e-commerce <span class="search-hit mathjax">applications</span> like personalized recommendations and product advertising can be formulated as XMC problems, where the objective is to predict for a user a small subset of items from a catalog of several million products. For such <span class="search-hit mathjax">applications</span>, a common approach is to organize these labels into a tree, enabling training and inference <span class="search-hit mathjax">times</span> that are logarithmic in the number of labels. While training a model once a label tree is available is well studied, designing the structure of the tree is a difficult task that is not yet well understood, and can dramatically impact both model latency and statistical performance. Existing approaches to tree construction fall at an extreme point, either <span class="search-hit mathjax">optimizing</span> exclusively for statistical performance, or for latency. We propose an efficient information theory inspired algorithm to construct intermediary operating points that trade off between the benefits of both. Our algorithm enables interpolation between these objectives, which was not previously possible. We corroborate our theoretical analysis with numerical results, showing that on the Wiki-500K benchmark dataset our method can <span class="search-hit mathjax">reduce</span> a proxy for expected latency by up to 28% while maintaining the same accuracy as Parabel. On several datasets derived from e-commerce customer logs, our modified label tree is able to <span class="search-hit mathjax">improve</span> this expected latency metric by up to 20% while maintaining the same accuracy. Finally, we discuss challenges in realizing these latency <span class="search-hit mathjax">improvements</span> in deployed models.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.00730v1-abstract-full').style.display = 'none'; document.getElementById('2106.00730v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 1 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.00279">arXiv:2106.00279</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.00279">pdf</a>, <a href="https://arxiv.org/ps/2106.00279">ps</a>, <a href="https://arxiv.org/format/2106.00279">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Data Structures and Algorithms">cs.DS</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        $L_0$ Isotonic Regression With Secondary Objectives
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Stout%2C+Q+F">Quentin F. Stout</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.00279v1-abstract-short" style="display: inline;">
        &hellip;error (Hamming distance). This is also known as monotonic relabeling, and is <span class="search-hit mathjax">applicable</span> when labels have a linear ordering but not necessarily a metric. There may be exponentially many <span class="search-hit mathjax">optimal</span> relabelings, so we look at secondary criteria to determine which are best. For arbitrary ordinal labels the criterion is maxim&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.00279v1-abstract-full').style.display = 'inline'; document.getElementById('2106.00279v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.00279v1-abstract-full" style="display: none;">
        We provide algorithms for isotonic regression minimizing $L_0$ error (Hamming distance). This is also known as monotonic relabeling, and is <span class="search-hit mathjax">applicable</span> when labels have a linear ordering but not necessarily a metric. There may be exponentially many <span class="search-hit mathjax">optimal</span> relabelings, so we look at secondary criteria to determine which are best. For arbitrary ordinal labels the criterion is maximizing the number of labels which are only changed to an adjacent label (and recursively apply this). For real-valued labels we minimize the $L_p$ error. For linearly ordered sets we also give algorithms which minimize the sum of the $L_p$ and weighted $L_0$ errors, a form of penalized (regularized) regression. We also examine $L_0$ isotonic regression on multidimensional coordinate-wise orderings. Previous algorithms took $Î(n^3)$ <span class="search-hit mathjax">time</span>, but we <span class="search-hit mathjax">reduce</span> this to $o(n^{3/2})$.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.00279v1-abstract-full').style.display = 'none'; document.getElementById('2106.00279v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 1 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2105.15015">arXiv:2105.15015</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2105.15015">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1109/RAM.2018.8463058">10.1109/RAM.2018.8463058 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Model-Based Reliability and Safety: <span class="search-hit mathjax">Reducing</span> the Complexity of Safety Analyses Using Component Fault Trees
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Hoefig%2C+K">Kai Hoefig</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Joanni%2C+A">Andreas Joanni</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zeller%2C+M">Marc Zeller</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Montrone%2C+F">Francesco Montrone</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rothfelder%2C+M">Martin Rothfelder</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Amarnath%2C+R">Rakshith Amarnath</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Munk%2C+P">Peter Munk</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Nordmann%2C+A">Arne Nordmann</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2105.15015v1-abstract-short" style="display: inline;">
        The importance of mission or safety critical <span class="search-hit mathjax">software</span> systems in many&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.15015v1-abstract-full').style.display = 'inline'; document.getElementById('2105.15015v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2105.15015v1-abstract-full" style="display: none;">
        The importance of mission or safety critical <span class="search-hit mathjax">software</span> systems in many <span class="search-hit mathjax">application</span> domains of embedded systems is continuously growing, and so is the effort and complexity for reliability and safety analysis. Model driven development is currently one of the key approaches to cope with increasing development complexity, in general. Applying similar concepts to reliability, availability, maintainability and safety (RAMS) analysis activities is a promising approach to extend the advantages of model driven development to safety engineering activities aiming at a reduction of development costs, a higher product quality and a shorter <span class="search-hit mathjax">time</span>-to-market. Nevertheless, many model-based safety or reliability engineering approaches aim at <span class="search-hit mathjax">reducing</span> the analysis complexity but <span class="search-hit mathjax">applications</span> or case studies are rare. Therefore we present here a large scale industrial case study which shows the benefits of the <span class="search-hit mathjax">application</span> of component fault trees when it comes to complex safety mechanisms. We compare the methodology of component fault trees against classic fault trees and summarize benefits and drawbacks of both modeling methodologies.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.15015v1-abstract-full').style.display = 'none'; document.getElementById('2105.15015v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 31 May, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2021.
      
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        2018 Annual Reliability and Maintainability Symposium (RAMS)
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2105.12912">arXiv:2105.12912</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2105.12912">pdf</a>, <a href="https://arxiv.org/format/2105.12912">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        cuSZ(x): <span class="search-hit mathjax">Optimizing</span> Error-Bounded Lossy Compression for Scientific Data on GPUs
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Tian%2C+J">Jiannan Tian</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Di%2C+S">Sheng Di</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yu%2C+X">Xiaodong Yu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rivera%2C+C">Cody Rivera</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhao%2C+K">Kai Zhao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jin%2C+S">Sian Jin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Feng%2C+Y">Yunhe Feng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liang%2C+X">Xin Liang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tao%2C+D">Dingwen Tao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cappello%2C+F">Franck Cappello</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2105.12912v1-abstract-short" style="display: inline;">
        Error-bounded lossy compression is a critical technique for significantly <span class="search-hit mathjax">reducing</span> scientific data volumes. With ever-emerging heterogeneous HPC architecture, GPU-accelerated error-bounded compressors (such as cuSZ and cuZFP) have been developed. However, they suffer from either low performance or low compression ratios. To this end, we propose cuSZ(x) to ta&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.12912v1-abstract-full').style.display = 'inline'; document.getElementById('2105.12912v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2105.12912v1-abstract-full" style="display: none;">
        Error-bounded lossy compression is a critical technique for significantly <span class="search-hit mathjax">reducing</span> scientific data volumes. With ever-emerging heterogeneous HPC architecture, GPU-accelerated error-bounded compressors (such as cuSZ and cuZFP) have been developed. However, they suffer from either low performance or low compression ratios. To this end, we propose cuSZ(x) to target both high compression ratio and throughput. We identify that data sparsity and data smoothness are key factors for high compression throughput. Our key contributions in this work are fourfold: (1) We propose an efficient compression workflow to adaptively perform run-length encoding and/or variable-length encoding. (2) We derive Lorenzo reconstruction in decompression as multidimensional partial-sum computation and propose a fine-grained Lorenzo reconstruction algorithm for GPU architectures. (3) We carefully <span class="search-hit mathjax">optimize</span> each of cuSZ&#39;s kernels by leveraging state-of-the-art CUDA parallel primitives. (4) We evaluate cuSZ(x) using seven real-world HPC <span class="search-hit mathjax">application</span> datasets on V100 and A100 GPUs. Experiments show cuSZ(x) <span class="search-hit mathjax">improves</span> the compression performance and ratios by up to 18.4<span class="search-hit mathjax">$\times$</span> and 5.3<span class="search-hit mathjax">$\times$</span>, respectively, over cuSZ on the tested datasets.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.12912v1-abstract-full').style.display = 'none'; document.getElementById('2105.12912v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 26 May, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">12 pages, 3 figures, 8 table, submitted to IEEE Cluster&#39;21</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2105.12841">arXiv:2105.12841</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2105.12841">pdf</a>, <a href="https://arxiv.org/format/2105.12841">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        DNNV: A Framework for Deep Neural Network Verification
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Shriver%2C+D">David Shriver</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Elbaum%2C+S">Sebastian Elbaum</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dwyer%2C+M+B">Matthew B. Dwyer</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2105.12841v1-abstract-short" style="display: inline;">
        &hellip;Existing benchmarks are rarely in formats supported by verifiers other than the one for which the benchmark was introduced. In this work we present DNNV, a framework for <span class="search-hit mathjax">reducing</span> the burden on DNN verifier researchers, developers, and users. DNNV standardizes input and output formats, includes a simple yet expressive DSL for specifying DNN properties, and p&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.12841v1-abstract-full').style.display = 'inline'; document.getElementById('2105.12841v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2105.12841v1-abstract-full" style="display: none;">
        Despite the large number of sophisticated deep neural network (DNN) verification algorithms, DNN verifier developers, users, and researchers still face several challenges. First, verifier developers must contend with the rapidly changing DNN field to support new DNN operations and property types. Second, verifier users have the burden of selecting a verifier input format to specify their problem. Due to the many input formats, this decision can greatly restrict the verifiers that a user may run. Finally, researchers face difficulties in re-using benchmarks to evaluate and compare verifiers, due to the large number of input formats required to run different verifiers. Existing benchmarks are rarely in formats supported by verifiers other than the one for which the benchmark was introduced. In this work we present DNNV, a framework for <span class="search-hit mathjax">reducing</span> the burden on DNN verifier researchers, developers, and users. DNNV standardizes input and output formats, includes a simple yet expressive DSL for specifying DNN properties, and provides powerful simplification and reduction operations to facilitate the <span class="search-hit mathjax">application</span>, development, and comparison of DNN verifiers. We show how DNNV increases the support of verifiers for existing benchmarks from 30% to 74%.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.12841v1-abstract-full').style.display = 'none'; document.getElementById('2105.12841v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 26 May, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2105.12826">arXiv:2105.12826</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2105.12826">pdf</a>, <a href="https://arxiv.org/ps/2105.12826">ps</a>, <a href="https://arxiv.org/format/2105.12826">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Networking and Internet Architecture">cs.NI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        <span class="search-hit mathjax">Optimizations</span> for Hardware-in-the-Loop-Based V2X Validation Platforms
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Mafakheri%2C+B">Babak Mafakheri</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gonnella%2C+P">Pierpaolo Gonnella</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bazzi%2C+A">Alessandro Bazzi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Masini%2C+B+M">Barbara Mavi Masini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Caggiano%2C+M">Michele Caggiano</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Verdone%2C+R">Roberto Verdone</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2105.12826v1-abstract-short" style="display: inline;">
        Connectivity and <span class="search-hit mathjax">automation</span> are increasingly getting importance in the automotive industry, which is observing a radical change from vehicles driven by humans to fully&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.12826v1-abstract-full').style.display = 'inline'; document.getElementById('2105.12826v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2105.12826v1-abstract-full" style="display: none;">
        Connectivity and <span class="search-hit mathjax">automation</span> are increasingly getting importance in the automotive industry, which is observing a radical change from vehicles driven by humans to fully <span class="search-hit mathjax">automated</span> and remotely controlled ones. The test and validation of all the related devices and <span class="search-hit mathjax">applications</span> is thus becoming a crucial aspect; this is raising the interest on hardware-in-the-loop (HiL) platforms which <span class="search-hit mathjax">reduce</span> the need for complicated field trials, thus limiting the costs and delay added to the process. With reference to the test and validation of vehicle-to-everything (V2X) communications aspects, and assuming either sidelink LTE/5GV2X or IEEE 802.11p/bd technologies, in this work we focus on the real-<span class="search-hit mathjax">time</span> HiL simulation of the information exchanged by one vehicle under test and the surrounding, simulated, objects. Such exchange must be reproduced in a <span class="search-hit mathjax">time</span>-efficient manner, with elaborations done <span class="search-hit mathjax">fast</span> enough to allow testing the <span class="search-hit mathjax">applications</span> in real-<span class="search-hit mathjax">time</span>. More precisely, we discuss the simulation of nonideal positioning and channel propagation taking into account current impairments. We also provide details on <span class="search-hit mathjax">optimization</span> solutions that allowed us to trade-off minor loss in accuracy with a significant reduction of the computation <span class="search-hit mathjax">time</span> burden, reaching up to more than one order of magnitude <span class="search-hit mathjax">speed</span> increase in our experiments.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.12826v1-abstract-full').style.display = 'none'; document.getElementById('2105.12826v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 26 April, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">The 2021 IEEE 93rd Vehicular Technology Conference: VTC2021-Spring</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2105.12678">arXiv:2105.12678</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2105.12678">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Logic in Computer Science">cs.LO</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A Flexible FPGA-Based ISA Configurable SoC platform
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Yuan%2C+S">Shih-Yi Yuan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhu%2C+B">Bo-Yu Zhu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2105.12678v1-abstract-short" style="display: inline;">
        We proposes a platform which can generate hardware/<span class="search-hit mathjax">software</span> description based on flexible in-struction set architectures (ISAs). The platform takes advantage of the flexibility of field pro-grammable gate array (FPGA) to design many micro control units (MCUs) based on different ISAs. The platform can generate many ISAs, MCUs, and Assemblers according to a pr&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.12678v1-abstract-full').style.display = 'inline'; document.getElementById('2105.12678v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2105.12678v1-abstract-full" style="display: none;">
        We proposes a platform which can generate hardware/<span class="search-hit mathjax">software</span> description based on flexible in-struction set architectures (ISAs). The platform takes advantage of the flexibility of field pro-grammable gate array (FPGA) to design many micro control units (MCUs) based on different ISAs. The platform can generate many ISAs, MCUs, and Assemblers according to a pre-defined ISA and user <span class="search-hit mathjax">applications</span>. Although the MCU performance is not <span class="search-hit mathjax">optimized</span>, the FPGA shows a great potential on resource reduction and enough performance at very low system clock rate. The flexible ISA has shown great importance for the design targeted to specific purpose. We also show a case study of the proposed flexible ISA-based FPGA-MCU. It can control many specifi-cally designed hardware IPs and a customized multi-task OS with tasks. Not only the case works correctly, but also the proposed FPGA-MCU of the case is flexible with <span class="search-hit mathjax">reduced</span> FPGA resources, low cost, and within <span class="search-hit mathjax">time</span> constraints.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.12678v1-abstract-full').style.display = 'none'; document.getElementById('2105.12678v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 26 May, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2105.12026">arXiv:2105.12026</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2105.12026">pdf</a>, <a href="https://arxiv.org/ps/2105.12026">ps</a>, <a href="https://arxiv.org/format/2105.12026">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Providing Meaningful Data Summarizations Using Exemplar-based Clustering in Industry 4.0
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Honysz%2C+P">Philipp-Jan Honysz</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Schulze-Struchtrup%2C+A">Alexander Schulze-Struchtrup</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Buschj%C3%A4ger%2C+S">Sebastian BuschjÃ¤ger</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Morik%2C+K">Katharina Morik</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2105.12026v2-abstract-short" style="display: inline;">
        Data summarizations are a valuable tool to derive knowledge from large data streams and have proven their usefulness in a great number of <span class="search-hit mathjax">applications</span>. Summaries can be found by&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.12026v2-abstract-full').style.display = 'inline'; document.getElementById('2105.12026v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2105.12026v2-abstract-full" style="display: none;">
        Data summarizations are a valuable tool to derive knowledge from large data streams and have proven their usefulness in a great number of <span class="search-hit mathjax">applications</span>. Summaries can be found by <span class="search-hit mathjax">optimizing</span> submodular functions. These functions map subsets of data to real values, which indicate their &#34;representativeness&#34; and which should be maximized to find a diverse summary of the underlying data. In this paper, we studied Exemplar-based clustering as a submodular function and provide a GPU algorithm to cope with its high computational complexity. We show, that our GPU implementation provides <span class="search-hit mathjax">speedups</span> of up to 72x using single-precision and up to 452x using half-precision computation compared to conventional CPU algorithms. We also show, that the GPU algorithm not only provides remarkable <span class="search-hit mathjax">runtime</span> benefits with workstation-grade GPUs but also with low-power embedded computation units for which <span class="search-hit mathjax">speedups</span> of up to 35x are possible. Furthermore, we apply our algorithm to real-world data from injection molding manufacturing processes and discuss how found summaries help with steering this specific process to cut costs and <span class="search-hit mathjax">reduce</span> the manufacturing of bad parts. Beyond pure <span class="search-hit mathjax">speedup</span> considerations, we show, that our approach can provide summaries within reasonable <span class="search-hit mathjax">time</span> frames for this kind of industrial, real-world data.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.12026v2-abstract-full').style.display = 'none'; document.getElementById('2105.12026v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 18 June, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 25 May, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">arXiv admin note: substantial text overlap with arXiv:2101.08763</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2105.11654">arXiv:2105.11654</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2105.11654">pdf</a>, <a href="https://arxiv.org/format/2105.11654">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Neural and Evolutionary Computing">cs.NE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        <span class="search-hit mathjax">Optimal</span> ANN-SNN Conversion for <span class="search-hit mathjax">Fast</span> and Accurate Inference in Deep Spiking Neural Networks
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ding%2C+J">Jianhao Ding</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yu%2C+Z">Zhaofei Yu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tian%2C+Y">Yonghong Tian</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Huang%2C+T">Tiejun Huang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2105.11654v1-abstract-short" style="display: inline;">
        &hellip;researchers and industry. The most efficient way to train deep SNNs is through ANN-SNN conversion. However, the conversion usually suffers from accuracy loss and long inference <span class="search-hit mathjax">time</span>, which impede the practical&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.11654v1-abstract-full').style.display = 'inline'; document.getElementById('2105.11654v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2105.11654v1-abstract-full" style="display: none;">
        Spiking Neural Networks (SNNs), as bio-inspired energy-efficient neural networks, have attracted great attentions from researchers and industry. The most efficient way to train deep SNNs is through ANN-SNN conversion. However, the conversion usually suffers from accuracy loss and long inference <span class="search-hit mathjax">time</span>, which impede the practical <span class="search-hit mathjax">application</span> of SNN. In this paper, we theoretically analyze ANN-SNN conversion and derive sufficient conditions of the <span class="search-hit mathjax">optimal</span> conversion. To better correlate ANN-SNN and get greater accuracy, we propose Rate Norm Layer to replace the ReLU activation function in source ANN training, enabling direct conversion from a trained ANN to an SNN. Moreover, we propose an <span class="search-hit mathjax">optimal</span> fit curve to quantify the fit between the activation value of source ANN and the actual firing rate of target SNN. We show that the inference <span class="search-hit mathjax">time</span> can be <span class="search-hit mathjax">reduced</span> by <span class="search-hit mathjax">optimizing</span> the upper bound of the fit curve in the revised ANN to achieve <span class="search-hit mathjax">fast</span> inference. Our theory can explain the existing work on <span class="search-hit mathjax">fast</span> reasoning and get better results. The experimental results show that the proposed method achieves near loss less conversion with VGG-16, PreActResNet-18, and deeper structures. Moreover, it can reach 8.6x <span class="search-hit mathjax">faster</span> reasoning performance under 0.265x energy consumption of the typical method. The <span class="search-hit mathjax">code</span> is available at https://github.com/DingJianhao/OptSNNConvertion-RNL-RIL.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.11654v1-abstract-full').style.display = 'none'; document.getElementById('2105.11654v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 25 May, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">9 pages, 7 figures, 2 tables. To appear in the 30th International Joint Conference on Artificial Intelligence (IJCAI 2021)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2105.11292">arXiv:2105.11292</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2105.11292">pdf</a>, <a href="https://arxiv.org/format/2105.11292">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Science and Game Theory">cs.GT</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A Polynomial-<span class="search-hit mathjax">time</span>, Truthful, Individually Rational and Budget Balanced Ridesharing Mechanism
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Iwase%2C+T">Tatsuya Iwase</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Stein%2C+S">Sebastian Stein</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gerding%2C+E+H">Enrico H. Gerding</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2105.11292v2-abstract-short" style="display: inline;">
        Ridesharing has great potential to <span class="search-hit mathjax">improve</span> transportation efficiency while&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.11292v2-abstract-full').style.display = 'inline'; document.getElementById('2105.11292v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2105.11292v2-abstract-full" style="display: none;">
        Ridesharing has great potential to <span class="search-hit mathjax">improve</span> transportation efficiency while <span class="search-hit mathjax">reducing</span> congestion and pollution. To realize this potential, mechanisms are needed that allocate vehicles <span class="search-hit mathjax">optimally</span> and provide the right incentives to riders. However, many existing approaches consider restricted settings (e.g., only one rider per vehicle or a common origin for all riders). Moreover, naive <span class="search-hit mathjax">applications</span> of standard approaches, such as the Vickrey-Clarke-Groves or greedy mechanisms, cannot achieve a polynomial-<span class="search-hit mathjax">time</span>, truthful, individually rational and budget balanced mechanism. To address this, we formulate a general ridesharing problem and apply mechanism design to develop a novel mechanism which satisfies all four properties and whose social cost is within 8.6% of the <span class="search-hit mathjax">optimal</span> on average.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.11292v2-abstract-full').style.display = 'none'; document.getElementById('2105.11292v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 June, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 21 May, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2105.11229">arXiv:2105.11229</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2105.11229">pdf</a>, <a href="https://arxiv.org/format/2105.11229">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        FaaSNet: Scalable and <span class="search-hit mathjax">Fast</span> Provisioning of Custom Serverless Container <span class="search-hit mathjax">Runtimes</span> at Alibaba Cloud Function Compute
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+A">Ao Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chang%2C+S">Shuai Chang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tian%2C+H">Huangshi Tian</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+H">Hongqi Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yang%2C+H">Haoran Yang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+H">Huiba Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Du%2C+R">Rui Du</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cheng%2C+Y">Yue Cheng</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2105.11229v2-abstract-short" style="display: inline;">
        Serverless computing, or Function-as-a-Service (FaaS), enables a new way of building and scaling <span class="search-hit mathjax">applications</span> by allowing users to deploy fine-grained functions while providing fully-managed resource provisioning and auto-scaling. Custom FaaS container support is gaining traction as it enables better control over OSes, versioning, and tooling for modernizing&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.11229v2-abstract-full').style.display = 'inline'; document.getElementById('2105.11229v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2105.11229v2-abstract-full" style="display: none;">
        Serverless computing, or Function-as-a-Service (FaaS), enables a new way of building and scaling <span class="search-hit mathjax">applications</span> by allowing users to deploy fine-grained functions while providing fully-managed resource provisioning and auto-scaling. Custom FaaS container support is gaining traction as it enables better control over OSes, versioning, and tooling for modernizing FaaS <span class="search-hit mathjax">applications</span>. However, providing rapid container provisioning introduces non-trivial challenges for FaaS providers, since container provisioning is costly, and real-world FaaS workloads exhibit highly dynamic patterns. In this paper, we design FaaSNet, a highly-scalable middleware system for accelerating FaaS container provisioning. FaaSNet is driven by the workload and infrastructure requirements of the FaaS platform at one of the world&#39;s largest cloud providers, Alibaba Cloud Function Compute. FaaSNet enables scalable container provisioning via a lightweight, adaptive function tree (FT) structure. FaaSNet uses an I/O efficient, on-demand fetching mechanism to further <span class="search-hit mathjax">reduce</span> provisioning costs at scale. We implement and integrate FaaSNet in Alibaba Cloud Function Compute. Evaluation results show that FaaSNet: (1) finishes provisioning 2500 function containers on 1000 virtual machines in 8.3 seconds, (2) scales 13.4x and 16.3x <span class="search-hit mathjax">faster</span> than Alibaba Cloud&#39;s current FaaS platform and a state-of-the-art P2P container registry (Kraken), respectively, and (3) sustains a bursty workload using 75.2% less <span class="search-hit mathjax">time</span> than an <span class="search-hit mathjax">optimized</span> baseline.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.11229v2-abstract-full').style.display = 'none'; document.getElementById('2105.11229v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 27 May, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 24 May, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">This is the preprint version of a paper published in USENIX ATC 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2105.11033">arXiv:2105.11033</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2105.11033">pdf</a>, <a href="https://arxiv.org/format/2105.11033">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1109/ICFEC51620.2021.00010">10.1109/ICFEC51620.2021.00010 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Multilayer Resource-aware Partitioning for Fog <span class="search-hit mathjax">Application</span> Placement
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Samani%2C+Z+N">Zahra Najafabadi Samani</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Saurabh%2C+N">Nishant Saurabh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Prodan%2C+R">Radu Prodan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2105.11033v1-abstract-short" style="display: inline;">
        Fog computing emerged as a crucial platform for the deployment of IoT <span class="search-hit mathjax">applications</span>. The complexity of such&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.11033v1-abstract-full').style.display = 'inline'; document.getElementById('2105.11033v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2105.11033v1-abstract-full" style="display: none;">
        Fog computing emerged as a crucial platform for the deployment of IoT <span class="search-hit mathjax">applications</span>. The complexity of such <span class="search-hit mathjax">applications</span> requires methods that handle the resource diversity and network structure of Fog devices while maximizing the service placement and <span class="search-hit mathjax">reducing</span> resource wastage. Prior studies in this domain primarily focused on <span class="search-hit mathjax">optimizing</span> specific <span class="search-hit mathjax">application</span> requirements and fail to address the network topology combined with the different types of resources encountered in Fog devices. To overcome these problems, we propose a multilayer resource-aware partitioning method to minimize the resource wastage and maximize the service placement and deadline satisfaction rates in a Fog infrastructure with high multi-user <span class="search-hit mathjax">application</span> placement requests. Our method represents the heterogeneous Fog resources as a multilayered network graph and partitions them based on network topology and resource features. Afterward, it identifies the appropriate device partitions for placing an <span class="search-hit mathjax">application</span> according to its requirements, which need to overlap in the same network topology partition. Simulation results show that our multilayer resource-aware partitioning method is able to place twice as many services, satisfy deadlines for three <span class="search-hit mathjax">times</span> as many <span class="search-hit mathjax">application</span> requests, and <span class="search-hit mathjax">reduce</span> the resource wastage by up to 15-32 <span class="search-hit mathjax">times</span> compared to two availability-aware and resource-aware methods.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.11033v1-abstract-full').style.display = 'none'; document.getElementById('2105.11033v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 23 May, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">13 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2105.10242">arXiv:2105.10242</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2105.10242">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Networking and Internet Architecture">cs.NI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Signal Processing">eess.SP</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Energy Minimized Federated Fog Computing over Passive Optical Networks
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Alqahtani%2C+A+M">Abdullah M. Alqahtani</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yosuf%2C+B">Barzan Yosuf</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mohamed%2C+S+H">Sanaa H. Mohamed</a>, 
      
      <a href="/search/?searchtype=author&amp;query=El-Gorashi%2C+T+E+H">Taisir E. H. El-Gorashi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Elmirghani%2C+J+M+H">Jaafar M. H. Elmirghani</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2105.10242v1-abstract-short" style="display: inline;">
        The rapid growth of <span class="search-hit mathjax">time</span>-sensitive&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.10242v1-abstract-full').style.display = 'inline'; document.getElementById('2105.10242v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2105.10242v1-abstract-full" style="display: none;">
        The rapid growth of <span class="search-hit mathjax">time</span>-sensitive <span class="search-hit mathjax">applications</span> and services has driven enhancements to computing infrastructures. The main challenge that needs addressing for these <span class="search-hit mathjax">applications</span> is the <span class="search-hit mathjax">optimal</span> placement of the end-users demands to <span class="search-hit mathjax">reduce</span> the total power consumption and delay. One of the widely adopted paradigms to address such a challenge is fog computing. Placing fog units close to end-users at the edge of the network can help mitigate some of the latency and energy efficiency issues. Compared to the traditional hyperscale cloud data centres, fog computing units are constrained by computational power, hence, the capacity of fog units plays a critical role in meeting the stringent demands of the end-users due to intensive processing workloads. In this paper, we aim to <span class="search-hit mathjax">optimize</span> the placement of virtual machines (VMs) demands originating from end-users in a fog computing setting by formulating a Mixed Integer Linear <span class="search-hit mathjax">Programming</span> (MILP) model to minimize the total power consumption through the use of a federated architecture made up of multiple distributed fog cells. The obtained results show an increase in processing capacity in the fog layer and a reduction in the power consumption by up to 26% compared to the Non-Federated fogs network.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.10242v1-abstract-full').style.display = 'none'; document.getElementById('2105.10242v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 21 May, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2105.09551">arXiv:2105.09551</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2105.09551">pdf</a>, <a href="https://arxiv.org/format/2105.09551">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Information Theory">cs.IT</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        CLARQ: A Dynamic ARQ Solution for Ultra-high Closed-loop Reliability
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Han%2C+B">Bin Han</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhu%2C+Y">Yao Zhu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sun%2C+M">Muxia Sun</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sciancalepore%2C+V">Vincenzo Sciancalepore</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hu%2C+Y">Yulin Hu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Schotten%2C+H+D">Hans D. Schotten</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2105.09551v2-abstract-short" style="display: inline;">
        Emerging wireless control <span class="search-hit mathjax">applications</span> demand for extremely high closed-loop reliability under strict latency constraints, which the conventional&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.09551v2-abstract-full').style.display = 'inline'; document.getElementById('2105.09551v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2105.09551v2-abstract-full" style="display: none;">
        Emerging wireless control <span class="search-hit mathjax">applications</span> demand for extremely high closed-loop reliability under strict latency constraints, which the conventional <span class="search-hit mathjax">Automatic</span> Repeat reQuest (ARQ) solutions with static schedules fail to provide. To overcome this issue and enable data-link layer error control for ultra reliable low-latency communication (URLLC) services, we propose a novel protocol: the Closed-Loop ARQ (CLARQ), which forces to accomplish an information exchange round within a fixed loop-back latency, and dynamically re-allocates the remaining resource between uplink and downlink slots upon the result of last uplink transmission. The proposed method guarantees to meet the latency requirement, while delivering high communication reliability and power efficiency. It can be efficiently offline <span class="search-hit mathjax">optimized</span> by means of dynamic <span class="search-hit mathjax">programming</span> techniques, and is capable of real-<span class="search-hit mathjax">time</span> deployment with a low-cost implementation based on look-up tables. Numerical evaluations have verified that CLARQ outperforms baselines with significantly <span class="search-hit mathjax">improved</span> closed-loop reliability and <span class="search-hit mathjax">reduced</span> energy consumption. Especially, over a Rayleigh channel with 0dB mean SNR, it is able to provide a closed-loop error rate below 1e-7 within 10ms loop-back latency, which makes our proposal competitive for practical URLLC <span class="search-hit mathjax">applications</span> in future 5G-and-beyond networks.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.09551v2-abstract-full').style.display = 'none'; document.getElementById('2105.09551v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 4 July, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 20 May, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted on 03.07.2021 by IEEE Transactions on Wireless Communications for publication</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2105.07936">arXiv:2105.07936</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2105.07936">pdf</a>, <a href="https://arxiv.org/format/2105.07936">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1109/CCGrid51090.2021.00061">10.1109/CCGrid51090.2021.00061 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A Two-Sided Matching Model for Data Stream Processing in the Cloud-Fog Continuum
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Mehran%2C+N">Narges Mehran</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kimovski%2C+D">Dragi Kimovski</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Prodan%2C+R">Radu Prodan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2105.07936v1-abstract-short" style="display: inline;">
        Latency-sensitive and bandwidth-intensive stream processing <span class="search-hit mathjax">applications</span> are dominant traffic generators over the Internet network. A stream consists of a continuous sequence of data elements, which require processing in nearly real-&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.07936v1-abstract-full').style.display = 'inline'; document.getElementById('2105.07936v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2105.07936v1-abstract-full" style="display: none;">
        Latency-sensitive and bandwidth-intensive stream processing <span class="search-hit mathjax">applications</span> are dominant traffic generators over the Internet network. A stream consists of a continuous sequence of data elements, which require processing in nearly real-<span class="search-hit mathjax">time</span>. To <span class="search-hit mathjax">improve</span> communication latency and <span class="search-hit mathjax">reduce</span> the network congestion, Fog computing complements the Cloud services by moving the computation towards the edge of the network. Unfortunately, the heterogeneity of the new Cloud-Fog continuum raises important challenges related to deploying and executing data stream <span class="search-hit mathjax">applications</span>. We explore in this work a two-sided stable matching model called Cloud-Fog to data stream <span class="search-hit mathjax">application</span> matching (CODA) for deploying a distributed <span class="search-hit mathjax">application</span> represented as a workflow of stream processing microservices on heterogeneous Cloud-Fog computing resources. In CODA, the <span class="search-hit mathjax">application</span> microservices rank the continuum resources based on their microservice stream processing <span class="search-hit mathjax">time</span>, while resources rank the stream processing microservices based on their residual bandwidth. A stable many-to-one matching algorithm assigns microservices to resources based on their mutual preferences, aiming to <span class="search-hit mathjax">optimize</span> the complete stream processing <span class="search-hit mathjax">time</span> on the <span class="search-hit mathjax">application</span> side, and the total streaming traffic on the resource side. We evaluate the CODA algorithm using simulated and real-world Cloud-Fog scenarios. We achieved 11 to 45% lower stream processing <span class="search-hit mathjax">time</span> and 1.3 to 20% lower streaming traffic compared to related state-of-the-art approaches.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.07936v1-abstract-full').style.display = 'none'; document.getElementById('2105.07936v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 May, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">7 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2105.07544">arXiv:2105.07544</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2105.07544">pdf</a>, <a href="https://arxiv.org/format/2105.07544">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Numerical Analysis">math.NA</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Mathematical Software">cs.MS</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Experimental Evaluation of Multiprecision Strategies for GMRES on GPUs
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Loe%2C+J+A">Jennifer A. Loe</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Glusa%2C+C+A">Christian A. Glusa</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yamazaki%2C+I">Ichitaro Yamazaki</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Boman%2C+E+G">Erik G. Boman</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rajamanickam%2C+S">Sivasankaran Rajamanickam</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2105.07544v1-abstract-short" style="display: inline;">
        Support for lower precision computation is becoming more common in accelerator hardware due to lower power usage, <span class="search-hit mathjax">reduced</span> data movement and increased computational performance. However, computational science and engineering (CSE) problems require double precision accuracy in several domains. This conflict between hardware trends and&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.07544v1-abstract-full').style.display = 'inline'; document.getElementById('2105.07544v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2105.07544v1-abstract-full" style="display: none;">
        Support for lower precision computation is becoming more common in accelerator hardware due to lower power usage, <span class="search-hit mathjax">reduced</span> data movement and increased computational performance. However, computational science and engineering (CSE) problems require double precision accuracy in several domains. This conflict between hardware trends and <span class="search-hit mathjax">application</span> needs has resulted in a need for multiprecision strategies at the linear algebra algorithms level if we want to exploit the hardware to its full potential while meeting the accuracy requirements. In this paper, we focus on preconditioned sparse iterative linear solvers, a key kernel in several CSE <span class="search-hit mathjax">applications</span>. We present a study of multiprecision strategies for accelerating this kernel on GPUs. We seek the best methods for incorporating multiple precisions into the GMRES linear solver; these include iterative refinement and parallelizable preconditioners. Our work presents strategies to determine when multiprecision GMRES will be effective and to choose parameters for a multiprecision iterative refinement solver to achieve better performance. We use an implementation that is based on the Trilinos library and employs Kokkos Kernels for performance portability of linear algebra kernels. Performance results demonstrate the promise of multiprecision approaches and demonstrate even further <span class="search-hit mathjax">improvements</span> are possible by <span class="search-hit mathjax">optimizing</span> low-level kernels.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.07544v1-abstract-full').style.display = 'none'; document.getElementById('2105.07544v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 May, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted for publication in the IEEE IPDPS Accelerators and Hybrid Emerging Systems (AsHES) 11th Workshop, 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2105.07420">arXiv:2105.07420</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2105.07420">pdf</a>, <a href="https://arxiv.org/format/2105.07420">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Resource Planning for Hospitals Under Special Consideration of the COVID-19 Pandemic: <span class="search-hit mathjax">Optimization</span> and Sensitivity Analysis
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Bartz-Beielstein%2C+T">Thomas Bartz-Beielstein</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dr%C3%B6scher%2C+M">Marcel DrÃ¶scher</a>, 
      
      <a href="/search/?searchtype=author&amp;query=G%C3%BCr%2C+A">Alpar GÃ¼r</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hinterleitner%2C+A">Alexander Hinterleitner</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mersmann%2C+O">Olaf Mersmann</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Peeva%2C+D">Dessislava Peeva</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Reese%2C+L">Lennard Reese</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rehbach%2C+N">Nicolas Rehbach</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rehbach%2C+F">Frederik Rehbach</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sen%2C+A">Amrita Sen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Subbotin%2C+A">Aleksandr Subbotin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zaefferer%2C+M">Martin Zaefferer</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2105.07420v1-abstract-short" style="display: inline;">
        &hellip;is determined by 29 parameters. Reasonable default values of these parameters were obtained in detailed discussions with medical professionals. We aim to investigate and <span class="search-hit mathjax">optimize</span> these parameters to&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.07420v1-abstract-full').style.display = 'inline'; document.getElementById('2105.07420v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2105.07420v1-abstract-full" style="display: none;">
        Crises like the COVID-19 pandemic pose a serious challenge to health-care institutions. They need to plan the resources required for handling the increased load, for instance, hospital beds and ventilators. To support the resource planning of local health authorities from the Cologne region, BaBSim.Hospital, a tool for capacity planning based on discrete event simulation, was created. The predictive quality of the simulation is determined by 29 parameters. Reasonable default values of these parameters were obtained in detailed discussions with medical professionals. We aim to investigate and <span class="search-hit mathjax">optimize</span> these parameters to <span class="search-hit mathjax">improve</span> BaBSim.Hospital. First approaches with &#34;out-of-the-box&#34; <span class="search-hit mathjax">optimization</span> algorithms failed. Implementing a surrogate-based <span class="search-hit mathjax">optimization</span> approach generated useful results in a reasonable <span class="search-hit mathjax">time</span>. To understand the behavior of the algorithm and to get valuable insights into the fitness landscape, an in-depth sensitivity analysis was performed. The sensitivity analysis is crucial for the <span class="search-hit mathjax">optimization</span> process because it allows focusing the <span class="search-hit mathjax">optimization</span> on the most important parameters. We illustrate how this <span class="search-hit mathjax">reduces</span> the problem dimension without compromising the resulting accuracy. The presented approach is <span class="search-hit mathjax">applicable</span> to many other real-world problems, e.g., the development of new elevator systems to cover the last mile or simulation of student flow in academic study periods.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.07420v1-abstract-full').style.display = 'none'; document.getElementById('2105.07420v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 May, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2105.07026">arXiv:2105.07026</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2105.07026">pdf</a>, <a href="https://arxiv.org/format/2105.07026">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Probability">math.PR</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A Monotone Approximate Dynamic <span class="search-hit mathjax">Programming</span> Approach for the Stochastic Scheduling, Allocation, and Inventory Replenishment Problem: <span class="search-hit mathjax">Applications</span> to Drone and Electric Vehicle Battery Swap Stations
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Asadi%2C+A">Amin Asadi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pinkley%2C+S+N">Sarah Nurre Pinkley</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2105.07026v1-abstract-short" style="display: inline;">
        There is a growing interest in using electric vehicles (EVs) and drones for many <span class="search-hit mathjax">applications</span>. However, battery-oriented issues, including range anxiety and battery degradation, impede adoption. Battery swap stations are one alternative to&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.07026v1-abstract-full').style.display = 'inline'; document.getElementById('2105.07026v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2105.07026v1-abstract-full" style="display: none;">
        There is a growing interest in using electric vehicles (EVs) and drones for many <span class="search-hit mathjax">applications</span>. However, battery-oriented issues, including range anxiety and battery degradation, impede adoption. Battery swap stations are one alternative to <span class="search-hit mathjax">reduce</span> these concerns that allow the swap of depleted for full batteries in minutes. We consider the problem of deriving actions at a battery swap station when explicitly considering the uncertain arrival of swap demand, battery degradation, and replacement. We model the operations at a battery swap station using a finite horizon Markov Decision Process model for the stochastic scheduling, allocation, and inventory replenishment problem (SAIRP), which determines when and how many batteries are charged, discharged, and replaced over <span class="search-hit mathjax">time</span>. We present theoretical proofs for the monotonicity of the value function and monotone structure of an <span class="search-hit mathjax">optimal</span> policy for special SAIRP cases. Due to the curses of dimensionality, we develop a new monotone approximate dynamic <span class="search-hit mathjax">programming</span> (ADP) method, which intelligently initializes a value function approximation using regression. In computational tests, we demonstrate the superior performance of the new regression-based monotone ADP method as compared to exact methods and other monotone ADP methods. Further, with the tests, we deduce policy insights for drone swap stations.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.07026v1-abstract-full').style.display = 'none'; document.getElementById('2105.07026v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 May, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2105.04086">arXiv:2105.04086</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2105.04086">pdf</a>, <a href="https://arxiv.org/format/2105.04086">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Deep Reinforcement Learning-based Methods for Resource Scheduling in Cloud Computing: A Review and Future Directions
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zhou%2C+G">Guangyao Zhou</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tian%2C+W">Wenhong Tian</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Buyya%2C+R">Rajkumar Buyya</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2105.04086v1-abstract-short" style="display: inline;">
        As the quantity and complexity of information processed by <span class="search-hit mathjax">software</span> systems increase, large-scale&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.04086v1-abstract-full').style.display = 'inline'; document.getElementById('2105.04086v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2105.04086v1-abstract-full" style="display: none;">
        As the quantity and complexity of information processed by <span class="search-hit mathjax">software</span> systems increase, large-scale <span class="search-hit mathjax">software</span> systems have an increasing requirement for high-performance distributed computing systems. With the acceleration of the Internet in Web 2.0, Cloud computing as a paradigm to provide dynamic, uncertain and elastic services has shown superiorities to meet the computing needs dynamically. Without an appropriate scheduling approach, extensive Cloud computing may cause high energy consumptions and high cost, in addition that high energy consumption will cause massive carbon dioxide emissions. Moreover, inappropriate scheduling will <span class="search-hit mathjax">reduce</span> the service life of physical devices as well as increase response <span class="search-hit mathjax">time</span> to users&#39; request. Hence, efficient scheduling of resource or <span class="search-hit mathjax">optimal</span> allocation of request, that usually a NP-hard problem, is one of the prominent issues in emerging trends of Cloud computing. Focusing on <span class="search-hit mathjax">improving</span> quality of service (QoS), <span class="search-hit mathjax">reducing</span> cost and abating contamination, researchers have conducted extensive work on resource scheduling problems of Cloud computing over years. Nevertheless, growing complexity of Cloud computing, that the super-massive distributed system, is limiting the <span class="search-hit mathjax">application</span> of scheduling approaches. Machine learning, a utility method to tackle problems in complex scenes, is used to resolve the resource scheduling of Cloud computing as an innovative idea in recent years. Deep reinforcement learning (DRL), a combination of deep learning (DL) and reinforcement learning (RL), is one branch of the machine learning and has a considerable prospect in resource scheduling of Cloud computing. This paper surveys the methods of resource scheduling with focus on DRL-based scheduling approaches in Cloud computing, also reviews the <span class="search-hit mathjax">application</span> of DRL as well as discusses challenges and future directions of DRL in scheduling of Cloud computing.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.04086v1-abstract-full').style.display = 'none'; document.getElementById('2105.04086v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 9 May, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">18 pages,9 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2105.03858">arXiv:2105.03858</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2105.03858">pdf</a>, <a href="https://arxiv.org/format/2105.03858">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Information Theory">cs.IT</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Location-Based <span class="search-hit mathjax">Timing</span> Advance Estimation for 5G Integrated LEO Satellite Communications
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+W">Wenjin Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+T">Tingting Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ding%2C+R">Rui Ding</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Seco-Granados%2C+G">Gonzalo Seco-Granados</a>, 
      
      <a href="/search/?searchtype=author&amp;query=You%2C+L">Li You</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gao%2C+X">Xiqi Gao</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2105.03858v1-abstract-short" style="display: inline;">
        &hellip;the satellite and the ground mobile communications, thus providing genuine ubiquitous coverage. For 5G integrated low earth orbit (LEO) satellite communication systems, the <span class="search-hit mathjax">timing</span> advance (TA) is required to be estimated in the initial random access procedure in order to facilitate the uplink frame alignment among different users. However, due to the inheren&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.03858v1-abstract-full').style.display = 'inline'; document.getElementById('2105.03858v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2105.03858v1-abstract-full" style="display: none;">
        Integrated satellite-terrestrial communications networks aim to exploit both the satellite and the ground mobile communications, thus providing genuine ubiquitous coverage. For 5G integrated low earth orbit (LEO) satellite communication systems, the <span class="search-hit mathjax">timing</span> advance (TA) is required to be estimated in the initial random access procedure in order to facilitate the uplink frame alignment among different users. However, due to the inherent characteristics of LEO satellite communication systems, e.g., wide beam coverage and long propagation delays, the existing 5G terrestrial uplink TA scheme is not <span class="search-hit mathjax">applicable</span> in the satellite networks. In this paper, we investigate location-based TA estimation for 5G integrated LEO satellite communication systems. We obtain the <span class="search-hit mathjax">time</span> difference of arrival (TDOA) and frequency difference of arrival (FDOA) measurements in the downlink <span class="search-hit mathjax">timing</span> and frequency synchronization phase, which are made from the satellite at different <span class="search-hit mathjax">time</span> instants. We propose to take these measurements for either UE geolocation or ephemeris estimation, thus calculating the TA value. The estimation is then formulated as a quadratic <span class="search-hit mathjax">optimization</span> problem whose globally <span class="search-hit mathjax">optimal</span> solution can be obtained by a quadratic penalty algorithm. To <span class="search-hit mathjax">reduce</span> the computational complexity, we further propose an alternative approximation method based on iteratively performing a linearization procedure on the quadratic equality constraints. Numerical results show that the proposed methods can approach the constrained Cramer-Rao lower bound (CRLB) of the TA estimation and thus assure uplink frame alignment for different users.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.03858v1-abstract-full').style.display = 'none'; document.getElementById('2105.03858v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 9 May, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2105.02788">arXiv:2105.02788</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2105.02788">pdf</a>, <a href="https://arxiv.org/format/2105.02788">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Graphics">cs.GR</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        ACORN: Adaptive Coordinate Networks for Neural Scene Representation
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Martel%2C+J+N+P">Julien N. P. Martel</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lindell%2C+D+B">David B. Lindell</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lin%2C+C+Z">Connor Z. Lin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chan%2C+E+R">Eric R. Chan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Monteiro%2C+M">Marco Monteiro</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wetzstein%2C+G">Gordon Wetzstein</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2105.02788v1-abstract-short" style="display: inline;">
        Neural representations have emerged as a new paradigm for <span class="search-hit mathjax">applications</span> in rendering, imaging, geometric modeling, and simulation. Compared to traditional representations such as meshes, point clouds, or volumes they can be flexibly incorporated into differentiable learning-based pipelines. While recent&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.02788v1-abstract-full').style.display = 'inline'; document.getElementById('2105.02788v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2105.02788v1-abstract-full" style="display: none;">
        Neural representations have emerged as a new paradigm for <span class="search-hit mathjax">applications</span> in rendering, imaging, geometric modeling, and simulation. Compared to traditional representations such as meshes, point clouds, or volumes they can be flexibly incorporated into differentiable learning-based pipelines. While recent <span class="search-hit mathjax">improvements</span> to neural representations now make it possible to represent signals with fine details at moderate resolutions (e.g., for images and 3D shapes), adequately representing large-scale or complex scenes has proven a challenge. Current neural representations fail to accurately represent images at resolutions greater than a megapixel or 3D scenes with more than a few hundred thousand polygons. Here, we introduce a new hybrid implicit-explicit network architecture and training strategy that adaptively allocates resources during training and inference based on the local complexity of a signal of interest. Our approach uses a multiscale block-coordinate decomposition, similar to a quadtree or octree, that is <span class="search-hit mathjax">optimized</span> during training. The network architecture operates in two stages: using the bulk of the network parameters, a coordinate encoder generates a feature grid in a single forward pass. Then, hundreds or thousands of samples within each block can be efficiently evaluated using a lightweight feature decoder. With this hybrid implicit-explicit network architecture, we demonstrate the first experiments that fit gigapixel images to nearly 40 dB peak signal-to-noise ratio. Notably this represents an increase in scale of over 1000x compared to the resolution of previously demonstrated image-fitting experiments. Moreover, our approach is able to represent 3D shapes significantly <span class="search-hit mathjax">faster</span> and better than previous techniques; it <span class="search-hit mathjax">reduces</span> training <span class="search-hit mathjax">times</span> from days to hours or minutes and memory requirements by over an order of magnitude.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.02788v1-abstract-full').style.display = 'none'; document.getElementById('2105.02788v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 6 May, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">J. N. P. Martel and D. B. Lindell equally contributed to this work</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2105.02600">arXiv:2105.02600</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2105.02600">pdf</a>, <a href="https://arxiv.org/format/2105.02600">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Discrete Mathematics">cs.DM</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        <span class="search-hit mathjax">Optimal</span> Subgraph on Disturbed Network
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Guillot%2C+M">Matthieu Guillot</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Aghezzaf%2C+E">El-Houssaine Aghezzaf</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Faouzi%2C+N+E">Nour-Eddin El Faouzi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Furno%2C+A">Angelo Furno</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2105.02600v1-abstract-short" style="display: inline;">
        &hellip;transportation systems are drastically changed both qualitatively and quantitatively and the network has become obsolete. In this article, we study the problem of finding an <span class="search-hit mathjax">optimal</span> subnetwork that guarantee that (i) the minimal access&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.02600v1-abstract-full').style.display = 'inline'; document.getElementById('2105.02600v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2105.02600v1-abstract-full" style="display: none;">
        During the pandemic of COVID-19, the demand of the transportation systems are drastically changed both qualitatively and quantitatively and the network has become obsolete. In this article, we study the problem of finding an <span class="search-hit mathjax">optimal</span> subnetwork that guarantee that (i) the minimal access <span class="search-hit mathjax">time</span> from any node of the urban network to the new network is not {\em too large} compared to the original transportation network; (ii) for any itinerary, the delay caused by the deletion of nodes of the transportation network is not {\em too big}; and (iii) the number of nodes of the transportation network has been <span class="search-hit mathjax">reduced</span> at least by a known factor. A solution is <span class="search-hit mathjax">optimal</span> if it induces a minimal global delay. We model this problem as a Mixed Integer Linear <span class="search-hit mathjax">Program</span> before applying the model on a real-case <span class="search-hit mathjax">application</span> on the Lyon&#39;s buses transportation network.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.02600v1-abstract-full').style.display = 'none'; document.getElementById('2105.02600v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 6 May, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2105.02540">arXiv:2105.02540</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2105.02540">pdf</a>, <a href="https://arxiv.org/format/2105.02540">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Distribution Awareness for AI System Testing
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Berend%2C+D">David Berend</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2105.02540v1-abstract-short" style="display: inline;">
        As Deep Learning (DL) is continuously adopted in many safety critical <span class="search-hit mathjax">applications</span>, its quality and reliability start to raise concerns. Similar to the traditional&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.02540v1-abstract-full').style.display = 'inline'; document.getElementById('2105.02540v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2105.02540v1-abstract-full" style="display: none;">
        As Deep Learning (DL) is continuously adopted in many safety critical <span class="search-hit mathjax">applications</span>, its quality and reliability start to raise concerns. Similar to the traditional <span class="search-hit mathjax">software</span> development process, testing the DL <span class="search-hit mathjax">software</span> to uncover its defects at an early stage is an effective way to <span class="search-hit mathjax">reduce</span> risks after deployment. Although recent progress has been made in designing novel testing techniques for DL <span class="search-hit mathjax">software</span>, the distribution of generated test data is not taken into consideration. It is therefore hard to judge whether the identified errors are indeed meaningful errors to the DL <span class="search-hit mathjax">application</span>. Therefore, we propose a new OOD-guided testing technique which aims to generate new unseen test cases relevant to the underlying DL system task. Our results show that this technique is able to filter up to 55.44% of error test case on CIFAR-10 and is 10.05% more effective in enhancing robustness.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.02540v1-abstract-full').style.display = 'none'; document.getElementById('2105.02540v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 6 May, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">2 pages, 1 figure, pre-print</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2105.01827">arXiv:2105.01827</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2105.01827">pdf</a>, <a href="https://arxiv.org/format/2105.01827">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Cryptography and Security">cs.CR</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        GALA: Greedy ComputAtion for Linear Algebra in Privacy-Preserved Neural Networks
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+Q">Qiao Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xin%2C+C">Chunsheng Xin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wu%2C+H">Hongyi Wu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2105.01827v1-abstract-short" style="display: inline;">
        Machine Learning as a Service (MLaaS) is enabling a wide range of smart <span class="search-hit mathjax">applications</span> on end devices. However, privacy-preserved computation is still expensive. Our investigation has found that the most&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.01827v1-abstract-full').style.display = 'inline'; document.getElementById('2105.01827v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2105.01827v1-abstract-full" style="display: none;">
        Machine Learning as a Service (MLaaS) is enabling a wide range of smart <span class="search-hit mathjax">applications</span> on end devices. However, privacy-preserved computation is still expensive. Our investigation has found that the most <span class="search-hit mathjax">time</span>-consuming component of the HE-based linear computation is a series of Permutation (Perm) operations that are imperative for dot product and convolution in privacy-preserved MLaaS. To this end, we propose GALA: Greedy computAtion for Linear Algebra in privacy-preserved neural networks, which views the HE-based linear computation as a series of Homomorphic Add, Mult and Perm operations and chooses the least expensive operation in each linear computation step to <span class="search-hit mathjax">reduce</span> the overall cost. GALA makes the following contributions: (1) It introduces a row-wise weight matrix encoding and combines the share generation that is needed for the GC-based nonlinear computation, to <span class="search-hit mathjax">reduce</span> the Perm operations for the dot product; (2) It designs a first-Add-second-Perm approach (named kernel grouping) to <span class="search-hit mathjax">reduce</span> Perm operations for convolution. As such, GALA efficiently <span class="search-hit mathjax">reduces</span> the cost for the HE-based linear computation, which is a critical building block in almost all of the recent frameworks for privacy-preserved neural networks, including GAZELLE (Usenix Security&#39;18), DELPHI (Usenix Security&#39;20), and CrypTFlow2 (CCS&#39;20). With its deep <span class="search-hit mathjax">optimization</span> of the HE-based linear computation, GALA can be a plug-and-play module integrated into these systems to further boost their efficiency. Our experiments show that it achieves a significant <span class="search-hit mathjax">speedup</span> up to 700x for the dot product and 14x for the convolution computation under different data dimensions. Meanwhile, GALA demonstrates an encouraging <span class="search-hit mathjax">runtime</span> boost by 2.5x, 2.7x, 3.2x, 8.3x, 7.7x, and 7.5x over GAZELLE and 6.5x, 6x, 5.7x, 4.5x, 4.2x, and 4.1x over CrypTFlow2, on AlexNet, VGG, ResNet-18, ResNet-50, ResNet-101, and ResNet-152, respectively.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.01827v1-abstract-full').style.display = 'none'; document.getElementById('2105.01827v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 4 May, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2105.00619">arXiv:2105.00619</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2105.00619">pdf</a>, <a href="https://arxiv.org/format/2105.00619">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Hardware Architecture">cs.AR</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        OpTorch: <span class="search-hit mathjax">Optimized</span> deep learning architectures for resource limited environments
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ahmed%2C+S">Salman Ahmed</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Naveed%2C+H">Hammad Naveed</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2105.00619v2-abstract-short" style="display: inline;">
        Deep learning algorithms have made many breakthroughs and have various <span class="search-hit mathjax">applications</span> in real life. Computational resources become a bottleneck as the data and complexity of the deep learning pipeline increases. In this paper, we propose&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.00619v2-abstract-full').style.display = 'inline'; document.getElementById('2105.00619v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2105.00619v2-abstract-full" style="display: none;">
        Deep learning algorithms have made many breakthroughs and have various <span class="search-hit mathjax">applications</span> in real life. Computational resources become a bottleneck as the data and complexity of the deep learning pipeline increases. In this paper, we propose <span class="search-hit mathjax">optimized</span> deep learning pipelines in multiple aspects of training including <span class="search-hit mathjax">time</span> and memory. OpTorch is a machine learning library designed to overcome weaknesses in existing implementations of neural network training. OpTorch provides features to train complex neural networks with limited computational resources. OpTorch achieved the same accuracy as existing libraries on Cifar-10 and Cifar-100 datasets while <span class="search-hit mathjax">reducing</span> memory usage to approximately 50%. We also explore the effect of weights on total memory usage in deep learning pipelines. In our experiments, parallel encoding-decoding along with sequential checkpoints results in much <span class="search-hit mathjax">improved</span> memory and <span class="search-hit mathjax">time</span> usage while keeping the accuracy similar to existing pipelines. OpTorch python package is available at available at https://github.com/cbrl-nuces/optorch
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.00619v2-abstract-full').style.display = 'none'; document.getElementById('2105.00619v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 4 May, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 2 May, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2105.00115">arXiv:2105.00115</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2105.00115">pdf</a>, <a href="https://arxiv.org/format/2105.00115">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Numerical Analysis">math.NA</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Mathematical Software">cs.MS</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        QDOT: Quantized Dot Product Kernel for Approximate High-Performance Computing
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Diffenderfer%2C+J">James Diffenderfer</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Osei-Kuffuor%2C+D">Daniel Osei-Kuffuor</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Menon%2C+H">Harshitha Menon</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2105.00115v1-abstract-short" style="display: inline;">
        Approximate computing techniques have been successful in <span class="search-hit mathjax">reducing</span> computation and power costs in several domains. However, error sensitive&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.00115v1-abstract-full').style.display = 'inline'; document.getElementById('2105.00115v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2105.00115v1-abstract-full" style="display: none;">
        Approximate computing techniques have been successful in <span class="search-hit mathjax">reducing</span> computation and power costs in several domains. However, error sensitive <span class="search-hit mathjax">applications</span> in high-performance computing are unable to benefit from existing approximate computing strategies that are not developed with guaranteed error bounds. While approximate computing techniques can be developed for individual high-performance computing <span class="search-hit mathjax">applications</span> by domain specialists, this often requires additional theoretical analysis and potentially extensive <span class="search-hit mathjax">software</span> modification. Hence, the development of low-level error-bounded approximate computing strategies that can be introduced into any high-performance computing <span class="search-hit mathjax">application</span> without requiring additional analysis or significant <span class="search-hit mathjax">software</span> alterations is desirable. In this paper, we provide a contribution in this direction by proposing a general framework for designing error-bounded approximate computing strategies and apply it to the dot product kernel to develop qdot -- an error-bounded approximate dot product kernel. Following the introduction of qdot, we perform a theoretical analysis that yields a deterministic bound on the relative approximation error introduced by qdot. Empirical tests are performed to illustrate the tightness of the derived error bound and to demonstrate the effectiveness of qdot on a synthetic dataset, as well as two scientific benchmarks -- Conjugate Gradient (CG) and the Power method. In particular, using qdot for the dot products in CG can result in a majority of components being perforated or quantized to half precision without increasing the iteration count required for convergence to the same solution as CG using a double precision dot product.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.00115v1-abstract-full').style.display = 'none'; document.getElementById('2105.00115v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 April, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2105.00027">arXiv:2105.00027</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2105.00027">pdf</a>, <a href="https://arxiv.org/format/2105.00027">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Materials Science">cond-mat.mtrl-sci</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Strongly Correlated Electrons">cond-mat.str-el</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Superconductivity">cond-mat.supr-con</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Memory Reduction using a Ring Abstraction over GPU RDMA for Distributed Quantum Monte Carlo Solver
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Wei%2C+W">Weile Wei</a>, 
      
      <a href="/search/?searchtype=author&amp;query=D%27Azevedo%2C+E">Eduardo D&#39;Azevedo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Huck%2C+K">Kevin Huck</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chatterjee%2C+A">Arghya Chatterjee</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hernandez%2C+O">Oscar Hernandez</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kaiser%2C+H">Hartmut Kaiser</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2105.00027v2-abstract-short" style="display: inline;">
        Scientific <span class="search-hit mathjax">applications</span> that run on leadership computing facilities often face the challenge of being unable to fit leading science cases onto accelerator devices due to memory constraints (memory-bound&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.00027v2-abstract-full').style.display = 'inline'; document.getElementById('2105.00027v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2105.00027v2-abstract-full" style="display: none;">
        Scientific <span class="search-hit mathjax">applications</span> that run on leadership computing facilities often face the challenge of being unable to fit leading science cases onto accelerator devices due to memory constraints (memory-bound <span class="search-hit mathjax">applications</span>). In this work, the authors studied one such US Department of Energy mission-critical condensed matter physics <span class="search-hit mathjax">application</span>, Dynamical Cluster Approximation (DCA++), and this paper discusses how device memory-bound challenges were successfully <span class="search-hit mathjax">reduced</span> by proposing an effective &#34;all-to-all&#34; communication method -- a ring communication algorithm. This implementation takes advantage of acceleration on GPUs and remote direct memory access (RDMA) for <span class="search-hit mathjax">fast</span> data exchange between GPUs.
  Additionally, the ring algorithm was <span class="search-hit mathjax">optimized</span> with sub-ring communicators and multi-threaded support to further <span class="search-hit mathjax">reduce</span> communication overhead and expose more concurrency, respectively. The computation and communication were also analyzed by using the Autonomic Performance Environment for Exascale (APEX) profiling tool, and this paper further discusses the performance trade-off for the ring algorithm implementation. The memory analysis on the ring algorithm shows that the allocation size for the authors&#39; most memory-intensive data structure per GPU is now <span class="search-hit mathjax">reduced</span> to 1/p of the original size, where p is the number of GPUs in the ring communicator. The communication analysis suggests that the distributed Quantum Monte Carlo execution <span class="search-hit mathjax">time</span> grows linearly as sub-ring size increases, and the cost of messages passing through the network interface connector could be a limiting factor.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.00027v2-abstract-full').style.display = 'none'; document.getElementById('2105.00027v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 13 May, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 30 April, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2104.14056">arXiv:2104.14056</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2104.14056">pdf</a>, <a href="https://arxiv.org/format/2104.14056">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Machine Learning Techniques for <span class="search-hit mathjax">Software</span> Quality Assurance: A Survey
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Omri%2C+S">Safa Omri</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sinz%2C+C">Carsten Sinz</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2104.14056v1-abstract-short" style="display: inline;">
        Over the last years, machine learning techniques have been applied to more and more <span class="search-hit mathjax">application</span> domains, including&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.14056v1-abstract-full').style.display = 'inline'; document.getElementById('2104.14056v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2104.14056v1-abstract-full" style="display: none;">
        Over the last years, machine learning techniques have been applied to more and more <span class="search-hit mathjax">application</span> domains, including <span class="search-hit mathjax">software</span> engineering and, especially, <span class="search-hit mathjax">software</span> quality assurance. Important <span class="search-hit mathjax">application</span> domains have been, e.g., <span class="search-hit mathjax">software</span> defect prediction or test case selection and prioritization. The ability to predict which components in a large <span class="search-hit mathjax">software</span> system are most likely to contain the largest numbers of faults in the next release helps to better manage projects, including early estimation of possible release delays, and affordably guide corrective actions to <span class="search-hit mathjax">improve</span> the quality of the <span class="search-hit mathjax">software</span>. However, developing robust fault prediction models is a challenging task and many techniques have been proposed in the literature. Closely related to estimating defect-prone parts of a <span class="search-hit mathjax">software</span> system is the question of how to select and prioritize test cases, and indeed test case prioritization has been extensively researched as a means for <span class="search-hit mathjax">reducing</span> the <span class="search-hit mathjax">time</span> taken to discover regressions in <span class="search-hit mathjax">software</span>. In this survey, we discuss various approaches in both fault prediction and test case prioritization, also explaining how in recent studies deep learning algorithms for fault prediction help to bridge the gap between <span class="search-hit mathjax">programs</span>&#39; semantics and fault prediction features. We also review recently proposed machine learning methods for test case prioritization (TCP), and their ability to <span class="search-hit mathjax">reduce</span> the cost of regression testing without negatively affecting fault detection capabilities.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.14056v1-abstract-full').style.display = 'none'; document.getElementById('2104.14056v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 28 April, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2104.13997">arXiv:2104.13997</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2104.13997">pdf</a>, <a href="https://arxiv.org/format/2104.13997">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Hardware Architecture">cs.AR</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Domain-specific Genetic Algorithm for Multi-tenant DNNAccelerator Scheduling
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Kao%2C+S">Sheng-Chun Kao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Krishna%2C+T">Tushar Krishna</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2104.13997v2-abstract-short" style="display: inline;">
        As Deep Learning continues to drive a variety of <span class="search-hit mathjax">applications</span> in datacenters and HPC, there is a growing trend towards building large accelerators with several sub-accelerator cores/chiplets. This work looks at the problem of supporting multi-tenancy on such accelerators. In particular, we focus on the problem of mapping layers from several DNNs simultaneous&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.13997v2-abstract-full').style.display = 'inline'; document.getElementById('2104.13997v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2104.13997v2-abstract-full" style="display: none;">
        As Deep Learning continues to drive a variety of <span class="search-hit mathjax">applications</span> in datacenters and HPC, there is a growing trend towards building large accelerators with several sub-accelerator cores/chiplets. This work looks at the problem of supporting multi-tenancy on such accelerators. In particular, we focus on the problem of mapping layers from several DNNs simultaneously on an accelerator. Given the extremely large search space, we formulate the search as an <span class="search-hit mathjax">optimization</span> problem and develop a specialized genetic algorithm called G# withcustom operators to enable structured sample-efficient exploration. We quantitatively compare G# with several common heuristics, state-of-the-art <span class="search-hit mathjax">optimization</span> methods, and reinforcement learning methods across different accelerator set-tings (large/small accelerators) and different sub-accelerator configurations (homogeneous/heterogeneous), and observeG# can consistently find better solutions. Further, to enable real-<span class="search-hit mathjax">time</span> scheduling, we also demonstrate a method to generalize the learnt schedules and transfer them to the next batch of jobs, <span class="search-hit mathjax">reducing</span> schedule compute <span class="search-hit mathjax">time</span> to near zero.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.13997v2-abstract-full').style.display = 'none'; document.getElementById('2104.13997v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 April, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 28 April, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2104.12586">arXiv:2104.12586</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2104.12586">pdf</a>, <a href="https://arxiv.org/ps/2104.12586">ps</a>, <a href="https://arxiv.org/format/2104.12586">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Information Theory">cs.IT</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Consistency issues in Gaussian Mixture Models reduction algorithms
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=D%27Ortenzio%2C+A">A. D&#39;Ortenzio</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Manes%2C+C">C. Manes</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2104.12586v1-abstract-short" style="display: inline;">
        In many contexts Gaussian Mixtures (GM) are used to approximate probability distributions, possibly <span class="search-hit mathjax">time</span>-varying. In some&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.12586v1-abstract-full').style.display = 'inline'; document.getElementById('2104.12586v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2104.12586v1-abstract-full" style="display: none;">
        In many contexts Gaussian Mixtures (GM) are used to approximate probability distributions, possibly <span class="search-hit mathjax">time</span>-varying. In some <span class="search-hit mathjax">applications</span> the number of GM components exponentially increases over <span class="search-hit mathjax">time</span>, and reduction procedures are required to keep them reasonably limited. The GM reduction (GMR) problem can be formulated by choosing different measures of the dissimilarity of GMs before and after reduction, like the Kullback-Leibler Divergence (KLD) and the Integral Squared Error (ISE). Since in no case the solution is obtained in closed form, many approximate GMR algorithms have been proposed in the past three decades, although none of them provides <span class="search-hit mathjax">optimality</span> guarantees. In this work we discuss the importance of the choice of the dissimilarity measure and the issue of consistency of all steps of a reduction algorithm with the chosen measure. Indeed, most of the existing GMR algorithms are composed by several steps which are not consistent with a unique measure, and for this reason may produce <span class="search-hit mathjax">reduced</span> GMs far from <span class="search-hit mathjax">optimality</span>. In particular, the use of the KLD, of the ISE and normalized ISE is discussed and compared in this perspective.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.12586v1-abstract-full').style.display = 'none'; document.getElementById('2104.12586v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 26 April, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2104.11426">arXiv:2104.11426</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2104.11426">pdf</a>, <a href="https://arxiv.org/format/2104.11426">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Methodology">stat.ME</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Regularized Nonlinear Regression for Simultaneously Selecting and Estimating Key Model Parameters
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Yoon%2C+K">Kyubaek Yoon</a>, 
      
      <a href="/search/?searchtype=author&amp;query=You%2C+H">Hojun You</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wu%2C+W">Wei-Ying Wu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lim%2C+C+Y">Chae Young Lim</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Choi%2C+J">Jongeun Choi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Boss%2C+C">Connor Boss</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ramadan%2C+A">Ahmed Ramadan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Popovich%2C+J+M">John M. Popovich Jr.</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cholewicki%2C+J">Jacek Cholewicki</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Reeves%2C+N+P">N. Peter Reeves</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Radcliffe%2C+C+J">Clark J. Radcliffe</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2104.11426v1-abstract-short" style="display: inline;">
        &hellip;First, we provide consistency and oracle properties of the proposed estimator as a theoretical foundation. Second, we provide a novel approach based on Levenberg-Marquardt <span class="search-hit mathjax">optimization</span> to numerically find the solution to the formulated problem. Third, to show the effectiveness, we present an&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.11426v1-abstract-full').style.display = 'inline'; document.getElementById('2104.11426v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2104.11426v1-abstract-full" style="display: none;">
        In system identification, estimating parameters of a model using limited observations results in poor identifiability. To cope with this issue, we propose a new method to simultaneously select and estimate sensitive parameters as key model parameters and fix the remaining parameters to a set of typical values. Our method is formulated as a nonlinear least squares estimator with L1-regularization on the deviation of parameters from a set of typical values. First, we provide consistency and oracle properties of the proposed estimator as a theoretical foundation. Second, we provide a novel approach based on Levenberg-Marquardt <span class="search-hit mathjax">optimization</span> to numerically find the solution to the formulated problem. Third, to show the effectiveness, we present an <span class="search-hit mathjax">application</span> identifying a biomechanical parametric model of a head position tracking task for 10 human subjects from limited data. In a simulation study, the variances of estimated parameters are decreased by 96.1% as compared to that of the estimated parameters without L1-regularization. In an experimental study, our method <span class="search-hit mathjax">improves</span> the model interpretation by <span class="search-hit mathjax">reducing</span> the number of parameters to be estimated while maintaining variance accounted for (VAF) at above 82.5%. Moreover, the variances of estimated parameters are <span class="search-hit mathjax">reduced</span> by 71.1% as compared to that of the estimated parameters without L1-regularization. Our method is 54 <span class="search-hit mathjax">times</span> <span class="search-hit mathjax">faster</span> than the standard simplex-based <span class="search-hit mathjax">optimization</span> to solve the regularized nonlinear regression.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.11426v1-abstract-full').style.display = 'none'; document.getElementById('2104.11426v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 23 April, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">13 pages, 4 figures, 2 Tables</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2104.10763">arXiv:2104.10763</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2104.10763">pdf</a>, <a href="https://arxiv.org/format/2104.10763">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computational Engineering, Finance, and Science">cs.CE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Development of aircraft spoiler demonstrators to test strain-based SHM under realistic loading
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Winklberger%2C+M">Markus Winklberger</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kralovec%2C+C">Christoph Kralovec</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Schagerl%2C+M">Martin Schagerl</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2104.10763v1-abstract-short" style="display: inline;">
        &hellip;scale 1:2 is developed to evaluate strain-based structural health monitoring (SHM) methods under realistic loading conditions. SHM promises to increase operational safety and <span class="search-hit mathjax">reduce</span> maintenance costs of&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.10763v1-abstract-full').style.display = 'inline'; document.getElementById('2104.10763v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2104.10763v1-abstract-full" style="display: none;">
        An idealized demonstrator of an civil aircraft wing spoiler in scale 1:2 is developed to evaluate strain-based structural health monitoring (SHM) methods under realistic loading conditions. SHM promises to increase operational safety and <span class="search-hit mathjax">reduce</span> maintenance costs of <span class="search-hit mathjax">optimized</span> lightweight structures by its early damage detection capabilities. Also localization and size identification of damages could be shown for simple parts, e.g. beams or plates in many laboratory experiments. However, the <span class="search-hit mathjax">application</span> of SHM systems on real structures under realistic loading conditions is cost intensive and <span class="search-hit mathjax">time</span> consuming. Furthermore, testing facilities which are large enough to fit full scale aircraft parts are often not available. The proposed procedure of developing a scaled spoiler demonstrator under idealized loading and support conditions solves these issues for strain-based SHM. The procedure shows how to reproduce the deformation shape of a real aircraft spoiler under a heavy loading condition during landing by numerical <span class="search-hit mathjax">optimization</span>. Subsequent finite element simulations and experimental measurements proved similar deformations and strain states of the idealized demonstrator and the real spoiler. Thus, using the developed idealized spoiler demonstrator strain-based SHM systems can be tested under loading conditions similar to realistic operational loads by significantly <span class="search-hit mathjax">reduced</span> test effort and costs.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.10763v1-abstract-full').style.display = 'none'; document.getElementById('2104.10763v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 April, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">21 pages, 11 figures, submitted to AIAA Journal</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2104.10716">arXiv:2104.10716</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2104.10716">pdf</a>, <a href="https://arxiv.org/format/2104.10716">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Accelerating SpMM Kernel with Cache-First Edge Sampling for Graph Neural Networks
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Lin%2C+C">Chien-Yu Lin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Luo%2C+L">Liang Luo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ceze%2C+L">Luis Ceze</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2104.10716v2-abstract-short" style="display: inline;">
        &hellip;deep learning model class, can extract meaningful representations from highly expressive graph-structured data and are therefore gaining popularity for wider ranges of <span class="search-hit mathjax">applications</span>. However, current GNNs suffer from the poor performance of their sparse-dense matrix multiplication (SpMM) operator, even when using powerful GPUs. Our analysis shows that 95% of&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.10716v2-abstract-full').style.display = 'inline'; document.getElementById('2104.10716v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2104.10716v2-abstract-full" style="display: none;">
        Graph neural networks (GNNs), an emerging deep learning model class, can extract meaningful representations from highly expressive graph-structured data and are therefore gaining popularity for wider ranges of <span class="search-hit mathjax">applications</span>. However, current GNNs suffer from the poor performance of their sparse-dense matrix multiplication (SpMM) operator, even when using powerful GPUs. Our analysis shows that 95% of the inference <span class="search-hit mathjax">time</span> could be spent on SpMM when running popular GNN models on NVIDIA&#39;s advanced V100 GPU. Such SpMM performance bottleneck hinders GNNs&#39; <span class="search-hit mathjax">applicability</span> to large-scale problems or the development of more sophisticated GNN models. To address this inference <span class="search-hit mathjax">time</span> bottleneck, we introduce ES-SpMM, a cache-first edge sampling mechanism and codesigned SpMM kernel. ES-SpMM uses edge sampling to downsize the graph to fit into GPU&#39;s shared memory. It thus <span class="search-hit mathjax">reduces</span> the computation cost and <span class="search-hit mathjax">improves</span> SpMM&#39;s cache locality. To evaluate ES-SpMM&#39;s performance, we integrated it with a popular GNN framework, DGL, and tested it using representative GNN models and datasets. Our results show that ES-SpMM outperforms the highly <span class="search-hit mathjax">optimized</span> cuSPARSE SpMM kernel by up to 4.35x with no accuracy loss and by 45.3x with less than a 1% accuracy loss.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.10716v2-abstract-full').style.display = 'none'; document.getElementById('2104.10716v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 23 April, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 21 April, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2104.10403">arXiv:2104.10403</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2104.10403">pdf</a>, <a href="https://arxiv.org/ps/2104.10403">ps</a>, <a href="https://arxiv.org/format/2104.10403">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Information Theory">cs.IT</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Model-aided Deep Reinforcement Learning for Sample-efficient UAV Trajectory Design in IoT Networks
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Esrafilian%2C+O">Omid Esrafilian</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bayerlein%2C+H">Harald Bayerlein</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gesbert%2C+D">David Gesbert</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2104.10403v2-abstract-short" style="display: inline;">
        &hellip;learning hence relying on very little prior contextual information. A corresponding drawback however lies in the need for many learning episodes which severely restricts the <span class="search-hit mathjax">applicability</span> of such approach in real-world&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.10403v2-abstract-full').style.display = 'inline'; document.getElementById('2104.10403v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2104.10403v2-abstract-full" style="display: none;">
        Deep Reinforcement Learning (DRL) is gaining attention as a potential approach to design trajectories for autonomous unmanned aerial vehicles (UAV) used as flying access points in the context of cellular or Internet of Things (IoT) connectivity. DRL solutions offer the advantage of on-the-go learning hence relying on very little prior contextual information. A corresponding drawback however lies in the need for many learning episodes which severely restricts the <span class="search-hit mathjax">applicability</span> of such approach in real-world <span class="search-hit mathjax">time</span>- and energy-constrained missions. Here, we propose a model-aided deep Q-learning approach that, in contrast to previous work, considerably <span class="search-hit mathjax">reduces</span> the need for extensive training data samples, while still achieving the overarching goal of DRL, i.e to guide a battery-limited UAV towards an efficient data harvesting trajectory, without prior knowledge of wireless channel characteristics and limited knowledge of wireless node locations. The key idea consists in using a small subset of nodes as anchors (i.e. with known location) and learning a model of the propagation environment while implicitly estimating the positions of regular nodes. Interaction with the model allows us to train a deep Q-network (DQN) to approximate the <span class="search-hit mathjax">optimal</span> UAV control policy. We show that in comparison with standard DRL approaches, the proposed model-aided approach requires at least one order of magnitude less training data samples to reach identical data collection performance, hence offering a first step towards making DRL a viable solution to the problem.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.10403v2-abstract-full').style.display = 'none'; document.getElementById('2104.10403v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 3 May, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 21 April, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">6 pages, 2 figures, submitted to GLOBECOM 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2104.10314">arXiv:2104.10314</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2104.10314">pdf</a>, <a href="https://arxiv.org/format/2104.10314">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Information Theory">cs.IT</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Signal Processing">eess.SP</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Efficient Sparse <span class="search-hit mathjax">Coding</span> using Hierarchical Riemannian Pursuit
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Xue%2C+Y">Ye Xue</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lau%2C+V">Vincent Lau</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cai%2C+S">Songfu Cai</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2104.10314v3-abstract-short" style="display: inline;">
        Sparse <span class="search-hit mathjax">coding</span> is a class of unsupervised methods for learning a sparse representation of the input data in the form of a linear combination of a dictionary and a sparse&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.10314v3-abstract-full').style.display = 'inline'; document.getElementById('2104.10314v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2104.10314v3-abstract-full" style="display: none;">
        Sparse <span class="search-hit mathjax">coding</span> is a class of unsupervised methods for learning a sparse representation of the input data in the form of a linear combination of a dictionary and a sparse <span class="search-hit mathjax">code</span>. This learning framework has led to state-of-the-art results in various image and video processing tasks. However, classical methods learn the dictionary and the sparse <span class="search-hit mathjax">code</span> based on alternative <span class="search-hit mathjax">optimizations</span>, usually without theoretical guarantees for either <span class="search-hit mathjax">optimality</span> or convergence due to non-convexity of the problem. Recent works on sparse <span class="search-hit mathjax">coding</span> with a complete dictionary provide strong theoretical guarantees thanks to the development of the non-convex <span class="search-hit mathjax">optimization</span>. However, initial non-convex approaches learn the dictionary in the sparse <span class="search-hit mathjax">coding</span> problem sequentially in an atom-by-atom manner, which leads to a long execution <span class="search-hit mathjax">time</span>. More recent works seek to directly learn the entire dictionary at once, which substantially <span class="search-hit mathjax">reduces</span> the execution <span class="search-hit mathjax">time</span>. However, the associated recovery performance is degraded with a finite number of data samples. In this paper, we propose an efficient sparse <span class="search-hit mathjax">coding</span> scheme with a two-stage <span class="search-hit mathjax">optimization</span>. The proposed scheme leverages the global and local Riemannian geometry of the two-stage <span class="search-hit mathjax">optimization</span> problem and facilitates <span class="search-hit mathjax">fast</span> implementation for superb dictionary recovery performance by a finite number of samples without atom-by-atom calculation. We further prove that, with high probability, the proposed scheme can exactly recover any atom in the target dictionary with a finite number of samples if it is adopted to recover one atom of the dictionary. An <span class="search-hit mathjax">application</span> on wireless sensor data compression is also proposed. Experiments on both synthetic and real-world data verify the efficiency and effectiveness of the proposed scheme.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.10314v3-abstract-full').style.display = 'none'; document.getElementById('2104.10314v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 4 July, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 20 April, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">This paper has been accepted by IEEE Transactions on Signal Processing</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2104.10301">arXiv:2104.10301</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2104.10301">pdf</a>, <a href="https://arxiv.org/format/2104.10301">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Neural and Evolutionary Computing">cs.NE</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1145/3449639.3459300">10.1145/3449639.3459300 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Towards Exploratory Landscape Analysis for Large-scale <span class="search-hit mathjax">Optimization</span>: A Dimensionality Reduction Framework
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Tanabe%2C+R">Ryoji Tanabe</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2104.10301v1-abstract-short" style="display: inline;">
        Although exploratory landscape analysis (ELA) has shown its effectiveness in various <span class="search-hit mathjax">applications</span>, most previous studies focused only on low- and moderate-dimensional problems. Thus, little is known about the scalability of the ELA approach for large-scale&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.10301v1-abstract-full').style.display = 'inline'; document.getElementById('2104.10301v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2104.10301v1-abstract-full" style="display: none;">
        Although exploratory landscape analysis (ELA) has shown its effectiveness in various <span class="search-hit mathjax">applications</span>, most previous studies focused only on low- and moderate-dimensional problems. Thus, little is known about the scalability of the ELA approach for large-scale <span class="search-hit mathjax">optimization</span>. In this context, first, this paper analyzes the computational cost of features in the flacco package. Our results reveal that two important feature classes (ela_level and ela_meta) cannot be applied to large-scale <span class="search-hit mathjax">optimization</span> due to their high computational cost. To <span class="search-hit mathjax">improve</span> the scalability of the ELA approach, this paper proposes a dimensionality reduction framework that computes features in a <span class="search-hit mathjax">reduced</span> lower-dimensional space than the original solution space. We demonstrate that the proposed framework can drastically <span class="search-hit mathjax">reduce</span> the computation <span class="search-hit mathjax">time</span> of ela_level and ela_meta for large dimensions. In addition, the proposed framework can make the cell-mapping feature classes scalable for large-scale <span class="search-hit mathjax">optimization</span>. Our results also show that features computed by the proposed framework are beneficial for predicting the high-level properties of the 24 large-scale BBOB functions.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.10301v1-abstract-full').style.display = 'none'; document.getElementById('2104.10301v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 20 April, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">This is an accepted version of a paper published in the proceedings of GECCO 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2104.09616">arXiv:2104.09616</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2104.09616">pdf</a>, <a href="https://arxiv.org/format/2104.09616">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Hardware Architecture">cs.AR</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        MELOPPR: <span class="search-hit mathjax">Software</span>/Hardware Co-design for Memory-efficient Low-latency Personalized PageRank
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+L">Lixiang Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+Y">Yao Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zirnheld%2C+Z">Zacharie Zirnheld</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+P">Pan Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hao%2C+C">Cong Hao</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2104.09616v1-abstract-short" style="display: inline;">
        Personalized PageRank (PPR) is a graph algorithm that evaluates the importance of the surrounding nodes from a source node. Widely used in social network related <span class="search-hit mathjax">applications</span> such as recommender systems, PPR requires real-&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.09616v1-abstract-full').style.display = 'inline'; document.getElementById('2104.09616v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2104.09616v1-abstract-full" style="display: none;">
        Personalized PageRank (PPR) is a graph algorithm that evaluates the importance of the surrounding nodes from a source node. Widely used in social network related <span class="search-hit mathjax">applications</span> such as recommender systems, PPR requires real-<span class="search-hit mathjax">time</span> responses (latency) for a better user experience. Existing works either focus on algorithmic <span class="search-hit mathjax">optimization</span> for <span class="search-hit mathjax">improving</span> precision while neglecting hardware implementations or focus on distributed global graph processing on large-scale systems for <span class="search-hit mathjax">improving</span> throughput rather than response <span class="search-hit mathjax">time</span>. <span class="search-hit mathjax">Optimizing</span> low-latency local PPR algorithm with a tight memory budget on edge devices remains unexplored. In this work, we propose a memory-efficient, low-latency PPR solution, namely MeLoPPR, with largely <span class="search-hit mathjax">reduced</span> memory requirement and a flexible trade-off between latency and precision. MeLoPPR is composed of stage decomposition and linear decomposition and exploits the node score sparsity: Through stage and linear decomposition, MeLoPPR breaks the computation on a large graph into a set of smaller sub-graphs, that significantly saves the computation memory; Through sparsity exploitation, MeLoPPR selectively chooses the sub-graphs that contribute the most to the precision to <span class="search-hit mathjax">reduce</span> the required computation. In addition, through <span class="search-hit mathjax">software</span>/hardware co-design, we propose a hardware implementation on a hybrid CPU and FPGA accelerating platform, that further <span class="search-hit mathjax">speeds</span> up the sub-graph computation. We evaluate the proposed MeLoPPR on memory-constrained devices including a personal laptop and Xilinx Kintex-7 KC705 FPGA using six real-world graphs. First, MeLoPPR demonstrates significant memory saving by 1.5x to 13.4x on CPU and 73x to 8699x on FPGA. Second, MeLoPPR allows flexible trade-offs between precision and execution <span class="search-hit mathjax">time</span>: when the precision is 80%, the <span class="search-hit mathjax">speedup</span> on CPU is up to 15x and up to 707x on FPGA; when the precision is around 90%, the <span class="search-hit mathjax">speedup</span> is up to 70x on FPGA.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.09616v1-abstract-full').style.display = 'none'; document.getElementById('2104.09616v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 13 April, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted by IEEE Design Automation Conference, 2021 (DAC&#39;21). Six pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2104.07526">arXiv:2104.07526</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2104.07526">pdf</a>, <a href="https://arxiv.org/format/2104.07526">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Graphics">cs.GR</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Rendering Point Clouds with Compute Shaders and Vertex Order <span class="search-hit mathjax">Optimization</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Sch%C3%BCtz%2C+M">Markus SchÃ¼tz</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kerbl%2C+B">Bernhard Kerbl</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wimmer%2C+M">Michael Wimmer</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2104.07526v1-abstract-short" style="display: inline;">
        &hellip;we present several compute-based point cloud rendering approaches that outperform the hardware pipeline by up to an order of magnitude and achieve significantly better frame <span class="search-hit mathjax">times</span> than previous compute-based methods. Beyond basic closest-point rendering, we also introduce a&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.07526v1-abstract-full').style.display = 'inline'; document.getElementById('2104.07526v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2104.07526v1-abstract-full" style="display: none;">
        While commodity GPUs provide a continuously growing range of features and sophisticated methods for accelerating compute jobs, many state-of-the-art solutions for point cloud rendering still rely on the provided point primitives (GL_POINTS, POINTLIST, ...) of graphics APIs for image synthesis. In this paper, we present several compute-based point cloud rendering approaches that outperform the hardware pipeline by up to an order of magnitude and achieve significantly better frame <span class="search-hit mathjax">times</span> than previous compute-based methods. Beyond basic closest-point rendering, we also introduce a <span class="search-hit mathjax">fast</span>, high-quality variant to <span class="search-hit mathjax">reduce</span> aliasing. We present and evaluate several variants of our proposed methods with different flavors of <span class="search-hit mathjax">optimization</span>, in order to ensure their <span class="search-hit mathjax">applicability</span> and achieve <span class="search-hit mathjax">optimal</span> performance on a range of platforms and architectures with varying support for novel GPU hardware features. During our experiments, the observed peak performance was reached rendering 796 million points (12.7GB) at rates of 62 to 64 frames per second (50 billion points per second, 802GB/s) on an RTX 3090 without the use of level-of-detail structures.
  We further introduce an <span class="search-hit mathjax">optimized</span> vertex order for point clouds to boost the efficiency of GL_POINTS by a factor of 5x in cases where hardware rendering is compulsory. We compare different orderings and show that Morton sorted buffers are <span class="search-hit mathjax">faster</span> for some viewpoints, while shuffled vertex buffers are <span class="search-hit mathjax">faster</span> in others. In contrast, combining both approaches by first sorting according to Morton-<span class="search-hit mathjax">code</span> and shuffling the resulting sequence in batches of 128 points leads to a vertex buffer layout with high rendering performance and low sensitivity to viewpoint changes.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.07526v1-abstract-full').style.display = 'none'; document.getElementById('2104.07526v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 April, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">13 pages content, 5 pages appendix</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2104.05158">arXiv:2104.05158</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2104.05158">pdf</a>, <a href="https://arxiv.org/format/2104.05158">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Performance">cs.PF</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        High-performance, Distributed Training of Large-scale Deep Learning Recommendation Models
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Mudigere%2C+D">Dheevatsa Mudigere</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hao%2C+Y">Yuchen Hao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Huang%2C+J">Jianyu Huang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tulloch%2C+A">Andrew Tulloch</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sridharan%2C+S">Srinivas Sridharan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+X">Xing Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ozdal%2C+M">Mustafa Ozdal</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Nie%2C+J">Jade Nie</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Park%2C+J">Jongsoo Park</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Luo%2C+L">Liang Luo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yang%2C+J+A">Jie Amy Yang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gao%2C+L">Leon Gao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ivchenko%2C+D">Dmytro Ivchenko</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Basant%2C+A">Aarti Basant</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hu%2C+Y">Yuxi Hu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yang%2C+J">Jiyan Yang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ardestani%2C+E+K">Ehsan K. Ardestani</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+X">Xiaodong Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Komuravelli%2C+R">Rakesh Komuravelli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chu%2C+C">Ching-Hsiang Chu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yilmaz%2C+S">Serhat Yilmaz</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+H">Huayu Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Qian%2C+J">Jiyuan Qian</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Feng%2C+Z">Zhuobo Feng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+Y">Yinbin Ma</a>
      , et al. (26 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2104.05158v3-abstract-short" style="display: inline;">
        Deep learning recommendation models (DLRMs) are used across many business-critical services at Facebook and are the single largest AI <span class="search-hit mathjax">application</span> in terms of infrastructure demand in its data-centers. In this paper we discuss the SW/HW co-designed solution for high-performance distributed training of large-scale DLRMs. We introduce a high-performance scalabl&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.05158v3-abstract-full').style.display = 'inline'; document.getElementById('2104.05158v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2104.05158v3-abstract-full" style="display: none;">
        Deep learning recommendation models (DLRMs) are used across many business-critical services at Facebook and are the single largest AI <span class="search-hit mathjax">application</span> in terms of infrastructure demand in its data-centers. In this paper we discuss the SW/HW co-designed solution for high-performance distributed training of large-scale DLRMs. We introduce a high-performance scalable <span class="search-hit mathjax">software</span> stack based on PyTorch and pair it with the new evolution of Zion platform, namely ZionEX. We demonstrate the capability to train very large DLRMs with up to 12 Trillion parameters and show that we can attain 40X <span class="search-hit mathjax">speedup</span> in terms of <span class="search-hit mathjax">time</span> to solution over previous systems. We achieve this by (i) designing the ZionEX platform with dedicated scale-out network, provisioned with high bandwidth, <span class="search-hit mathjax">optimal</span> topology and efficient transport (ii) implementing an <span class="search-hit mathjax">optimized</span> PyTorch-based training stack supporting both model and data parallelism (iii) developing sharding algorithms capable of hierarchical partitioning of the embedding tables along row, column dimensions and load balancing them across multiple workers; (iv) adding high-performance core operators while retaining flexibility to support <span class="search-hit mathjax">optimizers</span> with fully deterministic updates (v) leveraging <span class="search-hit mathjax">reduced</span> precision communications, multi-level memory hierarchy (HBM+DDR+SSD) and pipelining. Furthermore, we develop and briefly comment on distributed data ingestion and other supporting services that are required for the robust and efficient end-to-end training in production environments.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.05158v3-abstract-full').style.display = 'none'; document.getElementById('2104.05158v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 April, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 11 April, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2104.05050">arXiv:2104.05050</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2104.05050">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Research on <span class="search-hit mathjax">Optimization</span> Method of Multi-scale Fish Target <span class="search-hit mathjax">Fast</span> Detection Network
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+Y">Yang Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+S">Shengmao Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+F">Fei Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fan%2C+W">Wei Fan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zou%2C+G">Guohua Zou</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bo%2C+J">Jing Bo</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2104.05050v1-abstract-short" style="display: inline;">
        The fish target detection algorithm lacks a good quality data set, and the algorithm achieves real-<span class="search-hit mathjax">time</span> detection with lower power consumption on embedded devices, and it is difficult to balance the calculation&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.05050v1-abstract-full').style.display = 'inline'; document.getElementById('2104.05050v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2104.05050v1-abstract-full" style="display: none;">
        The fish target detection algorithm lacks a good quality data set, and the algorithm achieves real-<span class="search-hit mathjax">time</span> detection with lower power consumption on embedded devices, and it is difficult to balance the calculation <span class="search-hit mathjax">speed</span> and identification ability. To this end, this paper collected and annotated a data set named &#34;Aquarium Fish&#34; of 84 fishes containing 10042 images, and based on this data set, proposed a multi-scale input <span class="search-hit mathjax">fast</span> fish target detection network (BTP-yoloV3) and its <span class="search-hit mathjax">optimization</span> method. The experiment uses Depthwise convolution to redesign the backbone of the yoloV4 network, which <span class="search-hit mathjax">reduces</span> the amount of calculation by 94.1%, and the test accuracy is 92.34%. Then, the training model is enhanced with MixUp, CutMix, and mosaic to increase the test accuracy by 1.27%; Finally, use the mish, swish, and ELU activation functions to increase the test accuracy by 0.76%. As a result, the accuracy of testing the network with 2000 fish images reached 94.37%, and the computational complexity of the network BFLOPS was only 5.47. Comparing the YoloV3~4, MobileNetV2-yoloV3, and YoloV3-tiny networks of migration learning on this data set. The results show that BTP-Yolov3 has smaller model parameters, <span class="search-hit mathjax">faster</span> calculation <span class="search-hit mathjax">speed</span>, and lower energy consumption during operation while ensuring the calculation accuracy. It provides a certain reference value for the practical <span class="search-hit mathjax">application</span> of neural network.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.05050v1-abstract-full').style.display = 'none'; document.getElementById('2104.05050v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 11 April, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2104.04611">arXiv:2104.04611</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2104.04611">pdf</a>, <a href="https://arxiv.org/format/2104.04611">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Self-Boosted <span class="search-hit mathjax">Automated</span> <span class="search-hit mathjax">Program</span> Repair
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Benton%2C+S">Samuel Benton</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+M">Mengshi Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+X">Xia Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+L">Lingming Zhang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2104.04611v1-abstract-short" style="display: inline;">
        <span class="search-hit mathjax">Program</span> repair is an integral part of every&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.04611v1-abstract-full').style.display = 'inline'; document.getElementById('2104.04611v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2104.04611v1-abstract-full" style="display: none;">
        <span class="search-hit mathjax">Program</span> repair is an integral part of every <span class="search-hit mathjax">software</span> system&#39;s life-cycle but can be extremely challenging. To date, researchers have proposed various <span class="search-hit mathjax">automated</span> <span class="search-hit mathjax">program</span> repair (APR) techniques to <span class="search-hit mathjax">reduce</span> efforts of manual debugging. However, given a real-world buggy <span class="search-hit mathjax">program</span>, a typical APR technique usually generates a large number of patches, each of which needs to be validated against the original test suite which incurs extremely high computation costs. Although existing APR techniques have already leveraged various static and/or dynamic information to find the desired patches <span class="search-hit mathjax">faster</span>, they are still rather costly. In a recent work, researchers proposed unified debugging to leverage the patch execution information during APR to help boost fault localization; in this way,the <span class="search-hit mathjax">application</span> scope of APR techniques can be extended to all possible bugs, e.g., the patch execution information during APR can help with manual repair of the bugs that cannot be <span class="search-hit mathjax">automatically</span> fixed. Inspired by unified debugging, this work proposes SeAPR (Self-Boosted <span class="search-hit mathjax">Automated</span> <span class="search-hit mathjax">Program</span> Repair), the first technique to leverage the earlier patch execution information during APR to help boost <span class="search-hit mathjax">automated</span> repair itself on-the-fly. Our basic intuition is that patches similar to earlier high-quality/low-quality patches should be promoted/degraded to <span class="search-hit mathjax">speed</span> up the detection of the desired patches. This experimental study on 12 state-of-the-art APR systems demonstrates that, overall, SeAPR can substantially <span class="search-hit mathjax">reduce</span> the number of patch executions with negligible overhead. Our study also investigates the impact of various configurations on SeAPR. Lastly, our study demonstrates that SeAPR can even leverage the patch execution information from other APR tools from the same buggy <span class="search-hit mathjax">program</span> to further boost APR.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.04611v1-abstract-full').style.display = 'none'; document.getElementById('2104.04611v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 9 April, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">13 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2104.04049">arXiv:2104.04049</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2104.04049">pdf</a>, <a href="https://arxiv.org/format/2104.04049">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Quantum-Assisted Feature Selection for Vehicle Price Prediction Modeling
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Von+Dollen%2C+D">David Von Dollen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Neukart%2C+F">Florian Neukart</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Weimer%2C+D">Daniel Weimer</a>, 
      
      <a href="/search/?searchtype=author&amp;query=B%C3%A4ck%2C+T">Thomas BÃ¤ck</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2104.04049v2-abstract-short" style="display: inline;">
        Within machine learning model evaluation regimes, feature selection is a technique to <span class="search-hit mathjax">reduce</span> model complexity and <span class="search-hit mathjax">improve</span> model performance in regards to generalization, model fit, and accuracy of prediction. However, the search over the space of features to find the subset of $k$&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.04049v2-abstract-full').style.display = 'inline'; document.getElementById('2104.04049v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2104.04049v2-abstract-full" style="display: none;">
        Within machine learning model evaluation regimes, feature selection is a technique to <span class="search-hit mathjax">reduce</span> model complexity and <span class="search-hit mathjax">improve</span> model performance in regards to generalization, model fit, and accuracy of prediction. However, the search over the space of features to find the subset of $k$ <span class="search-hit mathjax">optimal</span> features is a known NP-Hard problem. In this work, we study metrics for encoding the combinatorial search as a binary quadratic model, such as Generalized Mean Information Coefficient and Pearson Correlation Coefficient in <span class="search-hit mathjax">application</span> to the underlying regression problem of price prediction. We investigate trade-offs in the form of run-<span class="search-hit mathjax">times</span> and model performance, of leveraging quantum-assisted vs. classical subroutines for the combinatorial search, using minimum redundancy maximal relevancy as the heuristic for our approach. We achieve accuracy scores of 0.9 (in the range of [0,1]) for finding <span class="search-hit mathjax">optimal</span> subsets on synthetic data using a new metric that we define. We test and cross-validate predictive models on a real-world problem of price prediction, and show a performance <span class="search-hit mathjax">improvement</span> of mean absolute error scores for our quantum-assisted method $(1471.02 \pm{135.6})$, vs. similar methodologies such as recursive feature elimination $(1678.3 \pm{143.7})$. Our findings show that by leveraging quantum-assisted routines we find solutions that increase the quality of predictive model output while <span class="search-hit mathjax">reducing</span> the input dimensionality to the learning algorithm on synthetic and real-world data.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.04049v2-abstract-full').style.display = 'none'; document.getElementById('2104.04049v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 May, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 8 April, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2104.01750">arXiv:2104.01750</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2104.01750">pdf</a>, <a href="https://arxiv.org/format/2104.01750">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        <span class="search-hit mathjax">Optimal</span> Sampling Gaps for Adaptive Submodular Maximization
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Tang%2C+S">Shaojie Tang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yuan%2C+J">Jing Yuan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2104.01750v2-abstract-short" style="display: inline;">
        Running machine learning algorithms on large and rapidly growing volumes of data are often computationally expensive, one common trick to <span class="search-hit mathjax">reduce</span> the size of a data set, and thus&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.01750v2-abstract-full').style.display = 'inline'; document.getElementById('2104.01750v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2104.01750v2-abstract-full" style="display: none;">
        Running machine learning algorithms on large and rapidly growing volumes of data are often computationally expensive, one common trick to <span class="search-hit mathjax">reduce</span> the size of a data set, and thus <span class="search-hit mathjax">reduce</span> the computational cost of machine learning algorithms, is \emph{probability sampling}. It creates a sampled data set by including each data point from the original data set with a known probability. Although the benefit of running machine learning algorithms on the <span class="search-hit mathjax">reduced</span> data set is obvious, one major concern is that the performance of the solution obtained from samples might be much worse than that of the <span class="search-hit mathjax">optimal</span> solution when using the full data set. In this paper, we examine the performance loss caused by probability sampling in the context of adaptive submodular maximization. We consider a easiest probability sampling method which selects each data point independently with probability $r\in[0,1]$. We define sampling gap as the largest ratio of the <span class="search-hit mathjax">optimal</span> solution obtained from the full data set and the <span class="search-hit mathjax">optimal</span> solution obtained from the samples, over independence systems. Our main contribution is to show that if the utility function is policywise submodular, then for a given sampling rate $r$, the sampling gap is both upper bounded and lower bounded by $1/r$. One immediate implication of our result is that if we can find an $Î±$-approximation solution based on a sampled data set (which is sampled at sampling rate $r$), then this solution achieves an $Î±r$ approximation ratio for the original problem when using the full data set. We also show that the property of policywise submodular can be found in a wide range of real-world <span class="search-hit mathjax">applications</span>, including pool-based active learning and adaptive viral marketing.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.01750v2-abstract-full').style.display = 'none'; document.getElementById('2104.01750v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 12 April, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 4 April, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2104.00142">arXiv:2104.00142</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2104.00142">pdf</a>, <a href="https://arxiv.org/format/2104.00142">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        NodeSRT: A Selective Regression Testing Tool for Node.js <span class="search-hit mathjax">Application</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+Y">Yufeng Chen</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2104.00142v1-abstract-short" style="display: inline;">
        Node.js is one of the most popular frameworks for building web <span class="search-hit mathjax">applications</span>. As&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.00142v1-abstract-full').style.display = 'inline'; document.getElementById('2104.00142v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2104.00142v1-abstract-full" style="display: none;">
        Node.js is one of the most popular frameworks for building web <span class="search-hit mathjax">applications</span>. As <span class="search-hit mathjax">software</span> systems mature, the cost of running their entire regression test suite can become significant. Selective Regression Testing (SRT) is a technique that executes only a subset of tests the regression test suite can detect <span class="search-hit mathjax">software</span> failures more efficiently. Previous SRT studies mainly focused on standard desktop <span class="search-hit mathjax">applications</span>. Node.js <span class="search-hit mathjax">applications</span> are considered hard to perform test reduction because of Node&#39;s asynchronous, event-driven <span class="search-hit mathjax">programming</span> model and because JavaScript is a dynamic <span class="search-hit mathjax">programming</span> language. In this paper, we present NodeSRT, a Selective Regression Testing framework for Node.js <span class="search-hit mathjax">applications</span>. By performing static and dynamic analysis, NodeSRT identifies the relationship between changed methods and tests, then <span class="search-hit mathjax">reduces</span> the regression test suite to only tests that are affected by the change to <span class="search-hit mathjax">improve</span> the execution <span class="search-hit mathjax">time</span> of the regression test suite. To evaluate our selection technique, we applied NodeSRT to two open-source projects: Uppy and Simorgh, then compared our approach with the retest-all strategy and current industry-standard SRT technique: Jest OnlyChange. The results demonstrate that NodeSRT correctly selects affected tests based on changes and is 250% <span class="search-hit mathjax">faster</span>, 450% more precise than the Jest OnlyChange.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.00142v1-abstract-full').style.display = 'none'; document.getElementById('2104.00142v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 31 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.17231">arXiv:2103.17231</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.17231">pdf</a>, <a href="https://arxiv.org/format/2103.17231">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        CDiNN -Convex Difference Neural Networks
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Sankaranarayanan%2C+P">Parameswaran Sankaranarayanan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rengaswamy%2C+R">Raghunathan Rengaswamy</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.17231v2-abstract-short" style="display: inline;">
        &hellip;shown to be universal function approximators and learn function mapping as non-smooth functions. Recently, there is considerable interest in the use of neural networks in <span class="search-hit mathjax">applications</span> such as&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.17231v2-abstract-full').style.display = 'inline'; document.getElementById('2103.17231v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.17231v2-abstract-full" style="display: none;">
        Neural networks with ReLU activation function have been shown to be universal function approximators and learn function mapping as non-smooth functions. Recently, there is considerable interest in the use of neural networks in <span class="search-hit mathjax">applications</span> such as <span class="search-hit mathjax">optimal</span> control. It is well-known that <span class="search-hit mathjax">optimization</span> involving non-convex, non-smooth functions are computationally intensive and have limited convergence guarantees. Moreover, the choice of <span class="search-hit mathjax">optimization</span> hyper-parameters used in gradient descent/ascent significantly affect the quality of the obtained solutions. A new neural network architecture called the Input Convex Neural Networks (ICNNs) learn the output as a convex function of inputs thereby allowing the use of efficient convex <span class="search-hit mathjax">optimization</span> methods. Use of ICNNs for determining the input for minimizing output has two major problems: learning of a non-convex function as a convex mapping could result in significant function approximation error, and we also note that the existing representations cannot capture simple dynamic structures like linear <span class="search-hit mathjax">time</span> delay systems. We attempt to address the above problems by introduction of a new neural network architecture, which we call the CDiNN, which learns the function as a difference of polyhedral convex functions from data. We also discuss that, in some cases, the <span class="search-hit mathjax">optimal</span> input can be obtained from CDiNN through difference of convex <span class="search-hit mathjax">optimization</span> with convergence guarantees and that at each iteration, the problem is <span class="search-hit mathjax">reduced</span> to a linear <span class="search-hit mathjax">programming</span> problem.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.17231v2-abstract-full').style.display = 'none'; document.getElementById('2103.17231v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 5 April, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 31 March, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.16365">arXiv:2103.16365</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.16365">pdf</a>, <a href="https://arxiv.org/format/2103.16365">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Graphics">cs.GR</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Foveated Neural Radiance Fields for Real-<span class="search-hit mathjax">Time</span> and Egocentric Virtual Reality
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Deng%2C+N">Nianchen Deng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=He%2C+Z">Zhenyi He</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ye%2C+J">Jiannan Ye</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chakravarthula%2C+P">Praneeth Chakravarthula</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yang%2C+X">Xubo Yang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sun%2C+Q">Qi Sun</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.16365v1-abstract-short" style="display: inline;">
        &hellip;from high latency or low quality for practical visualization of large immersive virtual scenes, notably with extra high resolution and refresh rate requirements for VR <span class="search-hit mathjax">applications</span> such as gaming and design.
  Tailored for the future portable, low-storage, and energy-efficient VR platforms, we present the first gaze-contingent 3D neural representation and vi&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.16365v1-abstract-full').style.display = 'inline'; document.getElementById('2103.16365v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.16365v1-abstract-full" style="display: none;">
        Traditional high-quality 3D graphics requires large volumes of fine-detailed scene data for rendering. This demand compromises computational efficiency and local storage resources. Specifically, it becomes more concerning for future wearable and portable virtual and augmented reality (VR/AR) displays. Recent approaches to combat this problem include remote rendering/streaming and neural representations of 3D assets. These approaches have redefined the traditional local storage-rendering pipeline by distributed computing or compression of large data. However, these methods typically suffer from high latency or low quality for practical visualization of large immersive virtual scenes, notably with extra high resolution and refresh rate requirements for VR <span class="search-hit mathjax">applications</span> such as gaming and design.
  Tailored for the future portable, low-storage, and energy-efficient VR platforms, we present the first gaze-contingent 3D neural representation and view synthesis method. We incorporate the human psychophysics of visual- and stereo-acuity into an egocentric neural representation of 3D scenery. Furthermore, we jointly <span class="search-hit mathjax">optimize</span> the latency/performance and visual quality, while mutually bridging human perception and neural scene synthesis, to achieve perceptually high-quality immersive interaction. Both objective analysis and subjective study demonstrate the effectiveness of our approach in significantly <span class="search-hit mathjax">reducing</span> local storage volume and synthesis latency (up to 99% reduction in both data size and computational <span class="search-hit mathjax">time</span>), while simultaneously presenting high-fidelity rendering, with perceptual quality identical to that of fully locally stored and rendered high-quality imagery.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.16365v1-abstract-full').style.display = 'none'; document.getElementById('2103.16365v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.16007">arXiv:2103.16007</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.16007">pdf</a>, <a href="https://arxiv.org/format/2103.16007">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Databases">cs.DB</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Production Machine Learning Pipelines: Empirical Analysis and <span class="search-hit mathjax">Optimization</span> Opportunities
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Xin%2C+D">Doris Xin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Miao%2C+H">Hui Miao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Parameswaran%2C+A">Aditya Parameswaran</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Polyzotis%2C+N">Neoklis Polyzotis</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.16007v1-abstract-short" style="display: inline;">
        Machine learning (ML) is now commonplace, powering data-driven <span class="search-hit mathjax">applications</span> in various organizations. Unlike the traditional perception of ML in research, ML production pipelines are complex, with many interlocking analytical components beyond training, whose sub-parts are often run multiple&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.16007v1-abstract-full').style.display = 'inline'; document.getElementById('2103.16007v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.16007v1-abstract-full" style="display: none;">
        Machine learning (ML) is now commonplace, powering data-driven <span class="search-hit mathjax">applications</span> in various organizations. Unlike the traditional perception of ML in research, ML production pipelines are complex, with many interlocking analytical components beyond training, whose sub-parts are often run multiple <span class="search-hit mathjax">times</span> on overlapping subsets of data. However, there is a lack of quantitative evidence regarding the lifespan, architecture, frequency, and complexity of these pipelines to understand how data management research can be used to make them more efficient, effective, robust, and reproducible. To that end, we analyze the provenance graphs of 3000 production ML pipelines at Google, comprising over 450,000 models trained, spanning a period of over four months, in an effort to understand the complexity and challenges underlying production ML. Our analysis reveals the characteristics, components, and topologies of typical industry-strength ML pipelines at various granularities. Along the way, we introduce a specialized data model for representing and reasoning about repeatedly run components in these ML pipelines, which we call model graphlets. We identify several rich opportunities for <span class="search-hit mathjax">optimization</span>, leveraging traditional data management ideas. We show how targeting even one of these opportunities, i.e., identifying and pruning wasted computation that does not translate to model deployment, can <span class="search-hit mathjax">reduce</span> wasted computation cost by 50% without compromising the model deployment cadence.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.16007v1-abstract-full').style.display = 'none'; document.getElementById('2103.16007v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 29 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        Proceedings of the 2021 International Conference on Management of Data
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.15820">arXiv:2103.15820</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.15820">pdf</a>, <a href="https://arxiv.org/format/2103.15820">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Logic in Computer Science">cs.LO</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Discrete Mathematics">cs.DM</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        ZX-Calculus and Extended Wolfram Model Systems II: <span class="search-hit mathjax">Fast</span> Diagrammatic Reasoning with an <span class="search-hit mathjax">Application</span> to Quantum Circuit Simplification
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Gorard%2C+J">Jonathan Gorard</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Namuduri%2C+M">Manojna Namuduri</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Arsiwalla%2C+X+D">Xerxes D. Arsiwalla</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.15820v1-abstract-short" style="display: inline;">
        This article presents a novel algorithmic methodology for performing <span class="search-hit mathjax">automated</span> diagrammatic deductions over combinatorial structures, using a combination of modified equational theorem-proving techniques and the extended Wolfram model hypergraph rewriting formalism developed by the authors in previous work. We focus especially upon the&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.15820v1-abstract-full').style.display = 'inline'; document.getElementById('2103.15820v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.15820v1-abstract-full" style="display: none;">
        This article presents a novel algorithmic methodology for performing <span class="search-hit mathjax">automated</span> diagrammatic deductions over combinatorial structures, using a combination of modified equational theorem-proving techniques and the extended Wolfram model hypergraph rewriting formalism developed by the authors in previous work. We focus especially upon the <span class="search-hit mathjax">application</span> of this new algorithm to the problem of <span class="search-hit mathjax">automated</span> circuit simplification in quantum information theory, using Wolfram model multiway operator systems combined with the ZX-calculus formalism for enacting <span class="search-hit mathjax">fast</span> diagrammatic reasoning over linear transformations between qubits. We show how to construct a generalization of the deductive inference rules for Knuth-Bendix completion in which equation matches are selected on the basis of causal edge density in the associated multiway system, before proceeding to demonstrate how to embed the higher-order logic of the ZX-calculus rules within this first-order equational framework. After showing explicitly how the (hyper)graph rewritings of both Wolfram model systems and the ZX-calculus can be effectively realized within this formalism, we proceed to exhibit comparisons of <span class="search-hit mathjax">time</span> complexity vs. proof complexity for this new algorithmic approach when simplifying randomly-generated Clifford circuits down to pseudo-normal form, as well as when <span class="search-hit mathjax">reducing</span> the number of T-gates in randomly-generated non-Clifford circuits, with circuit sizes ranging up to 3000 gates, illustrating that the method performs favorably in comparison with existing circuit simplification frameworks, and also exhibiting the approximately quadratic <span class="search-hit mathjax">speedup</span> obtained by employing the causal edge density <span class="search-hit mathjax">optimization</span>. Finally, we present a worked example of an <span class="search-hit mathjax">automated</span> proof of correctness for a simple quantum teleportation protocol, in order to demonstrate more clearly the internal operations of the theorem-proving procedure.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.15820v1-abstract-full').style.display = 'none'; document.getElementById('2103.15820v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 29 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">104 pages, 57 figures</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        
          <span class="has-text-black-bis has-text-weight-semibold">MSC Class:</span>
          68R10
        

        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.15608">arXiv:2103.15608</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.15608">pdf</a>, <a href="https://arxiv.org/format/2103.15608">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Neural and Evolutionary Computing">cs.NE</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Hybrid Evolutionary <span class="search-hit mathjax">Optimization</span> Approach for Oilfield Well Control <span class="search-hit mathjax">Optimization</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Kumar%2C+A">Ajitabh Kumar</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.15608v1-abstract-short" style="display: inline;">
        Oilfield production <span class="search-hit mathjax">optimization</span> is challenging due to subsurface model complexity and associated non-linearity, large number of control parameters, large number of production scenarios, and subsurface uncertainties.&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.15608v1-abstract-full').style.display = 'inline'; document.getElementById('2103.15608v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.15608v1-abstract-full" style="display: none;">
        Oilfield production <span class="search-hit mathjax">optimization</span> is challenging due to subsurface model complexity and associated non-linearity, large number of control parameters, large number of production scenarios, and subsurface uncertainties. <span class="search-hit mathjax">Optimization</span> involves <span class="search-hit mathjax">time</span>-consuming reservoir simulation studies to compare different production scenarios and settings. This paper presents efficacy of two hybrid evolutionary <span class="search-hit mathjax">optimization</span> approaches for well control <span class="search-hit mathjax">optimization</span> of a waterflooding operation, and demonstrates their <span class="search-hit mathjax">application</span> using Olympus benchmark. A simpler, weighted sum of cumulative fluid (WCF) is used as objective function first, which is then replaced by net present value (NPV) of discounted cash-flow for comparison. Two popular evolutionary <span class="search-hit mathjax">optimization</span> algorithms, genetic algorithm (GA) and particle swarm <span class="search-hit mathjax">optimization</span> (PSO), are first used in standalone mode to solve well control <span class="search-hit mathjax">optimization</span> problem. Next, both GA and PSO methods are used with another popular <span class="search-hit mathjax">optimization</span> algorithm, covariance matrix adaptation-evolution strategy (CMA-ES), in hybrid mode. Hybrid <span class="search-hit mathjax">optimization</span> run is made by transferring the resulting population from one algorithm to the next as its starting population for further <span class="search-hit mathjax">improvement</span>. Approximately four thousand simulation runs are needed for standalone GA and PSO methods to converge, while six thousand runs are needed in case of two hybrid <span class="search-hit mathjax">optimization</span> modes (GA-CMA-ES and PSO-CMA-ES). To <span class="search-hit mathjax">reduce</span> turn-around <span class="search-hit mathjax">time</span>, commercial cloud computing is used and simulation workload is distributed using parallel <span class="search-hit mathjax">programming</span>. GA and PSO algorithms have a good balance between exploratory and exploitative properties, thus are able identify regions of interest. CMA-ES algorithm is able to further refine the solution using its excellent exploitative properties. Thus, GA or PSO with CMA-ES in hybrid mode yields better <span class="search-hit mathjax">optimization</span> result as compared to standalone GA or PSO algorithms.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.15608v1-abstract-full').style.display = 'none'; document.getElementById('2103.15608v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 29 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.14607">arXiv:2103.14607</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.14607">pdf</a>, <a href="https://arxiv.org/format/2103.14607">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Search-based Planning of Dynamic MAV Trajectories Using Local Multiresolution State Lattices
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Schleich%2C+D">Daniel Schleich</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Behnke%2C+S">Sven Behnke</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.14607v1-abstract-short" style="display: inline;">
        &hellip;methods that use motion primitives can incorporate the system&#39;s dynamics into the planning and thus generate dynamically feasible MAV trajectories that are globally <span class="search-hit mathjax">optimal</span>. However, searching high-dimensional state lattices is computationally expensive. Local multiresolution is a commonly used method to accelerate spatial path planning. While paths with&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.14607v1-abstract-full').style.display = 'inline'; document.getElementById('2103.14607v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.14607v1-abstract-full" style="display: none;">
        Search-based methods that use motion primitives can incorporate the system&#39;s dynamics into the planning and thus generate dynamically feasible MAV trajectories that are globally <span class="search-hit mathjax">optimal</span>. However, searching high-dimensional state lattices is computationally expensive. Local multiresolution is a commonly used method to accelerate spatial path planning. While paths within the vicinity of the robot are represented at high resolution, the representation gets coarser for more distant parts. In this work, we apply the concept of local multiresolution to high-dimensional state lattices that include velocities and accelerations. Experiments show that our proposed approach significantly <span class="search-hit mathjax">reduces</span> planning <span class="search-hit mathjax">times</span>. Thus, it increases the <span class="search-hit mathjax">applicability</span> to large dynamic environments, where frequent replanning is necessary.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.14607v1-abstract-full').style.display = 'none'; document.getElementById('2103.14607v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 26 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted for IEEE International Conference on Robotics and Automation (ICRA), Xi&#39;an, China, to appear June 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.14024">arXiv:2103.14024</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.14024">pdf</a>, <a href="https://arxiv.org/format/2103.14024">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Graphics">cs.GR</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        PlenOctrees for Real-<span class="search-hit mathjax">time</span> Rendering of Neural Radiance Fields
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Yu%2C+A">Alex Yu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+R">Ruilong Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tancik%2C+M">Matthew Tancik</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+H">Hao Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ng%2C+R">Ren Ng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kanazawa%2C+A">Angjoo Kanazawa</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.14024v1-abstract-short" style="display: inline;">
        We introduce a method to render Neural Radiance Fields (NeRFs) in real <span class="search-hit mathjax">time</span> using PlenOctrees, an octree-based 3D representation which supports view-dependent effects. Our method can render 800x800 images at more than 150 FPS, which is over 3000&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.14024v1-abstract-full').style.display = 'inline'; document.getElementById('2103.14024v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.14024v1-abstract-full" style="display: none;">
        We introduce a method to render Neural Radiance Fields (NeRFs) in real <span class="search-hit mathjax">time</span> using PlenOctrees, an octree-based 3D representation which supports view-dependent effects. Our method can render 800x800 images at more than 150 FPS, which is over 3000 <span class="search-hit mathjax">times</span> <span class="search-hit mathjax">faster</span> than conventional NeRFs. We do so without sacrificing quality while preserving the ability of NeRFs to perform free-viewpoint rendering of scenes with arbitrary geometry and view-dependent effects. Real-<span class="search-hit mathjax">time</span> performance is achieved by pre-tabulating the NeRF into a PlenOctree. In order to preserve view-dependent effects such as specularities, we factorize the appearance via closed-form spherical basis functions. Specifically, we show that it is possible to train NeRFs to predict a spherical harmonic representation of radiance, removing the viewing direction as an input to the neural network. Furthermore, we show that PlenOctrees can be directly <span class="search-hit mathjax">optimized</span> to further minimize the reconstruction loss, which leads to equal or better quality compared to competing methods. Moreover, this octree <span class="search-hit mathjax">optimization</span> step can be used to <span class="search-hit mathjax">reduce</span> the training <span class="search-hit mathjax">time</span>, as we no longer need to wait for the NeRF training to converge fully. Our real-<span class="search-hit mathjax">time</span> neural rendering approach may potentially enable new <span class="search-hit mathjax">applications</span> such as 6-DOF industrial and product visualizations, as well as next generation AR/VR systems. PlenOctrees are amenable to in-browser rendering as well; please visit the project page for the interactive online demo, as well as video and <span class="search-hit mathjax">code</span>: https://alexyu.net/plenoctrees
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.14024v1-abstract-full').style.display = 'none'; document.getElementById('2103.14024v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 25 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.13909">arXiv:2103.13909</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.13909">pdf</a>, <a href="https://arxiv.org/ps/2103.13909">ps</a>, <a href="https://arxiv.org/format/2103.13909">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Numerical Analysis">math.NA</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1098/rsta.2020.0191">10.1098/rsta.2020.0191 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Regularization by Denoising Sub-sampled Newton Method for Spectral CT Multi-Material Decomposition
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Perelli%2C+A">Alessandro Perelli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Andersen%2C+M+S">Martin S. Andersen</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.13909v1-abstract-short" style="display: inline;">
        &hellip;exploiting different photon energy spectra. In this work, we aim at efficiently solving a model-based maximum-a-posterior problem to reconstruct multi-materials images with <span class="search-hit mathjax">application</span> to spectral CT. In particular, we propose to solve a regularized&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.13909v1-abstract-full').style.display = 'inline'; document.getElementById('2103.13909v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.13909v1-abstract-full" style="display: none;">
        Spectral Computed Tomography (CT) is an emerging technology that enables to estimate the concentration of basis materials within a scanned object by exploiting different photon energy spectra. In this work, we aim at efficiently solving a model-based maximum-a-posterior problem to reconstruct multi-materials images with <span class="search-hit mathjax">application</span> to spectral CT. In particular, we propose to solve a regularized <span class="search-hit mathjax">optimization</span> problem based on a plug-in image-denoising function using a randomized second order method. By approximating the Newton step using a sketching of the Hessian of the likelihood function, it is possible to <span class="search-hit mathjax">reduce</span> the complexity while retaining the complex prior structure given by the data-driven regularizer. We exploit a non-uniform block sub-sampling of the Hessian with inexact but efficient Conjugate gradient updates that require only Jacobian-vector products for denoising term. Finally, we show numerical and experimental results for spectral CT materials decomposition.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.13909v1-abstract-full').style.display = 'none'; document.getElementById('2103.13909v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 25 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted in Philosophical Transactions A, issue &#34;Synergistic tomographic image reconstruction (Part 1)&#34;</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.13147">arXiv:2103.13147</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.13147">pdf</a>, <a href="https://arxiv.org/format/2103.13147">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Multiagent Systems">cs.MA</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Multi-Agent Off-Policy TD Learning: Finite-<span class="search-hit mathjax">Time</span> Analysis with Near-<span class="search-hit mathjax">Optimal</span> Sample Complexity and Communication Complexity
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+Z">Ziyi Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhou%2C+Y">Yi Zhou</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+R">Rongrong Chen</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.13147v1-abstract-short" style="display: inline;">
        The finite-<span class="search-hit mathjax">time</span> convergence of off-policy TD learning has been comprehensively studied recently. However, such a type of convergence has not been well established for off-policy TD learning in the multi-agent setting, which covers broader&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.13147v1-abstract-full').style.display = 'inline'; document.getElementById('2103.13147v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.13147v1-abstract-full" style="display: none;">
        The finite-<span class="search-hit mathjax">time</span> convergence of off-policy TD learning has been comprehensively studied recently. However, such a type of convergence has not been well established for off-policy TD learning in the multi-agent setting, which covers broader <span class="search-hit mathjax">applications</span> and is fundamentally more challenging. This work develops two decentralized TD with correction (TDC) algorithms for multi-agent off-policy TD learning under Markovian sampling. In particular, our algorithms preserve full privacy of the actions, policies and rewards of the agents, and adopt mini-batch sampling to <span class="search-hit mathjax">reduce</span> the sampling variance and communication frequency. Under Markovian sampling and linear function approximation, we proved that the finite-<span class="search-hit mathjax">time</span> sample complexity of both algorithms for achieving an $Îµ$-accurate solution is in the order of $\mathcal{O}(Îµ^{-1}\ln Îµ^{-1})$, matching the near-<span class="search-hit mathjax">optimal</span> sample complexity of centralized TD(0) and TDC. Importantly, the communication complexity of our algorithms is in the order of $\mathcal{O}(\ln Îµ^{-1})$, which is significantly lower than the communication complexity $\mathcal{O}(Îµ^{-1}\ln Îµ^{-1})$ of the existing decentralized TD(0). Experiments corroborate our theoretical findings.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.13147v1-abstract-full').style.display = 'none'; document.getElementById('2103.13147v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 24 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">34 pages, 3 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.12874">arXiv:2103.12874</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.12874">pdf</a>, <a href="https://arxiv.org/format/2103.12874">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Information Retrieval">cs.IR</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Using Meta-learning to Recommend Process Discovery Methods
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Barbon%2C+S">Sylvio Barbon Jr</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ceravolo%2C+P">Paolo Ceravolo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Damiani%2C+E">Ernesto Damiani</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tavares%2C+G+M">Gabriel Marques Tavares</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.12874v1-abstract-short" style="display: inline;">
        &hellip;process models to enhance management capabilities. However, selecting the suitable method for a specific event log highly relies on human expertise, hindering its broad <span class="search-hit mathjax">application</span>. Solutions based on Meta-learning (MtL) have been promising for creating systems with <span class="search-hit mathjax">reduced</span> human assistance. This paper presents a MtL s&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.12874v1-abstract-full').style.display = 'inline'; document.getElementById('2103.12874v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.12874v1-abstract-full" style="display: none;">
        Process discovery methods have obtained remarkable achievements in Process Mining, delivering comprehensible process models to enhance management capabilities. However, selecting the suitable method for a specific event log highly relies on human expertise, hindering its broad <span class="search-hit mathjax">application</span>. Solutions based on Meta-learning (MtL) have been promising for creating systems with <span class="search-hit mathjax">reduced</span> human assistance. This paper presents a MtL solution for recommending process discovery methods that maximize model quality according to complementary dimensions. Thanks to our MtL pipeline, it was possible to recommend a discovery method with 92% of accuracy using light-weight features that describe the event log. Our experimental analysis also provided significant insights on the importance of log features in generating recommendations, paving the way to a deeper understanding of the discovery algorithms.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.12874v1-abstract-full').style.display = 'none'; document.getElementById('2103.12874v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 23 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">16 pages, 6 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.12513">arXiv:2103.12513</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.12513">pdf</a>, <a href="https://arxiv.org/format/2103.12513">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        On gray-box modeling for virtual flow metering
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Hotvedt%2C+M">Mathilde Hotvedt</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Grimstad%2C+B">Bjarne Grimstad</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ljungquist%2C+D">Dag Ljungquist</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Imsland%2C+L">Lars Imsland</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.12513v2-abstract-short" style="display: inline;">
        A virtual flow meter (VFM) enables continuous prediction of flow rates in petroleum production systems. The predicted flow rates may aid the daily control and <span class="search-hit mathjax">optimization</span> of a petroleum asset. Gray-box modeling is an approach that combines mechanistic and data-driven modeling. The objective is to create a computationally feasible VFM for use in real-&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.12513v2-abstract-full').style.display = 'inline'; document.getElementById('2103.12513v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.12513v2-abstract-full" style="display: none;">
        A virtual flow meter (VFM) enables continuous prediction of flow rates in petroleum production systems. The predicted flow rates may aid the daily control and <span class="search-hit mathjax">optimization</span> of a petroleum asset. Gray-box modeling is an approach that combines mechanistic and data-driven modeling. The objective is to create a computationally feasible VFM for use in real-<span class="search-hit mathjax">time</span> <span class="search-hit mathjax">applications</span>, with high prediction accuracy and scientifically consistent behavior. This article investigates five different gray-box model types in an industrial case study using real, historical production data from 10 petroleum wells, spanning at most four years of production. The results are diverse with an oil flow rate prediction error in the range of 1.8%-40.6%. Further, the study casts light upon the nontrivial task of balancing learning from both physics and data. Consequently, providing general recommendations towards the suitability of different hybrid models is challenging. Nevertheless, the results are promising and indicate that gray-box VFMs may <span class="search-hit mathjax">reduce</span> the prediction error of a mechanistic VFM while remaining scientifically consistent. The findings motivate further experimentation with gray-box VFM models and suggest several future research directions to <span class="search-hit mathjax">improve</span> upon the performance and scientific consistency.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.12513v2-abstract-full').style.display = 'none'; document.getElementById('2103.12513v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 28 May, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 23 March, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">38 pages, 28 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.12293">arXiv:2103.12293</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.12293">pdf</a>, <a href="https://arxiv.org/format/2103.12293">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Stochastic Reweighted Gradient Descent
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Hanchi%2C+A+E">Ayoub El Hanchi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Stephens%2C+D+A">David A. Stephens</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.12293v1-abstract-short" style="display: inline;">
        Despite the strong theoretical guarantees that variance-<span class="search-hit mathjax">reduced</span> finite-sum&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.12293v1-abstract-full').style.display = 'inline'; document.getElementById('2103.12293v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.12293v1-abstract-full" style="display: none;">
        Despite the strong theoretical guarantees that variance-<span class="search-hit mathjax">reduced</span> finite-sum <span class="search-hit mathjax">optimization</span> algorithms enjoy, their <span class="search-hit mathjax">applicability</span> remains limited to cases where the memory overhead they introduce (SAG/SAGA), or the periodic full gradient computation they require (SVRG/SARAH) are manageable. A promising approach to achieving variance reduction while avoiding these drawbacks is the use of importance sampling instead of control variates. While many such methods have been proposed in the literature, directly proving that they <span class="search-hit mathjax">improve</span> the convergence of the resulting <span class="search-hit mathjax">optimization</span> algorithm has remained elusive. In this work, we propose an importance-sampling-based algorithm we call SRG (stochastic reweighted gradient). We analyze the convergence of SRG in the strongly-convex case and show that, while it does not recover the linear rate of control variates methods, it provably outperforms SGD. We pay particular attention to the <span class="search-hit mathjax">time</span> and memory overhead of our proposed method, and design a specialized red-black tree allowing its efficient implementation. Finally, we present empirical results to support our findings.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.12293v1-abstract-full').style.display = 'none'; document.getElementById('2103.12293v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 23 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.11517">arXiv:2103.11517</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.11517">pdf</a>, <a href="https://arxiv.org/format/2103.11517">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Multiagent Systems">cs.MA</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Dual Monte Carlo Tree Search
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Kadam%2C+P">Prashank Kadam</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xu%2C+R">Ruiyang Xu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lieberherr%2C+K">Karl Lieberherr</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.11517v1-abstract-short" style="display: inline;">
        &hellip;and Monte Carlo Tree Search (MCTS), has successfully trained reinforcement learning agents in a tabula-rasa way. The neural MCTS algorithm has been successful in finding near-<span class="search-hit mathjax">optimal</span> strategies for games through self-play. However, the AlphaZero algorithm has a significant drawback; it takes a long&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.11517v1-abstract-full').style.display = 'inline'; document.getElementById('2103.11517v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.11517v1-abstract-full" style="display: none;">
        AlphaZero, using a combination of Deep Neural Networks and Monte Carlo Tree Search (MCTS), has successfully trained reinforcement learning agents in a tabula-rasa way. The neural MCTS algorithm has been successful in finding near-<span class="search-hit mathjax">optimal</span> strategies for games through self-play. However, the AlphaZero algorithm has a significant drawback; it takes a long <span class="search-hit mathjax">time</span> to converge and requires high computational power due to complex neural networks for solving games like Chess, Go, Shogi, etc. Owing to this, it is very difficult to pursue neural MCTS research without cutting-edge hardware, which is a roadblock for many aspiring neural MCTS researchers. In this paper, we propose a new neural MCTS algorithm, called Dual MCTS, which helps overcome these drawbacks. Dual MCTS uses two different search trees, a single deep neural network, and a new update technique for the search trees using a combination of the PUCB, a sliding-window, and the epsilon-greedy algorithm. This technique is <span class="search-hit mathjax">applicable</span> to any MCTS based algorithm to <span class="search-hit mathjax">reduce</span> the number of updates to the tree. We show that Dual MCTS performs better than one of the most widely used neural MCTS algorithms, AlphaZero, for various symmetric and asymmetric games.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.11517v1-abstract-full').style.display = 'none'; document.getElementById('2103.11517v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 21 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">8 pages, 4 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.11154">arXiv:2103.11154</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.11154">pdf</a>, <a href="https://arxiv.org/format/2103.11154">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Neural and Evolutionary Computing">cs.NE</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Train Deep Neural Networks in 40-D Subspaces
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+T">Tao Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tan%2C+L">Lei Tan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tao%2C+Q">Qinghua Tao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+Y">Yipeng Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Huang%2C+X">Xiaolin Huang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.11154v1-abstract-short" style="display: inline;">
        &hellip;space. By investigating such low-dimensional properties of the training trajectory, we propose a Dynamic Linear Dimensionality Reduction (DLDR), which dramatically <span class="search-hit mathjax">reduces</span> the parameter space to a variable subspace of significantly lower dimension. Since there are only a few variables to&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.11154v1-abstract-full').style.display = 'inline'; document.getElementById('2103.11154v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.11154v1-abstract-full" style="display: none;">
        Although there are massive parameters in deep neural networks, the training can actually proceed in a rather low-dimensional space. By investigating such low-dimensional properties of the training trajectory, we propose a Dynamic Linear Dimensionality Reduction (DLDR), which dramatically <span class="search-hit mathjax">reduces</span> the parameter space to a variable subspace of significantly lower dimension. Since there are only a few variables to <span class="search-hit mathjax">optimize</span>, second-order methods become <span class="search-hit mathjax">applicable</span>. Following this idea, we develop a quasi-Newton-based algorithm to train these variables obtained by DLDR, rather than the original parameters of neural networks. The experimental results strongly support the dimensionality reduction performance: for many standard neural networks, <span class="search-hit mathjax">optimizing</span> over only 40 variables, one can achieve comparable performance against the regular training over thousands or even millions of parameters.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.11154v1-abstract-full').style.display = 'none'; document.getElementById('2103.11154v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 20 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.11137">arXiv:2103.11137</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.11137">pdf</a>, <a href="https://arxiv.org/format/2103.11137">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Databases">cs.DB</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        PathEnum: Towards Real-<span class="search-hit mathjax">Time</span> Hop-Constrained s-t Path Enumeration
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Sun%2C+S">Shixuan Sun</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+Y">Yuhang Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=He%2C+B">Bingsheng He</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hooi%2C+B">Bryan Hooi</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.11137v2-abstract-short" style="display: inline;">
        &hellip;performance issues caused by the costly pruning operations during enumeration for the workloads with the large search space. Consequently, these algorithms hardly meet the real-<span class="search-hit mathjax">time</span> constraints of many online&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.11137v2-abstract-full').style.display = 'inline'; document.getElementById('2103.11137v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.11137v2-abstract-full" style="display: none;">
        We study the hop-constrained s-t path enumeration (HcPE) problem, which takes a graph $G$, two distinct vertices $s,t$ and a hop constraint $k$ as input, and outputs all paths from $s$ to $t$ whose length is at most $k$. The state-of-the-art algorithms suffer from severe performance issues caused by the costly pruning operations during enumeration for the workloads with the large search space. Consequently, these algorithms hardly meet the real-<span class="search-hit mathjax">time</span> constraints of many online <span class="search-hit mathjax">applications</span>. In this paper, we propose PathEnum, an efficient index-based algorithm towards real-<span class="search-hit mathjax">time</span> HcPE. For an input query, PathEnum first builds a light-weight index aiming to <span class="search-hit mathjax">reduce</span> the number of edges involved in the enumeration, and develops efficient index-based approaches for enumeration, one based on depth-first search and the other based on joins. We further develop a query <span class="search-hit mathjax">optimizer</span> based on a join-based cost model to <span class="search-hit mathjax">optimize</span> the search order. We conduct experiments with 15 real-world graphs. Our experiment results show that PathEnum outperforms the state-of-the-art approaches by orders of magnitude in terms of the query <span class="search-hit mathjax">time</span>, throughput and response <span class="search-hit mathjax">time</span>.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.11137v2-abstract-full').style.display = 'none'; document.getElementById('2103.11137v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 23 March, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 20 March, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.10872">arXiv:2103.10872</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.10872">pdf</a>, <a href="https://arxiv.org/format/2103.10872">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computational Engineering, Finance, and Science">cs.CE</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Mathematical Finance">q-fin.MF</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Risk Management">q-fin.RM</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        <span class="search-hit mathjax">Optimal</span> Clearing Payments in a Financial Contagion Model
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Calafiore%2C+G">Giuseppe Calafiore</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fracastoro%2C+G">Giulia Fracastoro</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Proskurnikov%2C+A+V">Anton V. Proskurnikov</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.10872v1-abstract-short" style="display: inline;">
        &hellip;of clearing vector (the vector of the entities&#39; total payments). In this paper, we propose a necessary and sufficient condition for the uniqueness of clearing vector <span class="search-hit mathjax">applicable</span> to an arbitrary topology of the financial network. Further, we show that the overall system loss can be <span class="search-hit mathjax">reduced</span> if one relaxes the pro-rata&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.10872v1-abstract-full').style.display = 'inline'; document.getElementById('2103.10872v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.10872v1-abstract-full" style="display: none;">
        Modern financial networks are characterized by complex structures of mutual obligations. Such interconnections may propagate and amplificate individual defaults, leading in some cases to financial disaster. For this reason, mathematical models for the study and control of systemic risk (the risk of severe instabilities on the system as a whole, due to default of single entities) have attracted considerable research attention in recent years. One important line of research is concerned with mechanisms of clearing, that is, the mechanism by which mutual debts are repaid, in the regular regime, or in a default regime. One of the first models of a clearing mechanism was proposed by Eisenberg and Noe and is based on the three rules: limited liability, the priority of debt claims over the shareholders&#39; interests, and the equal priority of debts (pro-rata rule). These three principles naturally lead to the concept of clearing vector (the vector of the entities&#39; total payments). In this paper, we propose a necessary and sufficient condition for the uniqueness of clearing vector <span class="search-hit mathjax">applicable</span> to an arbitrary topology of the financial network. Further, we show that the overall system loss can be <span class="search-hit mathjax">reduced</span> if one relaxes the pro-rata rule and replaces the clearing vector by a matrix of clearing payments. This approach shifts the focus from the individual interest to the system, or social, interest, in order to control and contain the adverse effects of cascaded failures.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.10872v1-abstract-full').style.display = 'none'; document.getElementById('2103.10872v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 19 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.10381">arXiv:2103.10381</a>
        <span>&nbsp;&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computational Engineering, Finance, and Science">cs.CE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computational Physics">physics.comp-ph</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Data-driven Coarse-grained Modeling of Non-equilibrium Systems
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+S">Shu Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+Z">Zhan Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pan%2C+W">Wenxiao Pan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.10381v2-abstract-short" style="display: inline;">
        Modeling a high-dimensional Hamiltonian system in <span class="search-hit mathjax">reduced</span> dimensions with respect to coarse-grained (CG) variables can greatly&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.10381v2-abstract-full').style.display = 'inline'; document.getElementById('2103.10381v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.10381v2-abstract-full" style="display: none;">
        Modeling a high-dimensional Hamiltonian system in <span class="search-hit mathjax">reduced</span> dimensions with respect to coarse-grained (CG) variables can greatly <span class="search-hit mathjax">reduce</span> computational cost and enable efficient bottom-up prediction of main features of the system for many <span class="search-hit mathjax">applications</span>. However, it usually experiences significantly altered dynamics due to loss of degrees of freedom upon coarse-graining. To establish CG models that can faithfully preserve dynamics, previous efforts mainly focused on equilibrium systems. In contrast, various soft matter systems are known out of equilibrium. Therefore, the present work concerns non-equilibrium systems and enables accurate and efficient CG modeling that preserves non-equilibrium dynamics and is generally <span class="search-hit mathjax">applicable</span> to any non-equilibrium process and any observable of interest. To this end, the dynamic equation of a CG variable is built in the form of the non-stationary generalized Langevin equation (nsGLE) to account for the dependence of non-equilibrium processes on the initial conditions, where the two-<span class="search-hit mathjax">time</span> memory kernel is determined from the data of the two-<span class="search-hit mathjax">time</span> auto-correlation function of the non-equilibrium trajectory-averaged observable of interest. By embedding the non-stationary non-Markovian process in an extended stochastic framework, an explicit form of the non-stationary random noise in the nsGLE is introduced, and the cost is significantly <span class="search-hit mathjax">reduced</span> for solving the nsGLE to predict the non-equilibrium dynamics of the CG variable. To prove and exploit the equivalence of the nsGLE and extended dynamics, the memory kernel is parameterized in a two-<span class="search-hit mathjax">time</span> exponential expansion. A data-driven hybrid <span class="search-hit mathjax">optimization</span> process is proposed for the parameterization, a non-convex and high-dimensional <span class="search-hit mathjax">optimization</span> problem.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.10381v2-abstract-full').style.display = 'none'; document.getElementById('2103.10381v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 18 March, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Large part of this paper needs to be revised</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.10294">arXiv:2103.10294</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.10294">pdf</a>, <a href="https://arxiv.org/format/2103.10294">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Discrete Mathematics">cs.DM</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Learning to Schedule Heuristics in Branch-and-Bound
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Chmiela%2C+A">Antonia Chmiela</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Khalil%2C+E+B">Elias B. Khalil</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gleixner%2C+A">Ambros Gleixner</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lodi%2C+A">Andrea Lodi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pokutta%2C+S">Sebastian Pokutta</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.10294v1-abstract-short" style="display: inline;">
        Primal heuristics play a crucial role in exact solvers for Mixed Integer <span class="search-hit mathjax">Programming</span> (MIP). While solvers are guaranteed to find&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.10294v1-abstract-full').style.display = 'inline'; document.getElementById('2103.10294v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.10294v1-abstract-full" style="display: none;">
        Primal heuristics play a crucial role in exact solvers for Mixed Integer <span class="search-hit mathjax">Programming</span> (MIP). While solvers are guaranteed to find <span class="search-hit mathjax">optimal</span> solutions given sufficient <span class="search-hit mathjax">time</span>, real-world <span class="search-hit mathjax">applications</span> typically require finding good solutions early on in the search to enable <span class="search-hit mathjax">fast</span> decision-making. While much of MIP research focuses on designing effective heuristics, the question of how to manage multiple MIP heuristics in a solver has not received equal attention. Generally, solvers follow hard-<span class="search-hit mathjax">coded</span> rules derived from empirical testing on broad sets of instances. Since the performance of heuristics is instance-dependent, using these general rules for a particular problem might not yield the best performance. In this work, we propose the first data-driven framework for scheduling heuristics in an exact MIP solver. By learning from data describing the performance of primal heuristics, we obtain a problem-specific schedule of heuristics that collectively find many solutions at minimal cost. We provide a formal description of the problem and propose an efficient algorithm for computing such a schedule. Compared to the default settings of a state-of-the-art academic MIP solver, we are able to <span class="search-hit mathjax">reduce</span> the average primal integral by up to 49% on a class of challenging instances.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.10294v1-abstract-full').style.display = 'none'; document.getElementById('2103.10294v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 18 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.09782">arXiv:2103.09782</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.09782">pdf</a>, <a href="https://arxiv.org/format/2103.09782">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Towards <span class="search-hit mathjax">Automated</span> Metamorphic Test Identification for Ocean System Models
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Hiremath%2C+D+J">Dilip Jagadeeshwarswamy Hiremath</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Claus%2C+M">Martin Claus</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hasselbring%2C+W">Wilhelm Hasselbring</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rath%2C+W">Willi Rath</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.09782v1-abstract-short" style="display: inline;">
        Metamorphic testing seeks to verify <span class="search-hit mathjax">software</span> in the absence of test oracles. Our&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.09782v1-abstract-full').style.display = 'inline'; document.getElementById('2103.09782v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.09782v1-abstract-full" style="display: none;">
        Metamorphic testing seeks to verify <span class="search-hit mathjax">software</span> in the absence of test oracles. Our <span class="search-hit mathjax">application</span> domain is ocean system modeling, where test oracles rarely exist, but where symmetries of the simulated physical systems are known. The input data set is large owing to the requirements of the <span class="search-hit mathjax">application</span> domain. This paper presents work in progress for the <span class="search-hit mathjax">automated</span> generation of metamorphic test scenarios using machine learning. We extended our previously proposed method [1] to identify metamorphic relations with <span class="search-hit mathjax">reduced</span> computational complexity. Initially, we represent metamorphic relations as identity maps. We construct a cost function that minimizes for identifying a metamorphic relation orthogonal to previously found metamorphic relations and penalize for the identity map. A machine learning algorithm is used to identify all possible metamorphic relations minimizing the defined cost function. We propose applying dimensionality reduction techniques to identify attributes in the input which have high variance among the identified metamorphic relations. We apply mutation on these selected attributes to identify distinct metamorphic relations with <span class="search-hit mathjax">reduced</span> computational complexity. For experimental evaluation, we subject the two implementations of an ocean-modeling <span class="search-hit mathjax">application</span> to the proposed method to present the use of metamorphic relations to test the two implementations of this <span class="search-hit mathjax">application</span>.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.09782v1-abstract-full').style.display = 'none'; document.getElementById('2103.09782v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">5 Pages, 1 Figure</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        
          <span class="has-text-black-bis has-text-weight-semibold">MSC Class:</span>
          J.2
        

        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.09595">arXiv:2103.09595</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.09595">pdf</a>, <a href="https://arxiv.org/format/2103.09595">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Cryptography and Security">cs.CR</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Assessing Smart Contracts Security Technical Debts
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ahmadjee%2C+S">Sabreen Ahmadjee</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mera-G%C3%B3mez%2C+C">Carlos Mera-GÃ³mez</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bahsoon%2C+R">Rami Bahsoon</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.09595v1-abstract-short" style="display: inline;">
        &hellip;of the identified vulnerabilities leveraging the technical debt metaphor, its principal and interest. We use examples of vulnerable contracts to demonstrate the <span class="search-hit mathjax">applicability</span> of our approach. The results show that our assessment approach increases the visibility of security design issues. It also allows developers to concentrate on resolving smart contract v&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.09595v1-abstract-full').style.display = 'inline'; document.getElementById('2103.09595v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.09595v1-abstract-full" style="display: none;">
        Smart contracts are self-enforcing agreements that are employed to exchange assets without the approval of trusted third parties. This feature has encouraged various sectors to make use of smart contracts when transacting. Experience shows that many deployed contracts are vulnerable to exploitation due to their poor design, which allows attackers to steal valuable assets from the involved parties. Therefore, an assessment approach that allows developers to recognise the consequences of deploying vulnerable contracts is needed. In this paper, we propose a debt-aware approach for assessing security design vulnerabilities in smart contracts. Our assessment approach involves two main steps: (i) identification of design vulnerabilities using security analysis techniques and (ii) an estimation of the ramifications of the identified vulnerabilities leveraging the technical debt metaphor, its principal and interest. We use examples of vulnerable contracts to demonstrate the <span class="search-hit mathjax">applicability</span> of our approach. The results show that our assessment approach increases the visibility of security design issues. It also allows developers to concentrate on resolving smart contract vulnerabilities through technical debt impact analysis and prioritisation. Developers can use our approach to inform the design of more secure contracts and for <span class="search-hit mathjax">reducing</span> unintentional debts caused by a lack of awareness of security issues.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.09595v1-abstract-full').style.display = 'none'; document.getElementById('2103.09595v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.07814">arXiv:2103.07814</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.07814">pdf</a>, <a href="https://arxiv.org/format/2103.07814">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Networking and Internet Architecture">cs.NI</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1145/3448613">10.1145/3448613 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Spatio-Temporal Bayesian Learning for Mobile Edge Computing Resource Planning in Smart Cities
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ale%2C+L">Laha Ale</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+N">Ning Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=King%2C+S+A">Scott A. King</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Guardiola%2C+J">Jose Guardiola</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.07814v1-abstract-short" style="display: inline;">
        A smart city <span class="search-hit mathjax">improves</span> operational efficiency and comfort of living by harnessing techniques such as the Internet of Things (IoT) to collect and process data for decision making. To better support smart cities, data collected by IoT should be stored and processed appropriately. However, IoT devices are often task-specialized and resource-constrained, and thus&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.07814v1-abstract-full').style.display = 'inline'; document.getElementById('2103.07814v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.07814v1-abstract-full" style="display: none;">
        A smart city <span class="search-hit mathjax">improves</span> operational efficiency and comfort of living by harnessing techniques such as the Internet of Things (IoT) to collect and process data for decision making. To better support smart cities, data collected by IoT should be stored and processed appropriately. However, IoT devices are often task-specialized and resource-constrained, and thus, they heavily rely on online resources in terms of computing and storage to accomplish various tasks. Moreover, these cloud-based solutions often centralize the resources and are far away from the end IoTs and cannot respond to users in <span class="search-hit mathjax">time</span> due to network congestion when massive numbers of tasks offload through the core network. Therefore, by decentralizing resources spatially close to IoT devices, mobile edge computing (MEC) can <span class="search-hit mathjax">reduce</span> latency and <span class="search-hit mathjax">improve</span> service quality for a smart city, where service requests can be fulfilled in proximity. As the service demands exhibit spatial-temporal features, deploying MEC servers at <span class="search-hit mathjax">optimal</span> locations and allocating MEC resources play an essential role in efficiently meeting service requirements in a smart city. In this regard, it is essential to learn the distribution of resource demands in <span class="search-hit mathjax">time</span> and space. In this work, we first propose a spatio-temporal Bayesian hierarchical learning approach to learn and predict the distribution of MEC resource demand over space and <span class="search-hit mathjax">time</span> to facilitate MEC deployment and resource management. Second, the proposed model is trained and tested on real-world data, and the results demonstrate that the proposed method can achieve very high accuracy. Third, we demonstrate an <span class="search-hit mathjax">application</span> of the proposed method by simulating task offloading. Finally, the simulated results show that resources allocated based upon our models&#39; predictions are exploited more efficiently than the resources are equally divided into all servers in unobserved areas.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.07814v1-abstract-full').style.display = 'none'; document.getElementById('2103.07814v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 13 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.07286">arXiv:2103.07286</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.07286">pdf</a>, <a href="https://arxiv.org/format/2103.07286">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Integration of Convolutional Neural Networks in Mobile <span class="search-hit mathjax">Applications</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Castanyer%2C+R+C">Roger Creus Castanyer</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mart%C3%ADnez-Fern%C3%A1ndez%2C+S">Silverio MartÃ­nez-FernÃ¡ndez</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Franch%2C+X">Xavier Franch</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.07286v1-abstract-short" style="display: inline;">
        When building Deep Learning (DL) models, data scientists and <span class="search-hit mathjax">software</span> engineers manage the trade-off between their accuracy, or any other suitable success criteria, and their complexity. In an environment with high computational power, a common practice is making the models go deeper by designing more sophisticated architectures. However, in the context of m&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.07286v1-abstract-full').style.display = 'inline'; document.getElementById('2103.07286v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.07286v1-abstract-full" style="display: none;">
        When building Deep Learning (DL) models, data scientists and <span class="search-hit mathjax">software</span> engineers manage the trade-off between their accuracy, or any other suitable success criteria, and their complexity. In an environment with high computational power, a common practice is making the models go deeper by designing more sophisticated architectures. However, in the context of mobile devices, which possess less computational power, keeping complexity under control is a must. In this paper, we study the performance of a system that integrates a DL model as a trade-off between the accuracy and the complexity. At the same <span class="search-hit mathjax">time</span>, we relate the complexity to the efficiency of the system. With this, we present a practical study that aims to explore the challenges met when <span class="search-hit mathjax">optimizing</span> the performance of DL models becomes a requirement. Concretely, we aim to identify: (i) the most concerning challenges when deploying DL-based <span class="search-hit mathjax">software</span> in mobile <span class="search-hit mathjax">applications</span>; and (ii) the path for <span class="search-hit mathjax">optimizing</span> the performance trade-off. We obtain results that verify many of the identified challenges in the related work such as the availability of frameworks and the <span class="search-hit mathjax">software</span>-data dependency. We provide a documentation of our experience when facing the identified challenges together with the discussion of possible solutions to them. Additionally, we implement a solution to the sustainability of the DL models when deployed in order to <span class="search-hit mathjax">reduce</span> the severity of other identified challenges. Moreover, we relate the performance trade-off to a new defined challenge featuring the impact of the complexity in the obtained accuracy. Finally, we discuss and motivate future work that aims to provide solutions to the more open challenges found.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.07286v1-abstract-full').style.display = 'none'; document.getElementById('2103.07286v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 11 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Pre-print. Accepted and to be published in WAIN@ICSE 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.06757">arXiv:2103.06757</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.06757">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Programming Languages">cs.PL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Auto-COP: Adaptation Generation in Context-Oriented <span class="search-hit mathjax">Programming</span> using Reinforcement Learning Options
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Cardozo%2C+N">NicolÃ¡s Cardozo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dusparic%2C+I">Ivana Dusparic</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.06757v1-abstract-short" style="display: inline;">
        Self-adaptive <span class="search-hit mathjax">software</span> systems continuously adapt in response to internal and external changes in their execution environment, captured as contexts. The COP paradigm posits a technique for the development of self-adaptive systems, capturing their main characteristics with specialized&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.06757v1-abstract-full').style.display = 'inline'; document.getElementById('2103.06757v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.06757v1-abstract-full" style="display: none;">
        Self-adaptive <span class="search-hit mathjax">software</span> systems continuously adapt in response to internal and external changes in their execution environment, captured as contexts. The COP paradigm posits a technique for the development of self-adaptive systems, capturing their main characteristics with specialized <span class="search-hit mathjax">programming</span> language constructs. COP adaptations are specified as independent modules composed in and out of the base system as contexts are activated and deactivated in response to sensed circumstances from the surrounding environment. However, the definition of adaptations, their contexts and associated specialized behavior, need to be specified at design <span class="search-hit mathjax">time</span>. In complex CPS this is intractable due to new unpredicted operating conditions. We propose Auto-COP, a new technique to enable generation of adaptations at run <span class="search-hit mathjax">time</span>. Auto-COP uses RL options to build action sequences, based on the previous instances of the system execution. Options are explored in interaction with the environment, and the most suitable options for each context are used to generate adaptations exploiting COP. To validate Auto-COP, we present two case studies exhibiting different system characteristics and <span class="search-hit mathjax">application</span> domains: a driving assistant and a robot delivery system. We present examples of Auto-COP <span class="search-hit mathjax">code</span> generated at run <span class="search-hit mathjax">time</span>, to illustrate the types of circumstances (contexts) requiring adaptation, and the corresponding generated adaptations for each context. We confirm that the generated adaptations exhibit correct system behavior measured by domain-specific performance metrics, while <span class="search-hit mathjax">reducing</span> the number of required execution/actuation steps by a factor of two showing that the adaptations are regularly selected by the running system as adaptive behavior is more appropriate than the execution of primitive actions.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.06757v1-abstract-full').style.display = 'none'; document.getElementById('2103.06757v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 11 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Submitted to The Art, Science, and Engineering of Programming Journal. 22 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.05331">arXiv:2103.05331</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.05331">pdf</a>, <a href="https://arxiv.org/format/2103.05331">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Active Testing: Sample-Efficient Model Evaluation
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Kossen%2C+J">Jannik Kossen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farquhar%2C+S">Sebastian Farquhar</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gal%2C+Y">Yarin Gal</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rainforth%2C+T">Tom Rainforth</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.05331v2-abstract-short" style="display: inline;">
        We introduce a new framework for sample-efficient model evaluation that we call active testing. While approaches like active learning <span class="search-hit mathjax">reduce</span> the number of labels needed for model training, existing literature largely ignores the cost of labeling test data, typically unrealistically assuming large test sets for model evaluation. This creates a disconnect to r&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.05331v2-abstract-full').style.display = 'inline'; document.getElementById('2103.05331v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.05331v2-abstract-full" style="display: none;">
        We introduce a new framework for sample-efficient model evaluation that we call active testing. While approaches like active learning <span class="search-hit mathjax">reduce</span> the number of labels needed for model training, existing literature largely ignores the cost of labeling test data, typically unrealistically assuming large test sets for model evaluation. This creates a disconnect to real <span class="search-hit mathjax">applications</span>, where test labels are important and just as expensive, e.g. for <span class="search-hit mathjax">optimizing</span> hyperparameters. Active testing addresses this by carefully selecting the test points to label, ensuring model evaluation is sample-efficient. To this end, we derive theoretically-grounded and intuitive acquisition strategies that are specifically tailored to the goals of active testing, noting these are distinct to those of active learning. As actively selecting labels introduces a bias; we further show how to remove this bias while <span class="search-hit mathjax">reducing</span> the variance of the estimator at the same <span class="search-hit mathjax">time</span>. Active testing is easy to implement and can be applied to any supervised machine learning method. We demonstrate its effectiveness on models including WideResNets and Gaussian processes on datasets including Fashion-MNIST and CIFAR-100.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.05331v2-abstract-full').style.display = 'none'; document.getElementById('2103.05331v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 June, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 9 March, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Published at the 38th International Conference on Machine Learning (ICML 2021)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.05244">arXiv:2103.05244</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.05244">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Mathematical Software">cs.MS</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Symbolic Computation">cs.SC</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        ModelingToolkit: A Composable Graph Transformation System For Equation-Based Modeling
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+Y">Yingbo Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gowda%2C+S">Shashi Gowda</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Anantharaman%2C+R">Ranjan Anantharaman</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Laughman%2C+C">Chris Laughman</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shah%2C+V">Viral Shah</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rackauckas%2C+C">Chris Rackauckas</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.05244v2-abstract-short" style="display: inline;">
        &hellip;out of numerical equation solvers requires that the user has provided stable and efficient functions representing their model. However, users should not be trusted to write good <span class="search-hit mathjax">code</span>. In this manuscript we describe ModelingToolkit (MTK), a symbolic equation-based modeling system which allows for composable transformations to generate stable, efficient, and p&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.05244v2-abstract-full').style.display = 'inline'; document.getElementById('2103.05244v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.05244v2-abstract-full" style="display: none;">
        Getting good performance out of numerical equation solvers requires that the user has provided stable and efficient functions representing their model. However, users should not be trusted to write good <span class="search-hit mathjax">code</span>. In this manuscript we describe ModelingToolkit (MTK), a symbolic equation-based modeling system which allows for composable transformations to generate stable, efficient, and parallelized model implementations. MTK blurs the lines of traditional symbolic computing by acting directly on a user&#39;s numerical <span class="search-hit mathjax">code</span>. We show the ability to apply graph algorithms for <span class="search-hit mathjax">automatically</span> parallelizing and performing index reduction on <span class="search-hit mathjax">code</span> written for differential-algebraic equation (DAE) solvers, &#34;fixing&#34; the performance and stability of the model without requiring any changes to on the user&#39;s part. We demonstrate how composable model transformations can be combined with <span class="search-hit mathjax">automated</span> data-driven surrogate generation techniques, allowing machine learning methods to generate accelerated approximate models within an acausal modeling framework. These <span class="search-hit mathjax">reduced</span> models are shown to outperform the Dymola Modelica compiler on an HVAC model by 590x at 3\% error. Together, this demonstrates MTK as a system for bringing the latest research in graph transformations directly to modeling <span class="search-hit mathjax">applications</span>.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.05244v2-abstract-full').style.display = 'none'; document.getElementById('2103.05244v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 24 March, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 9 March, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">10 pages, 3 figures, 1 table</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.04674">arXiv:2103.04674</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.04674">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Structural Coupling for Microservices
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Panichella%2C+S">Sebastiano Panichella</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rahman%2C+M+I">Mohammad Imranur Rahman</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Taibi%2C+D">Davide Taibi</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.04674v1-abstract-short" style="display: inline;">
        Cloud-native <span class="search-hit mathjax">Applications</span> are &#39;distributed, elastic and horizontal-scalable systems composed of (micro)services which isolate states in a minimum of stateful components&#39;. Hence, an important property is to ensure a low coupling and a high cohesion among the (micro)services composing the cloud-native&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.04674v1-abstract-full').style.display = 'inline'; document.getElementById('2103.04674v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.04674v1-abstract-full" style="display: none;">
        Cloud-native <span class="search-hit mathjax">Applications</span> are &#39;distributed, elastic and horizontal-scalable systems composed of (micro)services which isolate states in a minimum of stateful components&#39;. Hence, an important property is to ensure a low coupling and a high cohesion among the (micro)services composing the cloud-native <span class="search-hit mathjax">application</span>. Loosely coupled and highly cohesive services allow development teams to work in parallel, <span class="search-hit mathjax">reducing</span> the communication overhead between teams. However, despite both practitioners and researchers agree on the importance of this general property, there are no validated metrics to effectively measure or test the actual coupling level between services. In this work, we propose ways to compute and visualize the coupling between microservices, by extending and adapting the concepts behind the computation of the traditional structural coupling. We validate these measures with a case study involving 17 open-source projects and we provide an <span class="search-hit mathjax">automatic</span> approach to measure them. The results of this study highlight how these metrics provide to practitioners a quantitative and visual view of services compositions, which can be useful to conceive advanced systems to monitor the evolution of the service.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.04674v1-abstract-full').style.display = 'none'; document.getElementById('2103.04674v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">11th International Conference on Cloud Computing and Services Science, CLOSER 2021</span>
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        11th International Conference on Cloud Computing and Services Science, CLOSER 2021
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.04303">arXiv:2103.04303</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.04303">pdf</a>, <a href="https://arxiv.org/format/2103.04303">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Networking and Internet Architecture">cs.NI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Joint <span class="search-hit mathjax">Coding</span> and Scheduling <span class="search-hit mathjax">Optimization</span> for Distributed Learning over Wireless Edge Networks
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Van+Huynh%2C+N">Nguyen Van Huynh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hoang%2C+D+T">Dinh Thai Hoang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Nguyen%2C+D+N">Diep N. Nguyen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dutkiewicz%2C+E">Eryk Dutkiewicz</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.04303v2-abstract-short" style="display: inline;">
        &hellip;or even inapplicable under the highly dynamic wireless edge networks (e.g., using mmW interfaces). This article addresses these problems by leveraging recent advances in <span class="search-hit mathjax">coded</span> computing and the deep dueling neural network architecture. By introducing&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.04303v2-abstract-full').style.display = 'inline'; document.getElementById('2103.04303v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.04303v2-abstract-full" style="display: none;">
        Unlike theoretical distributed learning (DL), DL over wireless edge networks faces the inherent dynamics/uncertainty of wireless connections and edge nodes, making DL less efficient or even inapplicable under the highly dynamic wireless edge networks (e.g., using mmW interfaces). This article addresses these problems by leveraging recent advances in <span class="search-hit mathjax">coded</span> computing and the deep dueling neural network architecture. By introducing <span class="search-hit mathjax">coded</span> structures/redundancy, a distributed learning task can be completed without waiting for straggling nodes. Unlike conventional <span class="search-hit mathjax">coded</span> computing that only <span class="search-hit mathjax">optimizes</span> the <span class="search-hit mathjax">code</span> structure, <span class="search-hit mathjax">coded</span> distributed learning over the wireless edge also requires to <span class="search-hit mathjax">optimize</span> the selection/scheduling of wireless edge nodes with heterogeneous connections, computing capability, and straggling effects. However, even neglecting the aforementioned dynamics/uncertainty, the resulting joint <span class="search-hit mathjax">optimization</span> of <span class="search-hit mathjax">coding</span> and scheduling to minimize the distributed learning <span class="search-hit mathjax">time</span> turns out to be NP-hard. To tackle this and to account for the dynamics and uncertainty of wireless connections and edge nodes, we reformulate the problem as a Markov Decision Process and then design a novel deep reinforcement learning algorithm that employs the deep dueling neural network architecture to find the jointly <span class="search-hit mathjax">optimal</span> <span class="search-hit mathjax">coding</span> scheme and the best set of edge nodes for different learning tasks without explicit information about the wireless environment and edge nodes&#39; straggling parameters. Simulations show that the proposed framework <span class="search-hit mathjax">reduces</span> the average learning delay in wireless edge computing up to 66% compared with other DL approaches. The jointly <span class="search-hit mathjax">optimal</span> framework in this article is also <span class="search-hit mathjax">applicable</span> to any distributed learning scheme with heterogeneous and uncertain computing nodes.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.04303v2-abstract-full').style.display = 'none'; document.getElementById('2103.04303v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 March, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 7 March, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.03239">arXiv:2103.03239</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.03239">pdf</a>, <a href="https://arxiv.org/format/2103.03239">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Moshpit SGD: Communication-Efficient Decentralized Training on Heterogeneous Unreliable Devices
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ryabinin%2C+M">Max Ryabinin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gorbunov%2C+E">Eduard Gorbunov</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Plokhotnyuk%2C+V">Vsevolod Plokhotnyuk</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pekhimenko%2C+G">Gennady Pekhimenko</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.03239v1-abstract-short" style="display: inline;">
        &hellip;by using multiple compute nodes. This approach, known as distributed training, can utilize hundreds of computers via specialized message-passing protocols such as Ring All-<span class="search-hit mathjax">Reduce</span>. However, running these protocols at scale requires reliable high-&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.03239v1-abstract-full').style.display = 'inline'; document.getElementById('2103.03239v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.03239v1-abstract-full" style="display: none;">
        Training deep neural networks on large datasets can often be accelerated by using multiple compute nodes. This approach, known as distributed training, can utilize hundreds of computers via specialized message-passing protocols such as Ring All-<span class="search-hit mathjax">Reduce</span>. However, running these protocols at scale requires reliable high-<span class="search-hit mathjax">speed</span> networking that is only available in dedicated clusters. In contrast, many real-world <span class="search-hit mathjax">applications</span>, such as federated learning and cloud-based distributed training, operate on unreliable devices with unstable network bandwidth. As a result, these <span class="search-hit mathjax">applications</span> are restricted to using parameter servers or gossip-based averaging protocols. In this work, we lift that restriction by proposing Moshpit All-<span class="search-hit mathjax">Reduce</span> -- an iterative averaging protocol that exponentially converges to the global average. We demonstrate the efficiency of our protocol for distributed <span class="search-hit mathjax">optimization</span> with strong theoretical guarantees. The experiments show 1.3x <span class="search-hit mathjax">speedup</span> for ResNet-50 training on ImageNet compared to competitive gossip-based strategies and 1.5x <span class="search-hit mathjax">speedup</span> when training ALBERT-large from scratch using preemptible compute nodes.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.03239v1-abstract-full').style.display = 'none'; document.getElementById('2103.03239v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 4 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">41 pages, 6 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.01516">arXiv:2103.01516</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.01516">pdf</a>, <a href="https://arxiv.org/ps/2103.01516">ps</a>, <a href="https://arxiv.org/format/2103.01516">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Cryptography and Security">cs.CR</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Private Stochastic Convex <span class="search-hit mathjax">Optimization</span>: <span class="search-hit mathjax">Optimal</span> Rates in $\ell_1$ Geometry
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Asi%2C+H">Hilal Asi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Feldman%2C+V">Vitaly Feldman</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Koren%2C+T">Tomer Koren</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Talwar%2C+K">Kunal Talwar</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.01516v1-abstract-short" style="display: inline;">
        Stochastic convex <span class="search-hit mathjax">optimization</span> over an $\ell_1$-bounded domain is ubiquitous in machine learning <span class="search-hit mathjax">applications</span> such as LASSO but remains poorly understood when learning with differential privacy. We show that, up to logarithmic factors the <span class="search-hit mathjax">optimal</span> excess population loss of any&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.01516v1-abstract-full').style.display = 'inline'; document.getElementById('2103.01516v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.01516v1-abstract-full" style="display: none;">
        Stochastic convex <span class="search-hit mathjax">optimization</span> over an $\ell_1$-bounded domain is ubiquitous in machine learning <span class="search-hit mathjax">applications</span> such as LASSO but remains poorly understood when learning with differential privacy. We show that, up to logarithmic factors the <span class="search-hit mathjax">optimal</span> excess population loss of any $(\varepsilon,Î´)$-differentially private <span class="search-hit mathjax">optimizer</span> is $\sqrt{\log(d)/n} + \sqrt{d}/\varepsilon n.$ The upper bound is based on a new algorithm that combines the iterative localization approach of~\citet{FeldmanKoTa20} with a new analysis of private regularized mirror descent. It applies to $\ell_p$ bounded domains for $p\in [1,2]$ and queries at most $n^{3/2}$ gradients <span class="search-hit mathjax">improving</span> over the best previously known algorithm for the $\ell_2$ case which needs $n^2$ gradients. Further, we show that when the loss functions satisfy additional smoothness assumptions, the excess loss is upper bounded (up to logarithmic factors) by $\sqrt{\log(d)/n} + (\log(d)/\varepsilon n)^{2/3}.$ This bound is achieved by a new variance-<span class="search-hit mathjax">reduced</span> version of the Frank-Wolfe algorithm that requires just a single pass over the data. We also show that the lower bound in this case is the minimum of the two rates mentioned above.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.01516v1-abstract-full').style.display = 'none'; document.getElementById('2103.01516v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 2 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.01447">arXiv:2103.01447</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.01447">pdf</a>, <a href="https://arxiv.org/format/2103.01447">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        ZeroSARAH: Efficient Nonconvex Finite-Sum <span class="search-hit mathjax">Optimization</span> with Zero Full Gradient Computation
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+Z">Zhize Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Richt%C3%A1rik%2C+P">Peter RichtÃ¡rik</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.01447v1-abstract-short" style="display: inline;">
        We propose ZeroSARAH -- a novel variant of the variance-<span class="search-hit mathjax">reduced</span> method SARAH (Nguyen et al., 2017) -- for minimizing the average of a large number of nonconvex functions $\frac{1}{n}\sum_{i=1}^{n}f_i(x)$. To the best of our knowledge, in this nonconvex finite-sum regime, all existing variance-<span class="search-hit mathjax">reduced</span> methods, including&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.01447v1-abstract-full').style.display = 'inline'; document.getElementById('2103.01447v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.01447v1-abstract-full" style="display: none;">
        We propose ZeroSARAH -- a novel variant of the variance-<span class="search-hit mathjax">reduced</span> method SARAH (Nguyen et al., 2017) -- for minimizing the average of a large number of nonconvex functions $\frac{1}{n}\sum_{i=1}^{n}f_i(x)$. To the best of our knowledge, in this nonconvex finite-sum regime, all existing variance-<span class="search-hit mathjax">reduced</span> methods, including SARAH, SVRG, SAGA and their variants, need to compute the full gradient over all $n$ data samples at the initial point $x^0$, and then periodically compute the full gradient once every few iterations (for SVRG, SARAH and their variants). Moreover, SVRG, SAGA and their variants typically achieve weaker convergence results than variants of SARAH: $n^{2/3}/Îµ^2$ vs. $n^{1/2}/Îµ^2$. ZeroSARAH is the first variance-<span class="search-hit mathjax">reduced</span> method which does not require any full gradient computations, not even for the initial point. Moreover, ZeroSARAH obtains new state-of-the-art convergence results, which can <span class="search-hit mathjax">improve</span> the previous best-known result (given by e.g., SPIDER, SpiderBoost, SARAH, SSRGD and PAGE) in certain regimes. Avoiding any full gradient computations (which is a <span class="search-hit mathjax">time</span>-consuming step) is important in many <span class="search-hit mathjax">applications</span> as the number of data samples $n$ usually is very large. Especially in the distributed setting, periodic computation of full gradient over all data samples needs to periodically synchronize all machines/devices, which may be impossible or very hard to achieve. Thus, we expect that ZeroSARAH will have a practical impact in distributed and federated learning where full device participation is impractical.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.01447v1-abstract-full').style.display = 'none'; document.getElementById('2103.01447v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 1 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.01314">arXiv:2103.01314</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.01314">pdf</a>, <a href="https://arxiv.org/format/2103.01314">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Networking and Internet Architecture">cs.NI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        SWP: Microsecond Network SLOs Without Priorities
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zhao%2C+K">Kevin Zhao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Goyal%2C+P">Prateesh Goyal</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Alizadeh%2C+M">Mohammad Alizadeh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Anderson%2C+T+E">Thomas E. Anderson</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.01314v2-abstract-short" style="display: inline;">
        The increasing use of cloud computing for latency-sensitive <span class="search-hit mathjax">applications</span> has sparked renewed interest in providing tight bounds on network tail latency. Achieving this in practice at reasonable network utilization has proved elusive, due to a combination of highly bursty&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.01314v2-abstract-full').style.display = 'inline'; document.getElementById('2103.01314v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.01314v2-abstract-full" style="display: none;">
        The increasing use of cloud computing for latency-sensitive <span class="search-hit mathjax">applications</span> has sparked renewed interest in providing tight bounds on network tail latency. Achieving this in practice at reasonable network utilization has proved elusive, due to a combination of highly bursty <span class="search-hit mathjax">application</span> demand, <span class="search-hit mathjax">faster</span> link <span class="search-hit mathjax">speeds</span>, and heavy-tailed message sizes. While priority scheduling can be used to <span class="search-hit mathjax">reduce</span> tail latency for some traffic, this comes at a cost of much worse delay behavior for all other traffic on the network. Most operators choose to run their networks at very low average utilization, despite the added cost, and yet still suffer poor tail behavior.
  This paper takes a different approach. We build a system, swp, to help operators (and network designers) to understand and control tail latency without relying on priority scheduling. As network workload changes, swp is designed to give real-<span class="search-hit mathjax">time</span> advice on the network switch configurations needed to maintain tail latency objectives for each traffic class. The core of swp is an efficient model for simulating the combined effect of traffic characteristics, end-to-end congestion control, and switch scheduling on service-level objectives (SLOs), along with an <span class="search-hit mathjax">optimizer</span> that adjusts switch-level scheduling weights assigned to each class. Using simulation across a diverse set of workloads with different SLOs, we show that to meet the same SLOs as swp provides, FIFO would require 65% greater link capacity, and 79% more for scenarios with tight SLOs on bursty traffic classes.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.01314v2-abstract-full').style.display = 'none'; document.getElementById('2103.01314v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 2 March, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 1 March, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.00025">arXiv:2103.00025</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.00025">pdf</a>, <a href="https://arxiv.org/ps/2103.00025">ps</a>, <a href="https://arxiv.org/format/2103.00025">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        TEC: Tensor Ensemble Classifier for Big Data
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+P">Peide Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Karim%2C+R">Rejaul Karim</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Maiti%2C+T">Tapabrata Maiti</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.00025v1-abstract-short" style="display: inline;">
        Tensor (multidimensional array) classification problem has become very popular in modern <span class="search-hit mathjax">applications</span> such as image recognition and high dimensional spatio-temporal data analysis. Support Tensor Machine (STM) classifier, which is extended from the support vector machine, takes CANDECOMP / Parafac (CP) form of tensor data as input and predicts the data labels&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.00025v1-abstract-full').style.display = 'inline'; document.getElementById('2103.00025v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.00025v1-abstract-full" style="display: none;">
        Tensor (multidimensional array) classification problem has become very popular in modern <span class="search-hit mathjax">applications</span> such as image recognition and high dimensional spatio-temporal data analysis. Support Tensor Machine (STM) classifier, which is extended from the support vector machine, takes CANDECOMP / Parafac (CP) form of tensor data as input and predicts the data labels. The distribution-free and statistically consistent properties of STM highlight its potential in successfully handling wide varieties of data <span class="search-hit mathjax">applications</span>. Training a STM can be computationally expensive with high-dimensional tensors. However, <span class="search-hit mathjax">reducing</span> the size of tensor with a random projection technique can <span class="search-hit mathjax">reduce</span> the computational <span class="search-hit mathjax">time</span> and cost, making it feasible to handle large size tensors on regular machines. We name an STM estimated with randomly projected tensor as Random Projection-based Support Tensor Machine (RPSTM). In this work, we propose a Tensor Ensemble Classifier (TEC), which aggregates multiple RPSTMs for big tensor classification. TEC utilizes the ensemble idea to minimize the excessive classification risk brought by random projection, providing statistically consistent predictions while taking the computational advantage of RPSTM. Since each RPSTM can be estimated independently, TEC can further take advantage of parallel computing techniques and be more computationally efficient. The theoretical and numerical results demonstrate the decent performance of TEC model in high-dimensional tensor classification problems. The model prediction is statistically consistent as its risk is shown to converge to the <span class="search-hit mathjax">optimal</span> Bayes risk. Besides, we highlight the trade-off between the computational cost and the prediction risk for TEC model. The method is validated by extensive simulation and a real data example. We prepare a python package for applying TEC, which is available at our GitHub.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.00025v1-abstract-full').style.display = 'none'; document.getElementById('2103.00025v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 26 February, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.13403">arXiv:2102.13403</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.13403">pdf</a>, <a href="https://arxiv.org/format/2102.13403">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Numerical Analysis">math.NA</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Multi-fidelity regression using artificial neural networks: efficient approximation of parameter-dependent output quantities
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Guo%2C+M">Mengwu Guo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Manzoni%2C+A">Andrea Manzoni</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Amendt%2C+M">Maurice Amendt</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Conti%2C+P">Paolo Conti</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hesthaven%2C+J+S">Jan S. Hesthaven</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.13403v1-abstract-short" style="display: inline;">
        Highly accurate numerical or physical experiments are often <span class="search-hit mathjax">time</span>-consuming or expensive to obtain. When&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.13403v1-abstract-full').style.display = 'inline'; document.getElementById('2102.13403v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.13403v1-abstract-full" style="display: none;">
        Highly accurate numerical or physical experiments are often <span class="search-hit mathjax">time</span>-consuming or expensive to obtain. When <span class="search-hit mathjax">time</span> or budget restrictions prohibit the generation of additional data, the amount of available samples may be too limited to provide satisfactory model results. Multi-fidelity methods deal with such problems by incorporating information from other sources, which are ideally well-correlated with the high-fidelity data, but can be obtained at a lower cost. By leveraging correlations between different data sets, multi-fidelity methods often yield superior generalization when compared to models based solely on a small amount of high-fidelity data. In this work, we present the use of artificial neural networks applied to multi-fidelity regression problems. By elaborating a few existing approaches, we propose new neural network architectures for multi-fidelity regression. The introduced models are compared against a traditional multi-fidelity scheme, co-kriging. A collection of artificial benchmarks are presented to measure the performance of the analyzed models. The results show that cross-validation in combination with Bayesian <span class="search-hit mathjax">optimization</span> consistently leads to neural network models that outperform the co-kriging scheme. Additionally, we show an <span class="search-hit mathjax">application</span> of multi-fidelity regression to an engineering problem. The propagation of a pressure wave into an acoustic horn with parametrized shape and frequency is considered, and the index of reflection intensity is approximated using the multi-fidelity models. A finite element model and a <span class="search-hit mathjax">reduced</span> basis model are adopted as the high- and low-fidelity, respectively. It is shown that the multi-fidelity neural network returns outputs that achieve a comparable accuracy to those from the expensive, full-order model, using only very few full-order evaluations combined with a larger amount of inaccurate but cheap evaluations of a <span class="search-hit mathjax">reduced</span> order model.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.13403v1-abstract-full').style.display = 'none'; document.getElementById('2102.13403v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 26 February, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.12540">arXiv:2102.12540</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.12540">pdf</a>, <a href="https://arxiv.org/format/2102.12540">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Networking and Internet Architecture">cs.NI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Quantum Annealing for Large MIMO Downlink Vector Perturbation Precoding
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Kasi%2C+S">Srikar Kasi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Singh%2C+A+K">Abhishek Kumar Singh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Venturelli%2C+D">Davide Venturelli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jamieson%2C+K">Kyle Jamieson</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.12540v1-abstract-short" style="display: inline;">
        &hellip;Perturbation Precoding (VPP) is a non-linear variant of transmit-side channel inversion that perturbs user data to achieve full diversity order. While promising, finding an <span class="search-hit mathjax">optimal</span> perturbation in VPP is known to be an NP-hard problem, demanding heavy computational support at the base station and limiting the feasibility of the approach to small MIMO systems&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.12540v1-abstract-full').style.display = 'inline'; document.getElementById('2102.12540v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.12540v1-abstract-full" style="display: none;">
        In a multi-user system with multiple antennas at the base station, precoding techniques in the downlink broadcast channel allow users to detect their respective data in a non-cooperative manner. Vector Perturbation Precoding (VPP) is a non-linear variant of transmit-side channel inversion that perturbs user data to achieve full diversity order. While promising, finding an <span class="search-hit mathjax">optimal</span> perturbation in VPP is known to be an NP-hard problem, demanding heavy computational support at the base station and limiting the feasibility of the approach to small MIMO systems. This work proposes a radically different processing architecture for the downlink VPP problem, one based on Quantum Annealing (QA), to enable the <span class="search-hit mathjax">applicability</span> of VPP to large MIMO systems. Our design <span class="search-hit mathjax">reduces</span> VPP to a quadratic polynomial form amenable to QA, then refines the problem coefficients to mitigate the adverse effects of QA hardware noise. We evaluate our proposed QA based VPP (QAVP) technique on a real Quantum Annealing device over a variety of design and machine parameter settings. With existing hardware, QAVP can achieve a BER of $10^{-4}$ with 100$Î¼$s compute <span class="search-hit mathjax">time</span>, for a 6<span class="search-hit mathjax">$\times$</span>6 MIMO system using 64 QAM modulation at 32 dB SNR.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.12540v1-abstract-full').style.display = 'none'; document.getElementById('2102.12540v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 24 February, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted article to appear in the proceedings of IEEE ICC 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.12086">arXiv:2102.12086</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.12086">pdf</a>, <a href="https://arxiv.org/format/2102.12086">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Dynamical Systems">math.DS</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Modern Koopman Theory for Dynamical Systems
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Brunton%2C+S+L">Steven L. Brunton</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Budi%C5%A1i%C4%87%2C+M">Marko BudiÅ¡iÄ</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kaiser%2C+E">Eurika Kaiser</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kutz%2C+J+N">J. Nathan Kutz</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.12086v1-abstract-short" style="display: inline;">
        &hellip;big-data and machine learning techniques, and 3) simple, yet powerful numerical algorithms, such as the dynamic mode decomposition (DMD), have been developed and extended to <span class="search-hit mathjax">reduce</span> Koopman theory to practice in real-world&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.12086v1-abstract-full').style.display = 'inline'; document.getElementById('2102.12086v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.12086v1-abstract-full" style="display: none;">
        The field of dynamical systems is being transformed by the mathematical tools and algorithms emerging from modern computing and data science. First-principles derivations and asymptotic reductions are giving way to data-driven approaches that formulate models in operator theoretic or probabilistic frameworks. Koopman spectral theory has emerged as a dominant perspective over the past decade, in which nonlinear dynamics are represented in terms of an infinite-dimensional linear operator acting on the space of all possible measurement functions of the system. This linear representation of nonlinear dynamics has tremendous potential to enable the prediction, estimation, and control of nonlinear systems with standard textbook methods developed for linear systems. However, obtaining finite-dimensional coordinate systems and embeddings in which the dynamics appear approximately linear remains a central open challenge. The success of Koopman analysis is due primarily to three key factors: 1) there exists rigorous theory connecting it to classical geometric approaches for dynamical systems, 2) the approach is formulated in terms of measurements, making it ideal for leveraging big-data and machine learning techniques, and 3) simple, yet powerful numerical algorithms, such as the dynamic mode decomposition (DMD), have been developed and extended to <span class="search-hit mathjax">reduce</span> Koopman theory to practice in real-world <span class="search-hit mathjax">applications</span>. In this review, we provide an overview of modern Koopman operator theory, describing recent theoretical and algorithmic developments and highlighting these methods with a diverse range of <span class="search-hit mathjax">applications</span>. We also discuss key advances and challenges in the rapidly growing field of machine learning that are likely to drive future developments and significantly transform the theoretical landscape of dynamical systems.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.12086v1-abstract-full').style.display = 'none'; document.getElementById('2102.12086v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 24 February, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">96 pages, 27 figures</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        
          <span class="has-text-black-bis has-text-weight-semibold">MSC Class:</span>
          34A34; 37A30; 37C10; 37M10; 37M99; 37N35; 47A35; 47B33
        

        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.12081">arXiv:2102.12081</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.12081">pdf</a>, <a href="https://arxiv.org/format/2102.12081">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Networking and Internet Architecture">cs.NI</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1109/TrustCom50675.2020.00134">10.1109/TrustCom50675.2020.00134 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A Computation Offloading Model over Collaborative Cloud-Edge Networks with <span class="search-hit mathjax">Optimal</span> Transport Theory
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+Z">Zhuo Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhou%2C+X">Xu Zhou</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+Y">Yang Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fan%2C+C">Congshan Fan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+W">Wei Wang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.12081v1-abstract-short" style="display: inline;">
        As novel <span class="search-hit mathjax">applications</span> spring up in future network scenarios, the requirements on network service capabilities for differentiated services or burst services are diverse. Aiming at the research of collaborative computing and resource allocation in edge scenarios, migrating computing tasks to the edge and cloud for computing requires a comprehensive considerati&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.12081v1-abstract-full').style.display = 'inline'; document.getElementById('2102.12081v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.12081v1-abstract-full" style="display: none;">
        As novel <span class="search-hit mathjax">applications</span> spring up in future network scenarios, the requirements on network service capabilities for differentiated services or burst services are diverse. Aiming at the research of collaborative computing and resource allocation in edge scenarios, migrating computing tasks to the edge and cloud for computing requires a comprehensive consideration of energy consumption, bandwidth, and delay. Our paper proposes a collaboration mechanism based on computation offloading, which is flexible and customizable to meet the diversified requirements of differentiated networks. This mechanism handles the terminal&#39;s differentiated computing tasks by establishing a collaborative computation offloading model between the cloud server and edge server. Experiments show that our method has more significant <span class="search-hit mathjax">improvements</span> over regular <span class="search-hit mathjax">optimization</span> algorithms, including <span class="search-hit mathjax">reducing</span> the execution <span class="search-hit mathjax">time</span> of computing tasks, <span class="search-hit mathjax">improving</span> the utilization of server resources, and decreasing the terminal&#39;s energy consumption.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.12081v1-abstract-full').style.display = 'none'; document.getElementById('2102.12081v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 24 February, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        2020 IEEE 19th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.12071">arXiv:2102.12071</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.12071">pdf</a>, <a href="https://arxiv.org/format/2102.12071">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Numerical Analysis">math.NA</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Learning <span class="search-hit mathjax">optimal</span> multigrid smoothers via neural networks
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Huang%2C+R">Ru Huang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+R">Ruipeng Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xi%2C+Y">Yuanzhe Xi</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.12071v2-abstract-short" style="display: inline;">
        &hellip;methods are one of the most efficient techniques for solving linear systems arising from Partial Differential Equations (PDEs) and graph Laplacians from machine learning <span class="search-hit mathjax">applications</span>. One of the key components of multigrid is smoothing, which aims at&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.12071v2-abstract-full').style.display = 'inline'; document.getElementById('2102.12071v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.12071v2-abstract-full" style="display: none;">
        Multigrid methods are one of the most efficient techniques for solving linear systems arising from Partial Differential Equations (PDEs) and graph Laplacians from machine learning <span class="search-hit mathjax">applications</span>. One of the key components of multigrid is smoothing, which aims at <span class="search-hit mathjax">reducing</span> high-frequency errors on each grid level. However, finding <span class="search-hit mathjax">optimal</span> smoothing algorithms is problem-dependent and can impose challenges for many problems. In this paper, we propose an efficient adaptive framework for learning <span class="search-hit mathjax">optimized</span> smoothers from operator stencils in the form of convolutional neural networks (CNNs). The CNNs are trained on small-scale problems from a given type of PDEs based on a supervised loss function derived from multigrid convergence theories, and can be applied to large-scale problems of the same class of PDEs. Numerical results on anisotropic rotated Laplacian problems demonstrate <span class="search-hit mathjax">improved</span> convergence rates and solution <span class="search-hit mathjax">time</span> compared with classical hand-crafted relaxation methods.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.12071v2-abstract-full').style.display = 'none'; document.getElementById('2102.12071v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 5 July, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 24 February, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.11559">arXiv:2102.11559</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.11559">pdf</a>, <a href="https://arxiv.org/format/2102.11559">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Toward <span class="search-hit mathjax">Speeding</span> up Mutation Analysis by Memoizing Expensive Methods
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ghanbari%2C+A">Ali Ghanbari</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Marcus%2C+A">Andrian Marcus</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.11559v1-abstract-short" style="display: inline;">
        Mutation analysis has many <span class="search-hit mathjax">applications</span>, such as assessing the quality of test cases, fault localization, test input generation, security analysis, etc. Such&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.11559v1-abstract-full').style.display = 'inline'; document.getElementById('2102.11559v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.11559v1-abstract-full" style="display: none;">
        Mutation analysis has many <span class="search-hit mathjax">applications</span>, such as assessing the quality of test cases, fault localization, test input generation, security analysis, etc. Such <span class="search-hit mathjax">applications</span> involve running test suite against a large number of <span class="search-hit mathjax">program</span> mutants leading to poor scalability. Much research has been aimed at <span class="search-hit mathjax">speeding</span> up this process, focusing on <span class="search-hit mathjax">reducing</span> the number of mutants, the number of executed tests, or the execution <span class="search-hit mathjax">time</span> of the mutants. This paper presents a novel approach, named MeMu, for <span class="search-hit mathjax">reducing</span> the execution <span class="search-hit mathjax">time</span> of the mutants, by memoizing the most expensive methods in the system. Memoization is an <span class="search-hit mathjax">optimization</span> technique that allows bypassing the execution of expensive methods, when repeated inputs are detected. MeMu can be used in conjunction with existing acceleration techniques. We implemented MeMu on top of PITest, a well-known JVM bytecode-level mutation analysis system, and obtained, on average, an 18.15% <span class="search-hit mathjax">speed</span>-up over PITest, in the execution <span class="search-hit mathjax">time</span> of the mutants for 12 real-world <span class="search-hit mathjax">programs</span>. These promising results and the fact that MeMu could also be used for other <span class="search-hit mathjax">applications</span> that involve repeated execution of tests (e.g., <span class="search-hit mathjax">automatic</span> <span class="search-hit mathjax">program</span> repair and regression testing), strongly support future research for <span class="search-hit mathjax">improving</span> its efficiency.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.11559v1-abstract-full').style.display = 'none'; document.getElementById('2102.11559v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 23 February, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">In proceedings of the 43rd ACM/IEEE International Conference on <span class="search-hit mathjax">Software</span> Engineering (ICSE'21) NIER</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.11392">arXiv:2102.11392</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.11392">pdf</a>, <a href="https://arxiv.org/format/2102.11392">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Information Theory">cs.IT</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Signal Processing">eess.SP</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Reinforcement Learning of Beam Codebooks in Millimeter Wave and Terahertz MIMO Systems
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+Y">Yu Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Alrabeiah%2C+M">Muhammad Alrabeiah</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Alkhateeb%2C+A">Ahmed Alkhateeb</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.11392v1-abstract-short" style="display: inline;">
        &hellip;terahertz MIMO systems rely on pre-defined beamforming codebooks for both initial access and data transmission. Being pre-defined, however, these codebooks are commonly not <span class="search-hit mathjax">optimized</span> for specific environments, user distributions, and/or possible hardware impairments. This leads to large codebook sizes with high beam training overhead which increases the init&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.11392v1-abstract-full').style.display = 'inline'; document.getElementById('2102.11392v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.11392v1-abstract-full" style="display: none;">
        Millimeter wave (mmWave) and terahertz MIMO systems rely on pre-defined beamforming codebooks for both initial access and data transmission. Being pre-defined, however, these codebooks are commonly not <span class="search-hit mathjax">optimized</span> for specific environments, user distributions, and/or possible hardware impairments. This leads to large codebook sizes with high beam training overhead which increases the initial access/tracking latency and makes it hard for these systems to support highly mobile <span class="search-hit mathjax">applications</span>. To overcome these limitations, this paper develops a deep reinforcement learning framework that learns how to iteratively <span class="search-hit mathjax">optimize</span> the codebook beam patterns (shapes) relying only on the receive power measurements and without requiring any explicit channel knowledge. The developed model learns how to autonomously adapt the beam patterns to best match the surrounding environment, user distribution, hardware impairments, and array geometry. Further, this approach does not require any knowledge about the channel, array geometry, RF hardware, or user positions. To <span class="search-hit mathjax">reduce</span> the learning <span class="search-hit mathjax">time</span>, the proposed model designs a novel Wolpertinger-variant architecture that is capable of efficiently searching for an <span class="search-hit mathjax">optimal</span> policy in a large discrete action space, which is important for large antenna arrays with quantized phase shifters. This complex-valued neural network architecture design respects the practical RF hardware constraints such as the constant-modulus and quantized phase shifter constraints. Simulation results based on the publicly available DeepMIMO dataset confirm the ability of the developed framework to learn near-<span class="search-hit mathjax">optimal</span> beam patterns for both line-of-sight (LOS) and non-LOS scenarios and for arrays with hardware impairments without requiring any channel knowledge.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.11392v1-abstract-full').style.display = 'none'; document.getElementById('2102.11392v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 February, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Submitted to IEEE, 30 pages, 9 figures. The dataset/<span class="search-hit mathjax">code</span> files will be available soon on the DeepMIMO website https://www.deepmimo.net/. arXiv admin note: text overlap with arXiv:2102.09084</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.11222">arXiv:2102.11222</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.11222">pdf</a>, <a href="https://arxiv.org/format/2102.11222">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Information Theory">cs.IT</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Networking and Internet Architecture">cs.NI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Deep Learning for THz Drones with Flying Intelligent Surfaces: Beam and Handoff Prediction
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Abuzainab%2C+N">Nof Abuzainab</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Alrabeiah%2C+M">Muhammad Alrabeiah</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Alkhateeb%2C+A">Ahmed Alkhateeb</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sagduyu%2C+Y+E">Yalin E. Sagduyu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.11222v1-abstract-short" style="display: inline;">
        &hellip;coverage of drones and enhance the reliability of next-generation wireless communications. Predicting future beams based on the drone beam/position trajectory significantly <span class="search-hit mathjax">reduces</span> the beam training overhead and its associated latency, and thus emerges as a viable solution to serve&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.11222v1-abstract-full').style.display = 'inline'; document.getElementById('2102.11222v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.11222v1-abstract-full" style="display: none;">
        We consider the problem of proactive handoff and beam selection in Terahertz (THz) drone communication networks assisted with reconfigurable intelligent surfaces (RIS). Drones have emerged as critical assets for next-generation wireless networks to provide seamless connectivity and extend the coverage, and can largely benefit from operating in the THz band to achieve high data rates (such as considered for 6G). However, THz communications are highly susceptible to channel impairments and blockage effects that become extra challenging when accounting for drone mobility. RISs offer flexibility to extend coverage by adapting to channel dynamics. To integrate RISs into THz drone communications, we propose a novel deep learning solution based on a recurrent neural network, namely the Gated Recurrent Unit (GRU), that proactively predicts the serving base station/RIS and the serving beam for each drone based on the prior observations of drone location/beam trajectories. This solution has the potential to extend the coverage of drones and enhance the reliability of next-generation wireless communications. Predicting future beams based on the drone beam/position trajectory significantly <span class="search-hit mathjax">reduces</span> the beam training overhead and its associated latency, and thus emerges as a viable solution to serve <span class="search-hit mathjax">time</span>-critical <span class="search-hit mathjax">applications</span>. Numerical results based on realistic 3D ray-tracing simulations show that the proposed deep learning solution is promising for future RIS-assisted THz networks by achieving near-<span class="search-hit mathjax">optimal</span> proactive hand-off performance and more than 90% accuracy for beam prediction.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.11222v1-abstract-full').style.display = 'none'; document.getElementById('2102.11222v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 February, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.10846">arXiv:2102.10846</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.10846">pdf</a>, <a href="https://arxiv.org/ps/2102.10846">ps</a>, <a href="https://arxiv.org/format/2102.10846">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Signal Processing">eess.SP</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Expanding boundaries of Gap Safe screening
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Dantas%2C+C">Cassio Dantas</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Soubies%2C+E">Emmanuel Soubies</a>, 
      
      <a href="/search/?searchtype=author&amp;query=F%C3%A9votte%2C+C">CÃ©dric FÃ©votte</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.10846v1-abstract-short" style="display: inline;">
        Sparse <span class="search-hit mathjax">optimization</span> problems are ubiquitous in many fields such as statistics, signal/image processing and machine learning. This has led to the birth of many iterative algorithms to solve them. A powerful strategy to boost the performance of these algorithms is known as safe screening: it allows the early identification of zero coordinates in the solution,&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.10846v1-abstract-full').style.display = 'inline'; document.getElementById('2102.10846v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.10846v1-abstract-full" style="display: none;">
        Sparse <span class="search-hit mathjax">optimization</span> problems are ubiquitous in many fields such as statistics, signal/image processing and machine learning. This has led to the birth of many iterative algorithms to solve them. A powerful strategy to boost the performance of these algorithms is known as safe screening: it allows the early identification of zero coordinates in the solution, which can then be eliminated to <span class="search-hit mathjax">reduce</span> the problem&#39;s size and accelerate convergence. In this work, we extend the existing Gap Safe screening framework by relaxing the global strong-concavity assumption on the dual cost function. Instead, we exploit local regularity properties, that is, strong concavity on well-chosen subsets of the domain. The non-negativity constraint is also integrated to the existing framework. Besides making safe screening possible to a broader class of functions that includes beta-divergences (e.g., the Kullback-Leibler divergence), the proposed approach also <span class="search-hit mathjax">improves</span> upon the existing Gap Safe screening rules on previously <span class="search-hit mathjax">applicable</span> cases (e.g., logistic regression). The proposed general framework is exemplified by some notable particular cases: logistic function, beta = 1.5 and Kullback-Leibler divergences. Finally, we showcase the effectiveness of the proposed screening rules with different solvers (coordinate descent, multiplicative-update and proximal gradient algorithms) and different data sets (binary classification, hyperspectral and count data).
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.10846v1-abstract-full').style.display = 'none'; document.getElementById('2102.10846v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 February, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.10800">arXiv:2102.10800</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.10800">pdf</a>, <a href="https://arxiv.org/format/2102.10800">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Characterizing and <span class="search-hit mathjax">Optimizing</span> EDA Flows for the Cloud
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Hosny%2C+A">Abdelrahman Hosny</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Reda%2C+S">Sherief Reda</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.10800v1-abstract-short" style="display: inline;">
        &hellip;on these characteristics. Thus, in this paper, we formulate the problem of migrating EDA jobs to the cloud. First, we characterize the performance of four main EDA <span class="search-hit mathjax">applications</span>, namely: synthesis, placement, routing and static&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.10800v1-abstract-full').style.display = 'inline'; document.getElementById('2102.10800v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.10800v1-abstract-full" style="display: none;">
        Cloud computing accelerates design space exploration in logic synthesis, and parameter tuning in physical design. However, deploying EDA jobs on the cloud requires EDA teams to deeply understand the characteristics of their jobs in cloud environments. Unfortunately, there has been little to no public information on these characteristics. Thus, in this paper, we formulate the problem of migrating EDA jobs to the cloud. First, we characterize the performance of four main EDA <span class="search-hit mathjax">applications</span>, namely: synthesis, placement, routing and static <span class="search-hit mathjax">timing</span> analysis. We show that different EDA jobs require different machine configurations. Second, using observations from our characterization, we propose a novel model based on Graph Convolutional Networks to predict the total <span class="search-hit mathjax">runtime</span> of a given <span class="search-hit mathjax">application</span> on different machine configurations. Our model achieves a prediction accuracy of 87%. Third, we develop a new formulation for <span class="search-hit mathjax">optimizing</span> cloud deployments in order to <span class="search-hit mathjax">reduce</span> deployment costs while meeting deadline constraints. We present a pseudo-polynomial <span class="search-hit mathjax">optimal</span> solution using a multi-choice knapsack mapping that <span class="search-hit mathjax">reduces</span> costs by 35.29%.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.10800v1-abstract-full').style.display = 'none'; document.getElementById('2102.10800v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 February, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Presented at DATE2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.10707">arXiv:2102.10707</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.10707">pdf</a>, <a href="https://arxiv.org/format/2102.10707">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A Zeroth-Order Block Coordinate Descent Algorithm for Huge-Scale Black-Box <span class="search-hit mathjax">Optimization</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Cai%2C+H">HanQin Cai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lou%2C+Y">Yuchen Lou</a>, 
      
      <a href="/search/?searchtype=author&amp;query=McKenzie%2C+D">Daniel McKenzie</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yin%2C+W">Wotao Yin</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.10707v2-abstract-short" style="display: inline;">
        We consider the zeroth-order <span class="search-hit mathjax">optimization</span> problem in the huge-scale setting, where the dimension of the problem is so large that performing even basic vector operations on the decision variables is infeasible. In this paper, we propose a novel algorithm, coined ZO-BCD, that exhibits favorable overall query complexity and has a much smaller per-iteration comp&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.10707v2-abstract-full').style.display = 'inline'; document.getElementById('2102.10707v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.10707v2-abstract-full" style="display: none;">
        We consider the zeroth-order <span class="search-hit mathjax">optimization</span> problem in the huge-scale setting, where the dimension of the problem is so large that performing even basic vector operations on the decision variables is infeasible. In this paper, we propose a novel algorithm, coined ZO-BCD, that exhibits favorable overall query complexity and has a much smaller per-iteration computational complexity. In addition, we discuss how the memory footprint of ZO-BCD can be <span class="search-hit mathjax">reduced</span> even further by the clever use of circulant measurement matrices. As an <span class="search-hit mathjax">application</span> of our new method, we propose the idea of crafting adversarial attacks on neural network based classifiers in a wavelet domain, which can result in problem dimensions of over 1.7 million. In particular, we show that crafting adversarial examples to audio classifiers in a wavelet domain can achieve the state-of-the-art attack success rate of 97.9%.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.10707v2-abstract-full').style.display = 'none'; document.getElementById('2102.10707v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 11 June, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 21 February, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted to ICML 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.10294">arXiv:2102.10294</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.10294">pdf</a>, <a href="https://arxiv.org/format/2102.10294">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Graphics">cs.GR</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        An unbiased ray-marching transmittance estimator
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Kettunen%2C+M">Markus Kettunen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=d%27Eon%2C+E">Eugene d&#39;Eon</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pantaleoni%2C+J">Jacopo Pantaleoni</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Novak%2C+J">Jan Novak</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.10294v1-abstract-short" style="display: inline;">
        We present an in-depth analysis of the sources of variance in state-of-the-art unbiased volumetric transmittance estimators, and propose several new methods for <span class="search-hit mathjax">improving</span> their efficiency. These combine to produce a single estimator that is universally&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.10294v1-abstract-full').style.display = 'inline'; document.getElementById('2102.10294v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.10294v1-abstract-full" style="display: none;">
        We present an in-depth analysis of the sources of variance in state-of-the-art unbiased volumetric transmittance estimators, and propose several new methods for <span class="search-hit mathjax">improving</span> their efficiency. These combine to produce a single estimator that is universally <span class="search-hit mathjax">optimal</span> relative to prior work, with up to several orders of magnitude lower variance at the same cost, and has zero variance for any ray with non-varying extinction. We first <span class="search-hit mathjax">reduce</span> the variance of truncated power-series estimators using a novel efficient <span class="search-hit mathjax">application</span> of U-statistics. We then greatly <span class="search-hit mathjax">reduce</span> the average expansion order of the power series and redistribute density evaluations to filter the optical depth estimates with an equidistant sampling comb. Combined with the use of an online control variate built from a sampled mean density estimate, the resulting estimator effectively performs ray marching most of the <span class="search-hit mathjax">time</span> while using rarely-sampled higher order terms to correct the bias.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.10294v1-abstract-full').style.display = 'none'; document.getElementById('2102.10294v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 20 February, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">20 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.09336">arXiv:2102.09336</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.09336">pdf</a>, <a href="https://arxiv.org/format/2102.09336">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        FIXME: Enhance <span class="search-hit mathjax">Software</span> Reliability with Hybrid Approaches in Cloud
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Hwang%2C+J">Jinho Hwang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shwartz%2C+L">Larisa Shwartz</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+Q">Qing Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Batta%2C+R">Raghav Batta</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kumar%2C+H">Harshit Kumar</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Nidd%2C+M">Michael Nidd</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.09336v1-abstract-short" style="display: inline;">
        &hellip;of reliability in cloud, more enterprises are migrating to cloud. The process of continuous integration/deployment (CICD) in cloud connects developers who need to deliver value <span class="search-hit mathjax">faster</span> and more transparently with site reliability engineers (SREs) who need to manage&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.09336v1-abstract-full').style.display = 'inline'; document.getElementById('2102.09336v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.09336v1-abstract-full" style="display: none;">
        With the promise of reliability in cloud, more enterprises are migrating to cloud. The process of continuous integration/deployment (CICD) in cloud connects developers who need to deliver value <span class="search-hit mathjax">faster</span> and more transparently with site reliability engineers (SREs) who need to manage <span class="search-hit mathjax">applications</span> reliably. SREs feed back development issues to developers, and developers commit fixes and trigger CICD to redeploy. The release cycle is more continuous than ever, thus the <span class="search-hit mathjax">code</span> to production is <span class="search-hit mathjax">faster</span> and more <span class="search-hit mathjax">automated</span>. To provide this higher level agility, the cloud platforms become more complex in the face of flexibility with deeper layers of virtualization. However, reliability does not come for free with all these complexities. <span class="search-hit mathjax">Software</span> engineers and SREs need to deal with wider information spectrum from virtualized layers. Therefore, providing correlated information with true positive evidences is critical to identify the root cause of issues quickly in order to <span class="search-hit mathjax">reduce</span> mean <span class="search-hit mathjax">time</span> to recover (MTTR), performance metrics for SREs. Similarity, knowledge, or statistics driven approaches have been effective, but with increasing data volume and types, an individual approach is limited to correlate semantic relations of different data sources. In this paper, we introduce FIXME to enhance <span class="search-hit mathjax">software</span> reliability with hybrid diagnosis approaches for enterprises. Our evaluation results show using hybrid diagnosis approach is about 17% better in precision. The results are helpful for both practitioners and researchers to develop hybrid diagnosis in the highly dynamic cloud environment.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.09336v1-abstract-full').style.display = 'none'; document.getElementById('2102.09336v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 February, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">ICSE SEIP, 2021</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          I.2.1
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.09050">arXiv:2102.09050</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.09050">pdf</a>, <a href="https://arxiv.org/ps/2102.09050">ps</a>, <a href="https://arxiv.org/format/2102.09050">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Signal Processing">eess.SP</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        End-to-end learnable EEG channel selection for deep neural networks with Gumbel-softmax
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Strypsteen%2C+T">Thomas Strypsteen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bertrand%2C+A">Alexander Bertrand</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.09050v3-abstract-short" style="display: inline;">
        Many electroencephalography (EEG) <span class="search-hit mathjax">applications</span> rely on channel selection methods to remove the least informative channels, e.g., to&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.09050v3-abstract-full').style.display = 'inline'; document.getElementById('2102.09050v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.09050v3-abstract-full" style="display: none;">
        Many electroencephalography (EEG) <span class="search-hit mathjax">applications</span> rely on channel selection methods to remove the least informative channels, e.g., to <span class="search-hit mathjax">reduce</span> the amount of electrodes to be mounted, to decrease the computational load, or to <span class="search-hit mathjax">reduce</span> overfitting effects and <span class="search-hit mathjax">improve</span> performance. Wrapper-based channel selection methods aim to match the channel selection step to the target model, yet they require to re-train the model multiple <span class="search-hit mathjax">times</span> on different candidate channel subsets, which often leads to an unacceptably high computational cost, especially when said model is a (deep) neural network. To alleviate this, we propose a framework to embed the EEG channel selection in the neural network itself to jointly learn the network weights and <span class="search-hit mathjax">optimal</span> channels in an end-to-end manner by traditional backpropagation algorithms. We deal with the discrete nature of this new <span class="search-hit mathjax">optimization</span> problem by employing continuous relaxations of the discrete channel selection parameters based on the Gumbel-softmax trick. We also propose a regularization method that discourages selecting channels more than once. This generic approach is evaluated on two different EEG tasks: motor imagery brain-computer interfaces and auditory attention decoding. The results demonstrate that our framework is generally <span class="search-hit mathjax">applicable</span>, while being competitive with state-of-the art EEG channel selection methods, tailored to these tasks.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.09050v3-abstract-full').style.display = 'none'; document.getElementById('2102.09050v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 June, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 11 February, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Updated revisions</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.08571">arXiv:2102.08571</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.08571">pdf</a>, <a href="https://arxiv.org/ps/2102.08571">ps</a>, <a href="https://arxiv.org/format/2102.08571">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Self-Triggered Markov Decision Processes
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Huang%2C+Y">Yunhan Huang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhu%2C+Q">Quanyan Zhu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.08571v1-abstract-short" style="display: inline;">
        &hellip;Markov Decision Processes (MDPs) with self-triggered strategies, where the idea of self-triggered control is extended to more generic MDP models. This extension broadens the <span class="search-hit mathjax">application</span> of self-triggering policies to a broader range of systems. We study the co-design problems of the control policy and the triggering policy to&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.08571v1-abstract-full').style.display = 'inline'; document.getElementById('2102.08571v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.08571v1-abstract-full" style="display: none;">
        In this paper, we study Markov Decision Processes (MDPs) with self-triggered strategies, where the idea of self-triggered control is extended to more generic MDP models. This extension broadens the <span class="search-hit mathjax">application</span> of self-triggering policies to a broader range of systems. We study the co-design problems of the control policy and the triggering policy to <span class="search-hit mathjax">optimize</span> two pre-specified cost criteria. The first cost criterion is introduced by incorporating a pre-specified update penalty into the traditional MDP cost criteria to <span class="search-hit mathjax">reduce</span> the use of communication resources. Under this criteria, a novel dynamic <span class="search-hit mathjax">programming</span> (DP) equation called DP equation with <span class="search-hit mathjax">optimized</span> lookahead to proposed to solve for the self-triggering policy under this criteria. The second self-triggering policy is to maximize the triggering <span class="search-hit mathjax">time</span> while still guaranteeing a pre-specified level of sub-<span class="search-hit mathjax">optimality</span>. Theoretical underpinnings are established for the computation and implementation of both policies. Through a gridworld numerical example, we illustrate the two policies&#39; effectiveness in <span class="search-hit mathjax">reducing</span> sources consumption and demonstrate the trade-offs between resource consumption and system performance.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.08571v1-abstract-full').style.display = 'none'; document.getElementById('2102.08571v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 February, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.07959">arXiv:2102.07959</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.07959">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Hardware Architecture">cs.AR</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Emerging Technologies">cs.ET</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        ReGraphX: NoC-enabled 3D Heterogeneous ReRAM Architecture for Training Graph Neural Networks
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Arka%2C+A+I">Aqeeb Iqbal Arka</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Joardar%2C+B+K">Biresh Kumar Joardar</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Doppa%2C+J+R">Janardhan Rao Doppa</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pande%2C+P+P">Partha Pratim Pande</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chakrabarty%2C+K">Krishnendu Chakrabarty</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.07959v1-abstract-short" style="display: inline;">
        &hellip;of Deep Neural Networks (DNNs) operating on graphs. However, GNNs are more complex compared to traditional DNNs as they simultaneously exhibit features of both DNN and graph <span class="search-hit mathjax">applications</span>. As a result, architectures specifically&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.07959v1-abstract-full').style.display = 'inline'; document.getElementById('2102.07959v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.07959v1-abstract-full" style="display: none;">
        Graph Neural Network (GNN) is a variant of Deep Neural Networks (DNNs) operating on graphs. However, GNNs are more complex compared to traditional DNNs as they simultaneously exhibit features of both DNN and graph <span class="search-hit mathjax">applications</span>. As a result, architectures specifically <span class="search-hit mathjax">optimized</span> for either DNNs or graph <span class="search-hit mathjax">applications</span> are not suited for GNN training. In this work, we propose a 3D heterogeneous manycore architecture for on-chip GNN training to address this problem. The proposed architecture, ReGraphX, involves heterogeneous ReRAM crossbars to fulfill the disparate requirements of both DNN and graph computations simultaneously. The ReRAM-based architecture is complemented with a multicast-enabled 3D NoC to <span class="search-hit mathjax">improve</span> the overall achievable performance. We demonstrate that ReGraphX outperforms conventional GPUs by up to 3.5X (on an average 3X) in terms of execution <span class="search-hit mathjax">time</span>, while <span class="search-hit mathjax">reducing</span> energy consumption by as much as 11X.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.07959v1-abstract-full').style.display = 'none'; document.getElementById('2102.07959v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 February, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">This paper has been accepted and presented at Design Automation and Test in Europe (DATE) 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.07313">arXiv:2102.07313</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.07313">pdf</a>, <a href="https://arxiv.org/format/2102.07313">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Field Evaluations of A Deep Learning-based Intelligent Spraying Robot with Flow Control for Pear Orchards
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Seol%2C+J">Jaehwi Seol</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kim%2C+J">Jeongeun Kim</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Son%2C+H+I">Hyoung Il Son</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.07313v1-abstract-short" style="display: inline;">
        This paper proposes a variable flow control system in real <span class="search-hit mathjax">time</span> with deep learning using the segmentation of fruit trees in a pear orchard. The flow rate control in real&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.07313v1-abstract-full').style.display = 'inline'; document.getElementById('2102.07313v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.07313v1-abstract-full" style="display: none;">
        This paper proposes a variable flow control system in real <span class="search-hit mathjax">time</span> with deep learning using the segmentation of fruit trees in a pear orchard. The flow rate control in real <span class="search-hit mathjax">time</span>, undesired pressure fluctuation and theoretical modeling may differ from those in the real world. Therefore, two types of preliminary experiments were designed to examine the linear relationship of the flow rate modeling. Through a preliminary experiment, the parameters of the pulse width modulation (PWM) controller were <span class="search-hit mathjax">optimized</span>, and an actual field experiment was conducted to confirm the performance of the variable flow rate control system. As a result of the field experiment, the performance of the proposed system was satisfactory, as it showed that it could <span class="search-hit mathjax">reduce</span> pesticide use and the risk of pesticide exposure. Especially, since the field experiment was conducted in an unstructured environment, the proposed variable flow control system is expected to be sufficiently <span class="search-hit mathjax">applicable</span> to other orchards.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.07313v1-abstract-full').style.display = 'none'; document.getElementById('2102.07313v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 February, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">17 pages, 18 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.06311">arXiv:2102.06311</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.06311">pdf</a>, <a href="https://arxiv.org/ps/2102.06311">ps</a>, <a href="https://arxiv.org/format/2102.06311">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Does Culture Matter? Impact of Individualism and Uncertainty Avoidance on App Reviews
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Fischer%2C+R+A">Ricarda Anna-Lena Fischer</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Walczuch%2C+R">Rita Walczuch</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Guzman%2C+E">Emitza Guzman</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.06311v2-abstract-short" style="display: inline;">
        Mobile <span class="search-hit mathjax">applications</span> are often used by an international audience and therefore receive a high daily amount of user reviews from various countries. Previous work found evidence that app store reviews contain helpful information for&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.06311v2-abstract-full').style.display = 'inline'; document.getElementById('2102.06311v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.06311v2-abstract-full" style="display: none;">
        Mobile <span class="search-hit mathjax">applications</span> are often used by an international audience and therefore receive a high daily amount of user reviews from various countries. Previous work found evidence that app store reviews contain helpful information for <span class="search-hit mathjax">software</span> evolution processes. However, the cultural diversity of the reviews and its consequences on specific user feedback characteristics has only been researched to a limited extent so far. In this paper, we examine the influence of two cultural dimensions, Individualism and Uncertainty Avoidance on user feedback in Apple app store reviews written in different languages. For this purpose, we collected 647,141 reviews from eight countries and written in five languages over a period of six months. We then used manual content analysis and <span class="search-hit mathjax">automated</span> processing to examine a sample of 3,120 reviews. The results show that there is a statistically significant influence of Individualism and Uncertainty Avoidance on user feedback characteristics. The results of this study will help researchers and practitioners to <span class="search-hit mathjax">reduce</span> algorithm bias caused by less diversified training and test data and to raise awareness of the importance of analyzing diversified user feedback.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.06311v2-abstract-full').style.display = 'none'; document.getElementById('2102.06311v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 March, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 11 February, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.06199">arXiv:2102.06199</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.06199">pdf</a>, <a href="https://arxiv.org/format/2102.06199">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Graphics">cs.GR</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A-NeRF: Surface-free Human 3D Pose Refinement via Neural Rendering
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Su%2C+S">Shih-Yang Su</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yu%2C+F">Frank Yu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zollhoefer%2C+M">Michael Zollhoefer</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rhodin%2C+H">Helge Rhodin</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.06199v1-abstract-short" style="display: inline;">
        &hellip;are still in use to recover fine details if a high-quality 3D model of the user is available. Unfortunately, obtaining such a model for every user a priori is challenging, <span class="search-hit mathjax">time</span>-consuming, and limits the&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.06199v1-abstract-full').style.display = 'inline'; document.getElementById('2102.06199v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.06199v1-abstract-full" style="display: none;">
        While deep learning has reshaped the classical motion capture pipeline, generative, analysis-by-synthesis elements are still in use to recover fine details if a high-quality 3D model of the user is available. Unfortunately, obtaining such a model for every user a priori is challenging, <span class="search-hit mathjax">time</span>-consuming, and limits the <span class="search-hit mathjax">application</span> scenarios. We propose a novel test-<span class="search-hit mathjax">time</span> <span class="search-hit mathjax">optimization</span> approach for monocular motion capture that learns a volumetric body model of the user in a self-supervised manner. To this end, our approach combines the advantages of neural radiance fields with an articulated skeleton representation. Our proposed skeleton embedding serves as a common reference that links constraints across <span class="search-hit mathjax">time</span>, thereby <span class="search-hit mathjax">reducing</span> the number of required camera views from traditionally dozens of calibrated cameras, down to a single uncalibrated one. As a starting point, we employ the output of an off-the-shelf model that predicts the 3D skeleton pose. The volumetric body shape and appearance is then learned from scratch, while jointly refining the initial pose estimate. Our approach is self-supervised and does not require any additional ground truth labels for appearance, pose, or 3D shape. We demonstrate that our novel combination of a discriminative pose estimation technique with surface-free analysis-by-synthesis outperforms purely discriminative monocular pose estimation approaches and generalizes well to multiple views.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.06199v1-abstract-full').style.display = 'none'; document.getElementById('2102.06199v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 11 February, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Project website: https://lemonatsu.github.io/ANeRF-Surface-free-Pose-Refinement/</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.04890">arXiv:2102.04890</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.04890">pdf</a>, <a href="https://arxiv.org/format/2102.04890">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Applied Physics">physics.app-ph</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        On Theory-training Neural Networks to Infer the Solution of Highly Coupled Differential Equations
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Rad%2C+M+T">M. Torabi Rad</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Viardin%2C+A">A. Viardin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Apel%2C+M">M. Apel</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.04890v2-abstract-short" style="display: inline;">
        Deep neural networks are transforming fields ranging from computer vision to computational medicine, and we recently extended their <span class="search-hit mathjax">application</span> to the field of phase-change heat transfer by introducing theory-trained neural networks (TTNs) for a solidification problem \cite{TTN}. Here, we present general, in-depth, and empirical insights into theory-training&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.04890v2-abstract-full').style.display = 'inline'; document.getElementById('2102.04890v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.04890v2-abstract-full" style="display: none;">
        Deep neural networks are transforming fields ranging from computer vision to computational medicine, and we recently extended their <span class="search-hit mathjax">application</span> to the field of phase-change heat transfer by introducing theory-trained neural networks (TTNs) for a solidification problem \cite{TTN}. Here, we present general, in-depth, and empirical insights into theory-training networks for learning the solution of highly coupled differential equations. We analyze the deteriorating effects of the oscillating loss on the ability of a network to satisfy the equations at the training data points, measured by the final training loss, and on the accuracy of the inferred solution. We introduce a theory-training technique that, by leveraging regularization, eliminates those oscillations, decreases the final training loss, and <span class="search-hit mathjax">improves</span> the accuracy of the inferred solution, with no additional computational cost. Then, we present guidelines that allow a systematic search for the network that has the <span class="search-hit mathjax">optimal</span> training <span class="search-hit mathjax">time</span> and inference accuracy for a given set of equations; following these guidelines can <span class="search-hit mathjax">reduce</span> the number of tedious training iterations in that search. Finally, a comparison between theory-training and the rival, conventional method of solving differential equations using discretization attests to the advantages of theory-training not being necessarily limited to high-dimensional sets of equations. The comparison also reveals a limitation of the current theory-training framework that may limit its <span class="search-hit mathjax">application</span> in domains where extreme accuracies are necessary.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.04890v2-abstract-full').style.display = 'none'; document.getElementById('2102.04890v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 10 February, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 9 February, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.03877">arXiv:2102.03877</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.03877">pdf</a>, <a href="https://arxiv.org/format/2102.03877">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Materials Science">cond-mat.mtrl-sci</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Noise Reduction in X-ray Photon Correlation Spectroscopy with Convolutional Neural Networks Encoder-Decoder Models
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Konstantinova%2C+T">Tatiana Konstantinova</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wiegart%2C+L">Lutz Wiegart</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rakitin%2C+M">Maksim Rakitin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=DeGennaro%2C+A+M">Anthony M. DeGennaro</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Barbour%2C+A+M">Andi M. Barbour</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.03877v1-abstract-short" style="display: inline;">
        &hellip;techniques, X-ray Photon Correlation Spectroscopy is a subject to various kinds of noise. Random and correlated fluctuations and heterogeneities can be present in a two-<span class="search-hit mathjax">time</span> correlation function and obscure the information about the intrinsic dynamics of a sample. Simultaneously addressing the disparate origins of noise in the experimental data is challengin&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.03877v1-abstract-full').style.display = 'inline'; document.getElementById('2102.03877v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.03877v1-abstract-full" style="display: none;">
        Like other experimental techniques, X-ray Photon Correlation Spectroscopy is a subject to various kinds of noise. Random and correlated fluctuations and heterogeneities can be present in a two-<span class="search-hit mathjax">time</span> correlation function and obscure the information about the intrinsic dynamics of a sample. Simultaneously addressing the disparate origins of noise in the experimental data is challenging. We propose a computational approach for <span class="search-hit mathjax">improving</span> the signal-to-noise ratio in two-<span class="search-hit mathjax">time</span> correlation functions that is based on Convolutional Neural Network Encoder-Decoder (CNN-ED) models. Such models extract features from an image via convolutional layers, project them to a low dimensional space and then reconstruct a clean image from this <span class="search-hit mathjax">reduced</span> representation via transposed convolutional layers. Not only are ED models a general tool for random noise removal, but their <span class="search-hit mathjax">application</span> to low signal-to-noise data can enhance the data quantitative usage since they are able to learn the functional form of the signal. We demonstrate that the CNN-ED models trained on real-world experimental data help to effectively extract equilibrium dynamics parameters from two-<span class="search-hit mathjax">time</span> correlation functions, containing statistical noise and dynamic heterogeneities. Strategies for <span class="search-hit mathjax">optimizing</span> the models performance and their <span class="search-hit mathjax">applicability</span> limits are discussed.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.03877v1-abstract-full').style.display = 'none'; document.getElementById('2102.03877v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 February, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">5 pages, 10 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.03236">arXiv:2102.03236</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.03236">pdf</a>, <a href="https://arxiv.org/format/2102.03236">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Exact <span class="search-hit mathjax">Optimization</span> of Conformal Predictors via Incremental and Decremental Learning
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Cherubin%2C+G">Giovanni Cherubin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chatzikokolakis%2C+K">Konstantinos Chatzikokolakis</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jaggi%2C+M">Martin Jaggi</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.03236v1-abstract-short" style="display: inline;">
        &hellip;They are suitable for a wide range of problems, from classification and regression to anomaly detection. Unfortunately, their high computational complexity limits their <span class="search-hit mathjax">applicability</span> to large datasets.
  In this work, we show that it is possible to&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.03236v1-abstract-full').style.display = 'inline'; document.getElementById('2102.03236v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.03236v1-abstract-full" style="display: none;">
        Conformal Predictors (CP) are wrappers around ML methods, providing error guarantees under weak assumptions on the data distribution. They are suitable for a wide range of problems, from classification and regression to anomaly detection. Unfortunately, their high computational complexity limits their <span class="search-hit mathjax">applicability</span> to large datasets.
  In this work, we show that it is possible to <span class="search-hit mathjax">speed</span> up a CP classifier considerably, by studying it in conjunction with the underlying ML method, and by exploiting incremental&amp;decremental learning. For methods such as k-NN, KDE, and kernel LS-SVM, our approach <span class="search-hit mathjax">reduces</span> the running <span class="search-hit mathjax">time</span> by one order of magnitude, whilst producing exact solutions. With similar ideas, we also achieve a linear <span class="search-hit mathjax">speed</span> up for the harder case of bootstrapping. Finally, we extend these techniques to <span class="search-hit mathjax">improve</span> upon an <span class="search-hit mathjax">optimization</span> of k-NN CP for regression.
  We evaluate our findings empirically, and discuss when methods are suitable for CP <span class="search-hit mathjax">optimization</span>.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.03236v1-abstract-full').style.display = 'none'; document.getElementById('2102.03236v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 5 February, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.03012">arXiv:2102.03012</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.03012">pdf</a>, <a href="https://arxiv.org/format/2102.03012">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A Serverless Cloud-Fog Platform for DNN-Based Video Analytics with Incremental Learning
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+H">Huaizheng Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shen%2C+M">Meng Shen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Huang%2C+Y">Yizheng Huang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wen%2C+Y">Yonggang Wen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Luo%2C+Y">Yong Luo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gao%2C+G">Guanyu Gao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Guan%2C+K">Kyle Guan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.03012v1-abstract-short" style="display: inline;">
        DNN-based video analytics have empowered many new <span class="search-hit mathjax">applications</span> (e.g.,&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.03012v1-abstract-full').style.display = 'inline'; document.getElementById('2102.03012v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.03012v1-abstract-full" style="display: none;">
        DNN-based video analytics have empowered many new <span class="search-hit mathjax">applications</span> (e.g., <span class="search-hit mathjax">automated</span> retail). Meanwhile, the proliferation of fog devices provides developers with more design options to <span class="search-hit mathjax">improve</span> performance and save cost. To the best of our knowledge, this paper presents the first serverless system that takes full advantage of the client-fog-cloud synergy to better serve the DNN-based video analytics. Specifically, the system aims to achieve two goals: 1) Provide the <span class="search-hit mathjax">optimal</span> analytics results under the constraints of lower bandwidth usage and shorter round-trip <span class="search-hit mathjax">time</span> (RTT) by judiciously managing the computational and bandwidth resources deployed in the client, fog, and cloud environment. 2) Free developers from tedious administration and operation tasks, including DNN deployment, cloud and fog&#39;s resource management. To this end, we implement a holistic cloud-fog system referred to as VPaaS (Video-Platform-as-a-Service). VPaaS adopts serverless computing to enable developers to build a video analytics pipeline by simply <span class="search-hit mathjax">programming</span> a set of functions (e.g., model inference), which are then orchestrated to process videos through carefully designed modules. To save bandwidth and <span class="search-hit mathjax">reduce</span> RTT, VPaaS provides a new video streaming protocol that only sends low-quality video to the cloud. The state-of-the-art (SOTA) DNNs deployed at the cloud can identify regions of video frames that need further processing at the fog ends. At the fog ends, misidentified labels in these regions can be corrected using a light-weight DNN model. To address the data drift issues, we incorporate limited human feedback into the system to verify the results and adopt incremental learning to <span class="search-hit mathjax">improve</span> our system continuously. The evaluation demonstrates that VPaaS is superior to several SOTA systems: it maintains high accuracy while <span class="search-hit mathjax">reducing</span> bandwidth usage by up to 21%, RTT by up to 62.5%, and cloud monetary cost by up to 50%.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.03012v1-abstract-full').style.display = 'none'; document.getElementById('2102.03012v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 5 February, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">11 pages, 16 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.01048">arXiv:2102.01048</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.01048">pdf</a>, <a href="https://arxiv.org/format/2102.01048">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Databases">cs.DB</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Cryptography and Security">cs.CR</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Secrecy: Secure collaborative analytics on secret-shared data
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Liagouris%2C+J">John Liagouris</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kalavri%2C+V">Vasiliki Kalavri</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Faisal%2C+M">Muhammad Faisal</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Varia%2C+M">Mayank Varia</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.01048v1-abstract-short" style="display: inline;">
        We study the problem of composing and <span class="search-hit mathjax">optimizing</span> relational query plans under secure multi-party computation (MPC). MPC enables mutually distrusting parties to jointly compute arbitrary functions over private data, while preserving data privacy from each other and from external entities.
  In this paper, we propose a relational MPC framework based on replica&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.01048v1-abstract-full').style.display = 'inline'; document.getElementById('2102.01048v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.01048v1-abstract-full" style="display: none;">
        We study the problem of composing and <span class="search-hit mathjax">optimizing</span> relational query plans under secure multi-party computation (MPC). MPC enables mutually distrusting parties to jointly compute arbitrary functions over private data, while preserving data privacy from each other and from external entities.
  In this paper, we propose a relational MPC framework based on replicated secret sharing. We define a set of oblivious operators, explain the secure primitives they rely on, and provide an analysis of their costs in terms of operations and inter-party communication. We show how these operators can be composed to form end-to-end oblivious queries, and we introduce logical and physical <span class="search-hit mathjax">optimizations</span> that dramatically <span class="search-hit mathjax">reduce</span> the space and communication requirements during query execution, in some cases from quadratic to linear with respect to the cardinality of the input.
  We provide an efficient implementation of our framework, called Secrecy, and evaluate it using real queries from several MPC <span class="search-hit mathjax">application</span> areas. Our results demonstrate that the <span class="search-hit mathjax">optimizations</span> we propose can result in up to 1000x lower execution <span class="search-hit mathjax">times</span> compared to baseline approaches, enabling Secrecy to outperform state-of-the-art frameworks and compute MPC queries on millions of input rows with a single thread per party.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.01048v1-abstract-full').style.display = 'none'; document.getElementById('2102.01048v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 1 February, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.00755">arXiv:2102.00755</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.00755">pdf</a>, <a href="https://arxiv.org/format/2102.00755">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Numerical Analysis">math.NA</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computational Engineering, Finance, and Science">cs.CE</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        High Resolution 3D Ultrasonic Breast Imaging by <span class="search-hit mathjax">Time</span>-Domain Full Waveform Inversion
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Lucka%2C+F">Felix Lucka</a>, 
      
      <a href="/search/?searchtype=author&amp;query=P%C3%A9rez-Liva%2C+M">Mailyn PÃ©rez-Liva</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Treeby%2C+B+E">Bradley E. Treeby</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cox%2C+B+T">Ben T. Cox</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.00755v3-abstract-short" style="display: inline;">
        Ultrasound tomography (UST) scanners allow quantitative images of the human breast&#39;s acoustic properties to be derived with potential <span class="search-hit mathjax">applications</span> in screening, diagnosis and therapy planning.&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.00755v3-abstract-full').style.display = 'inline'; document.getElementById('2102.00755v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.00755v3-abstract-full" style="display: none;">
        Ultrasound tomography (UST) scanners allow quantitative images of the human breast&#39;s acoustic properties to be derived with potential <span class="search-hit mathjax">applications</span> in screening, diagnosis and therapy planning. <span class="search-hit mathjax">Time</span> domain full waveform inversion (TD-FWI) is a promising UST image formation technique that fits the parameter fields of a wave physics model by gradient-based <span class="search-hit mathjax">optimization</span>. For high resolution 3D UST, it holds three key challenges: Firstly, its central building block, the computation of the gradient for a single US measurement, has a restrictively large memory footprint. Secondly, this building block needs to be computed for each of the $10^3-10^4$ measurements, resulting in a massive parallel computation usually performed on large computational clusters for days. Lastly, the structure of the underlying <span class="search-hit mathjax">optimization</span> problem may result in slow progression of the solver and convergence to a local minimum. In this work, we design and evaluate a comprehensive computational strategy to overcome these challenges: Firstly, we introduce a novel gradient computation based on <span class="search-hit mathjax">time</span> reversal that dramatically <span class="search-hit mathjax">reduces</span> the memory footprint at the expense of one additional wave simulation per source. Secondly, we break the dependence on the number of measurements by using source encoding (SE) to compute stochastic gradient estimates. Also we describe a more accurate, TD-specific SE technique with a finer variance control and use a state-of-the-art stochastic LBFGS method. Lastly, we design an efficient TD multi-grid scheme together with preconditioning to <span class="search-hit mathjax">speed</span> up the convergence while avoiding local minima. All components are evaluated in extensive numerical proof-of-concept studies simulating a bowl-shaped 3D UST breast scanner prototype. Finally, we demonstrate that their combination allows us to obtain an accurate 442x442x222 voxel image with a resolution of 0.5mm using Matlab on a single GPU within 24h.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.00755v3-abstract-full').style.display = 'none'; document.getElementById('2102.00755v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 10 March, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 1 February, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.00092">arXiv:2102.00092</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.00092">pdf</a>, <a href="https://arxiv.org/format/2102.00092">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Can Machine Learning Help in Solving Cargo Capacity Management Booking Control Problems?
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Dumouchelle%2C+J">Justin Dumouchelle</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Frejinger%2C+E">Emma Frejinger</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lodi%2C+A">Andrea Lodi</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.00092v1-abstract-short" style="display: inline;">
        &hellip;accept a booking request or reject it to reserve capacity for future bookings with potentially higher revenue. We formulate the problem as a finite-horizon stochastic dynamic <span class="search-hit mathjax">program</span>. The cost of fulfilling the accepted bookings, incurred at the end of the horizon, depends on the packing and routing of the cargo. This is a computationally challenging aspect&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.00092v1-abstract-full').style.display = 'inline'; document.getElementById('2102.00092v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.00092v1-abstract-full" style="display: none;">
        Revenue management is important for carriers (e.g., airlines and railroads). In this paper, we focus on cargo capacity management which has received less attention in the literature than its passenger counterpart. More precisely, we focus on the problem of controlling booking accept/reject decisions: Given a limited capacity, accept a booking request or reject it to reserve capacity for future bookings with potentially higher revenue. We formulate the problem as a finite-horizon stochastic dynamic <span class="search-hit mathjax">program</span>. The cost of fulfilling the accepted bookings, incurred at the end of the horizon, depends on the packing and routing of the cargo. This is a computationally challenging aspect as the latter are solutions to an operational decision-making problem, in our <span class="search-hit mathjax">application</span> a vehicle routing problem (VRP). Seeking a balance between online and offline computation, we propose to train a predictor of the solution costs to the VRPs using supervised learning. In turn, we use the predictions online in approximate dynamic <span class="search-hit mathjax">programming</span> and reinforcement learning algorithms to solve the booking control problem. We compare the results to an existing approach in the literature and show that we are able to obtain control policies that provide increased profit at a <span class="search-hit mathjax">reduced</span> evaluation <span class="search-hit mathjax">time</span>. This is achieved thanks to accurate approximation of the operational costs and negligible computing <span class="search-hit mathjax">time</span> in comparison to solving the VRPs.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.00092v1-abstract-full').style.display = 'none'; document.getElementById('2102.00092v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 29 January, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2101.11118">arXiv:2101.11118</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2101.11118">pdf</a>, <a href="https://arxiv.org/format/2101.11118">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Can Offline Testing of Deep Neural Networks Replace Their Online Testing?
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Haq%2C+F+U">Fitash Ul Haq</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shin%2C+D">Donghwan Shin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Nejati%2C+S">Shiva Nejati</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Briand%2C+L">Lionel Briand</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2101.11118v2-abstract-short" style="display: inline;">
        &hellip;where DNNs are tested as individual units based on test datasets obtained without involving the DNNs under test, and online testing where DNNs are embedded into a specific <span class="search-hit mathjax">application</span> environment and tested in a closed-loop mode in interaction with the&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.11118v2-abstract-full').style.display = 'inline'; document.getElementById('2101.11118v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2101.11118v2-abstract-full" style="display: none;">
        We distinguish two general modes of testing for Deep Neural Networks (DNNs): Offline testing where DNNs are tested as individual units based on test datasets obtained without involving the DNNs under test, and online testing where DNNs are embedded into a specific <span class="search-hit mathjax">application</span> environment and tested in a closed-loop mode in interaction with the <span class="search-hit mathjax">application</span> environment. Typically, DNNs are subjected to both types of testing during their development life cycle where offline testing is applied immediately after DNN training and online testing follows after offline testing and once a DNN is deployed within a specific <span class="search-hit mathjax">application</span> environment. In this paper, we study the relationship between offline and online testing. Our goal is to determine how offline testing and online testing differ or complement one another and if offline testing results can be used to help <span class="search-hit mathjax">reduce</span> the cost of online testing? Though these questions are generally relevant to all autonomous systems, we study them in the context of <span class="search-hit mathjax">automated</span> driving systems where, as study subjects, we use DNNs <span class="search-hit mathjax">automating</span> end-to-end controls of steering functions of self-driving vehicles. Our results show that offline testing is less effective than online testing as many safety violations identified by online testing could not be identified by offline testing, while large prediction errors generated by offline testing always led to severe safety violations detectable by online testing. Further, we cannot exploit offline testing results to <span class="search-hit mathjax">reduce</span> the cost of online testing in practice since we are not able to identify specific situations where offline testing could be as accurate as online testing in identifying safety requirement violations.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.11118v2-abstract-full').style.display = 'none'; document.getElementById('2101.11118v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 April, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 26 January, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Journal extension of arXiv:1912.00805; To appear in Empirical <span class="search-hit mathjax">Software</span> Engineering</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2101.10444">arXiv:2101.10444</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2101.10444">pdf</a>, <a href="https://arxiv.org/ps/2101.10444">ps</a>, <a href="https://arxiv.org/format/2101.10444">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Image and Video Processing">eess.IV</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        GnetSeg: Semantic Segmentation Model <span class="search-hit mathjax">Optimized</span> on a 224mW CNN Accelerator Chip at the <span class="search-hit mathjax">Speed</span> of 318FPS
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Sun%2C+B">Baohua Sun</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lin%2C+W">Weixiong Lin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sha%2C+H">Hao Sha</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Su%2C+J">Jiapeng Su</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2101.10444v1-abstract-short" style="display: inline;">
        Semantic segmentation is the task to cluster pixels on an image belonging to the same class. It is widely used in the real-world <span class="search-hit mathjax">applications</span> including autonomous driving, medical imaging analysis, industrial inspection, smartphone camera for person segmentation and so on. Accelerating the semantic segmentation models on the mobile and edge devices are pract&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.10444v1-abstract-full').style.display = 'inline'; document.getElementById('2101.10444v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2101.10444v1-abstract-full" style="display: none;">
        Semantic segmentation is the task to cluster pixels on an image belonging to the same class. It is widely used in the real-world <span class="search-hit mathjax">applications</span> including autonomous driving, medical imaging analysis, industrial inspection, smartphone camera for person segmentation and so on. Accelerating the semantic segmentation models on the mobile and edge devices are practical needs for the industry. Recent years have witnessed the wide availability of CNN (Convolutional Neural Networks) accelerators. They have the advantages on power efficiency, inference <span class="search-hit mathjax">speed</span>, which are ideal for accelerating the semantic segmentation models on the edge devices. However, the CNN accelerator chips also have the limitations on flexibility and memory. In addition, the CPU load is very critical because the CNN accelerator chip works as a co-processor with a host CPU. In this paper, we <span class="search-hit mathjax">optimize</span> the semantic segmentation model in order to fully utilize the limited memory and the supported operators on the CNN accelerator chips, and at the same <span class="search-hit mathjax">time</span> <span class="search-hit mathjax">reduce</span> the CPU load of the CNN model to zero. The resulting model is called GnetSeg. Furthermore, we propose the integer encoding for the mask of the GnetSeg model, which minimizes the latency of data transfer between the CNN accelerator and the host CPU. The experimental result shows that the model running on the 224mW chip achieves the <span class="search-hit mathjax">speed</span> of 318FPS with excellent accuracy for <span class="search-hit mathjax">applications</span> such as person segmentation.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.10444v1-abstract-full').style.display = 'none'; document.getElementById('2101.10444v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 9 January, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">7 pages, 3 figures, and 2 tables</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2101.10357">arXiv:2101.10357</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2101.10357">pdf</a>, <a href="https://arxiv.org/ps/2101.10357">ps</a>, <a href="https://arxiv.org/format/2101.10357">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Regret-<span class="search-hit mathjax">Optimal</span> Filtering
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Sabag%2C+O">Oron Sabag</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hassibi%2C+B">Babak Hassibi</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2101.10357v1-abstract-short" style="display: inline;">
        We consider the problem of filtering in linear state-space models (e.g., the Kalman filter setting) through the lens of regret <span class="search-hit mathjax">optimization</span>. Different assumptions on the driving disturbance and the observation noise sequences give rise to different estimators: in the stochastic setting to the celebrated Kalman filter, and in the deterministic setting of boun&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.10357v1-abstract-full').style.display = 'inline'; document.getElementById('2101.10357v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2101.10357v1-abstract-full" style="display: none;">
        We consider the problem of filtering in linear state-space models (e.g., the Kalman filter setting) through the lens of regret <span class="search-hit mathjax">optimization</span>. Different assumptions on the driving disturbance and the observation noise sequences give rise to different estimators: in the stochastic setting to the celebrated Kalman filter, and in the deterministic setting of bounded energy disturbances to $H_\infty$ estimators. In this work, we formulate a novel criterion for filter design based on the concept of regret between the estimation error energy of a clairvoyant estimator that has access to all future observations (a so-called smoother) and a causal one that only has access to current and past observations. The regret-<span class="search-hit mathjax">optimal</span> estimator is chosen to minimize this worst-case difference across all bounded-energy noise sequences. The resulting estimator is adaptive in the sense that it aims to mimic the behavior of the clairvoyant estimator, irrespective of what the realization of the noise will be and thus interpolates between the stochastic and deterministic approaches. We provide a solution for the regret estimation problem at two different levels. First, we provide a solution at the operator level by <span class="search-hit mathjax">reducing</span> it to the Nehari problem. Second, for state-space models, we explicitly find the estimator that achieves the <span class="search-hit mathjax">optimal</span> regret. From a computational perspective, the regret-<span class="search-hit mathjax">optimal</span> estimator can be easily implemented by solving three Riccati equations and a single Lyapunov equation. For a state-space model of dimension $n$, the regret-<span class="search-hit mathjax">optimal</span> estimator has a state-space structure of dimension $3n$. We demonstrate the <span class="search-hit mathjax">applicability</span> and efficacy of the estimator in a variety of problems and observe that the estimator has average and worst-case performances that are simultaneously close to their <span class="search-hit mathjax">optimal</span> values. We therefore argue that regret-<span class="search-hit mathjax">optimality</span> is a viable approach to estimator design.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.10357v1-abstract-full').style.display = 'none'; document.getElementById('2101.10357v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 25 January, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted to AISTATS 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2101.10209">arXiv:2101.10209</a>
        <span>&nbsp;&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Novel Dynamic Load Balancing Algorithm for Cloud-Based Big Data Analytics
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Aghdashi%2C+A">Arman Aghdashi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mirtaheri%2C+S+L">Seyedeh Leili Mirtaheri</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2101.10209v2-abstract-short" style="display: inline;">
        Big data analytics in cloud environments introduces challenges such as real-<span class="search-hit mathjax">time</span> load balancing besides security, privacy, and energy efficiency. In this paper, we propose a novel load balancing algorithm in cloud environments that performs resource allocation and task scheduling efficiently. The proposed load balancer&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.10209v2-abstract-full').style.display = 'inline'; document.getElementById('2101.10209v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2101.10209v2-abstract-full" style="display: none;">
        Big data analytics in cloud environments introduces challenges such as real-<span class="search-hit mathjax">time</span> load balancing besides security, privacy, and energy efficiency. In this paper, we propose a novel load balancing algorithm in cloud environments that performs resource allocation and task scheduling efficiently. The proposed load balancer <span class="search-hit mathjax">reduces</span> the execution response <span class="search-hit mathjax">time</span> in big data <span class="search-hit mathjax">applications</span> performed on clouds. Scheduling, in general, is an NP-hard problem. In our proposed algorithm, we provide solutions to <span class="search-hit mathjax">reduce</span> the search area that leads to <span class="search-hit mathjax">reduced</span> complexity of the load balancing. We recommend two mathematical <span class="search-hit mathjax">optimization</span> models to perform dynamic resource allocation to virtual machines and task scheduling. The provided solution is based on the hill-climbing algorithm to minimize response <span class="search-hit mathjax">time</span>. We evaluate the performance of proposed algorithms in terms of response <span class="search-hit mathjax">time</span>, turnaround <span class="search-hit mathjax">time</span>, throughput metrics, and request distribution with some of the existing algorithms that show significant <span class="search-hit mathjax">improvements</span>
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.10209v2-abstract-full').style.display = 'none'; document.getElementById('2101.10209v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 1 February, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 25 January, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">My supervisor has requested that i withdraw the article</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2101.09796">arXiv:2101.09796</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2101.09796">pdf</a>, <a href="https://arxiv.org/format/2101.09796">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        The Ifs and Buts of the Development Approaches for IoT <span class="search-hit mathjax">Applications</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Agudelo-Sanabria%2C+S+D">Saitel Daniela Agudelo-Sanabria</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jindal%2C+A">Anshul Jindal</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2101.09796v1-abstract-short" style="display: inline;">
        The recent growth of the Internet of Things (IoT) devices has lead to the rise of various complex <span class="search-hit mathjax">applications</span> where these&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.09796v1-abstract-full').style.display = 'inline'; document.getElementById('2101.09796v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2101.09796v1-abstract-full" style="display: none;">
        The recent growth of the Internet of Things (IoT) devices has lead to the rise of various complex <span class="search-hit mathjax">applications</span> where these <span class="search-hit mathjax">applications</span> involve interactions among large numbers of heterogeneous devices. An important challenge that needs to be addressed is to facilitate the agile development of IoT <span class="search-hit mathjax">applications</span> with minimal effort by the various parties involved in the process. However, IoT <span class="search-hit mathjax">application</span> development is challenging due to the wide variety of hardware and <span class="search-hit mathjax">software</span> technologies that interact in an IoT system. Moreover, it involves dealing with issues that are attributed to different <span class="search-hit mathjax">software</span> life-cycle phases: development, deployment, and progression.
  In this paper, we examine three IoT <span class="search-hit mathjax">application</span> development approaches: Mashup-based development, Model-based development, and Function-as-a-Service based development. The advantages and disadvantages of each approach are discussed from different perspectives, including reliability, deployment expeditiousness, ease of use, and targeted audience. Finally, we propose a simple solution where these techniques are combined to deliver reliable <span class="search-hit mathjax">applications</span> while <span class="search-hit mathjax">reducing</span> costs and <span class="search-hit mathjax">time</span> to release.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.09796v1-abstract-full').style.display = 'none'; document.getElementById('2101.09796v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 24 January, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">7 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2101.09671">arXiv:2101.09671</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2101.09671">pdf</a>, <a href="https://arxiv.org/format/2101.09671">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Pruning and Quantization for Deep Neural Network Acceleration: A Survey
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Liang%2C+T">Tailin Liang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Glossner%2C+J">John Glossner</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+L">Lei Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shi%2C+S">Shaobo Shi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+X">Xiaotong Zhang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2101.09671v3-abstract-short" style="display: inline;">
        Deep neural networks have been applied in many <span class="search-hit mathjax">applications</span> exhibiting extraordinary abilities in the field of computer vision. However, complex network architectures challenge efficient real-&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.09671v3-abstract-full').style.display = 'inline'; document.getElementById('2101.09671v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2101.09671v3-abstract-full" style="display: none;">
        Deep neural networks have been applied in many <span class="search-hit mathjax">applications</span> exhibiting extraordinary abilities in the field of computer vision. However, complex network architectures challenge efficient real-<span class="search-hit mathjax">time</span> deployment and require significant computation resources and energy costs. These challenges can be overcome through <span class="search-hit mathjax">optimizations</span> such as network compression. Network compression can often be realized with little loss of accuracy. In some cases accuracy may even <span class="search-hit mathjax">improve</span>. This paper provides a survey on two types of network compression: pruning and quantization. Pruning can be categorized as static if it is performed offline or dynamic if it is performed at run-<span class="search-hit mathjax">time</span>. We compare pruning techniques and describe criteria used to remove redundant computations. We discuss trade-offs in element-wise, channel-wise, shape-wise, filter-wise, layer-wise and even network-wise pruning. Quantization <span class="search-hit mathjax">reduces</span> computations by <span class="search-hit mathjax">reducing</span> the precision of the datatype. Weights, biases, and activations may be quantized typically to 8-bit integers although lower bit width implementations are also discussed including binary neural networks. Both pruning and quantization can be used independently or combined. We compare current techniques, analyze their strengths and weaknesses, present compressed network accuracy results on a number of frameworks, and provide practical guidance for compressing networks.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.09671v3-abstract-full').style.display = 'none'; document.getElementById('2101.09671v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 June, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 24 January, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2101.09359">arXiv:2101.09359</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2101.09359">pdf</a>, <a href="https://arxiv.org/format/2101.09359">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Load-Balancing for <span class="search-hit mathjax">Improving</span> User Responsiveness on Multicore Embedded Systems
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Lim%2C+G">Geunsik Lim</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Min%2C+C">Changwoo Min</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Eom%2C+Y">YoungIk Eom</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2101.09359v1-abstract-short" style="display: inline;">
        Most commercial embedded devices have been deployed with a single processor architecture. The <span class="search-hit mathjax">code</span> size and complexity of&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.09359v1-abstract-full').style.display = 'inline'; document.getElementById('2101.09359v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2101.09359v1-abstract-full" style="display: none;">
        Most commercial embedded devices have been deployed with a single processor architecture. The <span class="search-hit mathjax">code</span> size and complexity of <span class="search-hit mathjax">applications</span> running on embedded devices are rapidly increasing due to the emergence of <span class="search-hit mathjax">application</span> business models such as Google Play Store and Apple App Store. As a result, a high-performance multicore CPUs have become a major trend in the embedded market as well as in the personal computer market. Due to this trend, many device manufacturers have been able to adopt more attractive user interfaces and high-performance <span class="search-hit mathjax">applications</span> for better user experiences on the multicore systems. In this paper, we describe how to <span class="search-hit mathjax">improve</span> the real-<span class="search-hit mathjax">time</span> performance by <span class="search-hit mathjax">reducing</span> the user waiting <span class="search-hit mathjax">time</span> on multicore systems that use a partitioned per-CPU run queue scheduling technique. Rather than focusing on naive load-balancing scheme for equally balanced CPU usage, our approach tries to minimize the cost of task migration by considering the importance level of running tasks and to <span class="search-hit mathjax">optimize</span> per-CPU utilization on multicore embedded systems. Consequently, our approach <span class="search-hit mathjax">improves</span> the real-<span class="search-hit mathjax">time</span> characteristics such as cache efficiency, user responsiveness, and latency. Experimental results under heavy background stress show that our approach <span class="search-hit mathjax">reduces</span> the average scheduling latency of an urgent task by 2.3 <span class="search-hit mathjax">times</span>.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.09359v1-abstract-full').style.display = 'none'; document.getElementById('2101.09359v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 20 January, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2101.09194">arXiv:2101.09194</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2101.09194">pdf</a>, <a href="https://arxiv.org/format/2101.09194">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        It Takes Two to Tango: Combining Visual and Textual Information for Detecting Duplicate Video-Based Bug Reports
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Cooper%2C+N">Nathan Cooper</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bernal-C%C3%A1rdenas%2C+C">Carlos Bernal-CÃ¡rdenas</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chaparro%2C+O">Oscar Chaparro</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moran%2C+K">Kevin Moran</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Poshyvanyk%2C+D">Denys Poshyvanyk</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2101.09194v2-abstract-short" style="display: inline;">
        When a bug manifests in a user-facing <span class="search-hit mathjax">application</span>, it is likely to be exposed through the graphical user interface (GUI). Given the importance of visual information to the process of identifying and understanding such bugs, users are increasingly making use of screenshots and screen-recordings as a means to report issues to developers. However, when such inf&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.09194v2-abstract-full').style.display = 'inline'; document.getElementById('2101.09194v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2101.09194v2-abstract-full" style="display: none;">
        When a bug manifests in a user-facing <span class="search-hit mathjax">application</span>, it is likely to be exposed through the graphical user interface (GUI). Given the importance of visual information to the process of identifying and understanding such bugs, users are increasingly making use of screenshots and screen-recordings as a means to report issues to developers. However, when such information is reported en masse, such as during crowd-sourced testing, managing these artifacts can be a <span class="search-hit mathjax">time</span>-consuming process. As the reporting of screen-recordings in particular becomes more popular, developers are likely to face challenges related to manually identifying videos that depict duplicate bugs. Due to their graphical nature, screen-recordings present challenges for <span class="search-hit mathjax">automated</span> analysis that preclude the use of current duplicate bug report detection techniques. To overcome these challenges and aid developers in this task, this paper presents Tango, a duplicate detection technique that operates purely on video-based bug reports by leveraging both visual and textual information. Tango combines tailored computer vision techniques, optical character recognition, and text retrieval. We evaluated multiple configurations of Tango in a comprehensive empirical evaluation on 4,860 duplicate detection tasks that involved a total of 180 screen-recordings from six Android apps. Additionally, we conducted a user study investigating the effort required for developers to manually detect duplicate video-based bug reports and compared this to the effort required to use Tango. The results reveal that Tango&#39;s <span class="search-hit mathjax">optimal</span> configuration is highly effective at detecting duplicate video-based bug reports, accurately ranking target duplicate videos in the top-2 returned results in 83% of the tasks. Additionally, our user study shows that, on average, Tango can <span class="search-hit mathjax">reduce</span> developer effort by over 60%, illustrating its practicality.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.09194v2-abstract-full').style.display = 'none'; document.getElementById('2101.09194v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 5 February, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 22 January, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">13 pages and 1 figure. Published at ICSE&#39;21</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2101.08763">arXiv:2101.08763</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2101.08763">pdf</a>, <a href="https://arxiv.org/ps/2101.08763">ps</a>, <a href="https://arxiv.org/format/2101.08763">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        GPU-Accelerated <span class="search-hit mathjax">Optimizer</span>-Aware Evaluation of Submodular Exemplar Clustering
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Honysz%2C+P">Philipp-Jan Honysz</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Buschj%C3%A4ger%2C+S">Sebastian BuschjÃ¤ger</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Morik%2C+K">Katharina Morik</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2101.08763v1-abstract-short" style="display: inline;">
        The <span class="search-hit mathjax">optimization</span> of submodular functions constitutes a viable way to perform clustering. Strong approximation guarantees and feasible&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.08763v1-abstract-full').style.display = 'inline'; document.getElementById('2101.08763v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2101.08763v1-abstract-full" style="display: none;">
        The <span class="search-hit mathjax">optimization</span> of submodular functions constitutes a viable way to perform clustering. Strong approximation guarantees and feasible <span class="search-hit mathjax">optimization</span> w.r.t. streaming data make this clustering approach favorable. Technically, submodular functions map subsets of data to real values, which indicate how &#34;representative&#34; a specific subset is. <span class="search-hit mathjax">Optimal</span> sets might then be used to partition the data space and to infer clusters. Exemplar-based clustering is one of the possible submodular functions, but suffers from high computational complexity. However, for practical <span class="search-hit mathjax">applications</span>, the particular real-<span class="search-hit mathjax">time</span> or wall-clock run-<span class="search-hit mathjax">time</span> is decisive. In this work, we present a novel way to evaluate this particular function on GPUs, which keeps the necessities of <span class="search-hit mathjax">optimizers</span> in mind and <span class="search-hit mathjax">reduces</span> wall-clock run-<span class="search-hit mathjax">time</span>. To discuss our GPU algorithm, we investigated both the impact of different run-<span class="search-hit mathjax">time</span> critical problem properties, like data dimensionality and the number of data points in a subset, and the influence of required floating-point precision. In reproducible experiments, our GPU algorithm was able to achieve competitive <span class="search-hit mathjax">speedups</span> of up to 72x depending on whether multi-threaded computation on CPUs was used for comparison and the type of floating-point precision required. Half-precision GPU computation led to large <span class="search-hit mathjax">speedups</span> of up to 452x compared to single-precision, single-thread CPU computations.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.08763v1-abstract-full').style.display = 'none'; document.getElementById('2101.08763v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 21 January, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2101.07910">arXiv:2101.07910</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2101.07910">pdf</a>, <a href="https://arxiv.org/format/2101.07910">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A Search-Based Testing Framework for Deep Neural Networks of Source <span class="search-hit mathjax">Code</span> Embedding
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Pour%2C+M+V">Maryam Vahdat Pour</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+Z">Zhuo Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+L">Lei Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hemmati%2C+H">Hadi Hemmati</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2101.07910v1-abstract-short" style="display: inline;">
        Over the past few years, deep neural networks (DNNs) have been continuously expanding their real-world <span class="search-hit mathjax">applications</span> for source&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.07910v1-abstract-full').style.display = 'inline'; document.getElementById('2101.07910v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2101.07910v1-abstract-full" style="display: none;">
        Over the past few years, deep neural networks (DNNs) have been continuously expanding their real-world <span class="search-hit mathjax">applications</span> for source <span class="search-hit mathjax">code</span> processing tasks across the <span class="search-hit mathjax">software</span> engineering domain, e.g., clone detection, <span class="search-hit mathjax">code</span> search, comment generation. Although quite a few recent works have been performed on testing of DNNs in the context of image and speech processing, limited progress has been achieved so far on DNN testing in the context of source <span class="search-hit mathjax">code</span> processing, that exhibits rather unique characteristics and challenges.
  In this paper, we propose a search-based testing framework for DNNs of source <span class="search-hit mathjax">code</span> embedding and its downstream processing tasks like <span class="search-hit mathjax">Code</span> Search. To generate new test inputs, we adopt popular source <span class="search-hit mathjax">code</span> refactoring tools to generate the semantically equivalent variants. For more effective testing, we leverage the DNN mutation testing to guide the testing direction. To demonstrate the usefulness of our technique, we perform a large-scale evaluation on popular DNNs of source <span class="search-hit mathjax">code</span> processing based on multiple state-of-the-art <span class="search-hit mathjax">code</span> embedding methods (i.e., Code2vec, Code2seq and CodeBERT). The testing results show that our generated adversarial samples can on average <span class="search-hit mathjax">reduce</span> the performance of these DNNs from 5.41% to 9.58%. Through retraining the DNNs with our generated adversarial samples, the robustness of DNN can <span class="search-hit mathjax">improve</span> by 23.05% on average. The evaluation results also show that our adversarial test generation strategy has the least negative impact (median of 3.56%), on the performance of the DNNs for regular test data, compared to the other methods.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.07910v1-abstract-full').style.display = 'none'; document.getElementById('2101.07910v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 19 January, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">ICST 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2101.07813">arXiv:2101.07813</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2101.07813">pdf</a>, <a href="https://arxiv.org/format/2101.07813">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Quantum Physics">quant-ph</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Data Structures and Algorithms">cs.DS</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Solving Quadratic Unconstrained Binary <span class="search-hit mathjax">Optimization</span> with divide-and-conquer and quantum algorithms
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Guerreschi%2C+G+G">Gian Giacomo Guerreschi</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2101.07813v1-abstract-short" style="display: inline;">
        Quadratic Unconstrained Binary <span class="search-hit mathjax">Optimization</span> (QUBO) is a broad class of&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.07813v1-abstract-full').style.display = 'inline'; document.getElementById('2101.07813v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2101.07813v1-abstract-full" style="display: none;">
        Quadratic Unconstrained Binary <span class="search-hit mathjax">Optimization</span> (QUBO) is a broad class of <span class="search-hit mathjax">optimization</span> problems with many practical <span class="search-hit mathjax">applications</span>. To solve its hard instances in an exact way, known classical algorithms require exponential <span class="search-hit mathjax">time</span> and several approximate methods have been devised to <span class="search-hit mathjax">reduce</span> such cost. With the growing maturity of quantum computing, quantum algorithms have been proposed to <span class="search-hit mathjax">speed</span> up the solution by using either quantum annealers or universal quantum computers. Here we apply the divide-and-conquer approach to <span class="search-hit mathjax">reduce</span> the original problem to a collection of smaller problems whose solutions can be assembled to form a single Polynomial Binary Unconstrained <span class="search-hit mathjax">Optimization</span> instance with fewer variables. This technique can be applied to any QUBO instance and leads to either an all-classical or a hybrid quantum-classical approach. When quantum heuristics like the Quantum Approximate <span class="search-hit mathjax">Optimization</span> Algorithm (QAOA) are used, our proposal leads to a double advantage: a substantial reduction of quantum resources, specifically an average of ~42% fewer qubits to solve MaxCut on random 3-regular graphs, together with an <span class="search-hit mathjax">improvement</span> in the quality of the approximate solutions reached.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.07813v1-abstract-full').style.display = 'none'; document.getElementById('2101.07813v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 19 January, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2101.07430">arXiv:2101.07430</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2101.07430">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Neural and Evolutionary Computing">cs.NE</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A Surrogate-Assisted Variable Grouping Algorithm for General Large Scale Global <span class="search-hit mathjax">Optimization</span> Problems
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+A">An Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ren%2C+Z">Zhigang Ren</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+M">Muyi Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liang%2C+Y">Yongsheng Liang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+H">Hanqing Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Du%2C+W">Wenhao Du</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2101.07430v1-abstract-short" style="display: inline;">
        Problem decomposition plays a vital role when applying cooperative coevolution (CC) to large scale global <span class="search-hit mathjax">optimization</span> problems. However, most learning-based decomposition algorithms either only apply to additively separable problems or face the issue of false separability detections. Directing against these limitations, this study proposes a novel decomposi&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.07430v1-abstract-full').style.display = 'inline'; document.getElementById('2101.07430v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2101.07430v1-abstract-full" style="display: none;">
        Problem decomposition plays a vital role when applying cooperative coevolution (CC) to large scale global <span class="search-hit mathjax">optimization</span> problems. However, most learning-based decomposition algorithms either only apply to additively separable problems or face the issue of false separability detections. Directing against these limitations, this study proposes a novel decomposition algorithm called surrogate-assisted variable grouping (SVG). SVG first designs a general-separability-oriented detection criterion according to whether the optimum of a variable changes with other variables. This criterion is consistent with the separability definition and thus endows SVG with broad <span class="search-hit mathjax">applicability</span> and high accuracy. To <span class="search-hit mathjax">reduce</span> the fitness evaluation requirement, SVG seeks the optimum of a variable with the help of a surrogate model rather than the original expensive high-dimensional model. Moreover, it converts the variable grouping process into a dynamic-binary-tree search one, which facilitates reutilizing historical separability detection information and thus <span class="search-hit mathjax">reducing</span> detection <span class="search-hit mathjax">times</span>. To evaluate the performance of SVG, a suite of benchmark functions with up to 2000 dimensions, including additively and non-additively separable ones, were designed. Experimental results on these functions indicate that, compared with six state-of-the-art decomposition algorithms, SVG possesses broader <span class="search-hit mathjax">applicability</span> and competitive efficiency. Furthermore, it can significantly enhance the <span class="search-hit mathjax">optimization</span> performance of CC.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.07430v1-abstract-full').style.display = 'none'; document.getElementById('2101.07430v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 18 January, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2101.07412">arXiv:2101.07412</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2101.07412">pdf</a>, <a href="https://arxiv.org/format/2101.07412">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Audio and Speech Processing">eess.AS</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Sound">cs.SD</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        <span class="search-hit mathjax">Improved</span> parallel WaveGAN vocoder with perceptually weighted spectrogram loss
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Song%2C+E">Eunwoo Song</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yamamoto%2C+R">Ryuichi Yamamoto</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hwang%2C+M">Min-Jae Hwang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kim%2C+J">Jin-Seob Kim</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kwon%2C+O">Ohsung Kwon</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kim%2C+J">Jae-Min Kim</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2101.07412v1-abstract-short" style="display: inline;">
        &hellip;weighting technique for Parallel WaveGAN-based text-to-speech (TTS) systems. The recently proposed Parallel WaveGAN vocoder successfully generates waveform sequences using a <span class="search-hit mathjax">fast</span> non-autoregressive WaveNet model. By employing multi-resolution short-&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.07412v1-abstract-full').style.display = 'inline'; document.getElementById('2101.07412v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2101.07412v1-abstract-full" style="display: none;">
        This paper proposes a spectral-domain perceptual weighting technique for Parallel WaveGAN-based text-to-speech (TTS) systems. The recently proposed Parallel WaveGAN vocoder successfully generates waveform sequences using a <span class="search-hit mathjax">fast</span> non-autoregressive WaveNet model. By employing multi-resolution short-<span class="search-hit mathjax">time</span> Fourier transform (MR-STFT) criteria with a generative adversarial network, the light-weight convolutional networks can be effectively trained without any distillation process. To further <span class="search-hit mathjax">improve</span> the vocoding performance, we propose the <span class="search-hit mathjax">application</span> of frequency-dependent weighting to the MR-STFT loss function. The proposed method penalizes perceptually-sensitive errors in the frequency domain; thus, the model is <span class="search-hit mathjax">optimized</span> toward <span class="search-hit mathjax">reducing</span> auditory noise in the synthesized speech. Subjective listening test results demonstrate that our proposed method achieves 4.21 and 4.26 TTS mean opinion scores for female and male Korean speakers, respectively.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.07412v1-abstract-full').style.display = 'none'; document.getElementById('2101.07412v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 18 January, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">To appear in SLT 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2101.07327">arXiv:2101.07327</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2101.07327">pdf</a>, <a href="https://arxiv.org/format/2101.07327">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Networking and Internet Architecture">cs.NI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">cs.HC</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Operating Systems">cs.OS</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        OpenUVR: an Open-Source System Framework for Untethered Virtual Reality <span class="search-hit mathjax">Applications</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Rohloff%2C+A">Alec Rohloff</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Allen%2C+Z">Zackary Allen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lin%2C+K">Kung-Min Lin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Okrend%2C+J">Joshua Okrend</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Nie%2C+C">Chengyi Nie</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+Y">Yu-Chia Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tseng%2C+H">Hung-Wei Tseng</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2101.07327v1-abstract-short" style="display: inline;">
        Advancements in heterogeneous computing technologies enable the significant potential of virtual reality (VR) <span class="search-hit mathjax">applications</span>. To offer the best user experience (UX), a system should adopt an untethered, wireless-network-based architecture to transfer VR content between the user and the content generator. However, modern wireless network technologies make imple&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.07327v1-abstract-full').style.display = 'inline'; document.getElementById('2101.07327v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2101.07327v1-abstract-full" style="display: none;">
        Advancements in heterogeneous computing technologies enable the significant potential of virtual reality (VR) <span class="search-hit mathjax">applications</span>. To offer the best user experience (UX), a system should adopt an untethered, wireless-network-based architecture to transfer VR content between the user and the content generator. However, modern wireless network technologies make implementing such an architecture challenging, as VR <span class="search-hit mathjax">applications</span> require superior video quality -- with high resolution, high frame rates, and very low latency.
  This paper presents OpenUVR, an open-source framework that uses commodity hardware components to satisfy the demands of interactive, real-<span class="search-hit mathjax">time</span> VR <span class="search-hit mathjax">applications</span>. OpenUVR significantly <span class="search-hit mathjax">improves</span> UX through a redesign of the system stack and addresses the most <span class="search-hit mathjax">time</span>-sensitive issues associated with redundant memory copying in modern computing systems. OpenUVR presents a cross-layered VR datapath to avoid redundant data operations and computation among system components, OpenUVR customizes the network stack to eliminate unnecessary memory operations incurred by mismatching data formats in each layer, and OpenUVR uses feedback from mobile devices to remove memory buffers.
  Together, these modifications allow OpenUVR to <span class="search-hit mathjax">reduce</span> VR <span class="search-hit mathjax">application</span> delays to 14.32 ms, meeting the 20 ms minimum latency in avoiding motion sickness. As an open-source system that is fully compatible with commodity hardware, OpenUVR offers the research community an opportunity to develop, investigate, and <span class="search-hit mathjax">optimize</span> <span class="search-hit mathjax">applications</span> for untethered, high-performance VR architectures.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.07327v1-abstract-full').style.display = 'none'; document.getElementById('2101.07327v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 18 January, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2101.07004">arXiv:2101.07004</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2101.07004">pdf</a>, <a href="https://arxiv.org/format/2101.07004">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Information Theory">cs.IT</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Machine Learning-Enabled Joint Antenna Selection and Precoding Design: From Offline Complexity to Online Performance
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Vu%2C+T+X">Thang X. Vu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chatzinotas%2C+S">Symeon Chatzinotas</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Nguyen%2C+V">Van-Dinh Nguyen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hoang%2C+D+T">Dinh Thai Hoang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Nguyen%2C+D+N">Diep N. Nguyen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Di+Renzo%2C+M">Marco Di Renzo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ottersten%2C+B">Bjorn Ottersten</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2101.07004v1-abstract-short" style="display: inline;">
        &hellip;power constraint and QoS requirements. The JASPD overcomes the non-convexity of the formulated problem via a doubly iterative algorithm, in which an inner loop successively <span class="search-hit mathjax">optimizes</span> the precoding vectors, followed by an outer loop that tries all valid antenna subsets. Although approaching the (near) global&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.07004v1-abstract-full').style.display = 'inline'; document.getElementById('2101.07004v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2101.07004v1-abstract-full" style="display: none;">
        We investigate the performance of multi-user multiple-antenna downlink systems in which a BS serves multiple users via a shared wireless medium. In order to fully exploit the spatial diversity while minimizing the passive energy consumed by radio frequency (RF) components, the BS is equipped with M RF chains and N antennas, where M &lt; N. Upon receiving pilot sequences to obtain the channel state information, the BS determines the best subset of M antennas for serving the users. We propose a joint antenna selection and precoding design (JASPD) algorithm to maximize the system sum rate subject to a transmit power constraint and QoS requirements. The JASPD overcomes the non-convexity of the formulated problem via a doubly iterative algorithm, in which an inner loop successively <span class="search-hit mathjax">optimizes</span> the precoding vectors, followed by an outer loop that tries all valid antenna subsets. Although approaching the (near) global <span class="search-hit mathjax">optimality</span>, the JASPD suffers from a combinatorial complexity, which may limit its <span class="search-hit mathjax">application</span> in real-<span class="search-hit mathjax">time</span> network operations. To overcome this limitation, we propose a learning-based antenna selection and precoding design algorithm (L-ASPA), which employs a DNN to establish underlaying relations between the key system parameters and the selected antennas. The proposed L-ASPD is robust against the number of users and their locations, BS&#39;s transmit power, as well as the small-scale channel fading. With a well-trained learning model, it is shown that the L-ASPD significantly outperforms baseline schemes based on the block diagonalization and a learning-assisted solution for broadcasting systems and achieves higher effective sum rate than that of the JASPA under limited processing <span class="search-hit mathjax">time</span>. In addition, we observed that the proposed L-ASPD can <span class="search-hit mathjax">reduce</span> the computation complexity by 95% while retaining more than 95% of the <span class="search-hit mathjax">optimal</span> performance.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.07004v1-abstract-full').style.display = 'none'; document.getElementById('2101.07004v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 18 January, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">accepted to the IEEE Transactions on Wireless Communications</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2101.06594">arXiv:2101.06594</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2101.06594">pdf</a>, <a href="https://arxiv.org/format/2101.06594">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        PLUME: Efficient 3D Object Detection from Stereo Images
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+Y">Yan Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yang%2C+B">Bin Yang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hu%2C+R">Rui Hu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liang%2C+M">Ming Liang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Urtasun%2C+R">Raquel Urtasun</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2101.06594v2-abstract-short" style="display: inline;">
        3D object detection plays a significant role in various robotic <span class="search-hit mathjax">applications</span> including self-driving. While many approaches rely on expensive 3D sensors like LiDAR to produce accurate 3D estimates, stereo-based methods have recently shown promising results at a lower cost. Existing methods tackle the problem in two steps: first depth estimation is performed,&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.06594v2-abstract-full').style.display = 'inline'; document.getElementById('2101.06594v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2101.06594v2-abstract-full" style="display: none;">
        3D object detection plays a significant role in various robotic <span class="search-hit mathjax">applications</span> including self-driving. While many approaches rely on expensive 3D sensors like LiDAR to produce accurate 3D estimates, stereo-based methods have recently shown promising results at a lower cost. Existing methods tackle the problem in two steps: first depth estimation is performed, a pseudo LiDAR point cloud representation is computed from the depth estimates, and then object detection is performed in 3D space. However, because the two separate tasks are <span class="search-hit mathjax">optimized</span> in different metric spaces, the depth estimation is biased towards nearby objects and may cause sub-<span class="search-hit mathjax">optimal</span> performance of 3D detection. In this paper we propose a model that unifies these two tasks in the same metric space. Specifically, our model directly constructs a pseudo LiDAR feature volume (PLUME) in 3D space, which is used to solve both occupancy estimation and object detection tasks. Our approach achieves state-of-the-art performance on the challenging KITTI benchmark, with significantly <span class="search-hit mathjax">reduced</span> inference <span class="search-hit mathjax">time</span> compared with existing methods.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.06594v2-abstract-full').style.display = 'none'; document.getElementById('2101.06594v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 11 March, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 17 January, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2101.06371">arXiv:2101.06371</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2101.06371">pdf</a>, <a href="https://arxiv.org/format/2101.06371">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        NNStreamer: Efficient and Agile Development of On-Device AI Systems
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ham%2C+M">MyungJoo Ham</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moon%2C+J">Jijoong Moon</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lim%2C+G">Geunsik Lim</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jung%2C+J">Jaeyun Jung</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ahn%2C+H">Hyoungjoo Ahn</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Song%2C+W">Wook Song</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Woo%2C+S">Sangjung Woo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kapoor%2C+P">Parichay Kapoor</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chae%2C+D">Dongju Chae</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jang%2C+G">Gichan Jang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ahn%2C+Y">Yongjoo Ahn</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lee%2C+J">Jihoon Lee</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2101.06371v1-abstract-short" style="display: inline;">
        We propose NNStreamer, a <span class="search-hit mathjax">software</span> system that handles neural networks as filters of stream pipelines, applying the stream processing paradigm to deep neural network&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.06371v1-abstract-full').style.display = 'inline'; document.getElementById('2101.06371v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2101.06371v1-abstract-full" style="display: none;">
        We propose NNStreamer, a <span class="search-hit mathjax">software</span> system that handles neural networks as filters of stream pipelines, applying the stream processing paradigm to deep neural network <span class="search-hit mathjax">applications</span>. A new trend with the wide-spread of deep neural network <span class="search-hit mathjax">applications</span> is on-device AI. It is to process neural networks on mobile devices or edge/IoT devices instead of cloud servers. Emerging privacy issues, data transmission costs, and operational costs signify the need for on-device AI, especially if we deploy a massive number of devices. NNStreamer efficiently handles neural networks with complex data stream pipelines on devices, significantly <span class="search-hit mathjax">improving</span> the overall performance with minimal efforts. Besides, NNStreamer simplifies implementations and allows reusing off-the-shelf media filters directly, which <span class="search-hit mathjax">reduces</span> developmental costs significantly. We are already deploying NNStreamer for a wide range of products and platforms, including the Galaxy series and various consumer electronic devices. The experimental results suggest a reduction in developmental costs and enhanced performance of pipeline architectures and NNStreamer. It is an open-source project incubated by Linux Foundation AI, available to the public and <span class="search-hit mathjax">applicable</span> to various hardware and <span class="search-hit mathjax">software</span> platforms.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.06371v1-abstract-full').style.display = 'none'; document.getElementById('2101.06371v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 January, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">IEEE/ACM ICSE 2021 SEIP (preprint)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2101.05216">arXiv:2101.05216</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2101.05216">pdf</a>, <a href="https://arxiv.org/format/2101.05216">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        AttentionLite: Towards Efficient Self-Attention Models for Vision
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Kundu%2C+S">Souvik Kundu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sundaresan%2C+S">Sairam Sundaresan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2101.05216v1-abstract-short" style="display: inline;">
        We propose a novel framework for producing a class of parameter and compute efficient models called AttentionLitesuitable for resource-constrained <span class="search-hit mathjax">applications</span>. Prior work has primarily focused on&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.05216v1-abstract-full').style.display = 'inline'; document.getElementById('2101.05216v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2101.05216v1-abstract-full" style="display: none;">
        We propose a novel framework for producing a class of parameter and compute efficient models called AttentionLitesuitable for resource-constrained <span class="search-hit mathjax">applications</span>. Prior work has primarily focused on <span class="search-hit mathjax">optimizing</span> models either via knowledge distillation or pruning. In addition to fusing these two mechanisms, our joint <span class="search-hit mathjax">optimization</span> framework also leverages recent advances in self-attention as a substitute for convolutions. We can simultaneously distill knowledge from a compute-heavy teacher while also pruning the student model in a single pass of training thereby <span class="search-hit mathjax">reducing</span> training and fine-tuning <span class="search-hit mathjax">times</span> considerably. We evaluate the merits of our proposed approach on the CIFAR-10, CIFAR-100, and Tiny-ImageNet datasets. Not only do our AttentionLite models significantly outperform their unoptimized counterparts in accuracy, we find that in some cases, that they perform almost as well as their compute-heavy teachers while consuming only a fraction of the parameters and FLOPs. Concretely, AttentionLite models can achieve upto30x parameter efficiency and 2x computation efficiency with no significant accuracy drop compared to their teacher.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.05216v1-abstract-full').style.display = 'none'; document.getElementById('2101.05216v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 21 December, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">5 pages, 3 figures, 2 tables</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2101.04434">arXiv:2101.04434</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2101.04434">pdf</a>, <a href="https://arxiv.org/format/2101.04434">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Developing an OpenAI Gym-compatible framework and simulation environment for testing Deep Reinforcement Learning agents solving the Ambulance Location Problem
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Allen%2C+M">Michael Allen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pearn%2C+K">Kerry Pearn</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Monks%2C+T">Tom Monks</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2101.04434v2-abstract-short" style="display: inline;">
        Background and motivation: Deep Reinforcement Learning (Deep RL) is a rapidly developing field. Historically most <span class="search-hit mathjax">application</span> has been made to games (such as chess, Atari games, and go). Deep RL is now reaching the stage where it may offer value in real world problems, including optimisation of healthcare systems. One such problem is where to locate ambulanc&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.04434v2-abstract-full').style.display = 'inline'; document.getElementById('2101.04434v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2101.04434v2-abstract-full" style="display: none;">
        Background and motivation: Deep Reinforcement Learning (Deep RL) is a rapidly developing field. Historically most <span class="search-hit mathjax">application</span> has been made to games (such as chess, Atari games, and go). Deep RL is now reaching the stage where it may offer value in real world problems, including optimisation of healthcare systems. One such problem is where to locate ambulances between calls in order to minimise <span class="search-hit mathjax">time</span> from emergency call to ambulance on-scene. This is known as the Ambulance Location problem.
  Aim: To develop an OpenAI Gym-compatible framework and simulation environment for testing Deep RL agents.
  Methods: A custom ambulance dispatch simulation environment was developed using OpenAI Gym and SimPy. Deep RL agents were built using PyTorch. The environment is a simplification of the real world, but allows control over the number of clusters of incident locations, number of possible dispatch locations, number of hospitals, and creating incidents that occur at different locations throughout each day.
  Results: A range of Deep RL agents based on Deep Q networks were tested in this custom environment. All <span class="search-hit mathjax">reduced</span> <span class="search-hit mathjax">time</span> to respond to emergency calls compared with random allocation to dispatch points. Bagging Noisy Duelling Deep Q networks gave the most consistence performance. All methods had a tendency to lose performance if trained for too long, and so agents were saved at their <span class="search-hit mathjax">optimal</span> performance (and tested on independent simulation runs).
  Conclusions: Deep RL agents, developed using simulated environments, have the potential to offer a novel approach to optimise the Ambulance Location problem. Creating open simulation environments should allow more rapid progress in this field.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.04434v2-abstract-full').style.display = 'none'; document.getElementById('2101.04434v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 13 January, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 12 January, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Fig 1 updated since first version (corrected panel 3 which previously replicated panel 2)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2101.02270">arXiv:2101.02270</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2101.02270">pdf</a>, <a href="https://arxiv.org/format/2101.02270">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computational Engineering, Finance, and Science">cs.CE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1016/j.segan.2021.100483">10.1016/j.segan.2021.100483 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        <span class="search-hit mathjax">Fast</span> Parallel Newton-Raphson Power Flow Solver for Large Number of System Calculations with CPU and GPU
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+Z">Zhenqi Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Berg%2C+S+W">Sebastian Wende-von Berg</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Braun%2C+M">Martin Braun</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2101.02270v3-abstract-short" style="display: inline;">
        &hellip;analyze large sets of grid states, e.g. when evaluating the impact from the uncertainties of the renewable generation with probabilistic Monte Carlo simulation or in stationary <span class="search-hit mathjax">time</span> series simulation, large number of power flow calculations have to be performed. For the&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.02270v3-abstract-full').style.display = 'inline'; document.getElementById('2101.02270v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2101.02270v3-abstract-full" style="display: none;">
        To analyze large sets of grid states, e.g. when evaluating the impact from the uncertainties of the renewable generation with probabilistic Monte Carlo simulation or in stationary <span class="search-hit mathjax">time</span> series simulation, large number of power flow calculations have to be performed. For the <span class="search-hit mathjax">application</span> in real-<span class="search-hit mathjax">time</span> grid operation, grid planning and in further cases when computational <span class="search-hit mathjax">time</span> is critical, a novel approach on simultaneous parallelization of many Newton-Raphson power flow calculations on CPU and with GPU-acceleration is proposed. The result shows a <span class="search-hit mathjax">speed</span>-up of over x100 comparing to the open-source tool pandapower, when performing repetitive power flows of system with admittance matrix of the same sparsity pattern on both CPU and GPU. The <span class="search-hit mathjax">speed</span>-up relies on the algorithm <span class="search-hit mathjax">improvement</span> and highly <span class="search-hit mathjax">optimized</span> parallelization strategy, which can <span class="search-hit mathjax">reduce</span> the repetitive work and saturate the high hardware computational capability of modern CPUs and GPUs well. This is achieved with the proposed batched sparse matrix operation and batched linear solver based on LU-refactorization. The batched linear solver shows a large performance <span class="search-hit mathjax">improvement</span> comparing to the state-of-the-art linear system solver KLU library and a better saturation of the GPU performance with small problem scale. Finally, the method of integrating the proposed solver into pandapower is presented, thus the parallel power flow solver with outstanding performance can be easily applied in challenging real-life grid operation and innovative researches e.g. data-driven machine learning studies.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.02270v3-abstract-full').style.display = 'none'; document.getElementById('2101.02270v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 28 April, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 6 January, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">preprint accepted in Sustainable Energy, Grids and Networks</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2101.01505">arXiv:2101.01505</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2101.01505">pdf</a>, <a href="https://arxiv.org/format/2101.01505">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Delayed Projection Techniques for Linearly Constrained Problems: Convergence Rates, Acceleration, and <span class="search-hit mathjax">Applications</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+X">Xiang Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+Z">Zhihua Zhang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2101.01505v1-abstract-short" style="display: inline;">
        In this work, we study a novel class of projection-based algorithms for linearly constrained problems (LCPs) which have a lot of <span class="search-hit mathjax">applications</span> in statistics,&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.01505v1-abstract-full').style.display = 'inline'; document.getElementById('2101.01505v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2101.01505v1-abstract-full" style="display: none;">
        In this work, we study a novel class of projection-based algorithms for linearly constrained problems (LCPs) which have a lot of <span class="search-hit mathjax">applications</span> in statistics, <span class="search-hit mathjax">optimization</span>, and machine learning. Conventional primal gradient-based methods for LCPs call a projection after each (stochastic) gradient descent, resulting in that the required number of projections equals that of gradient descents (or total iterations). Motivated by the recent progress in distributed <span class="search-hit mathjax">optimization</span>, we propose the delayed projection technique that calls a projection once for a while, lowering the projection frequency and <span class="search-hit mathjax">improving</span> the projection efficiency. Accordingly, we devise a series of stochastic methods for LCPs using the technique, including a variance <span class="search-hit mathjax">reduced</span> method and an accelerated one. We theoretically show that it is feasible to <span class="search-hit mathjax">improve</span> projection efficiency in both strongly convex and generally convex cases. Our analysis is simple and unified and can be easily extended to other methods using delayed projections. When applying our new algorithms to federated <span class="search-hit mathjax">optimization</span>, a newfangled and privacy-preserving subfield in distributed <span class="search-hit mathjax">optimization</span>, we obtain not only a variance <span class="search-hit mathjax">reduced</span> federated algorithm with convergence rates better than previous works, but also the first accelerated method able to handle data heterogeneity inherent in federated <span class="search-hit mathjax">optimization</span>.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.01505v1-abstract-full').style.display = 'none'; document.getElementById('2101.01505v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 5 January, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2101.01302">arXiv:2101.01302</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2101.01302">pdf</a>, <a href="https://arxiv.org/ps/2101.01302">ps</a>, <a href="https://arxiv.org/format/2101.01302">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Information Theory">cs.IT</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Exploiting Deep Learning for Secure Transmission in an Underlay Cognitive Radio Network
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+M">Miao Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cumanan%2C+K">Kanapathippillai Cumanan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Thiyagalingam%2C+J">Jeyarajan Thiyagalingam</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tang%2C+Y">Yanqun Tang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+W">Wei Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ding%2C+Z">Zhiguo Ding</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dobre%2C+O+A">Octavia A. Dobre</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2101.01302v1-abstract-short" style="display: inline;">
        &hellip;is the capability to solve the power allocation problem with both perfect and imperfect channel state information. In a conventional setting, two completely different <span class="search-hit mathjax">optimization</span> frameworks have to be designed, namely the robust and non-robust designs. Furthermore, conventional algorithms are often based on iterative techniques, and hence, they require a co&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.01302v1-abstract-full').style.display = 'inline'; document.getElementById('2101.01302v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2101.01302v1-abstract-full" style="display: none;">
        This paper investigates a machine learning-based power allocation design for secure transmission in a cognitive radio (CR) network. In particular, a neural network (NN)-based approach is proposed to maximize the secrecy rate of the secondary receiver under the constraints of total transmit power of secondary transmitter, and the interference leakage to the primary receiver, within which three different regularization schemes are developed. The key advantage of the proposed algorithm over conventional approaches is the capability to solve the power allocation problem with both perfect and imperfect channel state information. In a conventional setting, two completely different <span class="search-hit mathjax">optimization</span> frameworks have to be designed, namely the robust and non-robust designs. Furthermore, conventional algorithms are often based on iterative techniques, and hence, they require a considerable number of iterations, rendering them less suitable in future wireless networks where there are very stringent delay constraints. To meet the unprecedented requirements of future ultra-reliable low-latency networks, we propose an NN-based approach that can determine the power allocation in a CR network with significantly <span class="search-hit mathjax">reduced</span> computational <span class="search-hit mathjax">time</span> and complexity. As this trained NN only requires a small number of linear operations to yield the required power allocations, the approach can also be extended to different delay sensitive <span class="search-hit mathjax">applications</span> and services in future wireless networks. When evaluate the proposed method versus conventional approaches, using a suitable test set, the proposed approach can achieve more than 94% of the secrecy rate performance with less than 1% computation <span class="search-hit mathjax">time</span> and more than 93% satisfaction of interference leakage constraints. These results are obtained with significant reduction in computational <span class="search-hit mathjax">time</span>, which we believe that it is suitable for future real-<span class="search-hit mathjax">time</span> wireless <span class="search-hit mathjax">applications</span>.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.01302v1-abstract-full').style.display = 'none'; document.getElementById('2101.01302v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 4 January, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2101.00958">arXiv:2101.00958</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2101.00958">pdf</a>, <a href="https://arxiv.org/format/2101.00958">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Logic in Computer Science">cs.LO</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Scalable Online Conformance Checking Using Incremental Prefix-Alignment Computation
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Schuster%2C+D">Daniel Schuster</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kolhof%2C+G+J">Gero J. Kolhof</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2101.00958v1-abstract-short" style="display: inline;">
        &hellip;We have, therefore, recently introduced a novel approach to compute exact conformance checking results in an online environment. In this paper, we focus on the practical <span class="search-hit mathjax">application</span> and present a scalable, distributed implementation of the proposed online conformance checking approach. Moreover, we present two extensions to said approach to&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.00958v1-abstract-full').style.display = 'inline'; document.getElementById('2101.00958v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2101.00958v1-abstract-full" style="display: none;">
        Conformance checking techniques aim to collate observed process behavior with normative/modeled process models. The majority of existing approaches focuses on completed process executions, i.e., offline conformance checking. Recently, novel approaches have been designed to monitor ongoing processes, i.e., online conformance checking. Such techniques detect deviations of an ongoing process execution from a normative process model at the moment they occur. Thereby, countermeasures can be taken immediately to prevent a process deviation from causing further, undesired consequences. Most online approaches only allow to detect approximations of deviations. This causes the problem of falsely detected deviations, i.e., detected deviations that are actually no deviations. We have, therefore, recently introduced a novel approach to compute exact conformance checking results in an online environment. In this paper, we focus on the practical <span class="search-hit mathjax">application</span> and present a scalable, distributed implementation of the proposed online conformance checking approach. Moreover, we present two extensions to said approach to <span class="search-hit mathjax">reduce</span> its computational effort and its practical <span class="search-hit mathjax">applicability</span>. We evaluate our implementation using data sets capturing the execution of real processes.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.00958v1-abstract-full').style.display = 'none'; document.getElementById('2101.00958v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 December, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2101.00256">arXiv:2101.00256</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2101.00256">pdf</a>, <a href="https://arxiv.org/format/2101.00256">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Networking and Internet Architecture">cs.NI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        5G MEC Computation Handoff for Mobile Augmented Reality
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zhou%2C+P">Pengyuan Zhou</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Finley%2C+B">Benjamin Finley</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+X">Xuebing Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tarkoma%2C+S">Sasu Tarkoma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kangasharju%2C+J">Jussi Kangasharju</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ammar%2C+M">Mostafa Ammar</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hui%2C+P">Pan Hui</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2101.00256v1-abstract-short" style="display: inline;">
        The combination of 5G and Multi-access Edge Computing (MEC) can significantly <span class="search-hit mathjax">reduce</span>&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.00256v1-abstract-full').style.display = 'inline'; document.getElementById('2101.00256v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2101.00256v1-abstract-full" style="display: none;">
        The combination of 5G and Multi-access Edge Computing (MEC) can significantly <span class="search-hit mathjax">reduce</span> <span class="search-hit mathjax">application</span> delay by lowering transmission delay and bringing computational capabilities closer to the end user. Therefore, 5G MEC could enable excellent user experience in <span class="search-hit mathjax">applications</span> like Mobile Augmented Reality (MAR), which are computation-intensive, and delay and jitter-sensitive. However, existing 5G handoff algorithms often do not consider the computational load of MEC servers, are too complex for real-<span class="search-hit mathjax">time</span> execution, or do not integrate easily with the standard protocol stack. Thus they can impair the performance of 5G MEC. To address this gap, we propose Comp-HO, a handoff algorithm that finds a local solution to the joint problem of <span class="search-hit mathjax">optimizing</span> signal strength and computational load. Additionally, Comp-HO can easily be integrated into current LTE and 5G base stations thanks to its simplicity and standard-friendly deployability. Specifically, we evaluate Comp-HO through a custom NS-3 simulator which we calibrate via MAR prototype measurements from a real-world 5G testbed. We simulate both Comp-HO and several classic handoff algorithms. The results show that, even without a global optimum, the proposed algorithm still significantly <span class="search-hit mathjax">reduces</span> the number of large delays, caused by congestion at MECs, at the expense of a small increase in transmission delay.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.00256v1-abstract-full').style.display = 'none'; document.getElementById('2101.00256v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 1 January, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Submitted to Mobihoc&#39;21</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2101.00236">arXiv:2101.00236</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2101.00236">pdf</a>, <a href="https://arxiv.org/format/2101.00236">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        On Stochastic Variance <span class="search-hit mathjax">Reduced</span> Gradient Method for Semidefinite <span class="search-hit mathjax">Optimization</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zeng%2C+J">Jinshan Zeng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zha%2C+Y">Yixuan Zha</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+K">Ke Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yao%2C+Y">Yuan Yao</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2101.00236v1-abstract-short" style="display: inline;">
        The low-rank stochastic semidefinite <span class="search-hit mathjax">optimization</span> has attracted rising attention due to its wide range of&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.00236v1-abstract-full').style.display = 'inline'; document.getElementById('2101.00236v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2101.00236v1-abstract-full" style="display: none;">
        The low-rank stochastic semidefinite <span class="search-hit mathjax">optimization</span> has attracted rising attention due to its wide range of <span class="search-hit mathjax">applications</span>. The nonconvex reformulation based on the low-rank factorization, significantly <span class="search-hit mathjax">improves</span> the computational efficiency but brings some new challenge to the analysis. The stochastic variance <span class="search-hit mathjax">reduced</span> gradient (SVRG) method has been regarded as one of the most effective methods. SVRG in general consists of two loops, where a reference full gradient is first evaluated in the outer loop and then used to yield a variance <span class="search-hit mathjax">reduced</span> estimate of the current gradient in the inner loop. Two options have been suggested to yield the output of the inner loop, where Option I sets the output as its last iterate, and Option II yields the output via random sampling from all the iterates in the inner loop. However, there is a significant gap between the theory and practice of SVRG when adapted to the stochastic semidefinite <span class="search-hit mathjax">programming</span> (SDP). SVRG practically works better with Option I, while most of existing theoretical results focus on Option II. In this paper, we fill this gap via exploiting a new semi-stochastic variant of the original SVRG with Option I adapted to the semidefinite <span class="search-hit mathjax">optimization</span>. Equipped with this, we establish the global linear submanifold convergence (i.e., converging exponentially <span class="search-hit mathjax">fast</span> to a submanifold of a global minimum under the orthogonal group action) of the proposed SVRG method, given a provable initialization scheme and under certain smoothness and restricted strongly convex assumptions. Our analysis includes the effects of the mini-batch size and update frequency in the inner loop as well as two practical step size strategies, the fixed and stabilized Barzilai-Borwein step sizes. Some numerical results in matrix sensing demonstrate the efficiency of proposed SVRG method outperforming Option II counterpart as well as others.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.00236v1-abstract-full').style.display = 'none'; document.getElementById('2101.00236v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 1 January, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">27 pages, 5 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2101.00090">arXiv:2101.00090</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2101.00090">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        PHP <span class="search-hit mathjax">code</span> smells in web apps: survival and anomalies
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Rio%2C+A">AmÃ©rico Rio</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Abreu%2C+F+B+e">Fernando Brito e Abreu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2101.00090v1-abstract-short" style="display: inline;">
        Context: <span class="search-hit mathjax">Code</span> smells are considered symptoms of poor design, leading to future problems, such as&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.00090v1-abstract-full').style.display = 'inline'; document.getElementById('2101.00090v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2101.00090v1-abstract-full" style="display: none;">
        Context: <span class="search-hit mathjax">Code</span> smells are considered symptoms of poor design, leading to future problems, such as <span class="search-hit mathjax">reduced</span> maintainability. Except for anecdotal cases (e. g. <span class="search-hit mathjax">code</span> dropout), a <span class="search-hit mathjax">code</span> smell survives until it gets explicitly refactored or removed. This paper presents a longitudinal study on the survival of <span class="search-hit mathjax">code</span> smells for web apps built with PHP.
  Objectives: RQ: (i) <span class="search-hit mathjax">code</span> smells survival depends on their scope? (ii) practitioners attitudes towards <span class="search-hit mathjax">code</span> smells removal in web apps have changed throughout <span class="search-hit mathjax">time</span>? (iii) how long <span class="search-hit mathjax">code</span> smells survive in web <span class="search-hit mathjax">applications</span>? (iv) are there sudden variations (anomalies) in the density of <span class="search-hit mathjax">code</span> smells through the evolution of web apps?
  Method: We analyze the evolution of 6 <span class="search-hit mathjax">code</span> smells in 8 web <span class="search-hit mathjax">applications</span> written in PHP at the server side, across several years, using the survival analysis technique. We classify <span class="search-hit mathjax">code</span> smells according to scope in two categories: scattered and localized. Scattered <span class="search-hit mathjax">code</span> smells are expected to be more harmful since their influence is not circumscribed as in localized <span class="search-hit mathjax">code</span> smells. We split the observations for each web app into two equal and consecutive timeframes, to test the hypothesis that <span class="search-hit mathjax">code</span> smells awareness has increased throughout <span class="search-hit mathjax">time</span>. As for the anomalies, we standardize their detection criteria.
  Results: We present some evidence that <span class="search-hit mathjax">code</span> smells survival depends on their scope: the average survival rate decreases in some of them, while the opposite is observed for the remainder. The survival of localized <span class="search-hit mathjax">code</span> smells is around 4 years, while the scattered ones live around 5 years. Around 60% of the smells are removed, and some live through all the <span class="search-hit mathjax">application</span> life. We also show how a graphical representation of anomalies found in the evolution of <span class="search-hit mathjax">code</span> smells allows unveiling the story of a development project and make managers aware of the need for enforcing regular refactoring practices.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.00090v1-abstract-full').style.display = 'none'; document.getElementById('2101.00090v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 31 December, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2021.
      
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          D.2
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2012.15002">arXiv:2012.15002</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2012.15002">pdf</a>, <a href="https://arxiv.org/ps/2012.15002">ps</a>, <a href="https://arxiv.org/format/2012.15002">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Data Structures and Algorithms">cs.DS</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        New Partitioning Techniques and <span class="search-hit mathjax">Faster</span> Algorithms for Approximate Interval Scheduling
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Compton%2C+S">Spencer Compton</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mitrovi%C4%87%2C+S">Slobodan MitroviÄ</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rubinfeld%2C+R">Ronitt Rubinfeld</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2012.15002v2-abstract-short" style="display: inline;">
        Interval scheduling is a basic problem in the theory of algorithms and a classical task in combinatorial <span class="search-hit mathjax">optimization</span>. We develop a set of techniques for partitioning and grouping jobs based on their starting and ending <span class="search-hit mathjax">times</span>, that enable us to view an instance of interval scheduling on many jobs as a union of multiple&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.15002v2-abstract-full').style.display = 'inline'; document.getElementById('2012.15002v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2012.15002v2-abstract-full" style="display: none;">
        Interval scheduling is a basic problem in the theory of algorithms and a classical task in combinatorial <span class="search-hit mathjax">optimization</span>. We develop a set of techniques for partitioning and grouping jobs based on their starting and ending <span class="search-hit mathjax">times</span>, that enable us to view an instance of interval scheduling on many jobs as a union of multiple interval scheduling instances, each containing only a few jobs. Instantiating these techniques in dynamic and local settings of computation leads to several new results.
  For $(1+\varepsilon)$-approximation of job scheduling of $n$ jobs on a single machine, we obtain a fully dynamic algorithm with $O(\frac{\log{n}}{\varepsilon})$ update and $O(\log{n})$ query worst-case <span class="search-hit mathjax">time</span>. Further, we design a local computation algorithm that uses only $O(\frac{\log{n}}{\varepsilon})$ queries. Our techniques are also <span class="search-hit mathjax">applicable</span> in a setting where jobs have rewards/weights. For this case we obtain a fully dynamic algorithm whose worst-case update and query <span class="search-hit mathjax">time</span> has only polynomial dependence on $1/\varepsilon$, which is an exponential <span class="search-hit mathjax">improvement</span> over the result of Henzinger et al. [SoCG, 2020].
  We extend our approaches for unweighted interval scheduling on a single machine to the setting with $M$ machines, while achieving the same approximation factor and only $M$ <span class="search-hit mathjax">times</span> slower update <span class="search-hit mathjax">time</span> in the dynamic setting. In addition, we provide a general framework for <span class="search-hit mathjax">reducing</span> the task of interval scheduling on $M$ machines to that of interval scheduling on a single machine. In the unweighted case this approach incurs a multiplicative approximation factor $2 - 1/M$.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.15002v2-abstract-full').style.display = 'none'; document.getElementById('2012.15002v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 10 March, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 29 December, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2012.13600">arXiv:2012.13600</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2012.13600">pdf</a>, <a href="https://arxiv.org/format/2012.13600">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Hardware Architecture">cs.AR</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1109/JETCAS.2020.3040300">10.1109/JETCAS.2020.3040300 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        EdgeDRNN: Recurrent Neural Network Accelerator for Edge Inference
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Gao%2C+C">Chang Gao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rios-Navarro%2C+A">Antonio Rios-Navarro</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+X">Xi Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+S">Shih-Chii Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Delbruck%2C+T">Tobi Delbruck</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2012.13600v1-abstract-short" style="display: inline;">
        Low-latency, low-power portable recurrent neural network (RNN) accelerators offer powerful inference capabilities for real-<span class="search-hit mathjax">time</span>&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.13600v1-abstract-full').style.display = 'inline'; document.getElementById('2012.13600v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2012.13600v1-abstract-full" style="display: none;">
        Low-latency, low-power portable recurrent neural network (RNN) accelerators offer powerful inference capabilities for real-<span class="search-hit mathjax">time</span> <span class="search-hit mathjax">applications</span> such as IoT, robotics, and human-machine interaction. We propose a lightweight Gated Recurrent Unit (GRU)-based RNN accelerator called EdgeDRNN that is <span class="search-hit mathjax">optimized</span> for low-latency edge RNN inference with batch size of 1. EdgeDRNN adopts the spiking neural network inspired delta network algorithm to exploit temporal sparsity in RNNs. Weights are stored in inexpensive DRAM which enables EdgeDRNN to compute large multi-layer RNNs on the most inexpensive FPGA. The sparse updates <span class="search-hit mathjax">reduce</span> DRAM weight memory access by a factor of up to 10x and the delta can be varied dynamically to trade-off between latency and accuracy. EdgeDRNN updates a 5 million parameter 2-layer GRU-RNN in about 0.5ms. It achieves latency comparable with a 92W Nvidia 1080 GPU. It outperforms NVIDIA Jetson Nano, Jetson TX2 and Intel Neural Compute Stick 2 in latency by 5X. For a batch size of 1, EdgeDRNN achieves a mean effective throughput of 20.2GOp/s and a wall plug power efficiency that is over 4X higher than the commercial edge AI platforms.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.13600v1-abstract-full').style.display = 'none'; document.getElementById('2012.13600v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 25 December, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2020.
      
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        in IEEE Journal on Emerging and Selected Topics in Circuits and Systems, vol. 10, no. 4, pp. 419-432, Dec. 2020
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2012.12700">arXiv:2012.12700</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2012.12700">pdf</a>, <a href="https://arxiv.org/format/2012.12700">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Quantum Physics">quant-ph</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Hardware Architecture">cs.AR</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Programming Languages">cs.PL</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        <span class="search-hit mathjax">Software</span> Pipelining for Quantum Loop <span class="search-hit mathjax">Programs</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Guo%2C+J">Jingzhe Guo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ying%2C+M">Mingsheng Ying</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2012.12700v1-abstract-short" style="display: inline;">
        We propose a method for performing <span class="search-hit mathjax">software</span> pipelining on quantum for-loop&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.12700v1-abstract-full').style.display = 'inline'; document.getElementById('2012.12700v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2012.12700v1-abstract-full" style="display: none;">
        We propose a method for performing <span class="search-hit mathjax">software</span> pipelining on quantum for-loop <span class="search-hit mathjax">programs</span>, exploiting parallelism in and across iterations. We redefine concepts that are useful in <span class="search-hit mathjax">program</span> <span class="search-hit mathjax">optimization</span>, including array aliasing, instruction dependency and resource conflict, this <span class="search-hit mathjax">time</span> in <span class="search-hit mathjax">optimization</span> of quantum <span class="search-hit mathjax">programs</span>. Using the redefined concepts, we present a <span class="search-hit mathjax">software</span> pipelining algorithm exploiting instruction-level parallelism in quantum loop <span class="search-hit mathjax">programs</span>. The <span class="search-hit mathjax">optimization</span> method is then evaluated on some test cases, including popular <span class="search-hit mathjax">applications</span> like QAOA, and compared with several baseline results. The evaluation results show that our approach outperforms loop <span class="search-hit mathjax">optimizers</span> exploiting only in-loop <span class="search-hit mathjax">optimization</span> chances by <span class="search-hit mathjax">reducing</span> total depth of the loop <span class="search-hit mathjax">program</span> to close to the <span class="search-hit mathjax">optimal</span> <span class="search-hit mathjax">program</span> depth obtained by full loop unrolling, while generating much smaller <span class="search-hit mathjax">code</span> in size. This is the first step towards <span class="search-hit mathjax">optimization</span> of a quantum <span class="search-hit mathjax">program</span> with such loop control flow as far as we know.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.12700v1-abstract-full').style.display = 'none'; document.getElementById('2012.12700v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 23 December, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2012.10526">arXiv:2012.10526</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2012.10526">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Achieving Operational Scalability Using Razee Continuous Deployment Model and Kubernetes Operators
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Bhagavan%2C+S">Srini Bhagavan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Balasubramanian%2C+S">Saravanan Balasubramanian</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Annem%2C+P+R">Prasad Reddy Annem</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ngo%2C+T">Thuan Ngo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Soundararaj%2C+A">Arun Soundararaj</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2012.10526v1-abstract-short" style="display: inline;">
        Recent advancements in the cloud computing domain have resulted in huge strides toward simplifying the procurement of hardware and <span class="search-hit mathjax">software</span> for diverse needs. By moving enterprise workloads to managed cloud offerings (private, public, hybrid), customers are delegating mundane tasks and labor-intensive maintenance activities related to network connectivity, p&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.10526v1-abstract-full').style.display = 'inline'; document.getElementById('2012.10526v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2012.10526v1-abstract-full" style="display: none;">
        Recent advancements in the cloud computing domain have resulted in huge strides toward simplifying the procurement of hardware and <span class="search-hit mathjax">software</span> for diverse needs. By moving enterprise workloads to managed cloud offerings (private, public, hybrid), customers are delegating mundane tasks and labor-intensive maintenance activities related to network connectivity, procurement of cloud resource, <span class="search-hit mathjax">application</span> deployment, <span class="search-hit mathjax">software</span> patches, and upgrades, etc., This often translates to benefits such as high availability and <span class="search-hit mathjax">reduced</span> cost. The popularity of container and micro-services-based deployment has made Kubernetes the de-facto standard to deliver <span class="search-hit mathjax">applications</span>. However, even with Kubernetes orchestration, cloud service providers frequently have operational scalability issues due to lack of Continuous Integration and Continuous Deployment (CICD) <span class="search-hit mathjax">automation</span> and increased demand for human operators when managing a large number of <span class="search-hit mathjax">software</span> deployments across multiple data centers/availability zones. Kubernetes solves this in a novel way by creating and managing custom <span class="search-hit mathjax">applications</span> using Operators. Agile methodology advocates incremental CICD which are adopted by cloud providers. However, ironically, it is this same continuous delivery feature of <span class="search-hit mathjax">application</span> updates, Kubernetes cluster upgrades, etc., that is also a bane to cloud providers. In this paper, we will demonstrate the use of IBM open-source project Razee as a scalable continuous deployment framework to deploy open-source RStudio and Nginx Operators. We will discuss how IBM Watson SaaS <span class="search-hit mathjax">application</span> Operator, Blockchain <span class="search-hit mathjax">applications</span>, and Kubernetes resources updates, etc., can be deployed similarly and the use of Operators to perform <span class="search-hit mathjax">application</span> life cycle management. We assert that using Razee in conjunction with Operators on Kubernetes simplifies <span class="search-hit mathjax">application</span> life cycle management and increases scalability.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.10526v1-abstract-full').style.display = 'none'; document.getElementById('2012.10526v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 18 December, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">9 pages, 18 figures, 1 table</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          C.0
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2012.08842">arXiv:2012.08842</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2012.08842">pdf</a>, <a href="https://arxiv.org/format/2012.08842">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1007/s11831-021-09566-x">10.1007/s11831-021-09566-x <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        <span class="search-hit mathjax">Code</span> smells detection and visualization: A systematic literature review
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Reis%2C+J+P+d">JosÃ© Pereira dos Reis</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Abreu%2C+F+B+e">Fernando Brito e Abreu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Carneiro%2C+G+d+F">Glauco de Figueiredo Carneiro</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Anslow%2C+C">Craig Anslow</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2012.08842v1-abstract-short" style="display: inline;">
        Context: <span class="search-hit mathjax">Code</span> smells (CS) tend to compromise&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.08842v1-abstract-full').style.display = 'inline'; document.getElementById('2012.08842v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2012.08842v1-abstract-full" style="display: none;">
        Context: <span class="search-hit mathjax">Code</span> smells (CS) tend to compromise <span class="search-hit mathjax">software</span> quality and also demand more effort by developers to maintain and evolve the <span class="search-hit mathjax">application</span> throughout its life-cycle. They have long been catalogued with corresponding mitigating solutions called refactoring operations. Objective: This SLR has a twofold goal: the first is to identify the main <span class="search-hit mathjax">code</span> smells detection techniques and tools discussed in the literature, and the second is to analyze to which extent visual techniques have been applied to support the former. Method: Over 83 primary studies indexed in major scientific repositories were identified by our search string in this SLR. Then, following existing best practices for secondary studies, we applied inclusion/exclusion criteria to select the most relevant works, extract their features and classify them. Results: We found that the most commonly used approaches to <span class="search-hit mathjax">code</span> smells detection are search-based (30.1%), and metric-based (24.1%). Most of the studies (83.1%) use open-source <span class="search-hit mathjax">software</span>, with the Java language occupying the first position (77.1%). In terms of <span class="search-hit mathjax">code</span> smells, God Class (51.8%), Feature Envy (33.7%), and Long Method (26.5%) are the most covered ones. Machine learning techniques are used in 35% of the studies. Around 80% of the studies only detect <span class="search-hit mathjax">code</span> smells, without providing visualization techniques. In visualization-based approaches several methods are used, such as: city metaphors, 3D visualization techniques. Conclusions: We confirm that the detection of CS is a non trivial task, and there is still a lot of work to be done in terms of: <span class="search-hit mathjax">reducing</span> the subjectivity associated with the definition and detection of CS; increasing the diversity of detected CS and of supported <span class="search-hit mathjax">programming</span> languages; constructing and sharing oracles and datasets to facilitate the replication of CS detection and visualization techniques validation experiments.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.08842v1-abstract-full').style.display = 'none'; document.getElementById('2012.08842v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 December, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">submitted to ARCO</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          D.2.7
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2012.08181">arXiv:2012.08181</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2012.08181">pdf</a>, <a href="https://arxiv.org/format/2012.08181">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Multiagent Systems">cs.MA</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Social and Information Networks">cs.SI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        <span class="search-hit mathjax">Fast</span>-Convergent Dynamics for Distributed Resource Allocation Over Sparse <span class="search-hit mathjax">Time</span>-Varying Networks
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Doostmohammadian%2C+M">Mohammadreza Doostmohammadian</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Aghasi%2C+A">Alireza Aghasi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Charalambous%2C+T">Themistoklis Charalambous</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2012.08181v2-abstract-short" style="display: inline;">
        In this paper, distributed dynamics are deployed to solve resource allocation over <span class="search-hit mathjax">time</span>-varying multi-agent networks. The state of each agent represents the amount of resources used/produced at that agent while the total amount of resources is fixed. The idea is to&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.08181v2-abstract-full').style.display = 'inline'; document.getElementById('2012.08181v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2012.08181v2-abstract-full" style="display: none;">
        In this paper, distributed dynamics are deployed to solve resource allocation over <span class="search-hit mathjax">time</span>-varying multi-agent networks. The state of each agent represents the amount of resources used/produced at that agent while the total amount of resources is fixed. The idea is to <span class="search-hit mathjax">optimally</span> allocate the resources among the group of agents by <span class="search-hit mathjax">reducing</span> the total cost functions subject to fixed amount of total resources. The information of each agent is restricted to its own state and cost function and those of its immediate neighbors. This is motivated by distributed <span class="search-hit mathjax">applications</span> such as in mobile edge-computing, economic dispatch over smart grids, and multi-agent coverage control. The non-Lipschitz dynamics proposed in this work shows <span class="search-hit mathjax">fast</span> convergence as compared to the linear and some nonlinear solutions in the literature. Further, the multi-agent network connectivity is more relaxed in this paper. To be more specific, the proposed dynamics even reaches <span class="search-hit mathjax">optimal</span> solution over <span class="search-hit mathjax">time</span>-varying disconnected undirected networks as far as the union of these networks over some bounded non-overlapping <span class="search-hit mathjax">time</span>-intervals includes a spanning-tree. The proposed convergence analysis can be applied for similar 1st-order resource allocation nonlinear dynamics. We provide simulations to verify our results.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.08181v2-abstract-full').style.display = 'none'; document.getElementById('2012.08181v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 27 February, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 15 December, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2012.07543">arXiv:2012.07543</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2012.07543">pdf</a>, <a href="https://arxiv.org/format/2012.07543">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Recovery of Linear Components: <span class="search-hit mathjax">Reduced</span> Complexity Autoencoder Designs
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zocco%2C+F">Federico Zocco</a>, 
      
      <a href="/search/?searchtype=author&amp;query=McLoone%2C+S">SeÃ¡n McLoone</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2012.07543v1-abstract-short" style="display: inline;">
        <span class="search-hit mathjax">Reducing</span> dimensionality is a key preprocessing step in many data analysis&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.07543v1-abstract-full').style.display = 'inline'; document.getElementById('2012.07543v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2012.07543v1-abstract-full" style="display: none;">
        <span class="search-hit mathjax">Reducing</span> dimensionality is a key preprocessing step in many data analysis <span class="search-hit mathjax">applications</span> to address the negative effects of the curse of dimensionality and collinearity on model performance and computational complexity, to denoise the data or to <span class="search-hit mathjax">reduce</span> storage requirements. Moreover, in many <span class="search-hit mathjax">applications</span> it is desirable to <span class="search-hit mathjax">reduce</span> the input dimensions by choosing a subset of variables that best represents the entire set without any a priori information available. Unsupervised variable selection techniques provide a solution to this second problem. An autoencoder, if properly regularized, can solve both unsupervised dimensionality reduction and variable selection, but the training of large neural networks can be prohibitive in <span class="search-hit mathjax">time</span> sensitive <span class="search-hit mathjax">applications</span>. We present an approach called Recovery of Linear Components (RLC), which serves as a middle ground between linear and non-linear dimensionality reduction techniques, <span class="search-hit mathjax">reducing</span> autoencoder training <span class="search-hit mathjax">times</span> while enhancing performance over purely linear techniques. With the aid of synthetic and real world case studies, we show that the RLC, when compared with an autoencoder of similar complexity, shows higher accuracy, similar robustness to overfitting, and <span class="search-hit mathjax">faster</span> training <span class="search-hit mathjax">times</span>. Additionally, at the cost of a relatively small increase in computational complexity, RLC is shown to outperform the current state-of-the-art for a semiconductor manufacturing wafer measurement site <span class="search-hit mathjax">optimization</span> <span class="search-hit mathjax">application</span>.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.07543v1-abstract-full').style.display = 'none'; document.getElementById('2012.07543v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 December, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2012.07086">arXiv:2012.07086</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2012.07086">pdf</a>, <a href="https://arxiv.org/format/2012.07086">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        EfficientPose: Efficient Human Pose Estimation with Neural Architecture Search
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+W">Wenqiang Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fang%2C+J">Jiemin Fang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+X">Xinggang Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+W">Wenyu Liu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2012.07086v1-abstract-short" style="display: inline;">
        Human pose estimation from image and video is a vital task in many multimedia <span class="search-hit mathjax">applications</span>. Previous methods achieve great performance but rarely take efficiency into consideration, which makes it difficult to implement the networks on resource-constrained devices. Nowadays real-&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.07086v1-abstract-full').style.display = 'inline'; document.getElementById('2012.07086v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2012.07086v1-abstract-full" style="display: none;">
        Human pose estimation from image and video is a vital task in many multimedia <span class="search-hit mathjax">applications</span>. Previous methods achieve great performance but rarely take efficiency into consideration, which makes it difficult to implement the networks on resource-constrained devices. Nowadays real-<span class="search-hit mathjax">time</span> multimedia <span class="search-hit mathjax">applications</span> call for more efficient models for better interactions. Moreover, most deep neural networks for pose estimation directly reuse the networks designed for image classification as the backbone, which are not yet <span class="search-hit mathjax">optimized</span> for the pose estimation task. In this paper, we propose an efficient framework targeted at human pose estimation including two parts, the efficient backbone and the efficient head. By implementing the differentiable neural architecture search method, we customize the backbone network design for pose estimation and <span class="search-hit mathjax">reduce</span> the computation cost with negligible accuracy degradation. For the efficient head, we slim the transposed convolutions and propose a spatial information correction module to promote the performance of the final prediction. In experiments, we evaluate our networks on the MPII and COCO datasets. Our smallest model has only 0.65 GFLOPs with 88.1% PCKh@0.5 on MPII and our large model has only 2 GFLOPs while its accuracy is competitive with the state-of-the-art large model, i.e., HRNet with 9.5 GFLOPs.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.07086v1-abstract-full').style.display = 'none'; document.getElementById('2012.07086v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 13 December, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2012.07029">arXiv:2012.07029</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2012.07029">pdf</a>, <a href="https://arxiv.org/format/2012.07029">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Efficient Online Trajectory Planning for Integrator Chain Dynamics using Polynomial Elimination
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Rauscher%2C+F">Florentin Rauscher</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sawodny%2C+O">Oliver Sawodny</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2012.07029v1-abstract-short" style="display: inline;">
        Providing smooth reference trajectories can effectively increase performance and accuracy of tracking control <span class="search-hit mathjax">applications</span> while overshoot and unwanted vibrations are&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.07029v1-abstract-full').style.display = 'inline'; document.getElementById('2012.07029v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2012.07029v1-abstract-full" style="display: none;">
        Providing smooth reference trajectories can effectively increase performance and accuracy of tracking control <span class="search-hit mathjax">applications</span> while overshoot and unwanted vibrations are <span class="search-hit mathjax">reduced</span>. Trajectory planning computations can often be simplified significantly by transforming the system dynamics into decoupled integrator chains using methods such as feedback linearization, differential flatness or the controller canonical form. We present an efficient method to plan <span class="search-hit mathjax">time</span> <span class="search-hit mathjax">optimal</span> trajectories for integrator chains subject to derivative bound constraints. Therefore, an algebraic precomputation algorithm formulates the necessary conditions for <span class="search-hit mathjax">time</span> <span class="search-hit mathjax">optimality</span> in form of a set of polynomial systems, followed by a symbolic polynomial elimination using GrÃ¶bner bases. A <span class="search-hit mathjax">fast</span> online algorithm then plans the trajectories by calculating the roots of the decomposed polynomial systems. These roots describe the switching <span class="search-hit mathjax">time</span> instants of the input signal and the full trajectory simply follows by multiple integration. This method presents a systematic way to compute <span class="search-hit mathjax">time</span> <span class="search-hit mathjax">optimal</span> trajectories exactly via algebraic calculations without numerical approximation iterations. It is applied to various trajectory types with different continuity order, asymmetric derivative bounds and non-rest initial and final states.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.07029v1-abstract-full').style.display = 'none'; document.getElementById('2012.07029v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 13 December, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2012.05270">arXiv:2012.05270</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2012.05270">pdf</a>, <a href="https://arxiv.org/format/2012.05270">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Programming Languages">cs.PL</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        MLComp: A Methodology for Machine Learning-based Performance Estimation and Adaptive Selection of Pareto-<span class="search-hit mathjax">Optimal</span> Compiler <span class="search-hit mathjax">Optimization</span> Sequences
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Colucci%2C+A">Alessio Colucci</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Juh%C3%A1sz%2C+D">DÃ¡vid JuhÃ¡sz</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mosbeck%2C+M">Martin Mosbeck</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Marchisio%2C+A">Alberto Marchisio</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rehman%2C+S">Semeen Rehman</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kreutzer%2C+M">Manfred Kreutzer</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Nadbath%2C+G">Guenther Nadbath</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jantsch%2C+A">Axel Jantsch</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shafique%2C+M">Muhammad Shafique</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2012.05270v2-abstract-short" style="display: inline;">
        Embedded systems have proliferated in various consumer and industrial <span class="search-hit mathjax">applications</span> with the evolution of Cyber-Physical Systems and the Internet of Things. These systems are subjected to stringent constraints so that embedded&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.05270v2-abstract-full').style.display = 'inline'; document.getElementById('2012.05270v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2012.05270v2-abstract-full" style="display: none;">
        Embedded systems have proliferated in various consumer and industrial <span class="search-hit mathjax">applications</span> with the evolution of Cyber-Physical Systems and the Internet of Things. These systems are subjected to stringent constraints so that embedded <span class="search-hit mathjax">software</span> must be <span class="search-hit mathjax">optimized</span> for multiple objectives simultaneously, namely <span class="search-hit mathjax">reduced</span> energy consumption, execution <span class="search-hit mathjax">time</span>, and <span class="search-hit mathjax">code</span> size. Compilers offer <span class="search-hit mathjax">optimization</span> phases to <span class="search-hit mathjax">improve</span> these metrics. However, proper selection and ordering of them depends on multiple factors and typically requires expert knowledge. State-of-the-art <span class="search-hit mathjax">optimizers</span> facilitate different platforms and <span class="search-hit mathjax">applications</span> case by case, and they are limited by <span class="search-hit mathjax">optimizing</span> one metric at a <span class="search-hit mathjax">time</span>, as well as requiring a <span class="search-hit mathjax">time</span>-consuming adaptation for different targets through dynamic profiling.
  To address these problems, we propose the novel MLComp methodology, in which <span class="search-hit mathjax">optimization</span> phases are sequenced by a Reinforcement Learning-based policy. Training of the policy is supported by Machine Learning-based analytical models for quick performance estimation, thereby drastically <span class="search-hit mathjax">reducing</span> the <span class="search-hit mathjax">time</span> spent for dynamic profiling. In our framework, different Machine Learning models are <span class="search-hit mathjax">automatically</span> tested to choose the best-fitting one. The trained Performance Estimator model is leveraged to efficiently devise Reinforcement Learning-based multi-objective policies for creating quasi-<span class="search-hit mathjax">optimal</span> phase sequences.
  Compared to state-of-the-art estimation models, our Performance Estimator model achieves lower relative error (&lt;2%) with up to 50x <span class="search-hit mathjax">faster</span> training <span class="search-hit mathjax">time</span> over multiple platforms and <span class="search-hit mathjax">application</span> domains. Our Phase Selection Policy <span class="search-hit mathjax">improves</span> execution <span class="search-hit mathjax">time</span> and energy consumption of a given <span class="search-hit mathjax">code</span> by up to 12% and 6%, respectively. The Performance Estimator and the Phase Selection Policy can be trained efficiently for any target platform and <span class="search-hit mathjax">application</span> domain.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.05270v2-abstract-full').style.display = 'none'; document.getElementById('2012.05270v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 11 December, 2020; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 9 December, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted for publication at the 24th IEEE/ACM Design, Automation and Test in Europe (DATE&#39;21) Conference, February, 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2012.04760">arXiv:2012.04760</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2012.04760">pdf</a>, <a href="https://arxiv.org/format/2012.04760">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Social and Information Networks">cs.SI</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1145/3418209">10.1145/3418209 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Fine-Grained Network Analysis for Modern <span class="search-hit mathjax">Software</span> Ecosystems
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Boldi%2C+P">Paolo Boldi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gousios%2C+G">Georgios Gousios</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2012.04760v1-abstract-short" style="display: inline;">
        Modern <span class="search-hit mathjax">software</span> development is increasingly dependent on components, libraries and frameworks coming from third-party vendors or open-source suppliers and made available through a number of platforms (or forges). This way of writing&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.04760v1-abstract-full').style.display = 'inline'; document.getElementById('2012.04760v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2012.04760v1-abstract-full" style="display: none;">
        Modern <span class="search-hit mathjax">software</span> development is increasingly dependent on components, libraries and frameworks coming from third-party vendors or open-source suppliers and made available through a number of platforms (or forges). This way of writing <span class="search-hit mathjax">software</span> puts an emphasis on reuse and on composition, commoditizing the services which modern <span class="search-hit mathjax">applications</span> require. On the other hand, bugs and vulnerabilities in a single library living in one such ecosystem can affect, directly or by transitivity, a huge number of other libraries and <span class="search-hit mathjax">applications</span>. Currently, only product-level information on library dependencies is used to contain this kind of danger, but this knowledge often reveals itself too imprecise to lead to effective (and possibly <span class="search-hit mathjax">automated</span>) handling policies. We will discuss how fine-grained function-level dependencies can greatly <span class="search-hit mathjax">improve</span> reliability and <span class="search-hit mathjax">reduce</span> the impact of vulnerabilities on the whole <span class="search-hit mathjax">software</span> ecosystem.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.04760v1-abstract-full').style.display = 'none'; document.getElementById('2012.04760v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 December, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2012.04355">arXiv:2012.04355</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2012.04355">pdf</a>, <a href="https://arxiv.org/format/2012.04355">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        3DIoUMatch: Leveraging IoU Prediction for Semi-Supervised 3D Object Detection
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+H">He Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cong%2C+Y">Yezhen Cong</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Litany%2C+O">Or Litany</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gao%2C+Y">Yue Gao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Guibas%2C+L+J">Leonidas J. Guibas</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2012.04355v3-abstract-short" style="display: inline;">
        3D object detection is an important yet demanding task that heavily relies on difficult to obtain 3D annotations. To <span class="search-hit mathjax">reduce</span> the required amount of supervision, we propose 3DIoUMatch, a novel semi-supervised method for 3D object detection&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.04355v3-abstract-full').style.display = 'inline'; document.getElementById('2012.04355v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2012.04355v3-abstract-full" style="display: none;">
        3D object detection is an important yet demanding task that heavily relies on difficult to obtain 3D annotations. To <span class="search-hit mathjax">reduce</span> the required amount of supervision, we propose 3DIoUMatch, a novel semi-supervised method for 3D object detection <span class="search-hit mathjax">applicable</span> to both indoor and outdoor scenes. We leverage a teacher-student mutual learning framework to propagate information from the labeled to the unlabeled train set in the form of pseudo-labels. However, due to the high task complexity, we observe that the pseudo-labels suffer from significant noise and are thus not directly usable. To that end, we introduce a confidence-based filtering mechanism, inspired by FixMatch. We set confidence thresholds based upon the predicted objectness and class probability to filter low-quality pseudo-labels. While effective, we observe that these two measures do not sufficiently capture localization quality. We therefore propose to use the estimated 3D IoU as a localization metric and set category-aware self-adjusted thresholds to filter poorly localized proposals. We adopt VoteNet as our backbone detector on indoor datasets while we use PV-RCNN on the autonomous driving dataset, KITTI. Our method consistently <span class="search-hit mathjax">improves</span> state-of-the-art methods on both ScanNet and SUN-RGBD benchmarks by significant margins under all label ratios (including fully labeled setting). For example, when training using only 10\% labeled data on ScanNet, 3DIoUMatch achieves 7.7% absolute <span class="search-hit mathjax">improvement</span> on mAP@0.25 and 8.5% absolute <span class="search-hit mathjax">improvement</span> on mAP@0.5 upon the prior art. On KITTI, we are the first to demonstrate semi-supervised 3D object detection and our method surpasses a fully supervised baseline from 1.8% to 7.6% under different label ratios and categories.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.04355v3-abstract-full').style.display = 'none'; document.getElementById('2012.04355v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 6 July, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 8 December, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">CVPR 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2012.03655">arXiv:2012.03655</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2012.03655">pdf</a>, <a href="https://arxiv.org/format/2012.03655">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Signal Processing">eess.SP</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Information Theory">cs.IT</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Multicell Power Control under Rate Constraints with Deep Learning
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+Y">Yinghan Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Han%2C+S">Shengqian Han</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yang%2C+C">Chenyang Yang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2012.03655v1-abstract-short" style="display: inline;">
        &hellip;control results onto the constraint set. The projection block is designed based on a geometrical interpretation of the constraints, which is of low complexity, meeting the real-<span class="search-hit mathjax">time</span> requirement of online&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.03655v1-abstract-full').style.display = 'inline'; document.getElementById('2012.03655v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2012.03655v1-abstract-full" style="display: none;">
        In the paper we study a deep learning based method to solve the multicell power control problem for sum rate maximization subject to per-user rate constraints and per-base station (BS) power constraints. The core difficulty of this problem is how to ensure that the learned power control results by the deep neural network (DNN) satisfy the per-user rate constraints. To tackle the difficulty, we propose to cascade a projection block after a traditional DNN, which projects the infeasible power control results onto the constraint set. The projection block is designed based on a geometrical interpretation of the constraints, which is of low complexity, meeting the real-<span class="search-hit mathjax">time</span> requirement of online <span class="search-hit mathjax">applications</span>. Explicit-form expression of the backpropagated gradient is derived for the proposed projection block, with which the DNN can be trained to directly maximize the sum rate via unsupervised learning. We also develop a heuristic implementation of the projection block to <span class="search-hit mathjax">reduce</span> the size of DNN. Simulation results demonstrate the advantages of the proposed method over existing deep learning and numerical <span class="search-hit mathjax">optimization</span>~methods, and show the robustness of the proposed method with the model mismatch between training and testing~datasets.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.03655v1-abstract-full').style.display = 'none'; document.getElementById('2012.03655v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 December, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2012.03579">arXiv:2012.03579</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2012.03579">pdf</a>, <a href="https://arxiv.org/ps/2012.03579">ps</a>, <a href="https://arxiv.org/format/2012.03579">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Image and Video Processing">eess.IV</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Robustness Investigation on Deep Learning CT Reconstruction for Real-<span class="search-hit mathjax">Time</span> Dose <span class="search-hit mathjax">Optimization</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+C">Chang Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Huang%2C+Y">Yixing Huang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Maier%2C+J">Joscha Maier</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Klein%2C+L">Laura Klein</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kachelrie%C3%9F%2C+M">Marc KachelrieÃ</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Maier%2C+A">Andreas Maier</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2012.03579v1-abstract-short" style="display: inline;">
        In computed tomography (CT), <span class="search-hit mathjax">automatic</span> exposure control (AEC) is frequently used to&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.03579v1-abstract-full').style.display = 'inline'; document.getElementById('2012.03579v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2012.03579v1-abstract-full" style="display: none;">
        In computed tomography (CT), <span class="search-hit mathjax">automatic</span> exposure control (AEC) is frequently used to <span class="search-hit mathjax">reduce</span> radiation dose exposure to patients. For organ-specific AEC, a preliminary CT reconstruction is necessary to estimate organ shapes for dose <span class="search-hit mathjax">optimization</span>, where only a few projections are allowed for real-<span class="search-hit mathjax">time</span> reconstruction. In this work, we investigate the performance of <span class="search-hit mathjax">automated</span> transform by manifold approximation (AUTOMAP) in such <span class="search-hit mathjax">applications</span>. For proof of concept, we investigate its performance on the MNIST dataset first, where the dataset containing all the 10 digits are randomly split into a training set and a test set. We train the AUTOMAP model for image reconstruction from 2 projections or 4 projections directly. The test results demonstrate that AUTOMAP is able to reconstruct most digits well with a false rate of 1.6% and 6.8% respectively. In our subsequent experiment, the MNIST dataset is split in a way that the training set contains 9 digits only while the test set contains the excluded digit only, for instance &#34;2&#34;. In the test results, the digit &#34;2&#34;s are falsely predicted as &#34;3&#34; or &#34;5&#34; when using 2 projections for reconstruction, reaching a false rate of 94.4%. For the <span class="search-hit mathjax">application</span> in medical images, AUTOMAP is also trained on patients&#39; CT images. The test images reach an average root-mean-square error of 290 HU. Although the coarse body outlines are well reconstructed, some organs are misshaped.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.03579v1-abstract-full').style.display = 'none'; document.getElementById('2012.03579v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 December, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Proceedings for &#34;2020 IEEE Nuclear Science Symposium and Medical Imaging Conference&#34;</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2012.03005">arXiv:2012.03005</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2012.03005">pdf</a>, <a href="https://arxiv.org/format/2012.03005">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Information Theory">cs.IT</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Networking and Internet Architecture">cs.NI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        <span class="search-hit mathjax">Optimal</span> Caching for Low Latency in Distributed <span class="search-hit mathjax">Coded</span> Storage Systems
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+K">Kaiyang Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Peng%2C+J">Jun Peng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+J">Jingrong Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pan%2C+J">Jianping Pan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2012.03005v1-abstract-short" style="display: inline;">
        Erasure <span class="search-hit mathjax">codes</span> have been widely considered a promising solution to enhance data reliability at low storage costs. However, in modern geo-distributed storage systems, erasure&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.03005v1-abstract-full').style.display = 'inline'; document.getElementById('2012.03005v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2012.03005v1-abstract-full" style="display: none;">
        Erasure <span class="search-hit mathjax">codes</span> have been widely considered a promising solution to enhance data reliability at low storage costs. However, in modern geo-distributed storage systems, erasure <span class="search-hit mathjax">codes</span> may incur high data access latency as they require data retrieval from multiple remote storage nodes. This hinders the extensive <span class="search-hit mathjax">application</span> of erasure <span class="search-hit mathjax">codes</span> to data-intensive <span class="search-hit mathjax">applications</span>. This paper proposes novel caching schemes to achieve low latency in distributed <span class="search-hit mathjax">coded</span> storage systems. Experiments based on Amazon Simple Storage Service confirm the positive correlation between the latency and the physical distance of data retrieval. The average data access latency is used the performance metric to quantify the benefits of caching. Assuming that the future data popularity and network latency information is available, an offline caching scheme is proposed to find the <span class="search-hit mathjax">optimal</span> caching solution. Guided by the <span class="search-hit mathjax">optimal</span> scheme, an online caching scheme is proposed according to the measured data popularity and network latency information in real <span class="search-hit mathjax">time</span>. Experiment results demonstrate that the online scheme can approximate the <span class="search-hit mathjax">optimal</span> scheme well with dramatically <span class="search-hit mathjax">reduced</span> computation complexity.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.03005v1-abstract-full').style.display = 'none'; document.getElementById('2012.03005v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 5 December, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">12 pages, 13 figures, submitted to IEEE/ACM Transactions on Networking</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2012.02043">arXiv:2012.02043</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2012.02043">pdf</a>, <a href="https://arxiv.org/format/2012.02043">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Recovering Trajectories of Unmarked Joints in 3D Human Actions Using Latent Space <span class="search-hit mathjax">Optimization</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Lohit%2C+S">Suhas Lohit</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Anirudh%2C+R">Rushil Anirudh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Turaga%2C+P">Pavan Turaga</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2012.02043v1-abstract-short" style="display: inline;">
        Motion capture (mocap) and <span class="search-hit mathjax">time</span>-of-flight based sensing of human actions are becoming increasingly popular modalities to perform robust activity analysis.&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.02043v1-abstract-full').style.display = 'inline'; document.getElementById('2012.02043v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2012.02043v1-abstract-full" style="display: none;">
        Motion capture (mocap) and <span class="search-hit mathjax">time</span>-of-flight based sensing of human actions are becoming increasingly popular modalities to perform robust activity analysis. <span class="search-hit mathjax">Applications</span> range from action recognition to quantifying movement quality for health <span class="search-hit mathjax">applications</span>. While marker-less motion capture has made great progress, in critical <span class="search-hit mathjax">applications</span> such as healthcare, marker-based systems, especially active markers, are still considered gold-standard. However, there are several practical challenges in both modalities such as visibility, tracking errors, and simply the need to keep marker setup convenient wherein movements are recorded with a <span class="search-hit mathjax">reduced</span> marker-set. This implies that certain joint locations will not even be marked-up, making downstream analysis of full body movement challenging. To address this gap, we first pose the problem of reconstructing the unmarked joint data as an ill-posed linear inverse problem. We recover missing joints for a given action by projecting it onto the manifold of human actions, this is achieved by <span class="search-hit mathjax">optimizing</span> the latent space representation of a deep autoencoder. Experiments on both mocap and Kinect datasets clearly demonstrate that the proposed method performs very well in recovering semantics of the actions and dynamics of missing joints. We will release all the <span class="search-hit mathjax">code</span> and models publicly.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.02043v1-abstract-full').style.display = 'none'; document.getElementById('2012.02043v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 3 December, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted at WACV 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2012.01749">arXiv:2012.01749</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2012.01749">pdf</a>, <a href="https://arxiv.org/format/2012.01749">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Signal Processing">eess.SP</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Cross-Correlation Based Discriminant Criterion for Channel Selection in Motor Imagery BCI Systems
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Yu%2C+J">Jianli Yu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yu%2C+Z">Zhuliang Yu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2012.01749v5-abstract-short" style="display: inline;">
        Objective. Many electroencephalogram (EEG)-based brain-computer interface (BCI) systems use a large amount of channels for higher performance, which is <span class="search-hit mathjax">time</span>-consuming to set up and inconvenient for practical&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.01749v5-abstract-full').style.display = 'inline'; document.getElementById('2012.01749v5-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2012.01749v5-abstract-full" style="display: none;">
        Objective. Many electroencephalogram (EEG)-based brain-computer interface (BCI) systems use a large amount of channels for higher performance, which is <span class="search-hit mathjax">time</span>-consuming to set up and inconvenient for practical <span class="search-hit mathjax">applications</span>. Finding an <span class="search-hit mathjax">optimal</span> subset of channels without compromising the performance is a necessary and challenging task. Approach. In this article, we proposed a cross-correlation based discriminant criterion (XCDC) which assesses the importance of a channel for discriminating the mental states of different motor imagery (MI) tasks. Channels are ranked and selected according to the proposed criterion. The efficacy of XCDC is evaluated on two motor imagery EEG datasets. Main results. In both datasets, XCDC significantly <span class="search-hit mathjax">reduces</span> the amount of channels without compromising classification accuracy compared to the all-channel setups. Under the same constraint of accuracy, the proposed method requires fewer channels than existing channel selection methods based on Pearson&#39;s correlation coefficient and common spatial pattern. Visualization of XCDC shows consistent results with neurophysiological principles. Significance. This work proposes a quantitative criterion for assessing and ranking the importance of EEG channels in MI tasks and provides a practical method for selecting the ranked channels in the calibration phase of MI BCI systems, which alleviates the computational complexity and configuration difficulty in the subsequent steps, leading to real-<span class="search-hit mathjax">time</span> and more convenient BCI systems.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.01749v5-abstract-full').style.display = 'none'; document.getElementById('2012.01749v5-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 3 March, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 3 December, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2012.01714">arXiv:2012.01714</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2012.01714">pdf</a>, <a href="https://arxiv.org/format/2012.01714">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Graphics">cs.GR</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        AutoInt: <span class="search-hit mathjax">Automatic</span> Integration for <span class="search-hit mathjax">Fast</span> Neural Volume Rendering
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Lindell%2C+D+B">David B. Lindell</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Martel%2C+J+N+P">Julien N. P. Martel</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wetzstein%2C+G">Gordon Wetzstein</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2012.01714v2-abstract-short" style="display: inline;">
        Numerical integration is a foundational technique in scientific computing and is at the core of many computer vision <span class="search-hit mathjax">applications</span>. Among these&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.01714v2-abstract-full').style.display = 'inline'; document.getElementById('2012.01714v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2012.01714v2-abstract-full" style="display: none;">
        Numerical integration is a foundational technique in scientific computing and is at the core of many computer vision <span class="search-hit mathjax">applications</span>. Among these <span class="search-hit mathjax">applications</span>, neural volume rendering has recently been proposed as a new paradigm for view synthesis, achieving photorealistic image quality. However, a fundamental obstacle to making these methods practical is the extreme computational and memory requirements caused by the required volume integrations along the rendered rays during training and inference. Millions of rays, each requiring hundreds of forward passes through a neural network are needed to approximate those integrations with Monte Carlo sampling. Here, we propose <span class="search-hit mathjax">automatic</span> integration, a new framework for learning efficient, closed-form solutions to integrals using coordinate-based neural networks. For training, we instantiate the computational graph corresponding to the derivative of the network. The graph is fitted to the signal to integrate. After <span class="search-hit mathjax">optimization</span>, we reassemble the graph to obtain a network that represents the antiderivative. By the fundamental theorem of calculus, this enables the calculation of any definite integral in two evaluations of the network. Applying this approach to neural rendering, we <span class="search-hit mathjax">improve</span> a tradeoff between rendering <span class="search-hit mathjax">speed</span> and image quality: <span class="search-hit mathjax">improving</span> render <span class="search-hit mathjax">times</span> by greater than 10 <span class="search-hit mathjax">times</span> with a tradeoff of slightly <span class="search-hit mathjax">reduced</span> image quality.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.01714v2-abstract-full').style.display = 'none'; document.getElementById('2012.01714v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 May, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 3 December, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2012.01655">arXiv:2012.01655</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2012.01655">pdf</a>, <a href="https://arxiv.org/format/2012.01655">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.4204/EPTCS.330.1">10.4204/EPTCS.330.1 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        VICToRy: Visual Interactive Consistency Management in Tolerant Rule-based Systems
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Weidmann%2C+N">Nils Weidmann</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Anjorin%2C+A">Anthony Anjorin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cheney%2C+J">James Cheney</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2012.01655v1-abstract-short" style="display: inline;">
        &hellip;checking. The supported operations, however, typically run completely in the background with only input and output made visible to the user. We argue that this often <span class="search-hit mathjax">reduces</span> both understandability and controllability. As a step towards&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.01655v1-abstract-full').style.display = 'inline'; document.getElementById('2012.01655v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2012.01655v1-abstract-full" style="display: none;">
        In the field of Model-Driven Engineering, there exist numerous tools that support various consistency management operations including model transformation, synchronisation and consistency checking. The supported operations, however, typically run completely in the background with only input and output made visible to the user. We argue that this often <span class="search-hit mathjax">reduces</span> both understandability and controllability. As a step towards <span class="search-hit mathjax">improving</span> this situation, we present VICToRy, a debugger for model generation and transformation based on Triple Graph Grammars, a well-known rule-based approach to bidirectional transformation. In addition to a fine-grained, step-by-step, interactive visualisation, VICToRy enables the user to actively explore and choose between multiple valid rule <span class="search-hit mathjax">applications</span> thus <span class="search-hit mathjax">improving</span> control and understanding.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.01655v1-abstract-full').style.display = 'none'; document.getElementById('2012.01655v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 2 December, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">In Proceedings GCM 2020, arXiv:2012.01181</span>
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        EPTCS 330, 2020, pp. 1-12
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2012.00596">arXiv:2012.00596</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2012.00596">pdf</a>, <a href="https://arxiv.org/format/2012.00596">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Neural and Evolutionary Computing">cs.NE</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        NPAS: A Compiler-aware Framework of Unified Network Pruning and Architecture Search for Beyond Real-<span class="search-hit mathjax">Time</span> Mobile Acceleration
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+Z">Zhengang Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yuan%2C+G">Geng Yuan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Niu%2C+W">Wei Niu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhao%2C+P">Pu Zhao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+Y">Yanyu Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cai%2C+Y">Yuxuan Cai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shen%2C+X">Xuan Shen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhan%2C+Z">Zheng Zhan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kong%2C+Z">Zhenglun Kong</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jin%2C+Q">Qing Jin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+Z">Zhiyu Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+S">Sijia Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yang%2C+K">Kaiyuan Yang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ren%2C+B">Bin Ren</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+Y">Yanzhi Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lin%2C+X">Xue Lin</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2012.00596v3-abstract-short" style="display: inline;">
        With the increasing demand to efficiently deploy DNNs on mobile edge devices, it becomes much more important to <span class="search-hit mathjax">reduce</span> unnecessary computation and increase the execution&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.00596v3-abstract-full').style.display = 'inline'; document.getElementById('2012.00596v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2012.00596v3-abstract-full" style="display: none;">
        With the increasing demand to efficiently deploy DNNs on mobile edge devices, it becomes much more important to <span class="search-hit mathjax">reduce</span> unnecessary computation and increase the execution <span class="search-hit mathjax">speed</span>. Prior methods towards this goal, including model compression and network architecture search (NAS), are largely performed independently and do not fully consider compiler-level <span class="search-hit mathjax">optimizations</span> which is a must-do for mobile acceleration. In this work, we first propose (i) a general category of fine-grained structured pruning <span class="search-hit mathjax">applicable</span> to various DNN layers, and (ii) a comprehensive, compiler <span class="search-hit mathjax">automatic</span> <span class="search-hit mathjax">code</span> generation framework supporting different DNNs and different pruning schemes, which bridge the gap of model compression and NAS. We further propose NPAS, a compiler-aware unified network pruning, and architecture search. To deal with large search space, we propose a meta-modeling procedure based on reinforcement learning with <span class="search-hit mathjax">fast</span> evaluation and Bayesian <span class="search-hit mathjax">optimization</span>, ensuring the total number of training epochs comparable with representative NAS frameworks. Our framework achieves 6.7ms, 5.9ms, 3.9ms ImageNet inference <span class="search-hit mathjax">times</span> with 78.2%, 75% (MobileNet-V3 level), and 71% (MobileNet-V2 level) Top-1 accuracy respectively on an off-the-shelf mobile phone, consistently outperforming prior work.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.00596v3-abstract-full').style.display = 'none'; document.getElementById('2012.00596v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 June, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 1 December, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted as an oral paper in the Conference on Computer Vision and Pattern Recognition (CVPR), 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2012.00506">arXiv:2012.00506</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2012.00506">pdf</a>, <a href="https://arxiv.org/format/2012.00506">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Numerical Analysis">math.NA</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Mathematical Software">cs.MS</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A Parallel Direct Eigensolver for Sequences of Hermitian Eigenvalue Problems with No Tridiagonalization
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+S">Shengguo Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wu%2C+X">Xinzhe Wu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Roman%2C+J+E">Jose E. Roman</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yuan%2C+Z">Ziyang Yuan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cheng%2C+L">Lizhi Cheng</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2012.00506v1-abstract-short" style="display: inline;">
        &hellip;Eigenvalue Problems with no tridiagonalization is proposed, denoted by \texttt{PDESHEP}, and it combines direct methods with iterative methods. \texttt{PDESHEP} first <span class="search-hit mathjax">reduces</span> a Hermitian matrix to its banded form, then applies a spectrum slicing algorithm to the banded matrix, and finally computes the eigenvectors of the original matrix via backtransform. Th&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.00506v1-abstract-full').style.display = 'inline'; document.getElementById('2012.00506v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2012.00506v1-abstract-full" style="display: none;">
        In this paper, a Parallel Direct Eigensolver for Sequences of Hermitian Eigenvalue Problems with no tridiagonalization is proposed, denoted by \texttt{PDESHEP}, and it combines direct methods with iterative methods. \texttt{PDESHEP} first <span class="search-hit mathjax">reduces</span> a Hermitian matrix to its banded form, then applies a spectrum slicing algorithm to the banded matrix, and finally computes the eigenvectors of the original matrix via backtransform. Therefore, compared with conventional direct eigensolvers, \texttt{PDESHEP} avoids tridiagonalization, which consists of many memory-bounded operations. In this work, the iterative method in \texttt{PDESHEP} is based on the contour integral method implemented in FEAST. The combination of direct methods with iterative methods for banded matrices requires some efficient data redistribution algorithms both from 2D to 1D and from 1D to 2D data structures. Hence, some two-step data redistribution algorithms are proposed, which can be <span class="search-hit mathjax">$10\times$</span> <span class="search-hit mathjax">faster</span> than ScaLAPACK routine \texttt{PXGEMR2D}. For the symmetric self-consistent field (SCF) eigenvalue problems, \texttt{PDESHEP} can be on average <span class="search-hit mathjax">$1.25\times$</span> <span class="search-hit mathjax">faster</span> than the state-of-the-art direct solver in ELPA when using $4096$ processes. Numerical results are obtained for dense Hermitian matrices from real <span class="search-hit mathjax">applications</span> and large real sparse matrices from the SuiteSparse collection.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.00506v1-abstract-full').style.display = 'none'; document.getElementById('2012.00506v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 1 December, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">24 pages and 14 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2012.00102">arXiv:2012.00102</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2012.00102">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Hardware Architecture">cs.AR</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1145/3424239">10.1145/3424239 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        HeM3D: Heterogeneous Manycore Architecture Based on Monolithic 3D Vertical Integration
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Arka%2C+A+I">Aqeeb Iqbal Arka</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Joardar%2C+B+K">Biresh Kumar Joardar</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kim%2C+R+G">Ryan Gary Kim</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kim%2C+D+H">Dae Hyun Kim</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Doppa%2C+J+R">Janardhan Rao Doppa</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pande%2C+P+P">Partha Pratim Pande</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2012.00102v2-abstract-short" style="display: inline;">
        Heterogeneous manycore architectures are the key to efficiently execute compute- and data-intensive <span class="search-hit mathjax">applications</span>. Through silicon via (TSV)-based 3D manycore system is a promising solution in this direction as it enables integration of disparate computing cores on a single system. However, the achievable performance of conventional through-silicon-via (TSV)-&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.00102v2-abstract-full').style.display = 'inline'; document.getElementById('2012.00102v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2012.00102v2-abstract-full" style="display: none;">
        Heterogeneous manycore architectures are the key to efficiently execute compute- and data-intensive <span class="search-hit mathjax">applications</span>. Through silicon via (TSV)-based 3D manycore system is a promising solution in this direction as it enables integration of disparate computing cores on a single system. However, the achievable performance of conventional through-silicon-via (TSV)-based 3D systems is ultimately bottlenecked by the horizontal wires (wires in each planar die). Moreover, current TSV 3D architectures suffer from thermal limitations. Hence, TSV-based architectures do not realize the full potential of 3D integration. Monolithic 3D (M3D) integration, a breakthrough technology to achieve - More Moore and More Than Moore - and opens up the possibility of designing cores and associated network routers using multiple layers by utilizing monolithic inter-tier vias (MIVs) and hence, <span class="search-hit mathjax">reducing</span> the effective wire length. Compared to TSV-based 3D ICs, M3D offers the true benefits of vertical dimension for system integration: the size of a MIV used in M3D is over 100x smaller than a TSV. In this work, we demonstrate how M3D-enabled vertical core and uncore elements offer significant performance and thermal <span class="search-hit mathjax">improvements</span> in manycore heterogeneous architectures compared to its TSV-based counterpart. To overcome the difficult <span class="search-hit mathjax">optimization</span> challenges due to the large design space and complex interactions among the heterogeneous components (CPU, GPU, Last Level Cache, etc.) in an M3D-based manycore chip, we leverage novel design-space exploration algorithms to trade-off different objectives. The proposed M3D-enabled heterogeneous architecture, called HeM3D, outperforms its state-of-the-art TSV-equivalent counterpart by up to 18.3% in execution <span class="search-hit mathjax">time</span> while being up to 19 degrees Celcius cooler.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.00102v2-abstract-full').style.display = 'none'; document.getElementById('2012.00102v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 December, 2020; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 30 November, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">This work has been accepted in ACM Transactions on Design Automation of Electronic Systems</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          C.2
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2011.14266">arXiv:2011.14266</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2011.14266">pdf</a>, <a href="https://arxiv.org/format/2011.14266">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Distilled Thompson Sampling: Practical and Efficient Thompson Sampling via Imitation Learning
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Namkoong%2C+H">Hongseok Namkoong</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Daulton%2C+S">Samuel Daulton</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bakshy%2C+E">Eytan Bakshy</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2011.14266v2-abstract-short" style="display: inline;">
        Thompson sampling (TS) has emerged as a robust technique for contextual bandit problems. However, TS requires posterior inference and <span class="search-hit mathjax">optimization</span> for action generation, prohibiting its use in many internet&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.14266v2-abstract-full').style.display = 'inline'; document.getElementById('2011.14266v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2011.14266v2-abstract-full" style="display: none;">
        Thompson sampling (TS) has emerged as a robust technique for contextual bandit problems. However, TS requires posterior inference and <span class="search-hit mathjax">optimization</span> for action generation, prohibiting its use in many internet <span class="search-hit mathjax">applications</span> where latency and ease of deployment are of concern. We propose a novel imitation-learning-based algorithm that distills a TS policy into an explicit policy representation by performing posterior inference and <span class="search-hit mathjax">optimization</span> offline. The explicit policy representation enables <span class="search-hit mathjax">fast</span> online decision-making and easy deployment in mobile and server-based environments. Our algorithm iteratively performs offline batch updates to the TS policy and learns a new imitation policy. Since we update the TS policy with observations collected under the imitation policy, our algorithm emulates an off-policy version of TS. Our imitation algorithm guarantees Bayes regret comparable to TS, up to the sum of single-step imitation errors. We show these imitation errors can be made arbitrarily small when unlabeled contexts are cheaply available, which is the case for most large-scale internet <span class="search-hit mathjax">applications</span>. Empirically, we show that our imitation policy achieves comparable regret to TS, while <span class="search-hit mathjax">reducing</span> decision-<span class="search-hit mathjax">time</span> latency by over an order of magnitude.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.14266v2-abstract-full').style.display = 'none'; document.getElementById('2011.14266v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 December, 2020; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 28 November, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2020.
      
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        Offline Reinforcement Learning Workshop at Neural Information Processing Systems, 2020
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2011.13998">arXiv:2011.13998</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2011.13998">pdf</a>, <a href="https://arxiv.org/format/2011.13998">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computational Engineering, Finance, and Science">cs.CE</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1002/nme.6667">10.1002/nme.6667 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Preserving general physical properties in model reduction of dynamical systems via constrained-<span class="search-hit mathjax">optimization</span> projection
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Schein%2C+A">A. Schein</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Carlberg%2C+K+T">K. T. Carlberg</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zahr%2C+M+J">M. J. Zahr</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2011.13998v3-abstract-short" style="display: inline;">
        Model-reduction techniques aim to <span class="search-hit mathjax">reduce</span> the computational complexity of simulating dynamical systems by applying a (Petrov-)Galerkin projection process that enforces the dynamics to evolve in a low-dimensional subspace of the original state space. Frequently, the resulting&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.13998v3-abstract-full').style.display = 'inline'; document.getElementById('2011.13998v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2011.13998v3-abstract-full" style="display: none;">
        Model-reduction techniques aim to <span class="search-hit mathjax">reduce</span> the computational complexity of simulating dynamical systems by applying a (Petrov-)Galerkin projection process that enforces the dynamics to evolve in a low-dimensional subspace of the original state space. Frequently, the resulting <span class="search-hit mathjax">reduced</span>-order model (ROM) violates intrinsic physical properties of the original full-order model (FOM) (e.g., global conservation, Lagrangian structure, state-variable bounds) because the projection process does not generally ensure preservation of these properties. However, in many <span class="search-hit mathjax">applications</span>, ensuring the ROM preserves such intrinsic properties can enable the ROM to retain physical meaning and lead to <span class="search-hit mathjax">improved</span> accuracy and stability properties. In this work, we present a general constrained-<span class="search-hit mathjax">optimization</span> formulation for projection-based model reduction that can be used as a template to enforce the ROM to satisfy specific properties on the kinematics and dynamics. We introduce constrained-<span class="search-hit mathjax">optimization</span> formulations at both the <span class="search-hit mathjax">time</span>-continuous (i.e., ODE) level, which leads to a constrained Galerkin projection, and at the <span class="search-hit mathjax">time</span>-discrete level, which leads to a least-squares Petrov-Galerkin (LSPG) projection, in the context of linear multistep schemes. We demonstrate the ability of the proposed formulations to equip ROMs with desired properties such as global energy conservation and bounds on the total variation.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.13998v3-abstract-full').style.display = 'none'; document.getElementById('2011.13998v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 1 April, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 27 November, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2011.12886">arXiv:2011.12886</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2011.12886">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        An Empirical Investigation on the Challenges of Creating Custom Static Analysis Rules for Defect Localization
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Mendon%C3%A7a%2C+D+S">Diogo Silveira MendonÃ§a</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kalinowski%2C+M">Marcos Kalinowski</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2011.12886v2-abstract-short" style="display: inline;">
        Background: Custom static analysis rules, i.e., rules specific for one or more <span class="search-hit mathjax">applications</span>, have been successfully applied to perform corrective and preventive&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.12886v2-abstract-full').style.display = 'inline'; document.getElementById('2011.12886v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2011.12886v2-abstract-full" style="display: none;">
        Background: Custom static analysis rules, i.e., rules specific for one or more <span class="search-hit mathjax">applications</span>, have been successfully applied to perform corrective and preventive <span class="search-hit mathjax">software</span> maintenance. Their usage can <span class="search-hit mathjax">reduce</span> the costs of verification and <span class="search-hit mathjax">improve</span> the reliability and security of <span class="search-hit mathjax">applications</span>. Pattern-Driven Maintenance (PDM) is a method designed to support the creation of such rules during <span class="search-hit mathjax">software</span> maintenance. However, as PDM was recently created, few maintainers have reported on its usage. Hence, the challenges and skills needed to apply PDM properly are unknown. Aims: In this paper, we investigate the challenges faced by maintainers on applying PDM for creating custom static analysis rules for defect localization. Method: We conducted an observational study on novice maintainers creating custom static analysis rules by applying PDM. The study was divided into three tasks: (i) identifying a defect pattern, (ii) <span class="search-hit mathjax">programming</span> a static analysis rule to locate instances of the pattern, and (iii) verifying the located instances. We analyzed the efficiency of maintainers on applying each task and their comments on task challenges. We also analyzed the acceptance of PDM by the maintainers. Results: We observed that previous knowledge on debugging, the subject <span class="search-hit mathjax">software</span>, and related technologies influenced the performance of maintainers. However, the method&#39;s bottleneck was static analysis rules <span class="search-hit mathjax">programming</span>, being the task that maintainers had more difficulties in completing. Besides those difficulties, maintainers found PDM useful and demonstrated the intention of using it in practice. Conclusions: The results strengthen our confidence that PDM can help maintainers in producing custom static analysis rules for locating defects. However, a better approach for <span class="search-hit mathjax">programming</span> those rules and the proper selection and training of maintainers is needed to apply PDM effectively.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.12886v2-abstract-full').style.display = 'none'; document.getElementById('2011.12886v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 January, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 25 November, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2011.12715">arXiv:2011.12715</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2011.12715">pdf</a>, <a href="https://arxiv.org/format/2011.12715">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Networking and Internet Architecture">cs.NI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Resonance: Replacing <span class="search-hit mathjax">Software</span> Constants with Context-Aware Models in Real-<span class="search-hit mathjax">time</span> Communication
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Gupchup%2C+J">Jayant Gupchup</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Aazami%2C+A">Ashkan Aazami</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fan%2C+Y">Yaran Fan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Filipi%2C+S">Senja Filipi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Finley%2C+T">Tom Finley</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Inglis%2C+S">Scott Inglis</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Asteborg%2C+M">Marcus Asteborg</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Caroll%2C+L">Luke Caroll</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chari%2C+R">Rajan Chari</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cozowicz%2C+M">Markus Cozowicz</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gopal%2C+V">Vishak Gopal</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Prakash%2C+V">Vinod Prakash</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bendapudi%2C+S">Sasikanth Bendapudi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gerrits%2C+J">Jack Gerrits</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lau%2C+E">Eric Lau</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+H">Huazhou Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rossi%2C+M">Marco Rossi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Slobodianyk%2C+D">Dima Slobodianyk</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Birjukov%2C+D">Dmitri Birjukov</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cooper%2C+M">Matty Cooper</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Javar%2C+N">Nilesh Javar</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Perednya%2C+D">Dmitriy Perednya</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Srinivasan%2C+S">Sriram Srinivasan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Langford%2C+J">John Langford</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cutler%2C+R">Ross Cutler</a>
      , et al. (1 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2011.12715v1-abstract-short" style="display: inline;">
        Large <span class="search-hit mathjax">software</span> systems tune hundreds of &#39;constants&#39; to&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.12715v1-abstract-full').style.display = 'inline'; document.getElementById('2011.12715v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2011.12715v1-abstract-full" style="display: none;">
        Large <span class="search-hit mathjax">software</span> systems tune hundreds of &#39;constants&#39; to <span class="search-hit mathjax">optimize</span> their <span class="search-hit mathjax">runtime</span> performance. These values are commonly derived through intuition, lab tests, or A/B tests. A &#39;one-size-fits-all&#39; approach is often sub-<span class="search-hit mathjax">optimal</span> as the best value depends on <span class="search-hit mathjax">runtime</span> context. In this paper, we provide an experimental approach to replace constants with learned contextual functions for Skype - a widely used real-<span class="search-hit mathjax">time</span> communication (RTC) <span class="search-hit mathjax">application</span>. We present Resonance, a system based on contextual bandits (CB). We describe experiences from three real-world experiments: applying it to the audio, video, and transport components in Skype. We surface a unique and practical challenge of performing machine learning (ML) inference in large <span class="search-hit mathjax">software</span> systems written using encapsulation principles. Finally, we open-source FeatureBroker, a library to <span class="search-hit mathjax">reduce</span> the friction in adopting ML models in such development environments
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.12715v1-abstract-full').style.display = 'none'; document.getElementById('2011.12715v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 November, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Workshop on ML for Systems at NeurIPS 2020, Accepted</span>
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        ML for Systems, NeurIPS 2020
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2011.12257">arXiv:2011.12257</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2011.12257">pdf</a>, <a href="https://arxiv.org/format/2011.12257">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Dynamical Systems">math.DS</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Safely Learning Dynamical Systems from Short Trajectories
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ahmadi%2C+A+A">Amir Ali Ahmadi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chaudhry%2C+A">Abraar Chaudhry</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sindhwani%2C+V">Vikas Sindhwani</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tu%2C+S">Stephen Tu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2011.12257v1-abstract-short" style="display: inline;">
        A fundamental challenge in learning to control an unknown dynamical system is to <span class="search-hit mathjax">reduce</span> model uncertainty by making measurements while maintaining safety. In this work, we formulate a mathematical definition of what it means to safely learn a dynamical system by sequentially deciding where to initialize the next trajectory. In our framework, the state of the&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.12257v1-abstract-full').style.display = 'inline'; document.getElementById('2011.12257v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2011.12257v1-abstract-full" style="display: none;">
        A fundamental challenge in learning to control an unknown dynamical system is to <span class="search-hit mathjax">reduce</span> model uncertainty by making measurements while maintaining safety. In this work, we formulate a mathematical definition of what it means to safely learn a dynamical system by sequentially deciding where to initialize the next trajectory. In our framework, the state of the system is required to stay within a given safety region under the (possibly repeated) action of all dynamical systems that are consistent with the information gathered so far. For our first two results, we consider the setting of safely learning linear dynamics. We present a linear <span class="search-hit mathjax">programming</span>-based algorithm that either safely recovers the true dynamics from trajectories of length one, or certifies that safe learning is impossible. We also give an efficient semidefinite representation of the set of initial conditions whose resulting trajectories of length two are guaranteed to stay in the safety region. For our final result, we study the problem of safely learning a nonlinear dynamical system. We give a second-order cone <span class="search-hit mathjax">programming</span> based representation of the set of initial conditions that are guaranteed to remain in the safety region after one <span class="search-hit mathjax">application</span> of the system dynamics.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.12257v1-abstract-full').style.display = 'none'; document.getElementById('2011.12257v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 24 November, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2011.12101">arXiv:2011.12101</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2011.12101">pdf</a>, <a href="https://arxiv.org/format/2011.12101">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Numerical Analysis">math.NA</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computational Engineering, Finance, and Science">cs.CE</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        <span class="search-hit mathjax">Reduced</span> order methods for parametric flow control problems and <span class="search-hit mathjax">applications</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ballarin%2C+F">Francesco Ballarin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rozza%2C+G">Gianluigi Rozza</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Strazzullo%2C+M">Maria Strazzullo</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2011.12101v1-abstract-short" style="display: inline;">
        In this contribution we propose <span class="search-hit mathjax">reduced</span> order methods to&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.12101v1-abstract-full').style.display = 'inline'; document.getElementById('2011.12101v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2011.12101v1-abstract-full" style="display: none;">
        In this contribution we propose <span class="search-hit mathjax">reduced</span> order methods to <span class="search-hit mathjax">fast</span> and reliably solve parametrized <span class="search-hit mathjax">optimal</span> control problems governed by <span class="search-hit mathjax">time</span> dependent nonlinear partial differential equations. Our goal is to provide a general tool to deal with the <span class="search-hit mathjax">time</span> evolution of several nonlinear <span class="search-hit mathjax">optimality</span> systems in many-query context, where a system must be analysed for various physical and geometrical features. <span class="search-hit mathjax">Optimal</span> control is a tool which can be used in order to fill the gab between collected data and mathematical model and it is usually related to very <span class="search-hit mathjax">time</span> consuming activities: inverse problems, statistics, etc. Standard discretization techniques may lead to unbearable simulations for real <span class="search-hit mathjax">applications</span>. We aim at showing how <span class="search-hit mathjax">reduced</span> order modelling can solve this issue. We rely on a space-<span class="search-hit mathjax">time</span> POD-Galerkin reduction in order to solve the <span class="search-hit mathjax">optimal</span> control problem in a low dimensional <span class="search-hit mathjax">reduced</span> space in a <span class="search-hit mathjax">fast</span> way for several parametric instances. The generality of the proposed algorithm is validated with a numerical test based on environmental sciences: a <span class="search-hit mathjax">reduced</span> <span class="search-hit mathjax">optimal</span> control problem governed by Shallow Waters Equations parametrized not only in the physics features, but also in the geometrical ones. We will show how the <span class="search-hit mathjax">reduced</span> model can be useful in order to recover desired velocity and height profiles more rapidly with respect to the standard simulation, not loosing in accuracy.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.12101v1-abstract-full').style.display = 'none'; document.getElementById('2011.12101v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 24 November, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2011.11985">arXiv:2011.11985</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2011.11985">pdf</a>, <a href="https://arxiv.org/ps/2011.11985">ps</a>, <a href="https://arxiv.org/format/2011.11985">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Adam$^+$: A Stochastic Method with Adaptive Variance Reduction
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+M">Mingrui Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+W">Wei Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Orabona%2C+F">Francesco Orabona</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yang%2C+T">Tianbao Yang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2011.11985v1-abstract-short" style="display: inline;">
        Adam is a widely used stochastic <span class="search-hit mathjax">optimization</span> method for deep learning <span class="search-hit mathjax">applications</span>. While practitioners prefer Adam because it requires less parameter tuning, its use is problematic from a theoretical point of view since it may not converge. Variants of Adam have been proposed with provable convergence guarantee, but&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.11985v1-abstract-full').style.display = 'inline'; document.getElementById('2011.11985v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2011.11985v1-abstract-full" style="display: none;">
        Adam is a widely used stochastic <span class="search-hit mathjax">optimization</span> method for deep learning <span class="search-hit mathjax">applications</span>. While practitioners prefer Adam because it requires less parameter tuning, its use is problematic from a theoretical point of view since it may not converge. Variants of Adam have been proposed with provable convergence guarantee, but they tend not be competitive with Adam on the practical performance. In this paper, we propose a new method named Adam$^+$ (pronounced as Adam-plus). Adam$^+$ retains some of the key components of Adam but it also has several noticeable differences: (i) it does not maintain the moving average of second moment estimate but instead computes the moving average of first moment estimate at extrapolated points; (ii) its adaptive step size is formed not by dividing the square root of second moment estimate but instead by dividing the root of the norm of first moment estimate. As a result, Adam$^+$ requires few parameter tuning, as Adam, but it enjoys a provable convergence guarantee. Our analysis further shows that Adam$^+$ enjoys adaptive variance reduction, i.e., the variance of the stochastic gradient estimator <span class="search-hit mathjax">reduces</span> as the algorithm converges, hence enjoying an adaptive convergence. We also propose a more general variant of Adam$^+$ with different adaptive step sizes and establish their <span class="search-hit mathjax">fast</span> convergence rate. Our empirical studies on various deep learning tasks, including image classification, language modeling, and <span class="search-hit mathjax">automatic</span> speech recognition, demonstrate that Adam$^+$ significantly outperforms Adam and achieves comparable performance with best-tuned SGD and momentum SGD.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.11985v1-abstract-full').style.display = 'none'; document.getElementById('2011.11985v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 24 November, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2011.11835">arXiv:2011.11835</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2011.11835">pdf</a>, <a href="https://arxiv.org/ps/2011.11835">ps</a>, <a href="https://arxiv.org/format/2011.11835">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Signal Processing">eess.SP</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Peer Offloading with Delayed Feedback in Fog Networks
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Yang%2C+M">Miao Yang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhu%2C+H">Hongbin Zhu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Qian%2C+H">Hua Qian</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Koucheryavy%2C+Y">Yevgeni Koucheryavy</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Samouylov%2C+K">Konstantin Samouylov</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+H">Haifeng Wang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2011.11835v2-abstract-short" style="display: inline;">
        Comparing to cloud computing, fog computing performs computation and services at the edge of networks, thus relieving the computation burden of the data center and <span class="search-hit mathjax">reducing</span> the task latency of end devices. Computation latency is a crucial performance metric in fog computing, especially for real-&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.11835v2-abstract-full').style.display = 'inline'; document.getElementById('2011.11835v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2011.11835v2-abstract-full" style="display: none;">
        Comparing to cloud computing, fog computing performs computation and services at the edge of networks, thus relieving the computation burden of the data center and <span class="search-hit mathjax">reducing</span> the task latency of end devices. Computation latency is a crucial performance metric in fog computing, especially for real-<span class="search-hit mathjax">time</span> <span class="search-hit mathjax">applications</span>. In this paper, we study a peer computation offloading problem for a fog network with unknown dynamics. In this scenario, each fog node (FN) can offload their computation tasks to neighboring FNs in a <span class="search-hit mathjax">time</span> slot manner. The offloading latency, however, could not be fed back to the task dispatcher instantaneously due to the uncertainty of the processing <span class="search-hit mathjax">time</span> in peer FNs. Besides, peer competition occurs when different FNs offload tasks to one FN at the same <span class="search-hit mathjax">time</span>. To tackle the above difficulties, we model the computation offloading problem as a sequential FN selection problem with delayed information feedback. Using adversarial multi-arm bandit framework, we construct an online learning policy to deal with delayed information feedback. Different contention resolution approaches are considered to resolve peer competition. Performance analysis shows that the regret of the proposed algorithm, or the performance loss with suboptimal FN selections, achieves a sub-linear order, suggesting an <span class="search-hit mathjax">optimal</span> FN selection policy. In addition, we prove that the proposed strategy can result in a Nash equilibrium (NE) with all FNs playing the same policy. Simulation results validate the effectiveness of the proposed policy.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.11835v2-abstract-full').style.display = 'none'; document.getElementById('2011.11835v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 April, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 23 November, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">12 pages, 11 figures, accepted by IEEE Internet of Things Journal</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2011.09902">arXiv:2011.09902</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2011.09902">pdf</a>, <a href="https://arxiv.org/format/2011.09902">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1109/TII.2020.3017668">10.1109/TII.2020.3017668 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Low-latency Federated Learning and Blockchain for Edge Association in Digital Twin empowered 6G Networks
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Lu%2C+Y">Yunlong Lu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Huang%2C+X">Xiaohong Huang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+K">Ke Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Maharjan%2C+S">Sabita Maharjan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+Y">Yan Zhang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2011.09902v1-abstract-short" style="display: inline;">
        &hellip;data processing and learning in wireless networks. However, unreliable communication channels, limited resources, and lack of trust among users, hinder the effective <span class="search-hit mathjax">application</span> of federated learning in IIoT. In this paper, we introduce the Digital Twin Wireless Networks (DTWN) by incorporating digital twins into wireless networks, to migrate real-&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.09902v1-abstract-full').style.display = 'inline'; document.getElementById('2011.09902v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2011.09902v1-abstract-full" style="display: none;">
        Emerging technologies such as digital twins and 6th Generation mobile networks (6G) have accelerated the realization of edge intelligence in Industrial Internet of Things (IIoT). The integration of digital twin and 6G bridges the physical system with digital space and enables robust instant wireless connectivity. With increasing concerns on data privacy, federated learning has been regarded as a promising solution for deploying distributed data processing and learning in wireless networks. However, unreliable communication channels, limited resources, and lack of trust among users, hinder the effective <span class="search-hit mathjax">application</span> of federated learning in IIoT. In this paper, we introduce the Digital Twin Wireless Networks (DTWN) by incorporating digital twins into wireless networks, to migrate real-<span class="search-hit mathjax">time</span> data processing and computation to the edge plane. Then, we propose a blockchain empowered federated learning framework running in the DTWN for collaborative computing, which <span class="search-hit mathjax">improves</span> the reliability and security of the system, and enhances data privacy. Moreover, to balance the learning accuracy and <span class="search-hit mathjax">time</span> cost of the proposed scheme, we formulate an <span class="search-hit mathjax">optimization</span> problem for edge association by jointly considering digital twin association, training data batch size, and bandwidth allocation. We exploit multi-agent reinforcement learning to find an <span class="search-hit mathjax">optimal</span> solution to the problem. Numerical results on real-world dataset show that the proposed scheme yields <span class="search-hit mathjax">improved</span> efficiency and <span class="search-hit mathjax">reduced</span> cost compared to benchmark learning method.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2011.09902v1-abstract-full').style.display = 'none'; document.getElementById('2011.09902v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 November, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2020.
      
    </p>
    

    

    
  </li>

</ol>


  <nav class="pagination is-small is-centered breathe-horizontal" role="navigation" aria-label="pagination">
    
    <a href=""
      class="pagination-previous is-invisible">Previous
    </a>
    
    
      <a href="/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=%28code+OR+program+OR+software+OR+application%29+AND+%28optimize+OR+optimizing+OR+optimization+OR+improve+OR+improving+OR+improvement+OR+automated+OR+automatically+OR+reduce+OR+reducing%29+AND+%28time+OR+runtime+OR+speed+OR+speedup+OR+fast+OR+faster%29&amp;terms-0-field=all&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=200&amp;order=-announced_date_first&amp;start=200"
        class="pagination-next" >Next
      </a>
    
    <ul class="pagination-list">

      <li>
        <a href="/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=%28code+OR+program+OR+software+OR+application%29+AND+%28optimize+OR+optimizing+OR+optimization+OR+improve+OR+improving+OR+improvement+OR+automated+OR+automatically+OR+reduce+OR+reducing%29+AND+%28time+OR+runtime+OR+speed+OR+speedup+OR+fast+OR+faster%29&amp;terms-0-field=all&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=200&amp;order=-announced_date_first&amp;start=0"
          class="pagination-link is-current"
          aria-label="Goto page 1">1
        </a>
      </li>

      
        
        <li>
          <a href="/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=%28code+OR+program+OR+software+OR+application%29+AND+%28optimize+OR+optimizing+OR+optimization+OR+improve+OR+improving+OR+improvement+OR+automated+OR+automatically+OR+reduce+OR+reducing%29+AND+%28time+OR+runtime+OR+speed+OR+speedup+OR+fast+OR+faster%29&amp;terms-0-field=all&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=200&amp;order=-announced_date_first&amp;start=200"
            class="pagination-link "
            aria-label="Page 2"
            aria-current="page">2
          </a>
        </li>
        
        <li>
          <a href="/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=%28code+OR+program+OR+software+OR+application%29+AND+%28optimize+OR+optimizing+OR+optimization+OR+improve+OR+improving+OR+improvement+OR+automated+OR+automatically+OR+reduce+OR+reducing%29+AND+%28time+OR+runtime+OR+speed+OR+speedup+OR+fast+OR+faster%29&amp;terms-0-field=all&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=200&amp;order=-announced_date_first&amp;start=400"
            class="pagination-link "
            aria-label="Page 3"
            aria-current="page">3
          </a>
        </li>
        
        <li>
          <a href="/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=%28code+OR+program+OR+software+OR+application%29+AND+%28optimize+OR+optimizing+OR+optimization+OR+improve+OR+improving+OR+improvement+OR+automated+OR+automatically+OR+reduce+OR+reducing%29+AND+%28time+OR+runtime+OR+speed+OR+speedup+OR+fast+OR+faster%29&amp;terms-0-field=all&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=200&amp;order=-announced_date_first&amp;start=600"
            class="pagination-link "
            aria-label="Page 4"
            aria-current="page">4
          </a>
        </li>
        
        <li>
          <a href="/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=%28code+OR+program+OR+software+OR+application%29+AND+%28optimize+OR+optimizing+OR+optimization+OR+improve+OR+improving+OR+improvement+OR+automated+OR+automatically+OR+reduce+OR+reducing%29+AND+%28time+OR+runtime+OR+speed+OR+speedup+OR+fast+OR+faster%29&amp;terms-0-field=all&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=200&amp;order=-announced_date_first&amp;start=800"
            class="pagination-link "
            aria-label="Page 5"
            aria-current="page">5
          </a>
        </li>
        
        <li>
          <a href="/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=%28code+OR+program+OR+software+OR+application%29+AND+%28optimize+OR+optimizing+OR+optimization+OR+improve+OR+improving+OR+improvement+OR+automated+OR+automatically+OR+reduce+OR+reducing%29+AND+%28time+OR+runtime+OR+speed+OR+speedup+OR+fast+OR+faster%29&amp;terms-0-field=all&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=200&amp;order=-announced_date_first&amp;start=1000"
            class="pagination-link "
            aria-label="Page 6"
            aria-current="page">6
          </a>
        </li>
        
        <li>
          <a href="/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=%28code+OR+program+OR+software+OR+application%29+AND+%28optimize+OR+optimizing+OR+optimization+OR+improve+OR+improving+OR+improvement+OR+automated+OR+automatically+OR+reduce+OR+reducing%29+AND+%28time+OR+runtime+OR+speed+OR+speedup+OR+fast+OR+faster%29&amp;terms-0-field=all&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=200&amp;order=-announced_date_first&amp;start=1200"
            class="pagination-link "
            aria-label="Page 7"
            aria-current="page">7
          </a>
        </li>
        
      
    </ul>
  </nav>
  

    
  

      <div class="is-hidden-tablet">
        <!-- feedback for mobile only -->
        <span class="help" style="display: inline-block;"><a href="https://github.com/arXiv/arxiv-search/releases">Search v0.5.6 released 2020-02-24</a>&nbsp;&nbsp;</span>
        <button class="button is-small" id="feedback-button">Feedback?</button>
      </div>
    </div>

  </main>
  <footer>
    
    <div class="columns is-desktop" role="navigation" aria-label="Secondary">
  <!-- MetaColumn 1 -->
  <div class="column">
    <div class="columns">
      <div class="column">
        <ul class="nav-spaced">
          <li><a href="https://arxiv.org/about">About</a></li>
          <li><a href="https://arxiv.org/help">Help</a></li>
        </ul>
      </div>
      <div class="column">
        <ul class="nav-spaced">
          <li>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
            <a href="https://arxiv.org/help/contact"> Contact</a>
          </li>
          <li>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
            <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
          </li>
        </ul>
      </div>
    </div>
  </div> <!-- end MetaColumn 1 -->
  <!-- MetaColumn 2 -->
  <div class="column">
    <div class="columns">
      <div class="column">
        <ul class="nav-spaced">
          <li><a href="https://arxiv.org/help/license">Copyright</a></li>
          <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
        </ul>
      </div>
      <div class="column sorry-app-links">
        <ul class="nav-spaced">
          <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
          <li>
            <p class="help">
              <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
              Get status notifications via
              <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
              or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
            </p>
          </li>
        </ul>
      </div>
    </div>
  </div> <!-- end MetaColumn 2 -->
</div>
    
  </footer>
  </body>
</html>
