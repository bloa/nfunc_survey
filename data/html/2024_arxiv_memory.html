<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<!-- new favicon config and versions by realfavicongenerator.net -->
<link rel="apple-touch-icon" sizes="180x180" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/favicon-16x16.png">
<link rel="manifest" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/site.webmanifest">
<link rel="mask-icon" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/safari-pinned-tab.svg" color="#b31b1b">
<link rel="shortcut icon" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/favicon.ico">
<meta name="msapplication-TileColor" content="#b31b1b">
<meta name="msapplication-config" content="images/icons/browserconfig.xml">
<meta name="theme-color" content="#b31b1b">
<!-- end favicon config -->
<title>Advanced Search | arXiv e-print repository</title>
<script defer src="https://static.arxiv.org/static/base/1.0.0a5/fontawesome-free-5.11.2-web/js/all.js"></script>
<link rel="stylesheet" href="https://static.arxiv.org/static/base/1.0.0a5/css/arxivstyle.css" />
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    messageStyle: "none",
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true,
      ignoreClass: '.*',
      processClass: 'mathjax.*'
    },
    TeX: {
        extensions: ["AMSmath.js", "AMSsymbols.js", "noErrors.js"],
        noErrors: {
          inlineDelimiters: ["$","$"],
          multiLine: false,
          style: {
            "font-size": "normal",
            "border": ""
          }
        }
    },
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>
<script src='//static.arxiv.org/MathJax-2.7.3/MathJax.js'></script>
<script src="https://static.arxiv.org/static/base/1.0.0a5/js/notification.js"></script>

    
  <link rel="stylesheet" href="https://static.arxiv.org/static/search/0.5.6/css/bulma-tooltip.min.css" />
  <link rel="stylesheet" href="https://static.arxiv.org/static/search/0.5.6/css/search.css" />
  <script
    src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
    integrity="sha256-k2WSCIexGzOj3Euiig+TlR8gA0EmPjuc79OEeY5L45g="
    crossorigin="anonymous"></script>

  <script src="https://static.arxiv.org/static/search/0.5.6/js/fieldset.js"></script>
  <style>
  radio#cf-customfield_11400 {
    display: none;
  }
  </style>

  </head>
  <body>
  
  
  <header><a href="#main-container" class="is-sr-only">Skip to main content</a>
    
    <!-- contains Cornell logo and sponsor statement -->
<div class="attribution level is-marginless" role="banner">
  <div class="level-left">
    <a class="level-item" href="https://cornell.edu/"><img src="https://static.arxiv.org/static/base/1.0.0a5/images/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" aria-label="logo" /></a>
  </div>
  <div class="level-right is-marginless"><p class="sponsors level-item is-marginless"><a href="https://arxiv.org/about/ourmembers">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a></p></div>
</div>
<!-- contains arXiv identity and search bar -->
<div class="identity level is-marginless">
  <div class="level-left">
    <div class="level-item">
      <a class="arxiv" href="https://arxiv.org/" aria-label="arxiv-logo">
        <img src="https://static.arxiv.org/static/base/1.0.0a5/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;"/>
      </a>
    </div>
  </div>
  
  <div class="search-block level-right">
    <form class="level-item mini-search" method="GET" action="https://arxiv.org/search">
      <div class="field has-addons">
        <div class="control">
          <input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" />
          <p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
        </div>
        <div class="control">
          <div class="select is-small">
            <select name="searchtype" aria-label="Field to search">
              <option value="all" selected="selected">All fields</option>
              <option value="title">Title</option>
              <option value="author">Author</option>
              <option value="abstract">Abstract</option>
              <option value="comments">Comments</option>
              <option value="journal_ref">Journal reference</option>
              <option value="acm_class">ACM classification</option>
              <option value="msc_class">MSC classification</option>
              <option value="report_num">Report number</option>
              <option value="paper_id">arXiv identifier</option>
              <option value="doi">DOI</option>
              <option value="orcid">ORCID</option>
              <option value="author_id">arXiv author ID</option>
              <option value="help">Help pages</option>
              <option value="full_text">Full text</option>
            </select>
          </div>
        </div>
        <input type="hidden" name="source" value="header">
        <button class="button is-small is-cul-darker">Search</button>
      </div>
    </form>
  </div>
</div> <!-- closes identity -->

<div class="container">
    <div class="user-tools is-size-7 has-text-right has-text-weight-bold" role="navigation" aria-label="User menu">
      <a href="https://arxiv.org/login">Login</a>
    </div>
</div>
    
  </header>
  <main class="container" id="main-container">
    


    
  <div class="level is-marginless">
    <div class="level-left">
      <h1 class="title is-clearfix">
    
        Showing 1&ndash;19 of 19 results
    
</h1>
    </div>
    <div class="level-right is-hidden-mobile">
      <!-- feedback for mobile is moved to footer -->
      <span class="help" style="display: inline-block;"><a href="https://github.com/arXiv/arxiv-search/releases">Search v0.5.6 released 2020-02-24</a>&nbsp;&nbsp;</span>
      <button class="button is-small" id="feedback-button">Feedback?</button>
    </div>
  </div>
    <div class="content">
      
  
    

    <div class="columns">
      <div class="column is-two-thirds-tablet">
        <p style="margin-bottom: .5em">Query: <a href="/search/advanced?terms-0-operator=AND&amp;terms-0-term=%28code+OR+program+OR+software+OR+application%29+AND+%28optimising+OR+optimisation+OR+improving+OR+improvement+OR+refactoring+OR+tuning+OR+configuration+OR+parameter%29+AND+%28memory%29&amp;terms-0-field=all&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-year=&amp;date-filter_by=date_range&amp;date-from_date=2021&amp;date-to_date=2024&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=25&amp;order=-announced_date_first">order: -announced_date_first; size: 25; date_range: from 2021-01-01 to 2024-12-31; classification: Computer Science (cs); include_cross_list: True; terms: AND all=(code OR program OR software OR application) AND (optimising OR optimisation OR improving OR improvement OR refactoring OR tuning OR configuration OR parameter) AND (memory)</a></p>
        <div class="buttons">
          <a class="button is-link" href="/search/advanced?terms-0-operator=AND&amp;terms-0-term=%28code+OR+program+OR+software+OR+application%29+AND+%28optimising+OR+optimisation+OR+improving+OR+improvement+OR+refactoring+OR+tuning+OR+configuration+OR+parameter%29+AND+%28memory%29&amp;terms-0-field=all&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-year=&amp;date-filter_by=date_range&amp;date-from_date=2021&amp;date-to_date=2024&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=25&amp;order=-announced_date_first">Refine query</a><a class="button" href="/search/advanced">New search</a>
        </div>
      </div>
      <div class="column is-one-third-tablet is-hidden-mobile">
        <p class="has-text-right" style="margin-top: 1em">
          
          <a href="/search/?order=-announced_date_first&amp;size=25">Simple Search</a>
          
        </p>
      </div>
    </div>

    
        
<div class="level breathe-horizontal">
  <div class="level-left">
    <form method="GET" action="/search/advanced">
      <div style="display: none;">
        
          
            <input id="advanced" name="advanced" type="hidden" value="">
          
        
          
            <ul id="terms"><li><label for="terms-0">Terms-0</label> <table id="terms-0"><tr><th><label for="terms-0-term">Search term...</label></th><td><input id="terms-0-term" name="terms-0-term" type="text" value="(code OR program OR software OR application) AND (optimising OR optimisation OR improving OR improvement OR refactoring OR tuning OR configuration OR parameter) AND (memory)"></td></tr><tr><th><label for="terms-0-operator">Operator</label></th><td><select id="terms-0-operator" name="terms-0-operator"><option selected value="AND">AND</option><option value="OR">OR</option><option value="NOT">NOT</option></select></td></tr><tr><th><label for="terms-0-field">Field</label></th><td><select id="terms-0-field" name="terms-0-field"><option value="title">Title</option><option value="author">Author(s)</option><option value="abstract">Abstract</option><option value="comments">Comments</option><option value="journal_ref">Journal reference</option><option value="acm_class">ACM classification</option><option value="msc_class">MSC classification</option><option value="report_num">Report number</option><option value="paper_id">arXiv identifier</option><option value="cross_list_category">Cross-list category</option><option value="doi">DOI</option><option value="orcid">ORCID</option><option value="author_id">arXiv author ID</option><option selected value="all">All fields</option></select></td></tr></table></li></ul>
          
        
          
            <table id="classification"><tr><th><label for="classification-computer_science">Computer Science (cs)</label></th><td><input checked id="classification-computer_science" name="classification-computer_science" type="checkbox" value="y"></td></tr><tr><th><label for="classification-economics">Economics (econ)</label></th><td><input id="classification-economics" name="classification-economics" type="checkbox" value="y"></td></tr><tr><th><label for="classification-eess">Electrical Engineering and Systems Science (eess)</label></th><td><input id="classification-eess" name="classification-eess" type="checkbox" value="y"></td></tr><tr><th><label for="classification-mathematics">Mathematics (math)</label></th><td><input id="classification-mathematics" name="classification-mathematics" type="checkbox" value="y"></td></tr><tr><th><label for="classification-physics">Physics</label></th><td><input id="classification-physics" name="classification-physics" type="checkbox" value="y"></td></tr><tr><th><label for="classification-physics_archives">Physics Archives</label></th><td><select id="classification-physics_archives" name="classification-physics_archives"><option selected value="all">all</option><option value="astro-ph">astro-ph</option><option value="cond-mat">cond-mat</option><option value="gr-qc">gr-qc</option><option value="hep-ex">hep-ex</option><option value="hep-lat">hep-lat</option><option value="hep-ph">hep-ph</option><option value="hep-th">hep-th</option><option value="math-ph">math-ph</option><option value="nlin">nlin</option><option value="nucl-ex">nucl-ex</option><option value="nucl-th">nucl-th</option><option value="physics">physics</option><option value="quant-ph">quant-ph</option></select></td></tr><tr><th><label for="classification-q_biology">Quantitative Biology (q-bio)</label></th><td><input id="classification-q_biology" name="classification-q_biology" type="checkbox" value="y"></td></tr><tr><th><label for="classification-q_finance">Quantitative Finance (q-fin)</label></th><td><input id="classification-q_finance" name="classification-q_finance" type="checkbox" value="y"></td></tr><tr><th><label for="classification-statistics">Statistics (stat)</label></th><td><input id="classification-statistics" name="classification-statistics" type="checkbox" value="y"></td></tr><tr><th><label for="classification-include_cross_list">Include cross-list</label></th><td><ul id="classification-include_cross_list"><li><input checked id="classification-include_cross_list-0" name="classification-include_cross_list" type="radio" value="include"> <label for="classification-include_cross_list-0">Include cross-listed papers</label></li><li><input id="classification-include_cross_list-1" name="classification-include_cross_list" type="radio" value="exclude"> <label for="classification-include_cross_list-1">Exclude cross-listed papers</label></li></ul></td></tr></table>
          
        
          
            <table id="date"><tr><th><label for="date-filter_by">Filter by</label></th><td><ul id="date-filter_by"><li><input id="date-filter_by-0" name="date-filter_by" type="radio" value="all_dates"> <label for="date-filter_by-0">All dates</label></li><li><input id="date-filter_by-1" name="date-filter_by" type="radio" value="past_12"> <label for="date-filter_by-1">Past 12 months</label></li><li><input id="date-filter_by-2" name="date-filter_by" type="radio" value="specific_year"> <label for="date-filter_by-2">Specific year</label></li><li><input checked id="date-filter_by-3" name="date-filter_by" type="radio" value="date_range"> <label for="date-filter_by-3">Date range</label></li></ul></td></tr><tr><th><label for="date-year">Year</label></th><td><input id="date-year" name="date-year" type="text" value=""></td></tr><tr><th><label for="date-from_date">From</label></th><td><input id="date-from_date" name="date-from_date" type="text" value="2021"></td></tr><tr><th><label for="date-to_date">to</label></th><td><input id="date-to_date" name="date-to_date" type="text" value="2024"></td></tr><tr><th><label for="date-date_type">Apply to</label></th><td><ul id="date-date_type"><li><input checked id="date-date_type-0" name="date-date_type" type="radio" value="submitted_date"> <label for="date-date_type-0">Submission date (most recent)</label></li><li><input id="date-date_type-1" name="date-date_type" type="radio" value="submitted_date_first"> <label for="date-date_type-1">Submission date (original)</label></li><li><input id="date-date_type-2" name="date-date_type" type="radio" value="announced_date_first"> <label for="date-date_type-2">Announcement date</label></li></ul></td></tr></table>
          
        
          
        
          
        
          
            <input id="include_older_versions" name="include_older_versions" type="checkbox" value="y">
          
        
          
            <ul id="abstracts"><li><input checked id="abstracts-0" name="abstracts" type="radio" value="show"> <label for="abstracts-0">Show abstracts</label></li><li><input id="abstracts-1" name="abstracts" type="radio" value="hide"> <label for="abstracts-1">Hide abstracts</label></li></ul>
          
        
      </div>
      <div class="box field is-grouped is-grouped-multiline level-item">
        <div class="control">
          <span class="select is-small">
            <select id="size" name="size"><option selected value="25">25</option><option value="50">50</option><option value="100">100</option><option value="200">200</option></select>
          </span>
          <label for="size">results per page</label>.
        </div>
        <div class="control">
          <label for="order">Sort results by</label>
          <span class="select is-small">
            <select id="order" name="order"><option selected value="-announced_date_first">Announcement date (newest first)</option><option value="announced_date_first">Announcement date (oldest first)</option><option value="-submitted_date">Submission date (newest first)</option><option value="submitted_date">Submission date (oldest first)</option><option value="">Relevance</option></select>
          </span>
        </div>
        <div class="control">
          <button class="button is-small is-link">Go</button>
        </div>
      </div>
    </form>
  </div>
</div>
        




<ol class="breathe-horizontal" start="1"> 


  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2405.04324">arXiv:2405.04324</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2405.04324">pdf</a>, <a href="https://arxiv.org/format/2405.04324">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Granite <span class="search-hit mathjax">Code</span> Models: A Family of Open Foundation Models for <span class="search-hit mathjax">Code</span> Intelligence
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Mishra%2C+M">Mayank Mishra</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Stallone%2C+M">Matt Stallone</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+G">Gaoyuan Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shen%2C+Y">Yikang Shen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Prasad%2C+A">Aditya Prasad</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Soria%2C+A+M">Adriana Meza Soria</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Merler%2C+M">Michele Merler</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Selvam%2C+P">Parameswaran Selvam</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Surendran%2C+S">Saptha Surendran</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Singh%2C+S">Shivdeep Singh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sethi%2C+M">Manish Sethi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dang%2C+X">Xuan-Hong Dang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+P">Pengyuan Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wu%2C+K">Kun-Lung Wu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zawad%2C+S">Syed Zawad</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Coleman%2C+A">Andrew Coleman</a>, 
      
      <a href="/search/?searchtype=author&amp;query=White%2C+M">Matthew White</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lewis%2C+M">Mark Lewis</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pavuluri%2C+R">Raju Pavuluri</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Koyfman%2C+Y">Yan Koyfman</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lublinsky%2C+B">Boris Lublinsky</a>, 
      
      <a href="/search/?searchtype=author&amp;query=de+Bayser%2C+M">Maximilien de Bayser</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Abdelaziz%2C+I">Ibrahim Abdelaziz</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Basu%2C+K">Kinjal Basu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Agarwal%2C+M">Mayank Agarwal</a>
      , et al. (21 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2405.04324v1-abstract-short" style="display: inline;">
        Large Language Models (LLMs) trained on <span class="search-hit mathjax">code</span> are revolutionizing the&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2405.04324v1-abstract-full').style.display = 'inline'; document.getElementById('2405.04324v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2405.04324v1-abstract-full" style="display: none;">
        Large Language Models (LLMs) trained on <span class="search-hit mathjax">code</span> are revolutionizing the <span class="search-hit mathjax">software</span> development process. Increasingly, <span class="search-hit mathjax">code</span> LLMs are being integrated into <span class="search-hit mathjax">software</span> development environments to <span class="search-hit mathjax">improve</span> the productivity of human programmers, and LLM-based agents are beginning to show promise for handling complex tasks autonomously. Realizing the full potential of <span class="search-hit mathjax">code</span> LLMs requires a wide range of capabilities, including <span class="search-hit mathjax">code</span> generation, fixing bugs, explaining and documenting <span class="search-hit mathjax">code</span>, maintaining repositories, and more. In this work, we introduce the Granite series of decoder-only <span class="search-hit mathjax">code</span> models for <span class="search-hit mathjax">code</span> generative tasks, trained with <span class="search-hit mathjax">code</span> written in 116 <span class="search-hit mathjax">programming</span> languages. The Granite <span class="search-hit mathjax">Code</span> models family consists of models ranging in size from 3 to 34 billion <span class="search-hit mathjax">parameters</span>, suitable for <span class="search-hit mathjax">applications</span> ranging from complex <span class="search-hit mathjax">application</span> modernization tasks to on-device <span class="search-hit mathjax">memory</span>-constrained use cases. Evaluation on a comprehensive set of tasks demonstrates that Granite <span class="search-hit mathjax">Code</span> models consistently reaches state-of-the-art performance among available open-source <span class="search-hit mathjax">code</span> LLMs. The Granite <span class="search-hit mathjax">Code</span> model family was optimized for enterprise <span class="search-hit mathjax">software</span> development workflows and performs well across a range of <span class="search-hit mathjax">coding</span> tasks (e.g. <span class="search-hit mathjax">code</span> generation, fixing and explanation), making it a versatile all around <span class="search-hit mathjax">code</span> model. We release all our Granite <span class="search-hit mathjax">Code</span> models under an Apache 2.0 license for both research and commercial use.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2405.04324v1-abstract-full').style.display = 'none'; document.getElementById('2405.04324v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 May, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Corresponding Authors: Rameswar Panda, Ruchir Puri; Equal Contributors: Mayank Mishra, Matt Stallone, Gaoyuan Zhang</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2405.04172">arXiv:2405.04172</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2405.04172">pdf</a>, <a href="https://arxiv.org/ps/2405.04172">ps</a>, <a href="https://arxiv.org/format/2405.04172">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Mathematical Software">cs.MS</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        An efficient active-set method with <span class="search-hit mathjax">applications</span> to sparse approximations and risk minimization
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Pougkakiotis%2C+S">Spyridon Pougkakiotis</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gondzio%2C+J">Jacek Gondzio</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kalogerias%2C+D">Dionysis Kalogerias</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2405.04172v1-abstract-short" style="display: inline;">
        In this paper we present an efficient active-set method for the solution of convex quadratic <span class="search-hit mathjax">programming</span> problems with general piecewise-linear terms in the objective, with&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2405.04172v1-abstract-full').style.display = 'inline'; document.getElementById('2405.04172v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2405.04172v1-abstract-full" style="display: none;">
        In this paper we present an efficient active-set method for the solution of convex quadratic <span class="search-hit mathjax">programming</span> problems with general piecewise-linear terms in the objective, with <span class="search-hit mathjax">applications</span> to sparse approximations and risk-minimization. The algorithm is derived by combining a proximal method of multipliers (PMM) with a standard semismooth Newton method (SSN), and is shown to be globally convergent under minimal assumptions. Further local linear (and potentially superlinear) convergence is shown under standard additional conditions. The major computational bottleneck of the proposed approach arises from the solution of the associated SSN linear systems. These are solved using a Krylov-subspace method, accelerated by certain novel general-purpose preconditioners which are shown to be optimal with respect to the proximal penalty <span class="search-hit mathjax">parameters</span>. The preconditioners are easy to store and invert, since they exploit the structure of the nonsmooth terms appearing in the problem&#39;s objective to significantly reduce their <span class="search-hit mathjax">memory</span> requirements. We showcase the efficiency, robustness, and scalability of the proposed solver on a variety of problems arising in risk-averse portfolio selection, $L^1$-regularized partial differential equation constrained optimization, quantile regression, and binary classification via linear support vector machines. We provide computational evidence, on real-world datasets, to demonstrate the ability of the solver to efficiently and competitively handle a diverse set of medium- and large-scale optimization instances.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2405.04172v1-abstract-full').style.display = 'none'; document.getElementById('2405.04172v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 May, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">arXiv admin note: substantial text overlap with arXiv:2302.14497, arXiv:2201.10211</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2402.06763">arXiv:2402.06763</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2402.06763">pdf</a>, <a href="https://arxiv.org/format/2402.06763">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Scalable Kernel Logistic Regression with Nyström Approximation: Theoretical Analysis and <span class="search-hit mathjax">Application</span> to Discrete Choice Modelling
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Mart%C3%ADn-Baos%2C+J+%C3%81">José Ángel Martín-Baos</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Garc%C3%ADa-R%C3%B3denas%2C+R">Ricardo García-Ródenas</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rodriguez-Benitez%2C+L">Luis Rodriguez-Benitez</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bierlaire%2C+M">Michel Bierlaire</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2402.06763v1-abstract-short" style="display: inline;">
        The <span class="search-hit mathjax">application</span> of kernel-based Machine Learning (ML) techniques to discrete choice modelling using large datasets often faces challenges due to&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2402.06763v1-abstract-full').style.display = 'inline'; document.getElementById('2402.06763v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2402.06763v1-abstract-full" style="display: none;">
        The <span class="search-hit mathjax">application</span> of kernel-based Machine Learning (ML) techniques to discrete choice modelling using large datasets often faces challenges due to <span class="search-hit mathjax">memory</span> requirements and the considerable number of <span class="search-hit mathjax">parameters</span> involved in these models. This complexity hampers the efficient training of large-scale models. This paper addresses these problems of scalability by introducing the Nyström approximation for Kernel Logistic Regression (KLR) on large datasets. The study begins by presenting a theoretical analysis in which: i) the set of KLR solutions is characterised, ii) an upper bound to the solution of KLR with Nyström approximation is provided, and finally iii) a specialisation of the <span class="search-hit mathjax">optimisation</span> algorithms to Nyström KLR is described. After this, the Nyström KLR is computationally validated. Four landmark selection methods are tested, including basic uniform sampling, a k-means sampling strategy, and two non-uniform methods grounded in leverage scores. The performance of these strategies is evaluated using large-scale transport mode choice datasets and is compared with traditional methods such as Multinomial Logit (MNL) and contemporary ML techniques. The study also assesses the efficiency of various <span class="search-hit mathjax">optimisation</span> techniques for the proposed Nyström KLR model. The performance of gradient descent, Momentum, Adam, and L-BFGS-B <span class="search-hit mathjax">optimisation</span> methods is examined on these datasets. Among these strategies, the k-means Nyström KLR approach emerges as a successful solution for applying KLR to large datasets, particularly when combined with the L-BFGS-B and Adam <span class="search-hit mathjax">optimisation</span> methods. The results highlight the ability of this strategy to handle datasets exceeding 200,000 observations while maintaining robust performance.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2402.06763v1-abstract-full').style.display = 'none'; document.getElementById('2402.06763v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 9 February, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">32 pages, 5 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2310.19051">arXiv:2310.19051</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2310.19051">pdf</a>, <a href="https://arxiv.org/format/2310.19051">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Methodology">stat.ME</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Mathematical Software">cs.MS</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A Survey of Methods for Estimating Hurst Exponent of Time Sequence
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+H">Hong-Yan Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Feng%2C+Z">Zhi-Qiang Feng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Feng%2C+S">Si-Yu Feng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhou%2C+Y">Yu Zhou</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2310.19051v1-abstract-short" style="display: inline;">
        The Hurst exponent is a significant indicator for characterizing the self-similarity and long-term <span class="search-hit mathjax">memory</span> properties of time sequences. It has wide&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2310.19051v1-abstract-full').style.display = 'inline'; document.getElementById('2310.19051v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2310.19051v1-abstract-full" style="display: none;">
        The Hurst exponent is a significant indicator for characterizing the self-similarity and long-term <span class="search-hit mathjax">memory</span> properties of time sequences. It has wide <span class="search-hit mathjax">applications</span> in physics, technologies, engineering, mathematics, statistics, economics, psychology and so on. Currently, available methods for estimating the Hurst exponent of time sequences can be divided into different categories: time-domain methods and spectrum-domain methods based on the representation of time sequence, linear regression methods and Bayesian methods based on <span class="search-hit mathjax">parameter</span> estimation methods. Although various methods are discussed in literature, there are still some deficiencies: the descriptions of the estimation algorithms are just mathematics-oriented and the pseudo-<span class="search-hit mathjax">codes</span> are missing; the effectiveness and accuracy of the estimation algorithms are not clear; the classification of estimation methods is not considered and there is a lack of guidance for selecting the estimation methods. In this work, the emphasis is put on thirteen dominant methods for estimating the Hurst exponent. For the purpose of decreasing the difficulty of implementing the estimation methods with computer <span class="search-hit mathjax">programs</span>, the mathematical principles are discussed briefly and the pseudo-<span class="search-hit mathjax">codes</span> of algorithms are presented with necessary details. It is expected that the survey could help the researchers to select, implement and apply the estimation algorithms of interest in practical situations in an easy way.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2310.19051v1-abstract-full').style.display = 'none'; document.getElementById('2310.19051v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 29 October, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2023.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">46 pages, 8 figures, 4 tables, 24 algorithms with pseudo-codes</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2308.10462">arXiv:2308.10462</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2308.10462">pdf</a>, <a href="https://arxiv.org/format/2308.10462">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Exploring <span class="search-hit mathjax">Parameter</span>-Efficient Fine-<span class="search-hit mathjax">Tuning</span> Techniques for <span class="search-hit mathjax">Code</span> Generation with Large Language Models
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Weyssow%2C+M">Martin Weyssow</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhou%2C+X">Xin Zhou</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kim%2C+K">Kisub Kim</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lo%2C+D">David Lo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sahraoui%2C+H">Houari Sahraoui</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2308.10462v2-abstract-short" style="display: inline;">
        Large Language Models (LLMs) demonstrate impressive capabilities to generate accurate <span class="search-hit mathjax">code</span> snippets given natural language intents in zero-shot, i.e., without the need for specific fine-&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2308.10462v2-abstract-full').style.display = 'inline'; document.getElementById('2308.10462v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2308.10462v2-abstract-full" style="display: none;">
        Large Language Models (LLMs) demonstrate impressive capabilities to generate accurate <span class="search-hit mathjax">code</span> snippets given natural language intents in zero-shot, i.e., without the need for specific fine-<span class="search-hit mathjax">tuning</span>. While prior studies have highlighted the advantages of fine-<span class="search-hit mathjax">tuning</span> LLMs, this process incurs high computational costs, making it impractical in resource-scarce environments, particularly for models with billions of <span class="search-hit mathjax">parameters</span>. To address these challenges, previous research explored In-Context Learning (ICL) as a strategy to guide the LLM generative process with task-specific prompt examples. However, ICL introduces inconveniences, such as the need for designing contextually relevant prompts and the absence of learning task-specific <span class="search-hit mathjax">parameters</span>, thereby limiting downstream task performance. In this context, we foresee <span class="search-hit mathjax">Parameter</span>-Efficient Fine-<span class="search-hit mathjax">Tuning</span> (PEFT) techniques as a promising approach to efficiently specialize LLMs to task-specific data while maintaining reasonable resource consumption. In this paper, we deliver a comprehensive study of PEFT techniques for LLMs under the automated <span class="search-hit mathjax">code</span> generation scenario. Our comprehensive investigation of PEFT techniques for LLMs reveals their superiority and potential over ICL across a diverse set of LLMs. Additionally, we demonstrate the extended capabilities of PEFT, showcasing its ability to learn from two distinct datasets jointly without compromising performance. Furthermore, our study highlights the potential for <span class="search-hit mathjax">tuning</span> larger LLMs and significant reductions in <span class="search-hit mathjax">memory</span> usage by combining PEFT with quantization. Therefore, this study opens opportunities for broader <span class="search-hit mathjax">applications</span> of PEFT in <span class="search-hit mathjax">software</span> engineering scenarios. Our <span class="search-hit mathjax">code</span> is available at https://github.com/martin-wey/peft-llm-<span class="search-hit mathjax">code</span>/.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2308.10462v2-abstract-full').style.display = 'none'; document.getElementById('2308.10462v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 18 January, 2024; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 21 August, 2023;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2023.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2308.05937">arXiv:2308.05937</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2308.05937">pdf</a>, <a href="https://arxiv.org/format/2308.05937">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A Deep Recurrent-Reinforcement Learning Method for Intelligent AutoScaling of Serverless Functions
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Agarwal%2C+S">Siddharth Agarwal</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rodriguez%2C+M+A">Maria A. Rodriguez</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Buyya%2C+R">Rajkumar Buyya</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2308.05937v1-abstract-short" style="display: inline;">
        Function-as-a-Service (FaaS) introduces a lightweight, function-based cloud execution model that finds its relevance in <span class="search-hit mathjax">applications</span> like IoT-edge data processing and anomaly detection. While CSP offer a near-infinite function elasticity, these&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2308.05937v1-abstract-full').style.display = 'inline'; document.getElementById('2308.05937v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2308.05937v1-abstract-full" style="display: none;">
        Function-as-a-Service (FaaS) introduces a lightweight, function-based cloud execution model that finds its relevance in <span class="search-hit mathjax">applications</span> like IoT-edge data processing and anomaly detection. While CSP offer a near-infinite function elasticity, these <span class="search-hit mathjax">applications</span> often experience fluctuating workloads and stricter performance constraints. A typical CSP strategy is to empirically determine and adjust desired function instances, &#34;autoscaling&#34;, based on monitoring-based thresholds such as CPU or <span class="search-hit mathjax">memory</span>, to cope with demand and performance. However, threshold <span class="search-hit mathjax">configuration</span> either requires expert knowledge, historical data or a complete view of environment, making autoscaling a performance bottleneck lacking an adaptable solution.RL algorithms are proven to be beneficial in analysing complex cloud environments and result in an adaptable policy that maximizes the expected objectives. Most realistic cloud environments usually involve operational interference and have limited visibility, making them partially observable. A general solution to tackle observability in highly dynamic settings is to integrate Recurrent units with model-free RL algorithms and model a decision process as a POMDP. Therefore, in this paper, we investigate a model-free Recurrent RL agent for function autoscaling and compare it against the model-free Proximal Policy <span class="search-hit mathjax">Optimisation</span> (PPO) algorithm. We explore the integration of a LSTM network with the state-of-the-art PPO algorithm to find that under our experimental and evaluation settings, recurrent policies were able to capture the environment <span class="search-hit mathjax">parameters</span> and show promising results for function autoscaling. We further compare a PPO-based autoscaling agent with commercially used threshold-based function autoscaling and posit that a LSTM-based autoscaling agent is able to <span class="search-hit mathjax">improve</span> throughput by 18%, function execution by 13% and account for 8.4% more function instances.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2308.05937v1-abstract-full').style.display = 'none'; document.getElementById('2308.05937v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 11 August, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2023.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">12 pages, 13 figures, 4 tables</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2307.16576">arXiv:2307.16576</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2307.16576">pdf</a>, <a href="https://arxiv.org/format/2307.16576">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Toward Quantum Machine Translation of Syntactically Distinct Languages
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Abbaszade%2C+M">Mina Abbaszade</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zomorodi%2C+M">Mariam Zomorodi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Salari%2C+V">Vahid Salari</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kurian%2C+P">Philip Kurian</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2307.16576v1-abstract-short" style="display: inline;">
        &hellip;devices holds promise in harnessing quantum parallelism and entanglement to efficiently process and analyze vast amounts of linguistic data, potentially revolutionizing NLP <span class="search-hit mathjax">applications</span>. Our research endeavors to pave the way for quantum neural machine translation, which could potentially offer advantages over classical methods in the future. We employ Shann&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2307.16576v1-abstract-full').style.display = 'inline'; document.getElementById('2307.16576v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2307.16576v1-abstract-full" style="display: none;">
        The present study aims to explore the feasibility of language translation using quantum natural language processing algorithms on noisy intermediate-scale quantum (NISQ) devices. Classical methods in natural language processing (NLP) struggle with handling large-scale computations required for complex language tasks, but quantum NLP on NISQ devices holds promise in harnessing quantum parallelism and entanglement to efficiently process and analyze vast amounts of linguistic data, potentially revolutionizing NLP <span class="search-hit mathjax">applications</span>. Our research endeavors to pave the way for quantum neural machine translation, which could potentially offer advantages over classical methods in the future. We employ Shannon entropy to demonstrate the significant role of some appropriate angles of rotation gates in the performance of parametrized quantum circuits. In particular, we utilize these angles (<span class="search-hit mathjax">parameters</span>) as a means of communication between quantum circuits of different languages. To achieve our objective, we adopt the encoder-decoder model of classical neural networks and implement the translation task using long short-term <span class="search-hit mathjax">memory</span> (LSTM). Our experiments involved 160 samples comprising English sentences and their Persian translations. We trained the models with different <span class="search-hit mathjax">optimisers</span> implementing stochastic gradient descent (SGD) as primary and subsequently incorporating two additional optimizers in conjunction with SGD. Notably, we achieved optimal results-with mean absolute error of 0.03, mean squared error of 0.002, and 0.016 loss-by training the best model, consisting of two LSTM layers and using the Adam <span class="search-hit mathjax">optimiser</span>. Our small dataset, though consisting of simple synonymous sentences with word-to-word mappings, points to the utility of Shannon entropy as a figure of merit in more complex machine translation models for intricate sentence structures.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2307.16576v1-abstract-full').style.display = 'none'; document.getElementById('2307.16576v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 31 July, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2023.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">27 pages, 10 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2306.09729">arXiv:2306.09729</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2306.09729">pdf</a>, <a href="https://arxiv.org/format/2306.09729">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        <span class="search-hit mathjax">Parameter</span>-efficient is not sufficient: Exploring <span class="search-hit mathjax">Parameter</span>, <span class="search-hit mathjax">Memory</span>, and Time Efficient Adapter <span class="search-hit mathjax">Tuning</span> for Dense Predictions
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Yin%2C+D">Dongshuo Yin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Han%2C+X">Xueting Han</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+B">Bin Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Feng%2C+H">Hao Feng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bai%2C+J">Jing Bai</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2306.09729v2-abstract-short" style="display: inline;">
        Pre-training &amp; fine-<span class="search-hit mathjax">tuning</span> is a prevalent paradigm in computer vision (CV). Recently,&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2306.09729v2-abstract-full').style.display = 'inline'; document.getElementById('2306.09729v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2306.09729v2-abstract-full" style="display: none;">
        Pre-training &amp; fine-<span class="search-hit mathjax">tuning</span> is a prevalent paradigm in computer vision (CV). Recently, <span class="search-hit mathjax">parameter</span>-efficient transfer learning (PETL) methods have shown promising performance in adapting to downstream tasks with only a few trainable <span class="search-hit mathjax">parameters</span>. Despite their success, the existing PETL methods in CV can be computationally expensive and require large amounts of <span class="search-hit mathjax">memory</span> and time cost during training, which limits low-resource users from conducting research and <span class="search-hit mathjax">applications</span> on large models. In this work, we propose <span class="search-hit mathjax">Parameter</span>, <span class="search-hit mathjax">Memory</span>, and Time Efficient Visual Adapter ($\mathrm{E^3VA}$) <span class="search-hit mathjax">tuning</span> to address this issue. We provide a gradient backpropagation highway for low-rank adapters which eliminates the need for expensive backpropagation through the frozen pre-trained model, resulting in substantial savings of training <span class="search-hit mathjax">memory</span> and training time. Furthermore, we <span class="search-hit mathjax">optimise</span> the $\mathrm{E^3VA}$ structure for CV tasks to promote model performance. Extensive experiments on COCO, ADE20K, and Pascal VOC benchmarks show that $\mathrm{E^3VA}$ can save up to 62.2% training <span class="search-hit mathjax">memory</span> and 26.2% training time on average, while achieving comparable performance to full fine-<span class="search-hit mathjax">tuning</span> and better performance than most PETL methods. Note that we can even train the Swin-Large-based Cascade Mask RCNN on GTX 1080Ti GPUs with less than 1.5% trainable <span class="search-hit mathjax">parameters</span>.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2306.09729v2-abstract-full').style.display = 'none'; document.getElementById('2306.09729v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 27 November, 2023; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 16 June, 2023;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2023.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">14 pages, 4 figures, 5 tables, Submitted to NeurIPS2023</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2304.12673">arXiv:2304.12673</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2304.12673">pdf</a>, <a href="https://arxiv.org/format/2304.12673">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Quantum Physics">quant-ph</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Performance">cs.PF</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Tools for the analysis of quantum protocols requiring state generation within a time window
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Davies%2C+B">Bethany Davies</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Beauchamp%2C+T">Thomas Beauchamp</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Vardoyan%2C+G">Gayane Vardoyan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wehner%2C+S">Stephanie Wehner</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2304.12673v1-abstract-short" style="display: inline;">
        &hellip;in each time step, and stores it in a quantum <span class="search-hit mathjax">memory</span> that is subject to time-dependent noise. To maintain sufficient quality for an <span class="search-hit mathjax">application</span>, each resource state is discarded from the <span class="search-hit mathjax">memory</span> after $w$ time steps. Let $s$ be the number of desired resource states required by a&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2304.12673v1-abstract-full').style.display = 'inline'; document.getElementById('2304.12673v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2304.12673v1-abstract-full" style="display: none;">
        Quantum protocols commonly require a certain number of quantum resource states to be available simultaneously. An important class of examples is quantum network protocols that require a certain number of entangled pairs. Here, we consider a setting in which a process generates a quantum resource state with some probability $p$ in each time step, and stores it in a quantum <span class="search-hit mathjax">memory</span> that is subject to time-dependent noise. To maintain sufficient quality for an <span class="search-hit mathjax">application</span>, each resource state is discarded from the <span class="search-hit mathjax">memory</span> after $w$ time steps. Let $s$ be the number of desired resource states required by a protocol. We characterise the probability distribution $X_{(w,s)}$ of the ages of the quantum resource states, once $s$ states have been generated in a window $w$. Combined with a time-dependent noise model, the knowledge of this distribution allows for the calculation of fidelity statistics of the $s$ quantum resources. We also give exact solutions for the first and second moments of the waiting time $τ_{(w,s)}$ until $s$ resources are produced within a window $w$, which provides information about the rate of the protocol. Since it is difficult to obtain general closed-form expressions for statistical quantities describing the expected waiting time $\mathbb{E}(τ_{(w,s)})$ and the distribution $X_{(w,s)}$, we present two novel results that aid their computation in certain <span class="search-hit mathjax">parameter</span> regimes. The methods presented in this work can be used to analyse and <span class="search-hit mathjax">optimise</span> the execution of quantum protocols. Specifically, with an example of a Blind Quantum Computing (BQC) protocol, we illustrate how they may be used to infer $w$ and $p$ to <span class="search-hit mathjax">optimise</span> the rate of successful protocol execution.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2304.12673v1-abstract-full').style.display = 'none'; document.getElementById('2304.12673v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 25 April, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2023.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2303.05378">arXiv:2303.05378</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2303.05378">pdf</a>, <a href="https://arxiv.org/format/2303.05378">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Greener yet Powerful: Taming Large <span class="search-hit mathjax">Code</span> Generation Models with Quantization
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Wei%2C+X">Xiaokai Wei</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gonugondla%2C+S">Sujan Gonugondla</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ahmad%2C+W">Wasi Ahmad</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+S">Shiqi Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ray%2C+B">Baishakhi Ray</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Qian%2C+H">Haifeng Qian</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+X">Xiaopeng Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kumar%2C+V">Varun Kumar</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+Z">Zijian Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tian%2C+Y">Yuchen Tian</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sun%2C+Q">Qing Sun</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Athiwaratkun%2C+B">Ben Athiwaratkun</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shang%2C+M">Mingyue Shang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ramanathan%2C+M+K">Murali Krishna Ramanathan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bhatia%2C+P">Parminder Bhatia</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xiang%2C+B">Bing Xiang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2303.05378v1-abstract-short" style="display: inline;">
        ML-powered <span class="search-hit mathjax">code</span> generation aims to assist developers to write&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2303.05378v1-abstract-full').style.display = 'inline'; document.getElementById('2303.05378v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2303.05378v1-abstract-full" style="display: none;">
        ML-powered <span class="search-hit mathjax">code</span> generation aims to assist developers to write <span class="search-hit mathjax">code</span> in a more productive manner, by intelligently generating <span class="search-hit mathjax">code</span> blocks based on natural language prompts. Recently, large pretrained deep learning models have substantially pushed the boundary of <span class="search-hit mathjax">code</span> generation and achieved impressive performance. Despite their great power, the huge number of model <span class="search-hit mathjax">parameters</span> poses a significant threat to adapting them in a regular <span class="search-hit mathjax">software</span> development environment, where a developer might use a standard laptop or mid-size server to develop her <span class="search-hit mathjax">code</span>. Such large models incur significant resource usage (in terms of <span class="search-hit mathjax">memory</span>, latency, and dollars) as well as carbon footprint.
  Model compression is a promising approach to address these challenges. Several techniques are proposed to compress large pretrained models typically used for vision or textual data. Out of many available compression techniques, we identified that quantization is mostly <span class="search-hit mathjax">applicable</span> for <span class="search-hit mathjax">code</span> generation task as it does not require significant retraining cost. As quantization represents model <span class="search-hit mathjax">parameters</span> with lower-bit integer (e.g., int8), the model size and runtime latency would both benefit from such int representation. We extensively study the impact of quantized model on <span class="search-hit mathjax">code</span> generation tasks across different dimension: (i) resource usage and carbon footprint, (ii) accuracy, and (iii) robustness. To this end, through systematic experiments we find a recipe of quantization technique that could run even a $6$B model in a regular laptop without significant accuracy or robustness degradation. We further found the recipe is readily <span class="search-hit mathjax">applicable</span> to <span class="search-hit mathjax">code</span> summarization task as well.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2303.05378v1-abstract-full').style.display = 'none'; document.getElementById('2303.05378v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 9 March, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2023.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">10 pages, 7 figures, 10 tables</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2207.13695">arXiv:2207.13695</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2207.13695">pdf</a>, <a href="https://arxiv.org/format/2207.13695">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computational Engineering, Finance, and Science">cs.CE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Mathematical Software">cs.MS</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Fluid Dynamics">physics.flu-dyn</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1007/s00158-022-03420-9">10.1007/s00158-022-03420-9 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A detailed introduction to density-based topology <span class="search-hit mathjax">optimisation</span> of fluid flow problems with implementation in MATLAB
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Alexandersen%2C+J">Joe Alexandersen</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2207.13695v1-abstract-short" style="display: inline;">
        This article presents a detailed introduction to density-based topology <span class="search-hit mathjax">optimisation</span> of fluid flow problems. The goal is to allow new students and researchers to quickly get started in the research area and to skip many of the initial steps, often consuming unnecessarily long time from the scientific advancement of the field. This is achieved by providing a&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2207.13695v1-abstract-full').style.display = 'inline'; document.getElementById('2207.13695v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2207.13695v1-abstract-full" style="display: none;">
        This article presents a detailed introduction to density-based topology <span class="search-hit mathjax">optimisation</span> of fluid flow problems. The goal is to allow new students and researchers to quickly get started in the research area and to skip many of the initial steps, often consuming unnecessarily long time from the scientific advancement of the field. This is achieved by providing a step-by-step guide to the components necessary to understand and implement the theory, as well as extending the supplied MATLAB <span class="search-hit mathjax">code</span>. The continuous design representation used and how it is connected to the Brinkman penalty approach, for simulating an immersed solid in a fluid domain, is illustrated. The different interpretations of the Brinkman penalty term and how to chose the penalty <span class="search-hit mathjax">parameters</span> are explained. The accuracy of the Brinkman penalty approach is analysed through parametric simulations of a reference geometry. The chosen finite element formulation and the solution method is explained. The minimum dissipated energy <span class="search-hit mathjax">optimisation</span> problem is defined and how to solve it using an optimality criteria solver and a continuation scheme is discussed. The included MATLAB implementation is documented, with details on the mesh, pre-processing, <span class="search-hit mathjax">optimisation</span> and post-processing. The <span class="search-hit mathjax">code</span> has two benchmark examples implemented and the <span class="search-hit mathjax">application</span> of the <span class="search-hit mathjax">code</span> to these is reviewed. Subsequently, several modifications to the <span class="search-hit mathjax">code</span> for more complicated examples are presented through provided <span class="search-hit mathjax">code</span> modifications and explanations. Lastly, the computational performance of the <span class="search-hit mathjax">code</span> is examined through studies of the computational time and <span class="search-hit mathjax">memory</span> usage, along with recommendations to decrease computational time through approximations.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2207.13695v1-abstract-full').style.display = 'none'; document.getElementById('2207.13695v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 19 July, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2022.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">39 pages, 28 figures</span>
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        Published in &#34;Structural and Multidisciplinary Optimization&#34; (2023)
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2206.03611">arXiv:2206.03611</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2206.03611">pdf</a>, <a href="https://arxiv.org/format/2206.03611">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Methodology">stat.ME</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        FedPop: A Bayesian Approach for Personalised Federated Learning
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Kotelevskii%2C+N">Nikita Kotelevskii</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Vono%2C+M">Maxime Vono</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moulines%2C+E">Eric Moulines</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Durmus%2C+A">Alain Durmus</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2206.03611v2-abstract-short" style="display: inline;">
        &hellip;client. Albeit promising advances have been made in this direction, most of existing approaches works do not allow for uncertainty quantification which is crucial in many <span class="search-hit mathjax">applications</span>. In addition, personalisation in the cross-device setting still involves important issues, especially for new clients or those having small number of observations. This paper a&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2206.03611v2-abstract-full').style.display = 'inline'; document.getElementById('2206.03611v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2206.03611v2-abstract-full" style="display: none;">
        Personalised federated learning (FL) aims at collaboratively learning a machine learning model taylored for each client. Albeit promising advances have been made in this direction, most of existing approaches works do not allow for uncertainty quantification which is crucial in many <span class="search-hit mathjax">applications</span>. In addition, personalisation in the cross-device setting still involves important issues, especially for new clients or those having small number of observations. This paper aims at filling these gaps. To this end, we propose a novel methodology coined FedPop by recasting personalised FL into the population modeling paradigm where clients&#39; models involve fixed common population <span class="search-hit mathjax">parameters</span> and random effects, aiming at explaining data heterogeneity. To derive convergence guarantees for our scheme, we introduce a new class of federated stochastic <span class="search-hit mathjax">optimisation</span> algorithms which relies on Markov chain Monte Carlo methods. Compared to existing personalised FL methods, the proposed methodology has important benefits: it is robust to client drift, practical for inference on new clients, and above all, enables uncertainty quantification under mild computational and <span class="search-hit mathjax">memory</span> overheads. We provide non-asymptotic convergence guarantees for the proposed algorithms and illustrate their performances on various personalised federated learning tasks.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2206.03611v2-abstract-full').style.display = 'none'; document.getElementById('2206.03611v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 26 January, 2023; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 7 June, 2022;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2022.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2203.11423">arXiv:2203.11423</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2203.11423">pdf</a>, <a href="https://arxiv.org/format/2203.11423">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Performance">cs.PF</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1145/3534879.3534888">10.1145/3534879.3534888 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        RT-Bench: an Extensible Benchmark Framework for the Analysis and Management of Real-Time <span class="search-hit mathjax">Applications</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Nicolella%2C+M">Mattia Nicolella</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Roozkhosh%2C+S">Shahin Roozkhosh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hoornaert%2C+D">Denis Hoornaert</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bastoni%2C+A">Andrea Bastoni</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mancuso%2C+R">Renato Mancuso</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2203.11423v2-abstract-short" style="display: inline;">
        Benchmarking is crucial for testing and validating any system, even more so in real-time systems. Typical real-time <span class="search-hit mathjax">applications</span> adhere to well-understood abstractions: they exhibit a periodic behavior, operate on a well-defined working set, and strive for stable response time avoiding non-predicable factors such as page faults. Unfortunately, available benc&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2203.11423v2-abstract-full').style.display = 'inline'; document.getElementById('2203.11423v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2203.11423v2-abstract-full" style="display: none;">
        Benchmarking is crucial for testing and validating any system, even more so in real-time systems. Typical real-time <span class="search-hit mathjax">applications</span> adhere to well-understood abstractions: they exhibit a periodic behavior, operate on a well-defined working set, and strive for stable response time avoiding non-predicable factors such as page faults. Unfortunately, available benchmark suites fail to reflect key characteristics of real-time <span class="search-hit mathjax">applications</span>. Practitioners and researchers must resort to either benchmark heavily approximated real-time environments, or to re-engineer available benchmarks to add -- if possible -- the sought-after features. Additionally, the measuring and logging capabilities provided by most benchmark suites are not tailored &#34;out-of-the-box&#34; to real-time environments, and changing basic <span class="search-hit mathjax">parameters</span> such as the scheduling policy often becomes a tiring and error-prone exercise.
  In this paper, we present RT-bench, an open-source framework adding standard real-time features to virtually any existing benchmark. Furthermore, RT-bench provides an easy-to-use, unified command line interface to customize key aspects of the real-time execution of a set of benchmarks. Our framework is guided by four main criteria: 1) cohesive interface, 2) support for periodic <span class="search-hit mathjax">application</span> behavior and deadline semantics, 3) controllable <span class="search-hit mathjax">memory</span> footprint, and 4) extensibility and portability. We have integrated within the framework <span class="search-hit mathjax">applications</span> from the widely used SD-VBS and IsolBench suites. We showcase a set of use-cases that are representative of typical real-time system evaluation scenarios and that can be easily conducted via RT-Bench.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2203.11423v2-abstract-full').style.display = 'none'; document.getElementById('2203.11423v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 July, 2022; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 21 March, 2022;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2022.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">11 pages, 12 figures; <span class="search-hit mathjax">code</span> available at https://gitlab.com/rt-bench/rt-bench, documentation available at https://rt-bench.gitlab.io/rt-bench/</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          C.3; A.2
        
      </p>
    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        RTNS 2022: Proceedings of the 30th International Conference on Real-Time Networks and Systems June 2022 Pages 184-195
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2202.10776">arXiv:2202.10776</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2202.10776">pdf</a>, <a href="https://arxiv.org/format/2202.10776">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1007/978-3-030-96648-5_7">10.1007/978-3-030-96648-5_7 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        XtraLibD: Detecting Irrelevant Third-Party libraries in Java and Python <span class="search-hit mathjax">Applications</span>
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Kapur%2C+R">Ritu Kapur</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rao%2C+P+U">Poojith U Rao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dewan%2C+A">Agrim Dewan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sodhi%2C+B">Balwinder Sodhi</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2202.10776v1-abstract-short" style="display: inline;">
        <span class="search-hit mathjax">Software</span> development comprises the use of multiple Third-Party Libraries (TPLs). However, the irrelevant libraries present in&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2202.10776v1-abstract-full').style.display = 'inline'; document.getElementById('2202.10776v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2202.10776v1-abstract-full" style="display: none;">
        <span class="search-hit mathjax">Software</span> development comprises the use of multiple Third-Party Libraries (TPLs). However, the irrelevant libraries present in <span class="search-hit mathjax">software</span> <span class="search-hit mathjax">application&#39;s</span> distributable often lead to excessive consumption of resources such as CPU cycles, <span class="search-hit mathjax">memory</span>, and modile-devices&#39; battery usage. Therefore, the identification and removal of unused TPLs present in an <span class="search-hit mathjax">application</span> are desirable. We present a rapid, storage-efficient, obfuscation-resilient method to detect the irrelevant-TPLs in Java and Python <span class="search-hit mathjax">applications</span>. Our approach&#39;s novel aspects are i) Computing a vector representation of a .class file using a model that we call Lib2Vec. The Lib2Vec model is trained using the Paragraph Vector Algorithm. ii) Before using it for training the Lib2Vec models, a .class file is converted to a normalized form via semantics-preserving transformations. iii) A eXtra Library Detector (XtraLibD) developed and tested with 27 different language-specific Lib2Vec models. These models were trained using different <span class="search-hit mathjax">parameters</span> and &gt;30,000 .class and &gt;478,000 .py files taken from &gt;100 different Java libraries and 43,711 Python available at MavenCentral.com and Pypi.com, respectively. XtraLibD achieves an accuracy of 99.48% with an F1 score of 0.968 and outperforms the existing tools, viz., LibScout, LiteRadar, and LibD with an accuracy <span class="search-hit mathjax">improvement</span> of 74.5%, 30.33%, and 14.1%, respectively. Compared with LibD, XtraLibD achieves a response time <span class="search-hit mathjax">improvement</span> of 61.37% and a storage reduction of 87.93% (99.85% over JIngredient). Our <span class="search-hit mathjax">program</span> artifacts are available at https://www.doi.org/10.5281/zenodo.5179747.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2202.10776v1-abstract-full').style.display = 'none'; document.getElementById('2202.10776v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 February, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2022.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">25 pages, 5 figures, 4 tables, Book Chapter of Springer's Communications in Computer and Information Science, vol 1556. Springer, Cham. Extended version of paper published in Evaluation of Novel Approaches to <span class="search-hit mathjax">Software</span> Engineering. ENASE 2021</span>
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
         version of paper published in Evaluation of Novel Approaches to <span class="search-hit mathjax">Software</span> Engineering. ENASE 2021
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2201.08049">arXiv:2201.08049</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2201.08049">pdf</a>, <a href="https://arxiv.org/format/2201.08049">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1109/TGRS.2022.3145483">10.1109/TGRS.2022.3145483 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Lightweight Salient Object Detection in Optical Remote Sensing Images via Feature Correlation
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+G">Gongyang Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+Z">Zhi Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bai%2C+Z">Zhen Bai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lin%2C+W">Weisi Lin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ling%2C+a+H">and Haibin Ling</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2201.08049v1-abstract-short" style="display: inline;">
        Salient object detection in optical remote sensing images (ORSI-SOD) has been widely explored for understanding ORSIs. However, previous methods focus mainly on <span class="search-hit mathjax">improving</span> the detection accuracy while neglecting the cost in&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2201.08049v1-abstract-full').style.display = 'inline'; document.getElementById('2201.08049v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2201.08049v1-abstract-full" style="display: none;">
        Salient object detection in optical remote sensing images (ORSI-SOD) has been widely explored for understanding ORSIs. However, previous methods focus mainly on <span class="search-hit mathjax">improving</span> the detection accuracy while neglecting the cost in <span class="search-hit mathjax">memory</span> and computation, which may hinder their real-world <span class="search-hit mathjax">applications</span>. In this paper, we propose a novel lightweight ORSI-SOD solution, named CorrNet, to address these issues. In CorrNet, we first lighten the backbone (VGG-16) and build a lightweight subnet for feature extraction. Then, following the coarse-to-fine strategy, we generate an initial coarse saliency map from high-level semantic features in a Correlation Module (CorrM). The coarse saliency map serves as the location guidance for low-level features. In CorrM, we mine the object location information between high-level semantic features through the cross-layer correlation operation. Finally, based on low-level detailed features, we refine the coarse saliency map in the refinement subnet equipped with Dense Lightweight Refinement Blocks, and produce the final fine saliency map. By reducing the <span class="search-hit mathjax">parameters</span> and computations of each component, CorrNet ends up having only 4.09M <span class="search-hit mathjax">parameters</span> and running with 21.09G FLOPs. Experimental results on two public datasets demonstrate that our lightweight CorrNet achieves competitive or even better performance compared with 26 state-of-the-art methods (including 16 large CNN-based methods and 2 lightweight methods), and meanwhile enjoys the clear <span class="search-hit mathjax">memory</span> and run time efficiency. The <span class="search-hit mathjax">code</span> and results of our method are available at https://github.com/MathLee/CorrNet.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2201.08049v1-abstract-full').style.display = 'none'; document.getElementById('2201.08049v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 20 January, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2022.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">11 pages, 6 figures, Accepted by IEEE Transactions on Geoscience and Remote Sensing 2022</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2110.13264">arXiv:2110.13264</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2110.13264">pdf</a>, <a href="https://arxiv.org/format/2110.13264">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        <span class="search-hit mathjax">Memory</span> visualization tool for training neural network
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=N%2C+M">Mahendran N</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2110.13264v1-abstract-short" style="display: inline;">
        <span class="search-hit mathjax">Software</span> developed helps world a better place ranging from system&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2110.13264v1-abstract-full').style.display = 'inline'; document.getElementById('2110.13264v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2110.13264v1-abstract-full" style="display: none;">
        <span class="search-hit mathjax">Software</span> developed helps world a better place ranging from system <span class="search-hit mathjax">software</span>, open source, <span class="search-hit mathjax">application</span> <span class="search-hit mathjax">software</span> and so on. <span class="search-hit mathjax">Software</span> engineering does have neural network models applied to <span class="search-hit mathjax">code</span> suggestion, bug report summarizing and so on to demonstrate their effectiveness at a real SE task. <span class="search-hit mathjax">Software</span> and machine learning algorithms combine to make <span class="search-hit mathjax">software</span> give better solutions and understanding of environment. In <span class="search-hit mathjax">software</span>, there are both generalized <span class="search-hit mathjax">applications</span> which helps solve problems for entire world and also some specific <span class="search-hit mathjax">applications</span> which helps one particular community. To address the computational challenge in deep learning, many tools exploit hardware features such as multi-core CPUs and many-core GPUs to shorten the training time. Machine learning algorithms have a greater impact in the world but there is a considerable amount of <span class="search-hit mathjax">memory</span> utilization during the process. We propose a new tool for analysis of <span class="search-hit mathjax">memory</span> utilized for developing and training deep learning models. Our tool results in visual utilization of <span class="search-hit mathjax">memory</span> concurrently. Various <span class="search-hit mathjax">parameters</span> affecting the <span class="search-hit mathjax">memory</span> utilization are analysed while training. This tool helps in knowing better idea of processes or models which consumes more <span class="search-hit mathjax">memory</span>.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2110.13264v1-abstract-full').style.display = 'none'; document.getElementById('2110.13264v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 25 October, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">5 pages, 3 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2108.11932">arXiv:2108.11932</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2108.11932">pdf</a>, <a href="https://arxiv.org/format/2108.11932">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Mathematical Software">cs.MS</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        H2OPUS-TLR: High Performance Tile Low Rank Symmetric Factorizations using Adaptive Randomized Approximation
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Boukaram%2C+W">Wajih Boukaram</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zampini%2C+S">Stefano Zampini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Turkiyyah%2C+G">George Turkiyyah</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Keyes%2C+D">David Keyes</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2108.11932v1-abstract-short" style="display: inline;">
        &hellip;tile is compressed and stored as its own low rank factorization. They offer an attractive representation for many data-sparse dense operators that appear in practical <span class="search-hit mathjax">applications</span>, where substantial compression and a much smaller&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2108.11932v1-abstract-full').style.display = 'inline'; document.getElementById('2108.11932v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2108.11932v1-abstract-full" style="display: none;">
        Tile low rank representations of dense matrices partition them into blocks of roughly uniform size, where each off-diagonal tile is compressed and stored as its own low rank factorization. They offer an attractive representation for many data-sparse dense operators that appear in practical <span class="search-hit mathjax">applications</span>, where substantial compression and a much smaller <span class="search-hit mathjax">memory</span> footprint can be achieved. TLR matrices are a compromise between the simplicity of a regular perfectly-strided data structure and the optimal complexity of the unbalanced trees of hierarchically low rank matrices, and provide a convenient performance-<span class="search-hit mathjax">tuning</span> <span class="search-hit mathjax">parameter</span> through their tile size that can be proportioned to take into account the cache size where the tiles reside in the <span class="search-hit mathjax">memory</span> hierarchy.
  There are currently no high-performance algorithms that can generate Cholesky and $LDL^T$ factorizations, particularly on GPUs. The difficulties in achieving high performance when factoring TLR matrices come from the expensive compression operations that must be performed during the factorization process and the adaptive rank distribution of the tiles that causes an irregular work pattern for the processing cores. In this work, we develop a dynamic batching operation and combine it with batched adaptive randomized approximations to achieve high performance both on GPUs and CPUs.
  Our implementation attains over 1.2 TFLOP/s in double precision on the V100 GPU, and is limited by the performance of batched GEMM operations. The Cholesky factorization of covariance matrix of size $N = 131K$ arising in spatial statistics can be factored to an accuracy $ε=10^{-2}$ in just a few seconds. We believe the proposed GEMM-centric algorithm allows it to be readily ported to newer hardware such as the tensor cores that are optimized for small GEMM operations.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2108.11932v1-abstract-full').style.display = 'none'; document.getElementById('2108.11932v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 26 August, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2021.
      
    </p>
    

    
      <p class="comments is-size-7">
        

        
          <span class="has-text-black-bis has-text-weight-semibold">MSC Class:</span>
          65F05; 65F08; 65F55
        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          G.4
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.10710">arXiv:2103.10710</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.10710">pdf</a>, <a href="https://arxiv.org/format/2103.10710">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Sparse Algorithms for Markovian Gaussian Processes
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Wilkinson%2C+W+J">William J. Wilkinson</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Solin%2C+A">Arno Solin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Adam%2C+V">Vincent Adam</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.10710v3-abstract-short" style="display: inline;">
        &hellip;series. Sparse Markovian Gaussian processes combine the use of inducing variables with efficient Kalman filter-like recursions, resulting in algorithms whose computational and <span class="search-hit mathjax">memory</span> requirements scale linearly in the number of inducing points, whilst also enabling parallel&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.10710v3-abstract-full').style.display = 'inline'; document.getElementById('2103.10710v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.10710v3-abstract-full" style="display: none;">
        Approximate Bayesian inference methods that scale to very large datasets are crucial in leveraging probabilistic models for real-world time series. Sparse Markovian Gaussian processes combine the use of inducing variables with efficient Kalman filter-like recursions, resulting in algorithms whose computational and <span class="search-hit mathjax">memory</span> requirements scale linearly in the number of inducing points, whilst also enabling parallel <span class="search-hit mathjax">parameter</span> updates and stochastic <span class="search-hit mathjax">optimisation</span>. Under this paradigm, we derive a general site-based approach to approximate inference, whereby we approximate the non-Gaussian likelihood with local Gaussian terms, called sites. Our approach results in a suite of novel sparse extensions to algorithms from both the machine learning and signal processing literature, including variational inference, expectation propagation, and the classical nonlinear Kalman smoothers. The derived methods are suited to large time series, and we also demonstrate their <span class="search-hit mathjax">applicability</span> to spatio-temporal data, where the model has separate inducing points in both time and space.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.10710v3-abstract-full').style.display = 'none'; document.getElementById('2103.10710v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 9 June, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 19 March, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Appearing in the 24th International Conference on Artificial Intelligence and Statistics (AISTATS) 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.07554">arXiv:2103.07554</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.07554">pdf</a>, <a href="https://arxiv.org/format/2103.07554">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Sound">cs.SD</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Audio and Speech Processing">eess.AS</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A Distributed <span class="search-hit mathjax">Optimisation</span> Framework Combining Natural Gradient with Hessian-Free for Discriminative Sequence Training
      
    </p>
    <p class="authors">
      <span class="has-text-black-bis has-text-weight-semibold">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Haider%2C+A">Adnan Haider</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+C">Chao Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kreyssig%2C+F+L">Florian L. Kreyssig</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Woodland%2C+P+C">Philip C. Woodland</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="search-hit">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.07554v1-abstract-short" style="display: inline;">
        This paper presents a novel natural gradient and Hessian-free (NGHF) <span class="search-hit mathjax">optimisation</span> framework for neural network training that can operate efficiently in a distributed manner. It relies on the linear conjugate gradient (CG) algorithm to combine the natural gradient (NG) method with local curvature information from Hessian-free (HF) or other second-order method&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.07554v1-abstract-full').style.display = 'inline'; document.getElementById('2103.07554v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.07554v1-abstract-full" style="display: none;">
        This paper presents a novel natural gradient and Hessian-free (NGHF) <span class="search-hit mathjax">optimisation</span> framework for neural network training that can operate efficiently in a distributed manner. It relies on the linear conjugate gradient (CG) algorithm to combine the natural gradient (NG) method with local curvature information from Hessian-free (HF) or other second-order methods. A solution to a numerical issue in CG allows effective <span class="search-hit mathjax">parameter</span> updates to be generated with far fewer CG iterations than usually used (e.g. 5-8 instead of 200). This work also presents a novel preconditioning approach to <span class="search-hit mathjax">improve</span> the progress made by individual CG iterations for models with shared <span class="search-hit mathjax">parameters</span>. Although <span class="search-hit mathjax">applicable</span> to other training losses and model structures, NGHF is investigated in this paper for lattice-based discriminative sequence training for hybrid hidden Markov model acoustic models using a standard recurrent neural network, long short-term <span class="search-hit mathjax">memory</span>, and time delay neural network models for output probability calculation. Automatic speech recognition experiments are reported on the multi-genre broadcast data set for a range of different acoustic model types. These experiments show that NGHF achieves larger word error rate reductions than standard stochastic gradient descent or Adam, while requiring orders of magnitude fewer <span class="search-hit mathjax">parameter</span> updates.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.07554v1-abstract-full').style.display = 'none'; document.getElementById('2103.07554v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 12 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    

    

    
  </li>

</ol>


    
  

      <div class="is-hidden-tablet">
        <!-- feedback for mobile only -->
        <span class="help" style="display: inline-block;"><a href="https://github.com/arXiv/arxiv-search/releases">Search v0.5.6 released 2020-02-24</a>&nbsp;&nbsp;</span>
      </div>
    </div>

  </main>
  <footer>
    
    <div class="columns is-desktop" role="navigation" aria-label="Secondary">
  <!-- MetaColumn 1 -->
  <div class="column">
    <div class="columns">
      <div class="column">
        <ul class="nav-spaced">
          <li><a href="https://arxiv.org/about">About</a></li>
          <li><a href="https://arxiv.org/help">Help</a></li>
        </ul>
      </div>
      <div class="column">
        <ul class="nav-spaced">
          <li>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
            <a href="https://arxiv.org/help/contact"> Contact</a>
          </li>
          <li>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
            <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
          </li>
        </ul>
      </div>
    </div>
  </div> <!-- end MetaColumn 1 -->
  <!-- MetaColumn 2 -->
  <div class="column">
    <div class="columns">
      <div class="column">
        <ul class="nav-spaced">
          <li><a href="https://arxiv.org/help/license">Copyright</a></li>
          <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
        </ul>
      </div>
      <div class="column sorry-app-links">
        <ul class="nav-spaced">
          <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
          <li>
            <p class="help">
              <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
              Get status notifications via
              <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
              or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
            </p>
          </li>
        </ul>
      </div>
    </div>
  </div> <!-- end MetaColumn 2 -->
</div>
    
  </footer>
  </body>
</html>
